Model: Qwen/Qwen2-0.5B-Instruct, Batch size: 16, Epochs: 200
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
Layer: backbone.model.embed_tokens.weight, Size: torch.Size([151936, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.norm.weight, Size: torch.Size([896]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 896]), req grad: True
Epoch 1/200
Train Loss: 1.5348, Accuracy: 0.4930, Precision: 0.4024, Recall: 0.3835, F1: 0.3842
Validation Loss: 0.9284, Accuracy: 0.6823, Precision: 0.5318, Recall: 0.5517, F1: 0.5347
Testing Loss: 0.9166, Accuracy: 0.6896, Precision: 0.5464, Recall: 0.5717, F1: 0.5548
LM Predictions:  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 4, 3, 0, 0, 0, 0, 1, 4, 0, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7159, Accuracy: 0.3571, Precision: 0.6878, Recall: 0.4217, F1: 0.3818
Epoch 2/200
Train Loss: 0.5464, Accuracy: 0.8214, Precision: 0.7599, Recall: 0.7287, F1: 0.7401
Validation Loss: 0.8953, Accuracy: 0.7228, Precision: 0.6589, Recall: 0.6184, F1: 0.6244
Testing Loss: 0.9117, Accuracy: 0.7138, Precision: 0.6863, Recall: 0.6416, F1: 0.6510
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 3, 3, 0, 2, 0, 3, 3, 2, 4, 0, 2, 0, 0, 3, 3, 0, 2, 0, 4, 2, 5, 4, 3, 3, 2, 5, 0, 2, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2893, Accuracy: 0.6667, Precision: 0.6418, Recall: 0.5574, F1: 0.5610
Epoch 3/200
Train Loss: 0.2496, Accuracy: 0.9270, Precision: 0.8890, Recall: 0.8806, F1: 0.8845
Validation Loss: 1.0878, Accuracy: 0.7399, Precision: 0.7388, Recall: 0.6481, F1: 0.6654
Testing Loss: 1.0465, Accuracy: 0.7271, Precision: 0.6975, Recall: 0.6410, F1: 0.6537
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 5, 5, 0, 5, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0379, Accuracy: 0.7619, Precision: 0.7361, Recall: 0.6593, F1: 0.6583
Epoch 4/200
Train Loss: 0.1848, Accuracy: 0.9457, Precision: 0.9186, Recall: 0.9120, F1: 0.9152
Validation Loss: 1.2390, Accuracy: 0.7335, Precision: 0.6824, Recall: 0.6423, F1: 0.6528
Testing Loss: 1.1569, Accuracy: 0.7403, Precision: 0.6972, Recall: 0.6553, F1: 0.6636
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 5, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7678, Accuracy: 0.7381, Precision: 0.7222, Recall: 0.6426, F1: 0.6313
Epoch 5/200
Train Loss: 0.1205, Accuracy: 0.9576, Precision: 0.9317, Recall: 0.9329, F1: 0.9323
Validation Loss: 1.3046, Accuracy: 0.7292, Precision: 0.6691, Recall: 0.6412, F1: 0.6397
Testing Loss: 1.2717, Accuracy: 0.7210, Precision: 0.6739, Recall: 0.6539, F1: 0.6528
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 5, 3, 0, 4, 3, 1, 5, 2, 5, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4498, Accuracy: 0.8095, Precision: 0.7500, Recall: 0.6944, F1: 0.6965
Epoch 6/200
Train Loss: 0.0996, Accuracy: 0.9635, Precision: 0.9416, Recall: 0.9403, F1: 0.9409
Validation Loss: 1.7788, Accuracy: 0.7079, Precision: 0.6275, Recall: 0.5598, F1: 0.5684
Testing Loss: 1.6254, Accuracy: 0.7271, Precision: 0.6761, Recall: 0.5978, F1: 0.6114
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 0, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0410, Accuracy: 0.6667, Precision: 0.8526, Recall: 0.7061, F1: 0.6962
Epoch 7/200
Train Loss: 0.1092, Accuracy: 0.9559, Precision: 0.9314, Recall: 0.9321, F1: 0.9317
Validation Loss: 1.4020, Accuracy: 0.7143, Precision: 0.6343, Recall: 0.6353, F1: 0.6277
Testing Loss: 1.4913, Accuracy: 0.7258, Precision: 0.6608, Recall: 0.6564, F1: 0.6514
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 3, 3, 2, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5122, Accuracy: 0.7857, Precision: 0.8547, Recall: 0.8133, F1: 0.7871
Epoch 8/200
Train Loss: 0.1696, Accuracy: 0.9391, Precision: 0.9125, Recall: 0.9096, F1: 0.9110
Validation Loss: 1.2741, Accuracy: 0.7591, Precision: 0.6865, Recall: 0.6828, F1: 0.6800
Testing Loss: 1.2977, Accuracy: 0.7258, Precision: 0.6683, Recall: 0.6584, F1: 0.6532
LM Predictions:  [0, 5, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 4, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 4, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5771, Accuracy: 0.8095, Precision: 0.7222, Recall: 0.6824, F1: 0.6659
Epoch 9/200
Train Loss: 0.1804, Accuracy: 0.9388, Precision: 0.9170, Recall: 0.9133, F1: 0.9151
Validation Loss: 1.0885, Accuracy: 0.7569, Precision: 0.7322, Recall: 0.6786, F1: 0.6865
Testing Loss: 1.0089, Accuracy: 0.7367, Precision: 0.6950, Recall: 0.6637, F1: 0.6695
LM Predictions:  [0, 1, 0, 0, 1, 1, 0, 3, 4, 0, 0, 0, 2, 5, 3, 5, 2, 4, 5, 3, 0, 5, 3, 1, 5, 2, 5, 4, 2, 0, 4, 3, 3, 5, 0, 0, 5, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1912, Accuracy: 0.6429, Precision: 0.7186, Recall: 0.5676, F1: 0.5948
Epoch 10/200
Train Loss: 0.1098, Accuracy: 0.9587, Precision: 0.9381, Recall: 0.9345, F1: 0.9363
Validation Loss: 1.3393, Accuracy: 0.7761, Precision: 0.7086, Recall: 0.6820, F1: 0.6899
Testing Loss: 1.2674, Accuracy: 0.7524, Precision: 0.6878, Recall: 0.6712, F1: 0.6753
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 5, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3944, Accuracy: 0.8571, Precision: 0.7500, Recall: 0.7315, F1: 0.7175
Epoch 11/200
Train Loss: 0.0870, Accuracy: 0.9611, Precision: 0.9380, Recall: 0.9368, F1: 0.9374
Validation Loss: 1.3677, Accuracy: 0.7420, Precision: 0.7060, Recall: 0.6426, F1: 0.6537
Testing Loss: 1.3018, Accuracy: 0.7403, Precision: 0.7092, Recall: 0.6726, F1: 0.6757
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 5, 2, 4, 0, 3, 0, 4, 5, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9795, Accuracy: 0.7143, Precision: 0.7222, Recall: 0.6218, F1: 0.6172
Epoch 12/200
Train Loss: 0.0803, Accuracy: 0.9637, Precision: 0.9424, Recall: 0.9415, F1: 0.9420
Validation Loss: 1.7834, Accuracy: 0.7399, Precision: 0.6764, Recall: 0.6264, F1: 0.6391
Testing Loss: 1.5973, Accuracy: 0.7464, Precision: 0.7201, Recall: 0.6409, F1: 0.6588
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4399, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7928, F1: 0.7749
Epoch 13/200
Train Loss: 0.0808, Accuracy: 0.9642, Precision: 0.9420, Recall: 0.9420, F1: 0.9420
Validation Loss: 1.6951, Accuracy: 0.7335, Precision: 0.7030, Recall: 0.6025, F1: 0.6216
Testing Loss: 1.4108, Accuracy: 0.7524, Precision: 0.7298, Recall: 0.6546, F1: 0.6774
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3617, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7928, F1: 0.7749
Epoch 14/200
Train Loss: 0.0721, Accuracy: 0.9635, Precision: 0.9417, Recall: 0.9426, F1: 0.9422
Validation Loss: 1.5609, Accuracy: 0.7548, Precision: 0.7123, Recall: 0.6540, F1: 0.6706
Testing Loss: 1.4510, Accuracy: 0.7512, Precision: 0.6769, Recall: 0.6553, F1: 0.6554
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4032, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 15/200
Train Loss: 0.0679, Accuracy: 0.9673, Precision: 0.9494, Recall: 0.9459, F1: 0.9476
Validation Loss: 1.7201, Accuracy: 0.7505, Precision: 0.7063, Recall: 0.6432, F1: 0.6625
Testing Loss: 1.4947, Accuracy: 0.7536, Precision: 0.7093, Recall: 0.6601, F1: 0.6699
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4186, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 16/200
Train Loss: 0.0724, Accuracy: 0.9649, Precision: 0.9451, Recall: 0.9439, F1: 0.9445
Validation Loss: 1.4402, Accuracy: 0.7633, Precision: 0.7289, Recall: 0.6490, F1: 0.6714
Testing Loss: 1.2767, Accuracy: 0.7645, Precision: 0.7172, Recall: 0.6615, F1: 0.6795
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 1, 0, 2, 4, 3, 1, 2, 4, 1, 3, 1, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2695, Accuracy: 0.9048, Precision: 0.9385, Recall: 0.9200, F1: 0.9136
Epoch 17/200
Train Loss: 0.1298, Accuracy: 0.9474, Precision: 0.9250, Recall: 0.9223, F1: 0.9236
Validation Loss: 1.2871, Accuracy: 0.7569, Precision: 0.6824, Recall: 0.6648, F1: 0.6618
Testing Loss: 1.2174, Accuracy: 0.7754, Precision: 0.6995, Recall: 0.6731, F1: 0.6586
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 0, 3, 2, 4, 3, 0, 3, 4, 3, 1, 2, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3187, Accuracy: 0.9286, Precision: 0.9206, Recall: 0.9378, F1: 0.9209
Epoch 18/200
Train Loss: 0.0950, Accuracy: 0.9592, Precision: 0.9375, Recall: 0.9371, F1: 0.9373
Validation Loss: 1.8175, Accuracy: 0.7591, Precision: 0.7088, Recall: 0.6638, F1: 0.6772
Testing Loss: 1.5439, Accuracy: 0.7790, Precision: 0.7127, Recall: 0.6724, F1: 0.6745
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2189, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9150, F1: 0.8942
Epoch 19/200
Train Loss: 0.0821, Accuracy: 0.9635, Precision: 0.9426, Recall: 0.9380, F1: 0.9403
Validation Loss: 1.6404, Accuracy: 0.7569, Precision: 0.6989, Recall: 0.6544, F1: 0.6689
Testing Loss: 1.4579, Accuracy: 0.7742, Precision: 0.7019, Recall: 0.6733, F1: 0.6798
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4851, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7461, F1: 0.7351
Epoch 20/200
Train Loss: 0.0638, Accuracy: 0.9692, Precision: 0.9500, Recall: 0.9506, F1: 0.9503
Validation Loss: 1.6929, Accuracy: 0.7655, Precision: 0.6855, Recall: 0.6805, F1: 0.6779
Testing Loss: 1.6276, Accuracy: 0.7657, Precision: 0.6819, Recall: 0.6831, F1: 0.6745
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2483, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8800, F1: 0.8528
Epoch 21/200
Train Loss: 0.0696, Accuracy: 0.9663, Precision: 0.9428, Recall: 0.9484, F1: 0.9455
Validation Loss: 1.6001, Accuracy: 0.7676, Precision: 0.7271, Recall: 0.6737, F1: 0.6927
Testing Loss: 1.4968, Accuracy: 0.7802, Precision: 0.7142, Recall: 0.6929, F1: 0.7005
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1877, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 22/200
Train Loss: 0.0632, Accuracy: 0.9661, Precision: 0.9428, Recall: 0.9465, F1: 0.9446
Validation Loss: 1.2950, Accuracy: 0.7655, Precision: 0.7057, Recall: 0.6818, F1: 0.6893
Testing Loss: 1.2164, Accuracy: 0.7802, Precision: 0.7116, Recall: 0.7051, F1: 0.7066
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2300, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8750, F1: 0.8511
Epoch 23/200
Train Loss: 0.0520, Accuracy: 0.9692, Precision: 0.9489, Recall: 0.9464, F1: 0.9476
Validation Loss: 1.6294, Accuracy: 0.7591, Precision: 0.6743, Recall: 0.6840, F1: 0.6746
Testing Loss: 1.5903, Accuracy: 0.7814, Precision: 0.6980, Recall: 0.7020, F1: 0.6955
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2551, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9083, F1: 0.8895
Epoch 24/200
Train Loss: 0.0580, Accuracy: 0.9682, Precision: 0.9483, Recall: 0.9493, F1: 0.9488
Validation Loss: 1.5370, Accuracy: 0.7676, Precision: 0.6923, Recall: 0.6889, F1: 0.6879
Testing Loss: 1.4512, Accuracy: 0.7850, Precision: 0.7091, Recall: 0.7132, F1: 0.7095
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2246, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9150, F1: 0.8942
Epoch 25/200
Train Loss: 0.0551, Accuracy: 0.9694, Precision: 0.9520, Recall: 0.9518, F1: 0.9519
Validation Loss: 1.6425, Accuracy: 0.7612, Precision: 0.6905, Recall: 0.6872, F1: 0.6861
Testing Loss: 1.5450, Accuracy: 0.7814, Precision: 0.6996, Recall: 0.7005, F1: 0.6950
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1595, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 26/200
Train Loss: 0.0604, Accuracy: 0.9666, Precision: 0.9458, Recall: 0.9510, F1: 0.9483
Validation Loss: 1.4270, Accuracy: 0.7697, Precision: 0.7024, Recall: 0.6966, F1: 0.6955
Testing Loss: 1.3273, Accuracy: 0.7826, Precision: 0.7065, Recall: 0.6986, F1: 0.6986
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1659, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 27/200
Train Loss: 0.0532, Accuracy: 0.9706, Precision: 0.9490, Recall: 0.9533, F1: 0.9511
Validation Loss: 1.6674, Accuracy: 0.7761, Precision: 0.7317, Recall: 0.6922, F1: 0.7060
Testing Loss: 1.4774, Accuracy: 0.7826, Precision: 0.7172, Recall: 0.7159, F1: 0.7163
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1435, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 28/200
Train Loss: 0.0574, Accuracy: 0.9687, Precision: 0.9515, Recall: 0.9506, F1: 0.9511
Validation Loss: 1.2191, Accuracy: 0.7719, Precision: 0.7087, Recall: 0.6901, F1: 0.6957
Testing Loss: 1.0991, Accuracy: 0.7742, Precision: 0.6950, Recall: 0.6832, F1: 0.6844
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4882, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7461, F1: 0.7351
Epoch 29/200
Train Loss: 0.1143, Accuracy: 0.9561, Precision: 0.9391, Recall: 0.9332, F1: 0.9361
Validation Loss: 1.1246, Accuracy: 0.7356, Precision: 0.6996, Recall: 0.6911, F1: 0.6826
Testing Loss: 1.2210, Accuracy: 0.7174, Precision: 0.6856, Recall: 0.6741, F1: 0.6688
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 3, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 3, 0, 2, 4, 5, 3, 0, 4, 3, 3, 0, 0, 5, 0, 4, 3, 5, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7580, Accuracy: 0.7143, Precision: 0.6917, Recall: 0.5949, F1: 0.6042
Epoch 30/200
Train Loss: 0.1564, Accuracy: 0.9469, Precision: 0.9220, Recall: 0.9142, F1: 0.9178
Validation Loss: 1.0708, Accuracy: 0.7505, Precision: 0.6872, Recall: 0.6786, F1: 0.6745
Testing Loss: 1.0260, Accuracy: 0.7657, Precision: 0.7070, Recall: 0.6921, F1: 0.6941
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 3, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2686, Accuracy: 0.8810, Precision: 0.8818, Recall: 0.8683, F1: 0.8602
Epoch 31/200
Train Loss: 0.0789, Accuracy: 0.9649, Precision: 0.9456, Recall: 0.9431, F1: 0.9443
Validation Loss: 1.2502, Accuracy: 0.7612, Precision: 0.6902, Recall: 0.7064, F1: 0.6940
Testing Loss: 1.2444, Accuracy: 0.7742, Precision: 0.7123, Recall: 0.7291, F1: 0.7167
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3040, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8261, F1: 0.8053
Epoch 32/200
Train Loss: 0.0677, Accuracy: 0.9687, Precision: 0.9498, Recall: 0.9491, F1: 0.9494
Validation Loss: 1.1736, Accuracy: 0.7740, Precision: 0.7031, Recall: 0.7191, F1: 0.7058
Testing Loss: 1.1714, Accuracy: 0.7778, Precision: 0.7123, Recall: 0.7372, F1: 0.7186
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5108, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 33/200
Train Loss: 0.0541, Accuracy: 0.9685, Precision: 0.9485, Recall: 0.9491, F1: 0.9488
Validation Loss: 1.3729, Accuracy: 0.7719, Precision: 0.6798, Recall: 0.6778, F1: 0.6757
Testing Loss: 1.2994, Accuracy: 0.7959, Precision: 0.7458, Recall: 0.7342, F1: 0.7374
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2545, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 34/200
Train Loss: 0.0516, Accuracy: 0.9696, Precision: 0.9529, Recall: 0.9493, F1: 0.9510
Validation Loss: 1.4078, Accuracy: 0.7825, Precision: 0.6926, Recall: 0.7042, F1: 0.6961
Testing Loss: 1.3530, Accuracy: 0.7886, Precision: 0.7299, Recall: 0.7408, F1: 0.7332
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0907, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 35/200
Train Loss: 0.0517, Accuracy: 0.9687, Precision: 0.9489, Recall: 0.9497, F1: 0.9493
Validation Loss: 1.4150, Accuracy: 0.7846, Precision: 0.6975, Recall: 0.7038, F1: 0.6988
Testing Loss: 1.3858, Accuracy: 0.7874, Precision: 0.7276, Recall: 0.7297, F1: 0.7271
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3431, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 36/200
Train Loss: 0.0486, Accuracy: 0.9704, Precision: 0.9539, Recall: 0.9513, F1: 0.9526
Validation Loss: 1.4197, Accuracy: 0.7889, Precision: 0.7139, Recall: 0.7166, F1: 0.7142
Testing Loss: 1.3836, Accuracy: 0.7935, Precision: 0.7380, Recall: 0.7404, F1: 0.7380
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3378, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 37/200
Train Loss: 0.0523, Accuracy: 0.9651, Precision: 0.9428, Recall: 0.9453, F1: 0.9440
Validation Loss: 1.4131, Accuracy: 0.7804, Precision: 0.6826, Recall: 0.6852, F1: 0.6816
Testing Loss: 1.3922, Accuracy: 0.7935, Precision: 0.7284, Recall: 0.7214, F1: 0.7207
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2946, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 38/200
Train Loss: 0.0542, Accuracy: 0.9682, Precision: 0.9466, Recall: 0.9502, F1: 0.9483
Validation Loss: 1.4386, Accuracy: 0.7868, Precision: 0.7019, Recall: 0.7080, F1: 0.7022
Testing Loss: 1.4643, Accuracy: 0.7862, Precision: 0.7265, Recall: 0.7232, F1: 0.7204
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2656, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 39/200
Train Loss: 0.0521, Accuracy: 0.9699, Precision: 0.9501, Recall: 0.9533, F1: 0.9517
Validation Loss: 1.6056, Accuracy: 0.7761, Precision: 0.6876, Recall: 0.6810, F1: 0.6788
Testing Loss: 1.5621, Accuracy: 0.7911, Precision: 0.7249, Recall: 0.7040, F1: 0.7010
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2973, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 40/200
Train Loss: 0.0491, Accuracy: 0.9706, Precision: 0.9503, Recall: 0.9578, F1: 0.9539
Validation Loss: 1.5132, Accuracy: 0.7804, Precision: 0.6863, Recall: 0.6915, F1: 0.6861
Testing Loss: 1.5305, Accuracy: 0.7838, Precision: 0.7108, Recall: 0.7065, F1: 0.7011
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2800, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 41/200
Train Loss: 0.0486, Accuracy: 0.9704, Precision: 0.9522, Recall: 0.9533, F1: 0.9527
Validation Loss: 1.5812, Accuracy: 0.7804, Precision: 0.7149, Recall: 0.6861, F1: 0.6968
Testing Loss: 1.5498, Accuracy: 0.7911, Precision: 0.7346, Recall: 0.7180, F1: 0.7246
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2891, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 42/200
Train Loss: 0.0516, Accuracy: 0.9699, Precision: 0.9520, Recall: 0.9522, F1: 0.9521
Validation Loss: 1.4694, Accuracy: 0.7783, Precision: 0.6969, Recall: 0.6868, F1: 0.6872
Testing Loss: 1.4203, Accuracy: 0.7778, Precision: 0.6996, Recall: 0.6984, F1: 0.6909
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2880, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8483, F1: 0.8290
Epoch 43/200
Train Loss: 0.0549, Accuracy: 0.9675, Precision: 0.9490, Recall: 0.9437, F1: 0.9462
Validation Loss: 1.5175, Accuracy: 0.7740, Precision: 0.6810, Recall: 0.6671, F1: 0.6697
Testing Loss: 1.4606, Accuracy: 0.7923, Precision: 0.7363, Recall: 0.7178, F1: 0.7218
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2718, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 44/200
Train Loss: 0.0610, Accuracy: 0.9666, Precision: 0.9418, Recall: 0.9483, F1: 0.9450
Validation Loss: 1.7763, Accuracy: 0.7420, Precision: 0.7010, Recall: 0.6327, F1: 0.6205
Testing Loss: 1.7512, Accuracy: 0.7524, Precision: 0.7187, Recall: 0.6597, F1: 0.6517
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 5, 5, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3583, Accuracy: 0.8571, Precision: 0.7593, Recall: 0.7315, F1: 0.7204
Epoch 45/200
Train Loss: 0.1216, Accuracy: 0.9533, Precision: 0.9311, Recall: 0.9267, F1: 0.9288
Validation Loss: 1.4238, Accuracy: 0.7612, Precision: 0.7166, Recall: 0.6582, F1: 0.6776
Testing Loss: 1.2576, Accuracy: 0.7790, Precision: 0.7540, Recall: 0.6861, F1: 0.7103
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 2, 0, 3, 3, 0, 0, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3991, Accuracy: 0.7619, Precision: 0.8492, Recall: 0.7911, F1: 0.7641
Epoch 46/200
Train Loss: 0.0975, Accuracy: 0.9559, Precision: 0.9287, Recall: 0.9363, F1: 0.9324
Validation Loss: 1.3875, Accuracy: 0.7655, Precision: 0.7209, Recall: 0.6813, F1: 0.6883
Testing Loss: 1.1694, Accuracy: 0.7778, Precision: 0.7340, Recall: 0.7151, F1: 0.7185
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 5, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5261, Accuracy: 0.7143, Precision: 0.7188, Recall: 0.6259, F1: 0.6151
Epoch 47/200
Train Loss: 0.0657, Accuracy: 0.9670, Precision: 0.9504, Recall: 0.9500, F1: 0.9502
Validation Loss: 1.2974, Accuracy: 0.7868, Precision: 0.7165, Recall: 0.6856, F1: 0.6934
Testing Loss: 1.2763, Accuracy: 0.7874, Precision: 0.7202, Recall: 0.6962, F1: 0.7028
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3703, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7461, F1: 0.7351
Epoch 48/200
Train Loss: 0.0506, Accuracy: 0.9675, Precision: 0.9469, Recall: 0.9485, F1: 0.9477
Validation Loss: 1.4738, Accuracy: 0.7868, Precision: 0.7471, Recall: 0.7158, F1: 0.7270
Testing Loss: 1.4241, Accuracy: 0.7850, Precision: 0.7317, Recall: 0.7273, F1: 0.7288
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1905, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 49/200
Train Loss: 0.0526, Accuracy: 0.9670, Precision: 0.9464, Recall: 0.9477, F1: 0.9470
Validation Loss: 1.4622, Accuracy: 0.7889, Precision: 0.7277, Recall: 0.6923, F1: 0.7048
Testing Loss: 1.4547, Accuracy: 0.7923, Precision: 0.7324, Recall: 0.7053, F1: 0.7149
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3841, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 50/200
Train Loss: 0.0462, Accuracy: 0.9692, Precision: 0.9521, Recall: 0.9484, F1: 0.9502
Validation Loss: 1.4165, Accuracy: 0.7932, Precision: 0.7527, Recall: 0.7223, F1: 0.7346
Testing Loss: 1.3975, Accuracy: 0.7911, Precision: 0.7368, Recall: 0.7325, F1: 0.7343
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1261, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 51/200
Train Loss: 0.0489, Accuracy: 0.9692, Precision: 0.9519, Recall: 0.9508, F1: 0.9513
Validation Loss: 1.5281, Accuracy: 0.7846, Precision: 0.7297, Recall: 0.6932, F1: 0.7069
Testing Loss: 1.4461, Accuracy: 0.7923, Precision: 0.7444, Recall: 0.7209, F1: 0.7310
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2628, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 52/200
Train Loss: 0.0464, Accuracy: 0.9704, Precision: 0.9532, Recall: 0.9496, F1: 0.9514
Validation Loss: 1.5044, Accuracy: 0.7868, Precision: 0.7335, Recall: 0.7048, F1: 0.7152
Testing Loss: 1.4253, Accuracy: 0.7911, Precision: 0.7478, Recall: 0.7297, F1: 0.7372
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2066, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 53/200
Train Loss: 0.0468, Accuracy: 0.9711, Precision: 0.9499, Recall: 0.9566, F1: 0.9531
Validation Loss: 1.5116, Accuracy: 0.7868, Precision: 0.7259, Recall: 0.6919, F1: 0.7044
Testing Loss: 1.4656, Accuracy: 0.7911, Precision: 0.7329, Recall: 0.7078, F1: 0.7166
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2583, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 54/200
Train Loss: 0.0472, Accuracy: 0.9687, Precision: 0.9507, Recall: 0.9467, F1: 0.9486
Validation Loss: 1.4905, Accuracy: 0.7889, Precision: 0.7252, Recall: 0.7015, F1: 0.7111
Testing Loss: 1.4777, Accuracy: 0.7911, Precision: 0.7372, Recall: 0.7142, F1: 0.7228
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3399, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 55/200
Train Loss: 0.0452, Accuracy: 0.9713, Precision: 0.9526, Recall: 0.9561, F1: 0.9542
Validation Loss: 1.5272, Accuracy: 0.7889, Precision: 0.7325, Recall: 0.7017, F1: 0.7137
Testing Loss: 1.4802, Accuracy: 0.7874, Precision: 0.7273, Recall: 0.7044, F1: 0.7122
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1994, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 56/200
Train Loss: 0.0463, Accuracy: 0.9689, Precision: 0.9501, Recall: 0.9507, F1: 0.9504
Validation Loss: 1.6165, Accuracy: 0.7910, Precision: 0.7451, Recall: 0.7104, F1: 0.7236
Testing Loss: 1.5495, Accuracy: 0.7886, Precision: 0.7489, Recall: 0.7245, F1: 0.7351
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3032, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 57/200
Train Loss: 0.0466, Accuracy: 0.9687, Precision: 0.9489, Recall: 0.9507, F1: 0.9498
Validation Loss: 1.5638, Accuracy: 0.7996, Precision: 0.7438, Recall: 0.7239, F1: 0.7319
Testing Loss: 1.5187, Accuracy: 0.7923, Precision: 0.7451, Recall: 0.7327, F1: 0.7380
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1789, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 58/200
Train Loss: 0.0470, Accuracy: 0.9692, Precision: 0.9493, Recall: 0.9505, F1: 0.9499
Validation Loss: 1.5860, Accuracy: 0.7846, Precision: 0.7362, Recall: 0.6973, F1: 0.7117
Testing Loss: 1.5252, Accuracy: 0.7899, Precision: 0.7462, Recall: 0.7224, F1: 0.7325
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2370, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 59/200
Train Loss: 0.0446, Accuracy: 0.9713, Precision: 0.9493, Recall: 0.9555, F1: 0.9523
Validation Loss: 1.6905, Accuracy: 0.7889, Precision: 0.7403, Recall: 0.6848, F1: 0.7008
Testing Loss: 1.5727, Accuracy: 0.7911, Precision: 0.7320, Recall: 0.6999, F1: 0.7095
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2699, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 60/200
Train Loss: 0.0458, Accuracy: 0.9694, Precision: 0.9509, Recall: 0.9489, F1: 0.9499
Validation Loss: 1.6621, Accuracy: 0.7974, Precision: 0.7489, Recall: 0.7198, F1: 0.7308
Testing Loss: 1.5535, Accuracy: 0.7959, Precision: 0.7425, Recall: 0.7369, F1: 0.7393
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0919, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/200
Train Loss: 0.0474, Accuracy: 0.9689, Precision: 0.9504, Recall: 0.9501, F1: 0.9503
Validation Loss: 1.6768, Accuracy: 0.7953, Precision: 0.7287, Recall: 0.6978, F1: 0.7064
Testing Loss: 1.5758, Accuracy: 0.7911, Precision: 0.7295, Recall: 0.7085, F1: 0.7131
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1907, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 62/200
Train Loss: 0.0476, Accuracy: 0.9689, Precision: 0.9496, Recall: 0.9486, F1: 0.9491
Validation Loss: 1.5400, Accuracy: 0.7804, Precision: 0.7020, Recall: 0.6896, F1: 0.6934
Testing Loss: 1.5051, Accuracy: 0.7923, Precision: 0.7195, Recall: 0.7129, F1: 0.7122
LM Predictions:  [0, 1, 2, 4, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 4, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2649, Accuracy: 0.9048, Precision: 0.9065, Recall: 0.9133, F1: 0.8981
Epoch 63/200
Train Loss: 0.0883, Accuracy: 0.9611, Precision: 0.9429, Recall: 0.9353, F1: 0.9390
Validation Loss: 1.4538, Accuracy: 0.7548, Precision: 0.6616, Recall: 0.6513, F1: 0.6495
Testing Loss: 1.3326, Accuracy: 0.7645, Precision: 0.7040, Recall: 0.6776, F1: 0.6811
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 0, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5364, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7145
Epoch 64/200
Train Loss: 0.0914, Accuracy: 0.9592, Precision: 0.9355, Recall: 0.9346, F1: 0.9350
Validation Loss: 1.0053, Accuracy: 0.7697, Precision: 0.6660, Recall: 0.6713, F1: 0.6659
Testing Loss: 0.9964, Accuracy: 0.7850, Precision: 0.7002, Recall: 0.7015, F1: 0.6947
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2921, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 65/200
Train Loss: 0.0598, Accuracy: 0.9659, Precision: 0.9468, Recall: 0.9469, F1: 0.9469
Validation Loss: 1.3158, Accuracy: 0.7910, Precision: 0.7359, Recall: 0.7051, F1: 0.7166
Testing Loss: 1.2458, Accuracy: 0.7766, Precision: 0.7055, Recall: 0.6790, F1: 0.6891
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2701, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8283, F1: 0.8078
Epoch 66/200
Train Loss: 0.0497, Accuracy: 0.9682, Precision: 0.9527, Recall: 0.9427, F1: 0.9474
Validation Loss: 1.2826, Accuracy: 0.7996, Precision: 0.7404, Recall: 0.7289, F1: 0.7322
Testing Loss: 1.2075, Accuracy: 0.7911, Precision: 0.7233, Recall: 0.7138, F1: 0.7177
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1165, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 67/200
Train Loss: 0.0445, Accuracy: 0.9696, Precision: 0.9524, Recall: 0.9496, F1: 0.9509
Validation Loss: 1.4241, Accuracy: 0.7825, Precision: 0.7289, Recall: 0.6961, F1: 0.7071
Testing Loss: 1.3446, Accuracy: 0.7874, Precision: 0.7215, Recall: 0.6901, F1: 0.6999
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3226, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7461, F1: 0.7351
Epoch 68/200
Train Loss: 0.0442, Accuracy: 0.9723, Precision: 0.9531, Recall: 0.9546, F1: 0.9539
Validation Loss: 1.4716, Accuracy: 0.7910, Precision: 0.7527, Recall: 0.7174, F1: 0.7299
Testing Loss: 1.3946, Accuracy: 0.7862, Precision: 0.7355, Recall: 0.7043, F1: 0.7169
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3805, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 69/200
Train Loss: 0.0459, Accuracy: 0.9685, Precision: 0.9481, Recall: 0.9482, F1: 0.9481
Validation Loss: 1.4673, Accuracy: 0.7974, Precision: 0.7448, Recall: 0.7224, F1: 0.7310
Testing Loss: 1.3811, Accuracy: 0.7947, Precision: 0.7337, Recall: 0.7172, F1: 0.7238
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2356, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8261, F1: 0.8053
Epoch 70/200
Train Loss: 0.0436, Accuracy: 0.9720, Precision: 0.9558, Recall: 0.9577, F1: 0.9567
Validation Loss: 1.5188, Accuracy: 0.7889, Precision: 0.7310, Recall: 0.7008, F1: 0.7108
Testing Loss: 1.4222, Accuracy: 0.7862, Precision: 0.7117, Recall: 0.6882, F1: 0.6947
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2820, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 71/200
Train Loss: 0.0452, Accuracy: 0.9699, Precision: 0.9538, Recall: 0.9481, F1: 0.9509
Validation Loss: 1.5142, Accuracy: 0.7868, Precision: 0.7293, Recall: 0.6995, F1: 0.7093
Testing Loss: 1.4221, Accuracy: 0.7923, Precision: 0.7155, Recall: 0.6981, F1: 0.7025
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1277, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 72/200
Train Loss: 0.0430, Accuracy: 0.9734, Precision: 0.9550, Recall: 0.9604, F1: 0.9576
Validation Loss: 1.5308, Accuracy: 0.7910, Precision: 0.7334, Recall: 0.7038, F1: 0.7133
Testing Loss: 1.4657, Accuracy: 0.7838, Precision: 0.6964, Recall: 0.6847, F1: 0.6854
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2425, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 73/200
Train Loss: 0.0455, Accuracy: 0.9670, Precision: 0.9443, Recall: 0.9481, F1: 0.9462
Validation Loss: 1.5218, Accuracy: 0.7932, Precision: 0.7404, Recall: 0.7051, F1: 0.7182
Testing Loss: 1.4602, Accuracy: 0.7838, Precision: 0.7090, Recall: 0.6769, F1: 0.6867
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3139, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 74/200
Train Loss: 0.0445, Accuracy: 0.9692, Precision: 0.9492, Recall: 0.9496, F1: 0.9494
Validation Loss: 1.5067, Accuracy: 0.7953, Precision: 0.7423, Recall: 0.7170, F1: 0.7255
Testing Loss: 1.4207, Accuracy: 0.7886, Precision: 0.7254, Recall: 0.7055, F1: 0.7121
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2552, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8661, F1: 0.8440
Epoch 75/200
Train Loss: 0.0442, Accuracy: 0.9701, Precision: 0.9530, Recall: 0.9493, F1: 0.9511
Validation Loss: 1.4991, Accuracy: 0.7910, Precision: 0.7340, Recall: 0.7077, F1: 0.7170
Testing Loss: 1.4506, Accuracy: 0.7862, Precision: 0.7125, Recall: 0.6869, F1: 0.6938
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2857, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 76/200
Train Loss: 0.0499, Accuracy: 0.9661, Precision: 0.9428, Recall: 0.9473, F1: 0.9450
Validation Loss: 1.4452, Accuracy: 0.7783, Precision: 0.6985, Recall: 0.7095, F1: 0.7024
Testing Loss: 1.3312, Accuracy: 0.7814, Precision: 0.7029, Recall: 0.7117, F1: 0.7044
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3292, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8661, F1: 0.8440
Epoch 77/200
Train Loss: 0.0564, Accuracy: 0.9696, Precision: 0.9531, Recall: 0.9486, F1: 0.9508
Validation Loss: 1.6042, Accuracy: 0.8060, Precision: 0.7462, Recall: 0.7152, F1: 0.7272
Testing Loss: 1.5383, Accuracy: 0.7886, Precision: 0.7249, Recall: 0.6931, F1: 0.7055
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3088, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8528, F1: 0.8320
Epoch 78/200
Train Loss: 0.0530, Accuracy: 0.9661, Precision: 0.9437, Recall: 0.9444, F1: 0.9440
Validation Loss: 1.4066, Accuracy: 0.7825, Precision: 0.7345, Recall: 0.6756, F1: 0.6919
Testing Loss: 1.5532, Accuracy: 0.7669, Precision: 0.6923, Recall: 0.6485, F1: 0.6568
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2650, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8333, F1: 0.8106
Epoch 79/200
Train Loss: 0.0730, Accuracy: 0.9623, Precision: 0.9401, Recall: 0.9373, F1: 0.9387
Validation Loss: 1.2441, Accuracy: 0.7676, Precision: 0.7166, Recall: 0.6847, F1: 0.6973
Testing Loss: 1.1923, Accuracy: 0.7814, Precision: 0.7502, Recall: 0.7163, F1: 0.7288
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1880, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 80/200
Train Loss: 0.0529, Accuracy: 0.9675, Precision: 0.9462, Recall: 0.9516, F1: 0.9488
Validation Loss: 1.4638, Accuracy: 0.7889, Precision: 0.7391, Recall: 0.6915, F1: 0.7082
Testing Loss: 1.4279, Accuracy: 0.7850, Precision: 0.7333, Recall: 0.6899, F1: 0.7050
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2873, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 81/200
Train Loss: 0.0438, Accuracy: 0.9711, Precision: 0.9543, Recall: 0.9537, F1: 0.9540
Validation Loss: 1.5477, Accuracy: 0.7889, Precision: 0.7439, Recall: 0.7026, F1: 0.7180
Testing Loss: 1.4512, Accuracy: 0.7899, Precision: 0.7448, Recall: 0.7081, F1: 0.7229
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2881, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 82/200
Train Loss: 0.0434, Accuracy: 0.9725, Precision: 0.9555, Recall: 0.9581, F1: 0.9567
Validation Loss: 1.5726, Accuracy: 0.7846, Precision: 0.7365, Recall: 0.7046, F1: 0.7164
Testing Loss: 1.4563, Accuracy: 0.7935, Precision: 0.7376, Recall: 0.7130, F1: 0.7229
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0752, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 83/200
Train Loss: 0.0436, Accuracy: 0.9701, Precision: 0.9526, Recall: 0.9518, F1: 0.9522
Validation Loss: 1.5744, Accuracy: 0.7889, Precision: 0.7416, Recall: 0.7069, F1: 0.7208
Testing Loss: 1.4849, Accuracy: 0.7959, Precision: 0.7466, Recall: 0.7168, F1: 0.7291
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1479, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 84/200
Train Loss: 0.0452, Accuracy: 0.9708, Precision: 0.9513, Recall: 0.9587, F1: 0.9549
Validation Loss: 1.6074, Accuracy: 0.7825, Precision: 0.7344, Recall: 0.6940, F1: 0.7089
Testing Loss: 1.4858, Accuracy: 0.7874, Precision: 0.7400, Recall: 0.7024, F1: 0.7172
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2452, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 85/200
Train Loss: 0.0443, Accuracy: 0.9713, Precision: 0.9529, Recall: 0.9543, F1: 0.9535
Validation Loss: 1.5622, Accuracy: 0.7868, Precision: 0.7391, Recall: 0.7052, F1: 0.7183
Testing Loss: 1.4648, Accuracy: 0.7874, Precision: 0.7363, Recall: 0.7135, F1: 0.7235
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1582, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 86/200
Train Loss: 0.0440, Accuracy: 0.9701, Precision: 0.9497, Recall: 0.9583, F1: 0.9538
Validation Loss: 1.6104, Accuracy: 0.7889, Precision: 0.7413, Recall: 0.7068, F1: 0.7200
Testing Loss: 1.5084, Accuracy: 0.7874, Precision: 0.7312, Recall: 0.7083, F1: 0.7180
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1849, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 87/200
Train Loss: 0.0439, Accuracy: 0.9711, Precision: 0.9530, Recall: 0.9507, F1: 0.9518
Validation Loss: 1.6000, Accuracy: 0.7825, Precision: 0.7416, Recall: 0.7023, F1: 0.7171
Testing Loss: 1.4772, Accuracy: 0.7971, Precision: 0.7479, Recall: 0.7253, F1: 0.7353
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1570, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9400, F1: 0.9186
Epoch 88/200
Train Loss: 0.0421, Accuracy: 0.9708, Precision: 0.9540, Recall: 0.9533, F1: 0.9536
Validation Loss: 1.6400, Accuracy: 0.7910, Precision: 0.7479, Recall: 0.7098, F1: 0.7240
Testing Loss: 1.5420, Accuracy: 0.7899, Precision: 0.7418, Recall: 0.7204, F1: 0.7299
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2378, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 89/200
Train Loss: 0.0447, Accuracy: 0.9713, Precision: 0.9528, Recall: 0.9534, F1: 0.9531
Validation Loss: 1.6379, Accuracy: 0.7910, Precision: 0.7239, Recall: 0.6853, F1: 0.6985
Testing Loss: 1.5620, Accuracy: 0.7899, Precision: 0.7375, Recall: 0.6939, F1: 0.7062
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4015, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 90/200
Train Loss: 0.0450, Accuracy: 0.9680, Precision: 0.9450, Recall: 0.9505, F1: 0.9476
Validation Loss: 1.6851, Accuracy: 0.7932, Precision: 0.7488, Recall: 0.7116, F1: 0.7253
Testing Loss: 1.5598, Accuracy: 0.7886, Precision: 0.7356, Recall: 0.7129, F1: 0.7227
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2360, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 91/200
Train Loss: 0.0439, Accuracy: 0.9706, Precision: 0.9518, Recall: 0.9498, F1: 0.9508
Validation Loss: 1.6512, Accuracy: 0.7846, Precision: 0.7323, Recall: 0.6942, F1: 0.7096
Testing Loss: 1.5664, Accuracy: 0.7886, Precision: 0.7419, Recall: 0.7057, F1: 0.7194
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3510, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 92/200
Train Loss: 0.0443, Accuracy: 0.9685, Precision: 0.9472, Recall: 0.9492, F1: 0.9482
Validation Loss: 1.6510, Accuracy: 0.7910, Precision: 0.7507, Recall: 0.7078, F1: 0.7239
Testing Loss: 1.5587, Accuracy: 0.7850, Precision: 0.7382, Recall: 0.7144, F1: 0.7247
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2875, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 93/200
Train Loss: 0.0457, Accuracy: 0.9663, Precision: 0.9447, Recall: 0.9480, F1: 0.9463
Validation Loss: 1.6253, Accuracy: 0.7953, Precision: 0.7559, Recall: 0.7077, F1: 0.7256
Testing Loss: 1.5393, Accuracy: 0.7899, Precision: 0.7381, Recall: 0.7081, F1: 0.7204
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2386, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 94/200
Train Loss: 0.0521, Accuracy: 0.9694, Precision: 0.9499, Recall: 0.9546, F1: 0.9522
Validation Loss: 1.5977, Accuracy: 0.7910, Precision: 0.7355, Recall: 0.7021, F1: 0.7153
Testing Loss: 1.5299, Accuracy: 0.7850, Precision: 0.7462, Recall: 0.7048, F1: 0.7215
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2370, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7711, F1: 0.7528
Epoch 95/200
Train Loss: 0.0889, Accuracy: 0.9644, Precision: 0.9452, Recall: 0.9425, F1: 0.9438
Validation Loss: 1.1735, Accuracy: 0.8081, Precision: 0.7716, Recall: 0.7202, F1: 0.7393
Testing Loss: 1.1028, Accuracy: 0.8056, Precision: 0.7636, Recall: 0.7097, F1: 0.7271
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3172, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8350, F1: 0.8125
Epoch 96/200
Train Loss: 0.0702, Accuracy: 0.9666, Precision: 0.9472, Recall: 0.9450, F1: 0.9461
Validation Loss: 1.0470, Accuracy: 0.8081, Precision: 0.7519, Recall: 0.7240, F1: 0.7343
Testing Loss: 0.9342, Accuracy: 0.8043, Precision: 0.7542, Recall: 0.7263, F1: 0.7349
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2529, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8533, F1: 0.8276
Epoch 97/200
Train Loss: 0.0530, Accuracy: 0.9673, Precision: 0.9475, Recall: 0.9458, F1: 0.9466
Validation Loss: 1.2002, Accuracy: 0.7846, Precision: 0.7356, Recall: 0.7267, F1: 0.7281
Testing Loss: 1.1033, Accuracy: 0.7959, Precision: 0.7422, Recall: 0.7431, F1: 0.7419
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1113, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 98/200
Train Loss: 0.0470, Accuracy: 0.9704, Precision: 0.9503, Recall: 0.9521, F1: 0.9512
Validation Loss: 1.3792, Accuracy: 0.8038, Precision: 0.7293, Recall: 0.7117, F1: 0.7163
Testing Loss: 1.3068, Accuracy: 0.7971, Precision: 0.7319, Recall: 0.7094, F1: 0.7136
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1579, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 99/200
Train Loss: 0.0431, Accuracy: 0.9696, Precision: 0.9503, Recall: 0.9546, F1: 0.9524
Validation Loss: 1.4479, Accuracy: 0.8060, Precision: 0.7575, Recall: 0.7322, F1: 0.7428
Testing Loss: 1.3446, Accuracy: 0.8056, Precision: 0.7599, Recall: 0.7447, F1: 0.7514
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1907, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 100/200
Train Loss: 0.0441, Accuracy: 0.9701, Precision: 0.9517, Recall: 0.9532, F1: 0.9524
Validation Loss: 1.4585, Accuracy: 0.8017, Precision: 0.7517, Recall: 0.7233, F1: 0.7353
Testing Loss: 1.3714, Accuracy: 0.8056, Precision: 0.7614, Recall: 0.7443, F1: 0.7519
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2756, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 101/200
Train Loss: 0.0443, Accuracy: 0.9701, Precision: 0.9528, Recall: 0.9524, F1: 0.9526
Validation Loss: 1.4911, Accuracy: 0.8102, Precision: 0.7480, Recall: 0.7153, F1: 0.7269
Testing Loss: 1.4077, Accuracy: 0.7971, Precision: 0.7420, Recall: 0.7105, F1: 0.7214
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2361, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 102/200
Train Loss: 0.0426, Accuracy: 0.9737, Precision: 0.9591, Recall: 0.9562, F1: 0.9576
Validation Loss: 1.5146, Accuracy: 0.8060, Precision: 0.7559, Recall: 0.7318, F1: 0.7422
Testing Loss: 1.4193, Accuracy: 0.7971, Precision: 0.7569, Recall: 0.7426, F1: 0.7485
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2773, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 103/200
Train Loss: 0.0432, Accuracy: 0.9701, Precision: 0.9547, Recall: 0.9502, F1: 0.9524
Validation Loss: 1.5416, Accuracy: 0.8060, Precision: 0.7450, Recall: 0.7141, F1: 0.7257
Testing Loss: 1.4394, Accuracy: 0.8019, Precision: 0.7540, Recall: 0.7190, F1: 0.7316
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2902, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 104/200
Train Loss: 0.0435, Accuracy: 0.9687, Precision: 0.9519, Recall: 0.9491, F1: 0.9505
Validation Loss: 1.5432, Accuracy: 0.8038, Precision: 0.7488, Recall: 0.7307, F1: 0.7387
Testing Loss: 1.4437, Accuracy: 0.8031, Precision: 0.7621, Recall: 0.7453, F1: 0.7526
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1767, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9400, F1: 0.9186
Epoch 105/200
Train Loss: 0.0421, Accuracy: 0.9701, Precision: 0.9482, Recall: 0.9606, F1: 0.9540
Validation Loss: 1.6336, Accuracy: 0.8038, Precision: 0.7417, Recall: 0.7051, F1: 0.7169
Testing Loss: 1.5360, Accuracy: 0.7971, Precision: 0.7415, Recall: 0.7047, F1: 0.7147
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3233, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 106/200
Train Loss: 0.0442, Accuracy: 0.9687, Precision: 0.9510, Recall: 0.9439, F1: 0.9472
Validation Loss: 1.6008, Accuracy: 0.8060, Precision: 0.7483, Recall: 0.7122, F1: 0.7254
Testing Loss: 1.4996, Accuracy: 0.8031, Precision: 0.7559, Recall: 0.7190, F1: 0.7321
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3171, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 107/200
Train Loss: 0.0426, Accuracy: 0.9701, Precision: 0.9511, Recall: 0.9563, F1: 0.9534
Validation Loss: 1.6146, Accuracy: 0.8081, Precision: 0.7432, Recall: 0.7140, F1: 0.7243
Testing Loss: 1.5117, Accuracy: 0.8007, Precision: 0.7442, Recall: 0.7115, F1: 0.7211
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2190, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 108/200
Train Loss: 0.0439, Accuracy: 0.9685, Precision: 0.9499, Recall: 0.9506, F1: 0.9503
Validation Loss: 1.6338, Accuracy: 0.8081, Precision: 0.7326, Recall: 0.7098, F1: 0.7172
Testing Loss: 1.5229, Accuracy: 0.8043, Precision: 0.7481, Recall: 0.7181, F1: 0.7274
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1748, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 109/200
Train Loss: 0.0440, Accuracy: 0.9680, Precision: 0.9446, Recall: 0.9536, F1: 0.9489
Validation Loss: 1.6719, Accuracy: 0.8038, Precision: 0.7410, Recall: 0.7131, F1: 0.7229
Testing Loss: 1.5385, Accuracy: 0.8031, Precision: 0.7464, Recall: 0.7115, F1: 0.7222
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3349, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 110/200
Train Loss: 0.0434, Accuracy: 0.9720, Precision: 0.9569, Recall: 0.9534, F1: 0.9552
Validation Loss: 1.6835, Accuracy: 0.7953, Precision: 0.7323, Recall: 0.7085, F1: 0.7175
Testing Loss: 1.5496, Accuracy: 0.7959, Precision: 0.7409, Recall: 0.7089, F1: 0.7193
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4246, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 111/200
Train Loss: 0.0440, Accuracy: 0.9694, Precision: 0.9495, Recall: 0.9519, F1: 0.9507
Validation Loss: 1.6845, Accuracy: 0.7953, Precision: 0.7315, Recall: 0.7039, F1: 0.7144
Testing Loss: 1.5427, Accuracy: 0.7983, Precision: 0.7404, Recall: 0.7151, F1: 0.7242
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2933, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7861, F1: 0.7690
Epoch 112/200
Train Loss: 0.0453, Accuracy: 0.9661, Precision: 0.9464, Recall: 0.9412, F1: 0.9437
Validation Loss: 1.6778, Accuracy: 0.8017, Precision: 0.7519, Recall: 0.7308, F1: 0.7401
Testing Loss: 1.5304, Accuracy: 0.8019, Precision: 0.7580, Recall: 0.7402, F1: 0.7480
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2039, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 113/200
Train Loss: 0.0427, Accuracy: 0.9730, Precision: 0.9536, Recall: 0.9618, F1: 0.9574
Validation Loss: 1.5403, Accuracy: 0.8060, Precision: 0.7386, Recall: 0.7164, F1: 0.7239
Testing Loss: 1.4043, Accuracy: 0.8007, Precision: 0.7345, Recall: 0.7144, F1: 0.7209
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2561, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 114/200
Train Loss: 0.0429, Accuracy: 0.9708, Precision: 0.9477, Recall: 0.9544, F1: 0.9509
Validation Loss: 1.6453, Accuracy: 0.8038, Precision: 0.7375, Recall: 0.7151, F1: 0.7226
Testing Loss: 1.5148, Accuracy: 0.8068, Precision: 0.7457, Recall: 0.7229, F1: 0.7306
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1981, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 115/200
Train Loss: 0.0442, Accuracy: 0.9663, Precision: 0.9494, Recall: 0.9424, F1: 0.9458
Validation Loss: 1.6656, Accuracy: 0.7974, Precision: 0.7386, Recall: 0.7378, F1: 0.7379
Testing Loss: 1.5424, Accuracy: 0.8043, Precision: 0.7530, Recall: 0.7508, F1: 0.7512
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1386, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 116/200
Train Loss: 0.0422, Accuracy: 0.9704, Precision: 0.9521, Recall: 0.9517, F1: 0.9519
Validation Loss: 1.6552, Accuracy: 0.7740, Precision: 0.7196, Recall: 0.7232, F1: 0.7177
Testing Loss: 1.5571, Accuracy: 0.7959, Precision: 0.7480, Recall: 0.7610, F1: 0.7512
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1589, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 117/200
Train Loss: 0.0456, Accuracy: 0.9689, Precision: 0.9483, Recall: 0.9510, F1: 0.9496
Validation Loss: 1.7551, Accuracy: 0.7910, Precision: 0.7332, Recall: 0.7023, F1: 0.7150
Testing Loss: 1.6152, Accuracy: 0.7826, Precision: 0.7140, Recall: 0.6820, F1: 0.6938
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2823, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 118/200
Train Loss: 0.0614, Accuracy: 0.9654, Precision: 0.9419, Recall: 0.9443, F1: 0.9430
Validation Loss: 1.4629, Accuracy: 0.7825, Precision: 0.7311, Recall: 0.7057, F1: 0.7129
Testing Loss: 1.3391, Accuracy: 0.7838, Precision: 0.7346, Recall: 0.7070, F1: 0.7171
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 5, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2199, Accuracy: 0.9524, Precision: 0.8056, Recall: 0.8000, F1: 0.7997
Epoch 119/200
Train Loss: 0.0621, Accuracy: 0.9682, Precision: 0.9530, Recall: 0.9418, F1: 0.9471
Validation Loss: 1.2295, Accuracy: 0.7846, Precision: 0.7306, Recall: 0.7267, F1: 0.7242
Testing Loss: 1.0655, Accuracy: 0.7826, Precision: 0.7391, Recall: 0.7355, F1: 0.7350
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 5, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 5, 4, 2, 0, 4, 3, 3, 5, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3803, Accuracy: 0.8333, Precision: 0.7593, Recall: 0.7051, F1: 0.7085
Epoch 120/200
Train Loss: 0.0567, Accuracy: 0.9670, Precision: 0.9489, Recall: 0.9499, F1: 0.9494
Validation Loss: 1.3328, Accuracy: 0.7825, Precision: 0.7068, Recall: 0.7132, F1: 0.7093
Testing Loss: 1.2354, Accuracy: 0.7935, Precision: 0.7340, Recall: 0.7235, F1: 0.7278
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1686, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 121/200
Train Loss: 0.0490, Accuracy: 0.9689, Precision: 0.9488, Recall: 0.9550, F1: 0.9518
Validation Loss: 1.3533, Accuracy: 0.8060, Precision: 0.7311, Recall: 0.7113, F1: 0.7169
Testing Loss: 1.1976, Accuracy: 0.7959, Precision: 0.7408, Recall: 0.6995, F1: 0.7096
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3738, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 122/200
Train Loss: 0.0434, Accuracy: 0.9704, Precision: 0.9519, Recall: 0.9561, F1: 0.9539
Validation Loss: 1.5297, Accuracy: 0.7846, Precision: 0.7352, Recall: 0.7054, F1: 0.7153
Testing Loss: 1.4225, Accuracy: 0.7947, Precision: 0.7392, Recall: 0.6869, F1: 0.6981
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3222, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 123/200
Train Loss: 0.0434, Accuracy: 0.9704, Precision: 0.9537, Recall: 0.9481, F1: 0.9508
Validation Loss: 1.5114, Accuracy: 0.7996, Precision: 0.7361, Recall: 0.7289, F1: 0.7314
Testing Loss: 1.3469, Accuracy: 0.7826, Precision: 0.7267, Recall: 0.7093, F1: 0.7161
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2389, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8506, F1: 0.8293
Epoch 124/200
Train Loss: 0.0415, Accuracy: 0.9744, Precision: 0.9594, Recall: 0.9602, F1: 0.9598
Validation Loss: 1.5692, Accuracy: 0.7932, Precision: 0.7273, Recall: 0.7280, F1: 0.7269
Testing Loss: 1.3948, Accuracy: 0.7862, Precision: 0.7284, Recall: 0.7198, F1: 0.7233
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1724, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 125/200
Train Loss: 0.0424, Accuracy: 0.9677, Precision: 0.9477, Recall: 0.9511, F1: 0.9494
Validation Loss: 1.5609, Accuracy: 0.7996, Precision: 0.7355, Recall: 0.7395, F1: 0.7368
Testing Loss: 1.3899, Accuracy: 0.7826, Precision: 0.7198, Recall: 0.7179, F1: 0.7183
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1884, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 126/200
Train Loss: 0.0421, Accuracy: 0.9696, Precision: 0.9476, Recall: 0.9511, F1: 0.9493
Validation Loss: 1.5813, Accuracy: 0.7974, Precision: 0.7392, Recall: 0.7334, F1: 0.7357
Testing Loss: 1.4387, Accuracy: 0.7923, Precision: 0.7399, Recall: 0.7236, F1: 0.7304
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2497, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 127/200
Train Loss: 0.0420, Accuracy: 0.9696, Precision: 0.9509, Recall: 0.9514, F1: 0.9511
Validation Loss: 1.6342, Accuracy: 0.7996, Precision: 0.7306, Recall: 0.7309, F1: 0.7286
Testing Loss: 1.4737, Accuracy: 0.7874, Precision: 0.7236, Recall: 0.7044, F1: 0.7088
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1424, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 128/200
Train Loss: 0.0424, Accuracy: 0.9694, Precision: 0.9475, Recall: 0.9567, F1: 0.9518
Validation Loss: 1.6049, Accuracy: 0.8017, Precision: 0.7226, Recall: 0.7259, F1: 0.7229
Testing Loss: 1.4661, Accuracy: 0.7923, Precision: 0.7346, Recall: 0.7120, F1: 0.7174
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2037, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 129/200
Train Loss: 0.0431, Accuracy: 0.9656, Precision: 0.9442, Recall: 0.9439, F1: 0.9441
Validation Loss: 1.6162, Accuracy: 0.8060, Precision: 0.7356, Recall: 0.7346, F1: 0.7332
Testing Loss: 1.4890, Accuracy: 0.7971, Precision: 0.7371, Recall: 0.7140, F1: 0.7188
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2188, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 130/200
Train Loss: 0.0426, Accuracy: 0.9682, Precision: 0.9483, Recall: 0.9511, F1: 0.9496
Validation Loss: 1.6585, Accuracy: 0.7974, Precision: 0.7283, Recall: 0.7294, F1: 0.7265
Testing Loss: 1.4914, Accuracy: 0.7911, Precision: 0.7264, Recall: 0.7118, F1: 0.7132
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1823, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 131/200
Train Loss: 0.0428, Accuracy: 0.9689, Precision: 0.9486, Recall: 0.9505, F1: 0.9495
Validation Loss: 1.6707, Accuracy: 0.7868, Precision: 0.7101, Recall: 0.7133, F1: 0.7093
Testing Loss: 1.4929, Accuracy: 0.7899, Precision: 0.7218, Recall: 0.7086, F1: 0.7071
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1671, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 132/200
Train Loss: 0.0430, Accuracy: 0.9682, Precision: 0.9507, Recall: 0.9456, F1: 0.9481
Validation Loss: 1.6788, Accuracy: 0.7932, Precision: 0.7320, Recall: 0.7244, F1: 0.7272
Testing Loss: 1.5100, Accuracy: 0.7886, Precision: 0.7342, Recall: 0.7225, F1: 0.7272
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2521, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8506, F1: 0.8293
Epoch 133/200
Train Loss: 0.0424, Accuracy: 0.9694, Precision: 0.9510, Recall: 0.9493, F1: 0.9501
Validation Loss: 1.6757, Accuracy: 0.7953, Precision: 0.7282, Recall: 0.7201, F1: 0.7224
Testing Loss: 1.5323, Accuracy: 0.7959, Precision: 0.7446, Recall: 0.7130, F1: 0.7213
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2647, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 134/200
Train Loss: 0.0427, Accuracy: 0.9677, Precision: 0.9489, Recall: 0.9464, F1: 0.9476
Validation Loss: 1.6531, Accuracy: 0.7953, Precision: 0.7279, Recall: 0.7199, F1: 0.7225
Testing Loss: 1.5215, Accuracy: 0.7899, Precision: 0.7360, Recall: 0.7104, F1: 0.7166
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2746, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 135/200
Train Loss: 0.0418, Accuracy: 0.9701, Precision: 0.9519, Recall: 0.9513, F1: 0.9516
Validation Loss: 1.6731, Accuracy: 0.7910, Precision: 0.7229, Recall: 0.7261, F1: 0.7243
Testing Loss: 1.5405, Accuracy: 0.7899, Precision: 0.7356, Recall: 0.7241, F1: 0.7281
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2438, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 136/200
Train Loss: 0.0420, Accuracy: 0.9718, Precision: 0.9573, Recall: 0.9494, F1: 0.9531
Validation Loss: 1.7545, Accuracy: 0.7910, Precision: 0.7274, Recall: 0.7356, F1: 0.7307
Testing Loss: 1.5838, Accuracy: 0.7862, Precision: 0.7210, Recall: 0.7176, F1: 0.7181
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1235, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 137/200
Train Loss: 0.0435, Accuracy: 0.9704, Precision: 0.9542, Recall: 0.9480, F1: 0.9509
Validation Loss: 1.6978, Accuracy: 0.7868, Precision: 0.7253, Recall: 0.7370, F1: 0.7294
Testing Loss: 1.4842, Accuracy: 0.7886, Precision: 0.7363, Recall: 0.7411, F1: 0.7377
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2210, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 138/200
Train Loss: 0.0532, Accuracy: 0.9663, Precision: 0.9466, Recall: 0.9409, F1: 0.9436
Validation Loss: 1.5219, Accuracy: 0.7783, Precision: 0.7195, Recall: 0.6868, F1: 0.6949
Testing Loss: 1.3871, Accuracy: 0.7874, Precision: 0.7388, Recall: 0.7022, F1: 0.7149
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1633, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 139/200
Train Loss: 0.0628, Accuracy: 0.9677, Precision: 0.9519, Recall: 0.9518, F1: 0.9518
Validation Loss: 1.2881, Accuracy: 0.7889, Precision: 0.7248, Recall: 0.7072, F1: 0.7141
Testing Loss: 1.0949, Accuracy: 0.7886, Precision: 0.7279, Recall: 0.7118, F1: 0.7166
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1895, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9083, F1: 0.8895
Epoch 140/200
Train Loss: 0.0451, Accuracy: 0.9711, Precision: 0.9530, Recall: 0.9540, F1: 0.9535
Validation Loss: 1.4816, Accuracy: 0.7846, Precision: 0.7230, Recall: 0.6976, F1: 0.7063
Testing Loss: 1.2778, Accuracy: 0.7911, Precision: 0.7349, Recall: 0.7100, F1: 0.7191
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1747, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 141/200
Train Loss: 0.0445, Accuracy: 0.9680, Precision: 0.9459, Recall: 0.9513, F1: 0.9485
Validation Loss: 1.4903, Accuracy: 0.7953, Precision: 0.7286, Recall: 0.7030, F1: 0.7131
Testing Loss: 1.3129, Accuracy: 0.7923, Precision: 0.7575, Recall: 0.7097, F1: 0.7284
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3167, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 142/200
Train Loss: 0.0422, Accuracy: 0.9692, Precision: 0.9472, Recall: 0.9511, F1: 0.9491
Validation Loss: 1.5416, Accuracy: 0.8038, Precision: 0.7499, Recall: 0.7164, F1: 0.7295
Testing Loss: 1.3399, Accuracy: 0.7971, Precision: 0.7591, Recall: 0.7187, F1: 0.7349
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2514, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.9000, F1: 0.8728
Epoch 143/200
Train Loss: 0.0419, Accuracy: 0.9720, Precision: 0.9617, Recall: 0.9475, F1: 0.9541
Validation Loss: 1.5260, Accuracy: 0.7996, Precision: 0.7416, Recall: 0.7118, F1: 0.7241
Testing Loss: 1.3756, Accuracy: 0.7899, Precision: 0.7519, Recall: 0.7080, F1: 0.7248
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2964, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 144/200
Train Loss: 0.0417, Accuracy: 0.9723, Precision: 0.9564, Recall: 0.9542, F1: 0.9553
Validation Loss: 1.5503, Accuracy: 0.8017, Precision: 0.7447, Recall: 0.7133, F1: 0.7258
Testing Loss: 1.3955, Accuracy: 0.7886, Precision: 0.7484, Recall: 0.7083, F1: 0.7235
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2450, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 145/200
Train Loss: 0.0420, Accuracy: 0.9675, Precision: 0.9490, Recall: 0.9452, F1: 0.9471
Validation Loss: 1.5462, Accuracy: 0.7910, Precision: 0.7277, Recall: 0.7031, F1: 0.7126
Testing Loss: 1.3907, Accuracy: 0.7886, Precision: 0.7423, Recall: 0.7075, F1: 0.7199
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2563, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 146/200
Train Loss: 0.0424, Accuracy: 0.9670, Precision: 0.9473, Recall: 0.9459, F1: 0.9465
Validation Loss: 1.5671, Accuracy: 0.8038, Precision: 0.7310, Recall: 0.7182, F1: 0.7234
Testing Loss: 1.4111, Accuracy: 0.7923, Precision: 0.7302, Recall: 0.7093, F1: 0.7161
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1861, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 147/200
Train Loss: 0.0428, Accuracy: 0.9689, Precision: 0.9487, Recall: 0.9513, F1: 0.9500
Validation Loss: 1.5674, Accuracy: 0.7974, Precision: 0.7365, Recall: 0.7105, F1: 0.7215
Testing Loss: 1.4219, Accuracy: 0.7862, Precision: 0.7297, Recall: 0.7042, F1: 0.7139
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2199, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 148/200
Train Loss: 0.0420, Accuracy: 0.9696, Precision: 0.9501, Recall: 0.9544, F1: 0.9521
Validation Loss: 1.6113, Accuracy: 0.8038, Precision: 0.7422, Recall: 0.7132, F1: 0.7245
Testing Loss: 1.4818, Accuracy: 0.7862, Precision: 0.7375, Recall: 0.6950, F1: 0.7086
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2910, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 149/200
Train Loss: 0.0421, Accuracy: 0.9704, Precision: 0.9508, Recall: 0.9562, F1: 0.9535
Validation Loss: 1.6425, Accuracy: 0.7953, Precision: 0.7318, Recall: 0.7018, F1: 0.7132
Testing Loss: 1.4810, Accuracy: 0.7874, Precision: 0.7367, Recall: 0.6969, F1: 0.7116
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2027, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9350, F1: 0.9183
Epoch 150/200
Train Loss: 0.0420, Accuracy: 0.9708, Precision: 0.9548, Recall: 0.9521, F1: 0.9534
Validation Loss: 1.6395, Accuracy: 0.7910, Precision: 0.7359, Recall: 0.7035, F1: 0.7167
Testing Loss: 1.4829, Accuracy: 0.7874, Precision: 0.7444, Recall: 0.7169, F1: 0.7281
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2635, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 151/200
Train Loss: 0.0415, Accuracy: 0.9723, Precision: 0.9506, Recall: 0.9630, F1: 0.9563
Validation Loss: 1.6461, Accuracy: 0.8060, Precision: 0.7385, Recall: 0.7180, F1: 0.7266
Testing Loss: 1.4654, Accuracy: 0.7959, Precision: 0.7372, Recall: 0.7120, F1: 0.7219
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1981, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 152/200
Train Loss: 0.0467, Accuracy: 0.9685, Precision: 0.9523, Recall: 0.9444, F1: 0.9481
Validation Loss: 1.5184, Accuracy: 0.7676, Precision: 0.7144, Recall: 0.6912, F1: 0.6951
Testing Loss: 1.3406, Accuracy: 0.7850, Precision: 0.7427, Recall: 0.7313, F1: 0.7302
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2188, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8978, F1: 0.8716
Epoch 153/200
Train Loss: 0.0463, Accuracy: 0.9670, Precision: 0.9487, Recall: 0.9462, F1: 0.9474
Validation Loss: 2.0312, Accuracy: 0.7783, Precision: 0.7206, Recall: 0.7095, F1: 0.7133
Testing Loss: 2.0631, Accuracy: 0.7633, Precision: 0.7247, Recall: 0.7007, F1: 0.7068
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2190, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 154/200
Train Loss: 0.0536, Accuracy: 0.9689, Precision: 0.9493, Recall: 0.9548, F1: 0.9519
Validation Loss: 1.4371, Accuracy: 0.7974, Precision: 0.7447, Recall: 0.7013, F1: 0.7175
Testing Loss: 1.3874, Accuracy: 0.7838, Precision: 0.7344, Recall: 0.6822, F1: 0.6964
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2644, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8661, F1: 0.8440
Epoch 155/200
Train Loss: 0.0480, Accuracy: 0.9692, Precision: 0.9516, Recall: 0.9503, F1: 0.9509
Validation Loss: 1.4122, Accuracy: 0.8102, Precision: 0.7711, Recall: 0.7198, F1: 0.7388
Testing Loss: 1.3333, Accuracy: 0.7838, Precision: 0.7632, Recall: 0.7061, F1: 0.7275
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3644, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 156/200
Train Loss: 0.0512, Accuracy: 0.9668, Precision: 0.9452, Recall: 0.9519, F1: 0.9485
Validation Loss: 1.2612, Accuracy: 0.8060, Precision: 0.7483, Recall: 0.6971, F1: 0.7130
Testing Loss: 1.1157, Accuracy: 0.7983, Precision: 0.7454, Recall: 0.6898, F1: 0.7070
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3096, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 157/200
Train Loss: 0.0454, Accuracy: 0.9687, Precision: 0.9487, Recall: 0.9520, F1: 0.9503
Validation Loss: 1.3044, Accuracy: 0.8102, Precision: 0.7470, Recall: 0.7049, F1: 0.7186
Testing Loss: 1.1768, Accuracy: 0.7971, Precision: 0.7363, Recall: 0.6921, F1: 0.7067
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1883, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9778, F1: 0.9701
Epoch 158/200
Train Loss: 0.0422, Accuracy: 0.9696, Precision: 0.9534, Recall: 0.9460, F1: 0.9494
Validation Loss: 1.3732, Accuracy: 0.8017, Precision: 0.7502, Recall: 0.6986, F1: 0.7153
Testing Loss: 1.2505, Accuracy: 0.7995, Precision: 0.7449, Recall: 0.6940, F1: 0.7100
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2521, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 159/200
Train Loss: 0.0420, Accuracy: 0.9675, Precision: 0.9477, Recall: 0.9442, F1: 0.9459
Validation Loss: 1.4117, Accuracy: 0.8081, Precision: 0.7502, Recall: 0.7075, F1: 0.7223
Testing Loss: 1.2858, Accuracy: 0.8007, Precision: 0.7470, Recall: 0.7028, F1: 0.7178
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1766, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 160/200
Train Loss: 0.0420, Accuracy: 0.9680, Precision: 0.9530, Recall: 0.9425, F1: 0.9473
Validation Loss: 1.4762, Accuracy: 0.8017, Precision: 0.7540, Recall: 0.7114, F1: 0.7271
Testing Loss: 1.3413, Accuracy: 0.8031, Precision: 0.7589, Recall: 0.7204, F1: 0.7360
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2065, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 161/200
Train Loss: 0.0414, Accuracy: 0.9706, Precision: 0.9531, Recall: 0.9532, F1: 0.9531
Validation Loss: 1.4855, Accuracy: 0.8081, Precision: 0.7468, Recall: 0.7033, F1: 0.7169
Testing Loss: 1.3485, Accuracy: 0.8031, Precision: 0.7444, Recall: 0.7029, F1: 0.7145
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1393, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 162/200
Train Loss: 0.0424, Accuracy: 0.9701, Precision: 0.9531, Recall: 0.9513, F1: 0.9522
Validation Loss: 1.4936, Accuracy: 0.7974, Precision: 0.7425, Recall: 0.7098, F1: 0.7227
Testing Loss: 1.3563, Accuracy: 0.8068, Precision: 0.7649, Recall: 0.7303, F1: 0.7448
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2247, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8800, F1: 0.8528
Epoch 163/200
Train Loss: 0.0414, Accuracy: 0.9711, Precision: 0.9556, Recall: 0.9515, F1: 0.9535
Validation Loss: 1.5297, Accuracy: 0.8017, Precision: 0.7457, Recall: 0.7174, F1: 0.7285
Testing Loss: 1.3798, Accuracy: 0.8043, Precision: 0.7557, Recall: 0.7280, F1: 0.7397
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1800, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 164/200
Train Loss: 0.0417, Accuracy: 0.9718, Precision: 0.9540, Recall: 0.9543, F1: 0.9541
Validation Loss: 1.5077, Accuracy: 0.7974, Precision: 0.7511, Recall: 0.7210, F1: 0.7328
Testing Loss: 1.3752, Accuracy: 0.8031, Precision: 0.7643, Recall: 0.7301, F1: 0.7444
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2278, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 165/200
Train Loss: 0.0449, Accuracy: 0.9704, Precision: 0.9480, Recall: 0.9569, F1: 0.9521
Validation Loss: 1.5144, Accuracy: 0.7910, Precision: 0.7298, Recall: 0.7083, F1: 0.7169
Testing Loss: 1.4081, Accuracy: 0.7947, Precision: 0.7452, Recall: 0.7189, F1: 0.7291
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2347, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 166/200
Train Loss: 0.0449, Accuracy: 0.9706, Precision: 0.9565, Recall: 0.9473, F1: 0.9517
Validation Loss: 1.5290, Accuracy: 0.7889, Precision: 0.7234, Recall: 0.7025, F1: 0.7108
Testing Loss: 1.3859, Accuracy: 0.8019, Precision: 0.7517, Recall: 0.7217, F1: 0.7341
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1042, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 167/200
Train Loss: 0.0419, Accuracy: 0.9680, Precision: 0.9462, Recall: 0.9494, F1: 0.9478
Validation Loss: 1.5249, Accuracy: 0.8038, Precision: 0.7450, Recall: 0.7042, F1: 0.7180
Testing Loss: 1.4553, Accuracy: 0.7959, Precision: 0.7527, Recall: 0.6959, F1: 0.7155
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3151, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 168/200
Train Loss: 0.0420, Accuracy: 0.9689, Precision: 0.9557, Recall: 0.9429, F1: 0.9489
Validation Loss: 1.5387, Accuracy: 0.7932, Precision: 0.7325, Recall: 0.7094, F1: 0.7190
Testing Loss: 1.4467, Accuracy: 0.7983, Precision: 0.7548, Recall: 0.7186, F1: 0.7333
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2315, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7928, F1: 0.7749
Epoch 169/200
Train Loss: 0.0433, Accuracy: 0.9699, Precision: 0.9484, Recall: 0.9551, F1: 0.9516
Validation Loss: 1.5523, Accuracy: 0.7953, Precision: 0.7288, Recall: 0.7147, F1: 0.7203
Testing Loss: 1.4346, Accuracy: 0.7971, Precision: 0.7545, Recall: 0.7184, F1: 0.7330
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1673, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 170/200
Train Loss: 0.0418, Accuracy: 0.9713, Precision: 0.9556, Recall: 0.9492, F1: 0.9523
Validation Loss: 1.5538, Accuracy: 0.7932, Precision: 0.7341, Recall: 0.7053, F1: 0.7168
Testing Loss: 1.4891, Accuracy: 0.7971, Precision: 0.7554, Recall: 0.7137, F1: 0.7303
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3061, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 171/200
Train Loss: 0.0418, Accuracy: 0.9723, Precision: 0.9533, Recall: 0.9603, F1: 0.9566
Validation Loss: 1.5666, Accuracy: 0.7932, Precision: 0.7199, Recall: 0.6985, F1: 0.7047
Testing Loss: 1.5265, Accuracy: 0.7971, Precision: 0.7570, Recall: 0.6988, F1: 0.7186
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4434, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 172/200
Train Loss: 0.0435, Accuracy: 0.9689, Precision: 0.9484, Recall: 0.9496, F1: 0.9490
Validation Loss: 1.5021, Accuracy: 0.7996, Precision: 0.7382, Recall: 0.7090, F1: 0.7196
Testing Loss: 1.4448, Accuracy: 0.8043, Precision: 0.7587, Recall: 0.7085, F1: 0.7263
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1821, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 173/200
Train Loss: 0.0458, Accuracy: 0.9708, Precision: 0.9522, Recall: 0.9534, F1: 0.9528
Validation Loss: 1.6006, Accuracy: 0.7910, Precision: 0.7316, Recall: 0.7130, F1: 0.7181
Testing Loss: 1.4846, Accuracy: 0.7911, Precision: 0.7432, Recall: 0.7227, F1: 0.7303
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1804, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 174/200
Train Loss: 0.0435, Accuracy: 0.9682, Precision: 0.9460, Recall: 0.9515, F1: 0.9487
Validation Loss: 1.5189, Accuracy: 0.7974, Precision: 0.7260, Recall: 0.7058, F1: 0.7134
Testing Loss: 1.3996, Accuracy: 0.7923, Precision: 0.7445, Recall: 0.7070, F1: 0.7217
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3430, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7706, F1: 0.7569
Epoch 175/200
Train Loss: 0.0431, Accuracy: 0.9692, Precision: 0.9504, Recall: 0.9502, F1: 0.9503
Validation Loss: 1.7207, Accuracy: 0.7889, Precision: 0.7085, Recall: 0.6908, F1: 0.6963
Testing Loss: 1.6178, Accuracy: 0.7971, Precision: 0.7526, Recall: 0.7141, F1: 0.7284
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2142, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 176/200
Train Loss: 0.0442, Accuracy: 0.9694, Precision: 0.9539, Recall: 0.9485, F1: 0.9511
Validation Loss: 1.6522, Accuracy: 0.7910, Precision: 0.7238, Recall: 0.6963, F1: 0.7052
Testing Loss: 1.5058, Accuracy: 0.7995, Precision: 0.7534, Recall: 0.7159, F1: 0.7299
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2365, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 177/200
Train Loss: 0.0435, Accuracy: 0.9675, Precision: 0.9499, Recall: 0.9443, F1: 0.9469
Validation Loss: 1.6421, Accuracy: 0.7889, Precision: 0.7200, Recall: 0.6968, F1: 0.7051
Testing Loss: 1.3731, Accuracy: 0.8043, Precision: 0.7569, Recall: 0.7119, F1: 0.7276
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2296, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 178/200
Train Loss: 0.0424, Accuracy: 0.9675, Precision: 0.9469, Recall: 0.9453, F1: 0.9461
Validation Loss: 1.7104, Accuracy: 0.7868, Precision: 0.7169, Recall: 0.6999, F1: 0.7058
Testing Loss: 1.4398, Accuracy: 0.8056, Precision: 0.7586, Recall: 0.7346, F1: 0.7446
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1517, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 179/200
Train Loss: 0.0420, Accuracy: 0.9701, Precision: 0.9531, Recall: 0.9492, F1: 0.9511
Validation Loss: 1.6970, Accuracy: 0.7868, Precision: 0.7229, Recall: 0.7044, F1: 0.7113
Testing Loss: 1.4584, Accuracy: 0.8007, Precision: 0.7568, Recall: 0.7285, F1: 0.7406
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2131, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 180/200
Train Loss: 0.0414, Accuracy: 0.9708, Precision: 0.9480, Recall: 0.9549, F1: 0.9512
Validation Loss: 1.6848, Accuracy: 0.7889, Precision: 0.7021, Recall: 0.6925, F1: 0.6940
Testing Loss: 1.4546, Accuracy: 0.8007, Precision: 0.7423, Recall: 0.7094, F1: 0.7188
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2680, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 181/200
Train Loss: 0.0445, Accuracy: 0.9692, Precision: 0.9538, Recall: 0.9454, F1: 0.9494
Validation Loss: 1.6866, Accuracy: 0.7889, Precision: 0.7316, Recall: 0.7054, F1: 0.7162
Testing Loss: 1.4643, Accuracy: 0.7983, Precision: 0.7620, Recall: 0.7252, F1: 0.7405
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3093, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 182/200
Train Loss: 0.0467, Accuracy: 0.9680, Precision: 0.9469, Recall: 0.9489, F1: 0.9478
Validation Loss: 1.6847, Accuracy: 0.7868, Precision: 0.7101, Recall: 0.7128, F1: 0.7102
Testing Loss: 1.4309, Accuracy: 0.8007, Precision: 0.7381, Recall: 0.7198, F1: 0.7242
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2063, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 183/200
Train Loss: 0.0471, Accuracy: 0.9666, Precision: 0.9449, Recall: 0.9448, F1: 0.9448
Validation Loss: 1.4825, Accuracy: 0.7633, Precision: 0.6999, Recall: 0.6692, F1: 0.6793
Testing Loss: 1.2697, Accuracy: 0.7935, Precision: 0.7421, Recall: 0.7168, F1: 0.7270
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1821, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 184/200
Train Loss: 0.0456, Accuracy: 0.9744, Precision: 0.9563, Recall: 0.9576, F1: 0.9569
Validation Loss: 1.4348, Accuracy: 0.7655, Precision: 0.7185, Recall: 0.6807, F1: 0.6937
Testing Loss: 1.2438, Accuracy: 0.7947, Precision: 0.7453, Recall: 0.7217, F1: 0.7308
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2128, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 185/200
Train Loss: 0.0446, Accuracy: 0.9711, Precision: 0.9527, Recall: 0.9532, F1: 0.9528
Validation Loss: 1.7697, Accuracy: 0.7548, Precision: 0.7230, Recall: 0.6759, F1: 0.6900
Testing Loss: 1.6306, Accuracy: 0.7814, Precision: 0.7416, Recall: 0.7084, F1: 0.7209
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2832, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 186/200
Train Loss: 0.0420, Accuracy: 0.9699, Precision: 0.9494, Recall: 0.9537, F1: 0.9515
Validation Loss: 2.1575, Accuracy: 0.7676, Precision: 0.7136, Recall: 0.6853, F1: 0.6926
Testing Loss: 1.7483, Accuracy: 0.7778, Precision: 0.7206, Recall: 0.7126, F1: 0.7154
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1811, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 187/200
Train Loss: 0.0458, Accuracy: 0.9670, Precision: 0.9484, Recall: 0.9438, F1: 0.9461
Validation Loss: 1.4381, Accuracy: 0.7974, Precision: 0.7458, Recall: 0.7251, F1: 0.7333
Testing Loss: 1.4292, Accuracy: 0.7911, Precision: 0.7351, Recall: 0.7266, F1: 0.7299
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2704, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 188/200
Train Loss: 0.0473, Accuracy: 0.9699, Precision: 0.9498, Recall: 0.9559, F1: 0.9527
Validation Loss: 1.2193, Accuracy: 0.7846, Precision: 0.7522, Recall: 0.7179, F1: 0.7273
Testing Loss: 1.1191, Accuracy: 0.7778, Precision: 0.7404, Recall: 0.7166, F1: 0.7234
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2104, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 189/200
Train Loss: 0.0420, Accuracy: 0.9704, Precision: 0.9517, Recall: 0.9553, F1: 0.9534
Validation Loss: 1.4884, Accuracy: 0.7889, Precision: 0.7479, Recall: 0.7114, F1: 0.7233
Testing Loss: 1.4618, Accuracy: 0.7923, Precision: 0.7572, Recall: 0.7171, F1: 0.7329
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2586, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 190/200
Train Loss: 0.0414, Accuracy: 0.9720, Precision: 0.9552, Recall: 0.9546, F1: 0.9549
Validation Loss: 1.4931, Accuracy: 0.7996, Precision: 0.7371, Recall: 0.6958, F1: 0.7107
Testing Loss: 1.4844, Accuracy: 0.7971, Precision: 0.7613, Recall: 0.7025, F1: 0.7215
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2938, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7711, F1: 0.7528
Epoch 191/200
Train Loss: 0.0416, Accuracy: 0.9706, Precision: 0.9546, Recall: 0.9528, F1: 0.9537
Validation Loss: 1.5102, Accuracy: 0.7953, Precision: 0.7250, Recall: 0.6947, F1: 0.7054
Testing Loss: 1.4930, Accuracy: 0.7923, Precision: 0.7416, Recall: 0.6980, F1: 0.7106
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1852, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 192/200
Train Loss: 0.0416, Accuracy: 0.9706, Precision: 0.9505, Recall: 0.9564, F1: 0.9534
Validation Loss: 1.5344, Accuracy: 0.7953, Precision: 0.7228, Recall: 0.6889, F1: 0.7006
Testing Loss: 1.5472, Accuracy: 0.7947, Precision: 0.7579, Recall: 0.6967, F1: 0.7149
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2119, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 193/200
Train Loss: 0.0412, Accuracy: 0.9687, Precision: 0.9493, Recall: 0.9514, F1: 0.9502
Validation Loss: 1.5271, Accuracy: 0.7996, Precision: 0.7341, Recall: 0.6984, F1: 0.7118
Testing Loss: 1.5424, Accuracy: 0.7959, Precision: 0.7572, Recall: 0.7014, F1: 0.7190
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2404, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 194/200
Train Loss: 0.0411, Accuracy: 0.9692, Precision: 0.9549, Recall: 0.9439, F1: 0.9488
Validation Loss: 1.5454, Accuracy: 0.7868, Precision: 0.7397, Recall: 0.7052, F1: 0.7179
Testing Loss: 1.5517, Accuracy: 0.7935, Precision: 0.7553, Recall: 0.7179, F1: 0.7330
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2718, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8111, F1: 0.7876
Epoch 195/200
Train Loss: 0.0414, Accuracy: 0.9687, Precision: 0.9434, Recall: 0.9628, F1: 0.9518
Validation Loss: 1.5695, Accuracy: 0.7996, Precision: 0.7322, Recall: 0.6958, F1: 0.7084
Testing Loss: 1.6003, Accuracy: 0.7911, Precision: 0.7426, Recall: 0.6922, F1: 0.7049
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2067, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 196/200
Train Loss: 0.0406, Accuracy: 0.9727, Precision: 0.9655, Recall: 0.9470, F1: 0.9550
Validation Loss: 1.5927, Accuracy: 0.7868, Precision: 0.7448, Recall: 0.7125, F1: 0.7240
Testing Loss: 1.6007, Accuracy: 0.7911, Precision: 0.7470, Recall: 0.7169, F1: 0.7286
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2181, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 197/200
Train Loss: 0.0413, Accuracy: 0.9685, Precision: 0.9454, Recall: 0.9571, F1: 0.9508
Validation Loss: 1.5675, Accuracy: 0.8038, Precision: 0.7352, Recall: 0.7030, F1: 0.7147
Testing Loss: 1.5646, Accuracy: 0.7923, Precision: 0.7499, Recall: 0.6975, F1: 0.7125
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2219, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 198/200
Train Loss: 0.0419, Accuracy: 0.9673, Precision: 0.9478, Recall: 0.9472, F1: 0.9475
Validation Loss: 1.5643, Accuracy: 0.7953, Precision: 0.7423, Recall: 0.7157, F1: 0.7258
Testing Loss: 1.5557, Accuracy: 0.7911, Precision: 0.7428, Recall: 0.7190, F1: 0.7291
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1803, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 199/200
Train Loss: 0.0412, Accuracy: 0.9706, Precision: 0.9512, Recall: 0.9498, F1: 0.9505
Validation Loss: 1.5919, Accuracy: 0.7889, Precision: 0.7499, Recall: 0.7197, F1: 0.7296
Testing Loss: 1.5939, Accuracy: 0.7911, Precision: 0.7525, Recall: 0.7184, F1: 0.7316
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2796, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 200/200
Train Loss: 0.0414, Accuracy: 0.9694, Precision: 0.9461, Recall: 0.9610, F1: 0.9530
Validation Loss: 1.6081, Accuracy: 0.8017, Precision: 0.7310, Recall: 0.6953, F1: 0.7076
Testing Loss: 1.6440, Accuracy: 0.7899, Precision: 0.7439, Recall: 0.6907, F1: 0.7044
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3396, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Label Memorization Analysis: 
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3396, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165

