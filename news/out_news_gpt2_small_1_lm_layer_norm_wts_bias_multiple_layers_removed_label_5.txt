Model: openai-community/gpt2, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:2
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
For early layers:  [0, 1, 2, 3]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.7393, Accuracy: 0.2497, Precision: 0.1848, Recall: 0.1711, F1: 0.1510
Validation Loss: 1.6821, Accuracy: 0.2772, Precision: 0.1905, Recall: 0.1798, F1: 0.1282
Testing Loss: 1.6923, Accuracy: 0.2838, Precision: 0.1496, Recall: 0.1841, F1: 0.1274
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9573, Accuracy: 0.1429, Precision: 0.0500, Recall: 0.2222, F1: 0.0762
Epoch 2/70
Train Loss: 1.6714, Accuracy: 0.2798, Precision: 0.3186, Recall: 0.1854, F1: 0.1578
Validation Loss: 1.6487, Accuracy: 0.3134, Precision: 0.2122, Recall: 0.2066, F1: 0.1626
Testing Loss: 1.6734, Accuracy: 0.2959, Precision: 0.1864, Recall: 0.1922, F1: 0.1496
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9198, Accuracy: 0.1190, Precision: 0.0250, Recall: 0.2000, F1: 0.0444
Epoch 3/70
Train Loss: 1.6461, Accuracy: 0.3009, Precision: 0.2061, Recall: 0.1993, F1: 0.1714
Validation Loss: 1.6258, Accuracy: 0.3518, Precision: 0.2542, Recall: 0.2233, F1: 0.1603
Testing Loss: 1.6204, Accuracy: 0.3370, Precision: 0.2357, Recall: 0.2142, F1: 0.1557
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8767, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 4/70
Train Loss: 1.6096, Accuracy: 0.3597, Precision: 0.2408, Recall: 0.2401, F1: 0.2094
Validation Loss: 1.4942, Accuracy: 0.4797, Precision: 0.2775, Recall: 0.3152, F1: 0.2702
Testing Loss: 1.4689, Accuracy: 0.4734, Precision: 0.2860, Recall: 0.3119, F1: 0.2718
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9776, Accuracy: 0.1429, Precision: 0.2263, Recall: 0.2222, F1: 0.0865
Epoch 5/70
Train Loss: 1.4800, Accuracy: 0.4468, Precision: 0.4186, Recall: 0.3001, F1: 0.2624
Validation Loss: 1.2422, Accuracy: 0.5480, Precision: 0.2891, Recall: 0.3654, F1: 0.3157
Testing Loss: 1.2237, Accuracy: 0.5725, Precision: 0.4705, Recall: 0.3873, F1: 0.3427
LM Predictions:  [0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8028, Accuracy: 0.0952, Precision: 0.0229, Recall: 0.1600, F1: 0.0400
Epoch 6/70
Train Loss: 1.3504, Accuracy: 0.5030, Precision: 0.3760, Recall: 0.3458, F1: 0.3153
Validation Loss: 1.0750, Accuracy: 0.6333, Precision: 0.6042, Recall: 0.4499, F1: 0.4274
Testing Loss: 1.0734, Accuracy: 0.6027, Precision: 0.5278, Recall: 0.4234, F1: 0.3947
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9959, Accuracy: 0.1190, Precision: 0.0270, Recall: 0.2000, F1: 0.0476
Epoch 7/70
Train Loss: 1.2229, Accuracy: 0.5468, Precision: 0.4266, Recall: 0.3947, F1: 0.3791
Validation Loss: 1.0266, Accuracy: 0.6397, Precision: 0.5875, Recall: 0.5375, F1: 0.5449
Testing Loss: 0.9923, Accuracy: 0.6449, Precision: 0.6005, Recall: 0.5440, F1: 0.5507
LM Predictions:  [0, 1, 0, 5, 4, 5, 3, 5, 4, 5, 5, 5, 2, 5, 0, 0, 0, 2, 0, 3, 3, 0, 2, 0, 1, 0, 1, 5, 3, 5, 2, 5, 5, 5, 5, 1, 2, 1, 0, 5, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5743, Accuracy: 0.1905, Precision: 0.2778, Recall: 0.1620, F1: 0.1907
Epoch 8/70
Train Loss: 1.1124, Accuracy: 0.6021, Precision: 0.5248, Recall: 0.4651, F1: 0.4642
Validation Loss: 0.9450, Accuracy: 0.6908, Precision: 0.6984, Recall: 0.5661, F1: 0.5837
Testing Loss: 0.8845, Accuracy: 0.6896, Precision: 0.7566, Recall: 0.5493, F1: 0.5656
LM Predictions:  [0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5421, Accuracy: 0.0714, Precision: 0.0167, Recall: 0.1000, F1: 0.0286
Epoch 9/70
Train Loss: 1.0142, Accuracy: 0.6267, Precision: 0.5662, Recall: 0.5079, F1: 0.5164
Validation Loss: 0.8820, Accuracy: 0.7463, Precision: 0.7461, Recall: 0.6390, F1: 0.6674
Testing Loss: 0.8289, Accuracy: 0.7283, Precision: 0.7021, Recall: 0.5924, F1: 0.6070
LM Predictions:  [0, 3, 0, 0, 4, 5, 0, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5900, Accuracy: 0.1190, Precision: 0.0655, Recall: 0.1500, F1: 0.0642
Epoch 10/70
Train Loss: 0.9451, Accuracy: 0.6685, Precision: 0.6093, Recall: 0.5512, F1: 0.5591
Validation Loss: 0.8043, Accuracy: 0.7591, Precision: 0.7643, Recall: 0.6499, F1: 0.6783
Testing Loss: 0.7570, Accuracy: 0.7524, Precision: 0.7676, Recall: 0.6259, F1: 0.6472
LM Predictions:  [0, 0, 0, 0, 4, 5, 0, 5, 0, 5, 5, 5, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4235, Accuracy: 0.0952, Precision: 0.1019, Recall: 0.1208, F1: 0.0646
Epoch 11/70
Train Loss: 0.8755, Accuracy: 0.6917, Precision: 0.6411, Recall: 0.5847, F1: 0.5975
Validation Loss: 0.7588, Accuracy: 0.7846, Precision: 0.7603, Recall: 0.6948, F1: 0.7164
Testing Loss: 0.7140, Accuracy: 0.7693, Precision: 0.7469, Recall: 0.6681, F1: 0.6871
LM Predictions:  [0, 0, 0, 0, 4, 5, 0, 5, 0, 4, 5, 5, 2, 5, 0, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 3, 0, 1, 0, 0, 5, 5, 5, 0, 1, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2661, Accuracy: 0.0952, Precision: 0.1061, Recall: 0.1208, F1: 0.0704
Epoch 12/70
Train Loss: 0.8507, Accuracy: 0.7093, Precision: 0.6557, Recall: 0.6010, F1: 0.6123
Validation Loss: 0.7206, Accuracy: 0.7783, Precision: 0.7484, Recall: 0.7323, F1: 0.7303
Testing Loss: 0.6268, Accuracy: 0.7947, Precision: 0.7675, Recall: 0.7459, F1: 0.7524
LM Predictions:  [0, 3, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 3, 5, 5, 0, 0, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8888, Accuracy: 0.0476, Precision: 0.0256, Recall: 0.0667, F1: 0.0370
Epoch 13/70
Train Loss: 0.8180, Accuracy: 0.7190, Precision: 0.6635, Recall: 0.6167, F1: 0.6305
Validation Loss: 0.6827, Accuracy: 0.8081, Precision: 0.7912, Recall: 0.7504, F1: 0.7667
Testing Loss: 0.6035, Accuracy: 0.8007, Precision: 0.7907, Recall: 0.7357, F1: 0.7562
LM Predictions:  [0, 0, 0, 0, 4, 5, 0, 5, 0, 5, 5, 5, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 0, 1, 0, 0, 5, 5, 5, 0, 1, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6025, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 14/70
Train Loss: 0.7929, Accuracy: 0.7173, Precision: 0.6611, Recall: 0.6151, F1: 0.6280
Validation Loss: 0.7302, Accuracy: 0.7846, Precision: 0.7637, Recall: 0.7030, F1: 0.7216
Testing Loss: 0.6201, Accuracy: 0.7971, Precision: 0.8033, Recall: 0.7075, F1: 0.7322
LM Predictions:  [0, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 5, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 5, 5, 0, 0, 1, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7298, Accuracy: 0.0714, Precision: 0.0200, Recall: 0.1000, F1: 0.0333
Epoch 15/70
Train Loss: 0.7408, Accuracy: 0.7451, Precision: 0.6900, Recall: 0.6508, F1: 0.6620
Validation Loss: 0.6408, Accuracy: 0.8166, Precision: 0.7807, Recall: 0.7642, F1: 0.7711
Testing Loss: 0.5413, Accuracy: 0.8237, Precision: 0.8058, Recall: 0.7759, F1: 0.7890
LM Predictions:  [0, 3, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 3, 5, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 3, 0, 0, 5, 5, 5, 0, 1, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4730, Accuracy: 0.0952, Precision: 0.1961, Recall: 0.1208, F1: 0.0825
Epoch 16/70
Train Loss: 0.7076, Accuracy: 0.7553, Precision: 0.6981, Recall: 0.6568, F1: 0.6686
Validation Loss: 0.6261, Accuracy: 0.8102, Precision: 0.7724, Recall: 0.7720, F1: 0.7677
Testing Loss: 0.5394, Accuracy: 0.8333, Precision: 0.7926, Recall: 0.8065, F1: 0.7977
LM Predictions:  [0, 3, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 1, 5, 0, 5, 5, 5, 0, 1, 0, 4, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4363, Accuracy: 0.0476, Precision: 0.1786, Recall: 0.0542, F1: 0.0546
Epoch 17/70
Train Loss: 0.7003, Accuracy: 0.7612, Precision: 0.7017, Recall: 0.6668, F1: 0.6788
Validation Loss: 0.5859, Accuracy: 0.8443, Precision: 0.8169, Recall: 0.7942, F1: 0.8027
Testing Loss: 0.5157, Accuracy: 0.8382, Precision: 0.8360, Recall: 0.7800, F1: 0.7953
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 4, 5, 5, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 5, 5, 4, 0, 4, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1590, Accuracy: 0.2143, Precision: 0.3303, Recall: 0.2208, F1: 0.1753
Epoch 18/70
Train Loss: 0.6712, Accuracy: 0.7697, Precision: 0.7171, Recall: 0.6757, F1: 0.6887
Validation Loss: 0.5808, Accuracy: 0.8486, Precision: 0.8114, Recall: 0.8058, F1: 0.8083
Testing Loss: 0.5202, Accuracy: 0.8297, Precision: 0.7990, Recall: 0.7843, F1: 0.7905
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2393, Accuracy: 0.1667, Precision: 0.3238, Recall: 0.1542, F1: 0.1610
Epoch 19/70
Train Loss: 0.6464, Accuracy: 0.7804, Precision: 0.7302, Recall: 0.6926, F1: 0.7058
Validation Loss: 0.6019, Accuracy: 0.8337, Precision: 0.8175, Recall: 0.7592, F1: 0.7796
Testing Loss: 0.5170, Accuracy: 0.8345, Precision: 0.8489, Recall: 0.7555, F1: 0.7798
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 0, 5, 0, 0, 1, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5268, Accuracy: 0.1190, Precision: 0.1944, Recall: 0.1542, F1: 0.0830
Epoch 20/70
Train Loss: 0.6454, Accuracy: 0.7852, Precision: 0.7401, Recall: 0.6998, F1: 0.7122
Validation Loss: 0.6001, Accuracy: 0.8316, Precision: 0.7938, Recall: 0.7944, F1: 0.7929
Testing Loss: 0.4909, Accuracy: 0.8357, Precision: 0.8057, Recall: 0.8001, F1: 0.8025
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 5, 3, 0, 3, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 4, 5, 0, 5, 5, 5, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0479, Accuracy: 0.1429, Precision: 0.3462, Recall: 0.1208, F1: 0.1508
Epoch 21/70
Train Loss: 0.6127, Accuracy: 0.7925, Precision: 0.7476, Recall: 0.7083, F1: 0.7214
Validation Loss: 0.5832, Accuracy: 0.8209, Precision: 0.7916, Recall: 0.7779, F1: 0.7803
Testing Loss: 0.4865, Accuracy: 0.8394, Precision: 0.8253, Recall: 0.7869, F1: 0.7961
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 3, 0, 3, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 3]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6288, Accuracy: 0.1190, Precision: 0.1513, Recall: 0.1333, F1: 0.0933
Epoch 22/70
Train Loss: 0.5894, Accuracy: 0.7996, Precision: 0.7551, Recall: 0.7184, F1: 0.7316
Validation Loss: 0.5734, Accuracy: 0.8337, Precision: 0.7969, Recall: 0.7855, F1: 0.7897
Testing Loss: 0.4814, Accuracy: 0.8454, Precision: 0.8328, Recall: 0.7889, F1: 0.8037
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 5, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3089, Accuracy: 0.1190, Precision: 0.2974, Recall: 0.1208, F1: 0.1186
Epoch 23/70
Train Loss: 0.5953, Accuracy: 0.8013, Precision: 0.7502, Recall: 0.7187, F1: 0.7298
Validation Loss: 0.5418, Accuracy: 0.8422, Precision: 0.8360, Recall: 0.7829, F1: 0.7980
Testing Loss: 0.4564, Accuracy: 0.8466, Precision: 0.8561, Recall: 0.7693, F1: 0.7855
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 5, 0, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2164, Accuracy: 0.1190, Precision: 0.1329, Recall: 0.1333, F1: 0.0870
Epoch 24/70
Train Loss: 0.5645, Accuracy: 0.8141, Precision: 0.7667, Recall: 0.7282, F1: 0.7408
Validation Loss: 0.6061, Accuracy: 0.8422, Precision: 0.7989, Recall: 0.8111, F1: 0.8018
Testing Loss: 0.5024, Accuracy: 0.8370, Precision: 0.7979, Recall: 0.7948, F1: 0.7922
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 3, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 1, 5, 0, 5, 5, 4, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9795, Accuracy: 0.1190, Precision: 0.3036, Recall: 0.1042, F1: 0.1260
Epoch 25/70
Train Loss: 0.5765, Accuracy: 0.8112, Precision: 0.7708, Recall: 0.7335, F1: 0.7469
Validation Loss: 0.5220, Accuracy: 0.8443, Precision: 0.8126, Recall: 0.7963, F1: 0.8033
Testing Loss: 0.4328, Accuracy: 0.8514, Precision: 0.8497, Recall: 0.7919, F1: 0.8096
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2440, Accuracy: 0.0952, Precision: 0.1287, Recall: 0.1000, F1: 0.0791
Epoch 26/70
Train Loss: 0.5520, Accuracy: 0.8155, Precision: 0.7642, Recall: 0.7340, F1: 0.7448
Validation Loss: 0.5641, Accuracy: 0.8401, Precision: 0.8015, Recall: 0.8151, F1: 0.8066
Testing Loss: 0.4495, Accuracy: 0.8466, Precision: 0.8155, Recall: 0.8050, F1: 0.8071
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 4, 4, 0, 5, 5, 5, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1813, Accuracy: 0.1190, Precision: 0.2786, Recall: 0.1042, F1: 0.1212
Epoch 27/70
Train Loss: 0.5492, Accuracy: 0.8134, Precision: 0.7585, Recall: 0.7299, F1: 0.7406
Validation Loss: 0.5844, Accuracy: 0.8380, Precision: 0.8062, Recall: 0.7740, F1: 0.7858
Testing Loss: 0.4350, Accuracy: 0.8563, Precision: 0.8626, Recall: 0.7874, F1: 0.8086
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 5, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6740, Accuracy: 0.0714, Precision: 0.0985, Recall: 0.0833, F1: 0.0525
Epoch 28/70
Train Loss: 0.5333, Accuracy: 0.8198, Precision: 0.7719, Recall: 0.7467, F1: 0.7566
Validation Loss: 0.5569, Accuracy: 0.8486, Precision: 0.8273, Recall: 0.7809, F1: 0.7994
Testing Loss: 0.4348, Accuracy: 0.8478, Precision: 0.8587, Recall: 0.7668, F1: 0.7851
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 0, 5, 5, 0, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5475, Accuracy: 0.1190, Precision: 0.1395, Recall: 0.1167, F1: 0.0952
Epoch 29/70
Train Loss: 0.5352, Accuracy: 0.8214, Precision: 0.7771, Recall: 0.7436, F1: 0.7565
Validation Loss: 0.5350, Accuracy: 0.8486, Precision: 0.8123, Recall: 0.8106, F1: 0.8100
Testing Loss: 0.4287, Accuracy: 0.8454, Precision: 0.8309, Recall: 0.7844, F1: 0.7961
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 5, 5, 0, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2907, Accuracy: 0.0952, Precision: 0.1833, Recall: 0.1000, F1: 0.0822
Epoch 30/70
Train Loss: 0.5258, Accuracy: 0.8250, Precision: 0.7836, Recall: 0.7502, F1: 0.7631
Validation Loss: 0.5487, Accuracy: 0.8571, Precision: 0.8437, Recall: 0.8077, F1: 0.8207
Testing Loss: 0.4377, Accuracy: 0.8575, Precision: 0.8579, Recall: 0.7877, F1: 0.8006
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1804, Accuracy: 0.1429, Precision: 0.1467, Recall: 0.1500, F1: 0.1071
Epoch 31/70
Train Loss: 0.5184, Accuracy: 0.8229, Precision: 0.7804, Recall: 0.7484, F1: 0.7604
Validation Loss: 0.5447, Accuracy: 0.8486, Precision: 0.8162, Recall: 0.8222, F1: 0.8153
Testing Loss: 0.4266, Accuracy: 0.8599, Precision: 0.8301, Recall: 0.8323, F1: 0.8305
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 5, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 0, 4, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0581, Accuracy: 0.0714, Precision: 0.1263, Recall: 0.0667, F1: 0.0721
Epoch 32/70
Train Loss: 0.4908, Accuracy: 0.8340, Precision: 0.7920, Recall: 0.7626, F1: 0.7742
Validation Loss: 0.6209, Accuracy: 0.8422, Precision: 0.8156, Recall: 0.7981, F1: 0.8042
Testing Loss: 0.4816, Accuracy: 0.8563, Precision: 0.8287, Recall: 0.8057, F1: 0.8142
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 1, 0, 0, 5, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8557, Accuracy: 0.1190, Precision: 0.1435, Recall: 0.1167, F1: 0.1004
Epoch 33/70
Train Loss: 0.4929, Accuracy: 0.8361, Precision: 0.7910, Recall: 0.7632, F1: 0.7741
Validation Loss: 0.5764, Accuracy: 0.8358, Precision: 0.8215, Recall: 0.7839, F1: 0.7950
Testing Loss: 0.4433, Accuracy: 0.8514, Precision: 0.8421, Recall: 0.7885, F1: 0.7970
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4211, Accuracy: 0.1429, Precision: 0.1467, Recall: 0.1500, F1: 0.1071
Epoch 34/70
Train Loss: 0.4946, Accuracy: 0.8366, Precision: 0.7922, Recall: 0.7665, F1: 0.7773
Validation Loss: 0.5286, Accuracy: 0.8507, Precision: 0.8158, Recall: 0.8168, F1: 0.8154
Testing Loss: 0.4095, Accuracy: 0.8599, Precision: 0.8258, Recall: 0.8188, F1: 0.8204
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 5, 4, 5, 0, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3551, Accuracy: 0.0952, Precision: 0.1287, Recall: 0.1000, F1: 0.0791
Epoch 35/70
Train Loss: 0.4724, Accuracy: 0.8378, Precision: 0.7923, Recall: 0.7706, F1: 0.7791
Validation Loss: 0.5364, Accuracy: 0.8507, Precision: 0.8426, Recall: 0.7870, F1: 0.8078
Testing Loss: 0.4201, Accuracy: 0.8539, Precision: 0.8540, Recall: 0.7794, F1: 0.7964
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3653, Accuracy: 0.0952, Precision: 0.1042, Recall: 0.1167, F1: 0.0623
Epoch 36/70
Train Loss: 0.4739, Accuracy: 0.8380, Precision: 0.7910, Recall: 0.7685, F1: 0.7777
Validation Loss: 0.4934, Accuracy: 0.8550, Precision: 0.8234, Recall: 0.8341, F1: 0.8251
Testing Loss: 0.4040, Accuracy: 0.8623, Precision: 0.8338, Recall: 0.8284, F1: 0.8298
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3211, Accuracy: 0.0714, Precision: 0.1239, Recall: 0.0667, F1: 0.0698
Epoch 37/70
Train Loss: 0.4576, Accuracy: 0.8468, Precision: 0.8017, Recall: 0.7767, F1: 0.7868
Validation Loss: 0.5333, Accuracy: 0.8422, Precision: 0.8089, Recall: 0.8241, F1: 0.8121
Testing Loss: 0.4228, Accuracy: 0.8539, Precision: 0.8164, Recall: 0.8313, F1: 0.8216
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 4, 5, 5, 5, 3, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 3, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4079, Accuracy: 0.0714, Precision: 0.1263, Recall: 0.0667, F1: 0.0721
Epoch 38/70
Train Loss: 0.4594, Accuracy: 0.8473, Precision: 0.8029, Recall: 0.7791, F1: 0.7889
Validation Loss: 0.4976, Accuracy: 0.8678, Precision: 0.8469, Recall: 0.8293, F1: 0.8371
Testing Loss: 0.3728, Accuracy: 0.8696, Precision: 0.8479, Recall: 0.8210, F1: 0.8330
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 5, 0, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0929, Accuracy: 0.1429, Precision: 0.3028, Recall: 0.1542, F1: 0.1283
Epoch 39/70
Train Loss: 0.4535, Accuracy: 0.8435, Precision: 0.7989, Recall: 0.7784, F1: 0.7869
Validation Loss: 0.5164, Accuracy: 0.8614, Precision: 0.8260, Recall: 0.8237, F1: 0.8238
Testing Loss: 0.3809, Accuracy: 0.8671, Precision: 0.8393, Recall: 0.8119, F1: 0.8202
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0953, Accuracy: 0.1429, Precision: 0.1488, Recall: 0.1500, F1: 0.1099
Epoch 40/70
Train Loss: 0.4320, Accuracy: 0.8527, Precision: 0.8139, Recall: 0.7894, F1: 0.7999
Validation Loss: 0.5291, Accuracy: 0.8635, Precision: 0.8252, Recall: 0.8252, F1: 0.8245
Testing Loss: 0.3870, Accuracy: 0.8647, Precision: 0.8426, Recall: 0.8101, F1: 0.8202
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0046, Accuracy: 0.1667, Precision: 0.1571, Recall: 0.1667, F1: 0.1274
Epoch 41/70
Train Loss: 0.4503, Accuracy: 0.8461, Precision: 0.7968, Recall: 0.7778, F1: 0.7858
Validation Loss: 0.5020, Accuracy: 0.8593, Precision: 0.8323, Recall: 0.8187, F1: 0.8245
Testing Loss: 0.3882, Accuracy: 0.8671, Precision: 0.8504, Recall: 0.8118, F1: 0.8267
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3584, Accuracy: 0.1190, Precision: 0.2944, Recall: 0.1208, F1: 0.1150
Epoch 42/70
Train Loss: 0.4344, Accuracy: 0.8546, Precision: 0.8080, Recall: 0.7898, F1: 0.7978
Validation Loss: 0.5450, Accuracy: 0.8635, Precision: 0.8600, Recall: 0.8054, F1: 0.8229
Testing Loss: 0.4136, Accuracy: 0.8551, Precision: 0.8607, Recall: 0.7714, F1: 0.7923
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3666, Accuracy: 0.1190, Precision: 0.1303, Recall: 0.1333, F1: 0.0835
Epoch 43/70
Train Loss: 0.4085, Accuracy: 0.8580, Precision: 0.8144, Recall: 0.7961, F1: 0.8040
Validation Loss: 0.5342, Accuracy: 0.8571, Precision: 0.8529, Recall: 0.8009, F1: 0.8184
Testing Loss: 0.4082, Accuracy: 0.8551, Precision: 0.8522, Recall: 0.7815, F1: 0.7986
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4081, Accuracy: 0.1190, Precision: 0.1296, Recall: 0.1333, F1: 0.0825
Epoch 44/70
Train Loss: 0.4210, Accuracy: 0.8618, Precision: 0.8200, Recall: 0.8001, F1: 0.8087
Validation Loss: 0.5324, Accuracy: 0.8657, Precision: 0.8486, Recall: 0.8165, F1: 0.8287
Testing Loss: 0.3917, Accuracy: 0.8720, Precision: 0.8594, Recall: 0.8124, F1: 0.8262
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 4, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9327, Accuracy: 0.1429, Precision: 0.3005, Recall: 0.1542, F1: 0.1254
Epoch 45/70
Train Loss: 0.4161, Accuracy: 0.8553, Precision: 0.8136, Recall: 0.7960, F1: 0.8039
Validation Loss: 0.5608, Accuracy: 0.8529, Precision: 0.8214, Recall: 0.8256, F1: 0.8225
Testing Loss: 0.4302, Accuracy: 0.8527, Precision: 0.8325, Recall: 0.8058, F1: 0.8140
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 5, 1, 5, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9822, Accuracy: 0.0952, Precision: 0.1307, Recall: 0.1000, F1: 0.0816
Epoch 46/70
Train Loss: 0.3916, Accuracy: 0.8674, Precision: 0.8299, Recall: 0.8107, F1: 0.8190
Validation Loss: 0.5368, Accuracy: 0.8550, Precision: 0.8272, Recall: 0.8054, F1: 0.8145
Testing Loss: 0.3823, Accuracy: 0.8732, Precision: 0.8497, Recall: 0.8193, F1: 0.8320
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 5, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0040, Accuracy: 0.1190, Precision: 0.2953, Recall: 0.1208, F1: 0.1161
Epoch 47/70
Train Loss: 0.3979, Accuracy: 0.8610, Precision: 0.8215, Recall: 0.7985, F1: 0.8081
Validation Loss: 0.4893, Accuracy: 0.8593, Precision: 0.8280, Recall: 0.8283, F1: 0.8269
Testing Loss: 0.3881, Accuracy: 0.8720, Precision: 0.8469, Recall: 0.8367, F1: 0.8394
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 5, 5, 5, 4, 5, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1053, Accuracy: 0.1190, Precision: 0.1458, Recall: 0.1167, F1: 0.1032
Epoch 48/70
Train Loss: 0.4111, Accuracy: 0.8587, Precision: 0.8173, Recall: 0.7988, F1: 0.8072
Validation Loss: 0.4956, Accuracy: 0.8678, Precision: 0.8326, Recall: 0.8203, F1: 0.8232
Testing Loss: 0.3739, Accuracy: 0.8623, Precision: 0.8316, Recall: 0.7919, F1: 0.7956
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9241, Accuracy: 0.1429, Precision: 0.1458, Recall: 0.1500, F1: 0.1059
Epoch 49/70
Train Loss: 0.3943, Accuracy: 0.8705, Precision: 0.8329, Recall: 0.8110, F1: 0.8201
Validation Loss: 0.5048, Accuracy: 0.8507, Precision: 0.8264, Recall: 0.8116, F1: 0.8174
Testing Loss: 0.3975, Accuracy: 0.8708, Precision: 0.8649, Recall: 0.8282, F1: 0.8422
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 5, 4, 5, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 5, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9845, Accuracy: 0.0952, Precision: 0.1333, Recall: 0.0833, F1: 0.0848
Epoch 50/70
Train Loss: 0.3828, Accuracy: 0.8679, Precision: 0.8272, Recall: 0.8081, F1: 0.8162
Validation Loss: 0.5107, Accuracy: 0.8593, Precision: 0.8301, Recall: 0.8199, F1: 0.8237
Testing Loss: 0.3983, Accuracy: 0.8732, Precision: 0.8604, Recall: 0.8239, F1: 0.8370
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 5, 4, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 4, 0, 0, 0, 5, 5, 4, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8908, Accuracy: 0.0952, Precision: 0.0926, Recall: 0.0833, F1: 0.0770
Epoch 51/70
Train Loss: 0.3843, Accuracy: 0.8696, Precision: 0.8274, Recall: 0.8119, F1: 0.8189
Validation Loss: 0.5127, Accuracy: 0.8678, Precision: 0.8439, Recall: 0.8179, F1: 0.8275
Testing Loss: 0.3774, Accuracy: 0.8708, Precision: 0.8502, Recall: 0.8180, F1: 0.8288
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6929, Accuracy: 0.1667, Precision: 0.3144, Recall: 0.1708, F1: 0.1455
Epoch 52/70
Train Loss: 0.3748, Accuracy: 0.8696, Precision: 0.8332, Recall: 0.8119, F1: 0.8207
Validation Loss: 0.4931, Accuracy: 0.8614, Precision: 0.8375, Recall: 0.8045, F1: 0.8174
Testing Loss: 0.3768, Accuracy: 0.8732, Precision: 0.8627, Recall: 0.8206, F1: 0.8367
LM Predictions:  [0, 5, 5, 0, 5, 0, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6573, Accuracy: 0.1429, Precision: 0.3551, Recall: 0.1542, F1: 0.1283
Epoch 53/70
Train Loss: 0.3741, Accuracy: 0.8710, Precision: 0.8344, Recall: 0.8150, F1: 0.8235
Validation Loss: 0.5315, Accuracy: 0.8614, Precision: 0.8361, Recall: 0.8180, F1: 0.8255
Testing Loss: 0.4181, Accuracy: 0.8659, Precision: 0.8616, Recall: 0.8150, F1: 0.8324
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 4, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9507, Accuracy: 0.1190, Precision: 0.1167, Recall: 0.1167, F1: 0.0933
Epoch 54/70
Train Loss: 0.3628, Accuracy: 0.8746, Precision: 0.8361, Recall: 0.8217, F1: 0.8283
Validation Loss: 0.5343, Accuracy: 0.8593, Precision: 0.8297, Recall: 0.8167, F1: 0.8210
Testing Loss: 0.3984, Accuracy: 0.8708, Precision: 0.8566, Recall: 0.8313, F1: 0.8402
LM Predictions:  [5, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 4, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 5, 0, 5, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7776, Accuracy: 0.1429, Precision: 0.1296, Recall: 0.1333, F1: 0.1123
Epoch 55/70
Train Loss: 0.3688, Accuracy: 0.8724, Precision: 0.8297, Recall: 0.8154, F1: 0.8216
Validation Loss: 0.5048, Accuracy: 0.8699, Precision: 0.8391, Recall: 0.8271, F1: 0.8318
Testing Loss: 0.3881, Accuracy: 0.8720, Precision: 0.8589, Recall: 0.8256, F1: 0.8371
LM Predictions:  [5, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 4, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8019, Accuracy: 0.0952, Precision: 0.1088, Recall: 0.0833, F1: 0.0806
Epoch 56/70
Train Loss: 0.3649, Accuracy: 0.8691, Precision: 0.8289, Recall: 0.8139, F1: 0.8207
Validation Loss: 0.5057, Accuracy: 0.8657, Precision: 0.8315, Recall: 0.8304, F1: 0.8298
Testing Loss: 0.3876, Accuracy: 0.8635, Precision: 0.8263, Recall: 0.8212, F1: 0.8225
LM Predictions:  [5, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 0, 5, 5, 4, 0, 4, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5892, Accuracy: 0.1190, Precision: 0.1431, Recall: 0.1000, F1: 0.1040
Epoch 57/70
Train Loss: 0.3496, Accuracy: 0.8821, Precision: 0.8507, Recall: 0.8367, F1: 0.8430
Validation Loss: 0.5419, Accuracy: 0.8486, Precision: 0.8225, Recall: 0.8029, F1: 0.8107
Testing Loss: 0.4338, Accuracy: 0.8514, Precision: 0.8450, Recall: 0.8063, F1: 0.8215
LM Predictions:  [5, 5, 5, 0, 5, 5, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0465, Accuracy: 0.0714, Precision: 0.1759, Recall: 0.0667, F1: 0.0700
Epoch 58/70
Train Loss: 0.3512, Accuracy: 0.8774, Precision: 0.8386, Recall: 0.8267, F1: 0.8322
Validation Loss: 0.5698, Accuracy: 0.8443, Precision: 0.8742, Recall: 0.7675, F1: 0.7970
Testing Loss: 0.4522, Accuracy: 0.8490, Precision: 0.8980, Recall: 0.7521, F1: 0.7721
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 0, 4, 0, 0, 0, 3, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5707, Accuracy: 0.1429, Precision: 0.1319, Recall: 0.1667, F1: 0.0873
Epoch 59/70
Train Loss: 0.3467, Accuracy: 0.8829, Precision: 0.8464, Recall: 0.8292, F1: 0.8365
Validation Loss: 0.5924, Accuracy: 0.8507, Precision: 0.8468, Recall: 0.7775, F1: 0.8028
Testing Loss: 0.4650, Accuracy: 0.8394, Precision: 0.8606, Recall: 0.7425, F1: 0.7715
LM Predictions:  [0, 5, 0, 0, 0, 0, 5, 0, 4, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9631, Accuracy: 0.1429, Precision: 0.3500, Recall: 0.1542, F1: 0.1212
Epoch 60/70
Train Loss: 0.3482, Accuracy: 0.8810, Precision: 0.8458, Recall: 0.8264, F1: 0.8351
Validation Loss: 0.5527, Accuracy: 0.8571, Precision: 0.8354, Recall: 0.8052, F1: 0.8153
Testing Loss: 0.4070, Accuracy: 0.8623, Precision: 0.8523, Recall: 0.8000, F1: 0.8153
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 0, 5, 0, 5, 0, 0, 3, 0, 3, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4509, Accuracy: 0.1905, Precision: 0.3699, Recall: 0.1875, F1: 0.1711
Epoch 61/70
Train Loss: 0.3387, Accuracy: 0.8788, Precision: 0.8405, Recall: 0.8255, F1: 0.8324
Validation Loss: 0.5499, Accuracy: 0.8593, Precision: 0.8388, Recall: 0.8174, F1: 0.8237
Testing Loss: 0.4331, Accuracy: 0.8575, Precision: 0.8472, Recall: 0.7922, F1: 0.8052
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 4, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7099, Accuracy: 0.1667, Precision: 0.1329, Recall: 0.1667, F1: 0.1190
Epoch 62/70
Train Loss: 0.3316, Accuracy: 0.8871, Precision: 0.8523, Recall: 0.8400, F1: 0.8456
Validation Loss: 0.5605, Accuracy: 0.8635, Precision: 0.8363, Recall: 0.8055, F1: 0.8183
Testing Loss: 0.4132, Accuracy: 0.8684, Precision: 0.8498, Recall: 0.8011, F1: 0.8178
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0, 4, 5, 0, 5, 5, 4, 0, 0, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3068, Accuracy: 0.1905, Precision: 0.3167, Recall: 0.1917, F1: 0.1781
Epoch 63/70
Train Loss: 0.3226, Accuracy: 0.8850, Precision: 0.8457, Recall: 0.8302, F1: 0.8372
Validation Loss: 0.5351, Accuracy: 0.8550, Precision: 0.8204, Recall: 0.8107, F1: 0.8148
Testing Loss: 0.4316, Accuracy: 0.8575, Precision: 0.8411, Recall: 0.8143, F1: 0.8244
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 5, 4, 5, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8861, Accuracy: 0.1429, Precision: 0.3529, Recall: 0.1375, F1: 0.1443
Epoch 64/70
Train Loss: 0.3286, Accuracy: 0.8874, Precision: 0.8470, Recall: 0.8383, F1: 0.8423
Validation Loss: 0.5922, Accuracy: 0.8486, Precision: 0.8484, Recall: 0.7725, F1: 0.7968
Testing Loss: 0.4584, Accuracy: 0.8563, Precision: 0.8826, Recall: 0.7633, F1: 0.7903
LM Predictions:  [0, 3, 0, 0, 0, 0, 5, 0, 4, 5, 0, 0, 2, 0, 5, 0, 0, 5, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5291, Accuracy: 0.1905, Precision: 0.4061, Recall: 0.1917, F1: 0.1716
Epoch 65/70
Train Loss: 0.3201, Accuracy: 0.8829, Precision: 0.8386, Recall: 0.8223, F1: 0.8292
Validation Loss: 0.5436, Accuracy: 0.8571, Precision: 0.8521, Recall: 0.8044, F1: 0.8236
Testing Loss: 0.4266, Accuracy: 0.8539, Precision: 0.8539, Recall: 0.7938, F1: 0.8167
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5852, Accuracy: 0.1667, Precision: 0.3180, Recall: 0.1708, F1: 0.1501
Epoch 66/70
Train Loss: 0.3192, Accuracy: 0.8864, Precision: 0.8475, Recall: 0.8386, F1: 0.8427
Validation Loss: 0.5486, Accuracy: 0.8614, Precision: 0.8407, Recall: 0.7980, F1: 0.8151
Testing Loss: 0.4201, Accuracy: 0.8635, Precision: 0.8529, Recall: 0.8040, F1: 0.8235
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 2, 0, 0, 0, 5, 5, 0, 3, 0, 0, 3, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 0, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4789, Accuracy: 0.1905, Precision: 0.4662, Recall: 0.1875, F1: 0.1796
Epoch 67/70
Train Loss: 0.3111, Accuracy: 0.8916, Precision: 0.8528, Recall: 0.8384, F1: 0.8450
Validation Loss: 0.5484, Accuracy: 0.8593, Precision: 0.8563, Recall: 0.7960, F1: 0.8173
Testing Loss: 0.4418, Accuracy: 0.8514, Precision: 0.8624, Recall: 0.7698, F1: 0.7884
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 0, 4, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3112, Accuracy: 0.2143, Precision: 0.4845, Recall: 0.2042, F1: 0.1865
Epoch 68/70
Train Loss: 0.3067, Accuracy: 0.8883, Precision: 0.8531, Recall: 0.8416, F1: 0.8469
Validation Loss: 0.5478, Accuracy: 0.8571, Precision: 0.8315, Recall: 0.8097, F1: 0.8189
Testing Loss: 0.4220, Accuracy: 0.8720, Precision: 0.8497, Recall: 0.8259, F1: 0.8361
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 5, 0, 5, 5, 0, 3, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 0, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4730, Accuracy: 0.1905, Precision: 0.4821, Recall: 0.1875, F1: 0.1772
Epoch 69/70
Train Loss: 0.2993, Accuracy: 0.8942, Precision: 0.8543, Recall: 0.8485, F1: 0.8513
Validation Loss: 0.5927, Accuracy: 0.8443, Precision: 0.8176, Recall: 0.7915, F1: 0.8017
Testing Loss: 0.4534, Accuracy: 0.8708, Precision: 0.8643, Recall: 0.8077, F1: 0.8242
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 0, 4, 5, 0, 0, 2, 0, 5, 0, 5, 4, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 5, 0, 4, 5, 0, 0, 5, 4, 0, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1794, Accuracy: 0.2619, Precision: 0.4384, Recall: 0.2375, F1: 0.2282
Epoch 70/70
Train Loss: 0.3099, Accuracy: 0.8885, Precision: 0.8518, Recall: 0.8340, F1: 0.8419
Validation Loss: 0.5325, Accuracy: 0.8635, Precision: 0.8313, Recall: 0.8215, F1: 0.8261
Testing Loss: 0.4104, Accuracy: 0.8647, Precision: 0.8285, Recall: 0.8282, F1: 0.8276
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 0, 5, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3049, Accuracy: 0.1429, Precision: 0.3125, Recall: 0.1375, F1: 0.1402
For middle layers:  [4, 5, 6, 7]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.8037, Accuracy: 0.2665, Precision: 0.1891, Recall: 0.1871, F1: 0.1770
Validation Loss: 1.5783, Accuracy: 0.4243, Precision: 0.2725, Recall: 0.2839, F1: 0.2516
Testing Loss: 1.5793, Accuracy: 0.3768, Precision: 0.2084, Recall: 0.2513, F1: 0.2209
LM Predictions:  [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9032, Accuracy: 0.1190, Precision: 0.0600, Recall: 0.1822, F1: 0.0724
Epoch 2/70
Train Loss: 1.6368, Accuracy: 0.3334, Precision: 0.2208, Recall: 0.2258, F1: 0.2014
Validation Loss: 1.4309, Accuracy: 0.5096, Precision: 0.3288, Recall: 0.3425, F1: 0.3025
Testing Loss: 1.4183, Accuracy: 0.5121, Precision: 0.3410, Recall: 0.3424, F1: 0.3033
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9595, Accuracy: 0.1190, Precision: 0.0278, Recall: 0.2000, F1: 0.0488
Epoch 3/70
Train Loss: 1.4704, Accuracy: 0.4413, Precision: 0.3496, Recall: 0.3035, F1: 0.2759
Validation Loss: 1.0369, Accuracy: 0.6311, Precision: 0.5712, Recall: 0.4567, F1: 0.4413
Testing Loss: 0.9693, Accuracy: 0.6401, Precision: 0.5673, Recall: 0.4667, F1: 0.4548
LM Predictions:  [0, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 3, 3, 0, 0, 0, 2, 0, 0, 3, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5189, Accuracy: 0.1667, Precision: 0.1115, Recall: 0.2200, F1: 0.1150
Epoch 4/70
Train Loss: 0.9729, Accuracy: 0.6616, Precision: 0.5846, Recall: 0.5259, F1: 0.5263
Validation Loss: 0.7752, Accuracy: 0.7633, Precision: 0.6546, Recall: 0.6281, F1: 0.6274
Testing Loss: 0.6944, Accuracy: 0.8080, Precision: 0.6892, Recall: 0.6796, F1: 0.6778
LM Predictions:  [0, 3, 3, 0, 4, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 3, 0, 0, 3, 3, 3]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.2935, Accuracy: 0.0714, Precision: 0.0214, Recall: 0.1200, F1: 0.0364
Epoch 5/70
Train Loss: 0.7055, Accuracy: 0.7659, Precision: 0.6698, Recall: 0.6493, F1: 0.6461
Validation Loss: 0.6331, Accuracy: 0.8017, Precision: 0.7345, Recall: 0.6950, F1: 0.6939
Testing Loss: 0.5374, Accuracy: 0.8225, Precision: 0.7601, Recall: 0.7182, F1: 0.7141
LM Predictions:  [0, 3, 3, 0, 4, 0, 3, 5, 0, 3, 0, 0, 0, 0, 0, 0, 3, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 3, 0, 0, 3, 3, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.6278, Accuracy: 0.0714, Precision: 0.0192, Recall: 0.1000, F1: 0.0323
Epoch 6/70
Train Loss: 0.5926, Accuracy: 0.8089, Precision: 0.7350, Recall: 0.7019, F1: 0.7053
Validation Loss: 0.6334, Accuracy: 0.8337, Precision: 0.7849, Recall: 0.7426, F1: 0.7474
Testing Loss: 0.5096, Accuracy: 0.8430, Precision: 0.8269, Recall: 0.7563, F1: 0.7657
LM Predictions:  [0, 3, 3, 0, 4, 0, 3, 5, 0, 2, 0, 0, 0, 0, 3, 0, 3, 3, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 5, 0, 0, 3, 0, 0, 3, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.3933, Accuracy: 0.0952, Precision: 0.0394, Recall: 0.1167, F1: 0.0520
Epoch 7/70
Train Loss: 0.5517, Accuracy: 0.8238, Precision: 0.7564, Recall: 0.7256, F1: 0.7330
Validation Loss: 0.5867, Accuracy: 0.8358, Precision: 0.7642, Recall: 0.7365, F1: 0.7357
Testing Loss: 0.4590, Accuracy: 0.8671, Precision: 0.8579, Recall: 0.7916, F1: 0.8052
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 2, 0, 0, 0, 0, 3, 0, 5, 3, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 5, 0, 0, 3, 1, 0, 3, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.0251, Accuracy: 0.1429, Precision: 0.1017, Recall: 0.1667, F1: 0.0905
Epoch 8/70
Train Loss: 0.5145, Accuracy: 0.8354, Precision: 0.7783, Recall: 0.7400, F1: 0.7467
Validation Loss: 0.5765, Accuracy: 0.8507, Precision: 0.8091, Recall: 0.7696, F1: 0.7779
Testing Loss: 0.4498, Accuracy: 0.8732, Precision: 0.8569, Recall: 0.7985, F1: 0.8100
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 4, 0, 0, 0, 0, 3, 0, 5, 3, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 5, 0, 0, 3, 0, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8322, Accuracy: 0.1190, Precision: 0.0673, Recall: 0.1500, F1: 0.0668
Epoch 9/70
Train Loss: 0.4976, Accuracy: 0.8406, Precision: 0.7879, Recall: 0.7556, F1: 0.7639
Validation Loss: 0.5270, Accuracy: 0.8486, Precision: 0.8212, Recall: 0.7701, F1: 0.7865
Testing Loss: 0.4569, Accuracy: 0.8659, Precision: 0.8593, Recall: 0.7879, F1: 0.8038
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 4, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 4, 4, 0, 5, 0, 0, 0, 0, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.9699, Accuracy: 0.0952, Precision: 0.0526, Recall: 0.1167, F1: 0.0545
Epoch 10/70
Train Loss: 0.4542, Accuracy: 0.8553, Precision: 0.8092, Recall: 0.7767, F1: 0.7871
Validation Loss: 0.5233, Accuracy: 0.8529, Precision: 0.8266, Recall: 0.7954, F1: 0.8057
Testing Loss: 0.4228, Accuracy: 0.8768, Precision: 0.8503, Recall: 0.8251, F1: 0.8359
LM Predictions:  [0, 3, 0, 5, 4, 0, 5, 5, 0, 5, 5, 5, 5, 5, 3, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.0053, Accuracy: 0.0714, Precision: 0.1019, Recall: 0.0833, F1: 0.0568
Epoch 11/70
Train Loss: 0.4411, Accuracy: 0.8632, Precision: 0.8144, Recall: 0.7920, F1: 0.8004
Validation Loss: 0.5068, Accuracy: 0.8635, Precision: 0.8447, Recall: 0.8101, F1: 0.8207
Testing Loss: 0.3884, Accuracy: 0.8792, Precision: 0.8500, Recall: 0.8212, F1: 0.8313
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6260, Accuracy: 0.0714, Precision: 0.0200, Recall: 0.1000, F1: 0.0333
Epoch 12/70
Train Loss: 0.4204, Accuracy: 0.8625, Precision: 0.8156, Recall: 0.7971, F1: 0.8047
Validation Loss: 0.4855, Accuracy: 0.8571, Precision: 0.8212, Recall: 0.8216, F1: 0.8200
Testing Loss: 0.3907, Accuracy: 0.8901, Precision: 0.8595, Recall: 0.8595, F1: 0.8586
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 3, 5, 5, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5474, Accuracy: 0.0714, Precision: 0.0385, Recall: 0.1000, F1: 0.0556
Epoch 13/70
Train Loss: 0.4028, Accuracy: 0.8663, Precision: 0.8214, Recall: 0.8012, F1: 0.8098
Validation Loss: 0.5190, Accuracy: 0.8465, Precision: 0.8286, Recall: 0.7810, F1: 0.7976
Testing Loss: 0.4252, Accuracy: 0.8696, Precision: 0.8616, Recall: 0.7914, F1: 0.8103
LM Predictions:  [0, 0, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8637, Accuracy: 0.0714, Precision: 0.0200, Recall: 0.1000, F1: 0.0333
Epoch 14/70
Train Loss: 0.3773, Accuracy: 0.8776, Precision: 0.8403, Recall: 0.8099, F1: 0.8221
Validation Loss: 0.5032, Accuracy: 0.8721, Precision: 0.8396, Recall: 0.8341, F1: 0.8348
Testing Loss: 0.4021, Accuracy: 0.8877, Precision: 0.8559, Recall: 0.8539, F1: 0.8545
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 0, 3, 1, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5988, Accuracy: 0.0476, Precision: 0.0278, Recall: 0.0667, F1: 0.0392
Epoch 15/70
Train Loss: 0.3696, Accuracy: 0.8786, Precision: 0.8346, Recall: 0.8222, F1: 0.8278
Validation Loss: 0.4777, Accuracy: 0.8742, Precision: 0.8438, Recall: 0.8331, F1: 0.8368
Testing Loss: 0.3787, Accuracy: 0.8853, Precision: 0.8569, Recall: 0.8426, F1: 0.8481
LM Predictions:  [0, 3, 5, 5, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5347, Accuracy: 0.0714, Precision: 0.0250, Recall: 0.1000, F1: 0.0400
Epoch 16/70
Train Loss: 0.3584, Accuracy: 0.8812, Precision: 0.8336, Recall: 0.8172, F1: 0.8242
Validation Loss: 0.4771, Accuracy: 0.8785, Precision: 0.8436, Recall: 0.8485, F1: 0.8456
Testing Loss: 0.3833, Accuracy: 0.8949, Precision: 0.8684, Recall: 0.8723, F1: 0.8699
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2435, Accuracy: 0.0952, Precision: 0.1250, Recall: 0.1167, F1: 0.0866
Epoch 17/70
Train Loss: 0.3549, Accuracy: 0.8810, Precision: 0.8377, Recall: 0.8265, F1: 0.8316
Validation Loss: 0.4849, Accuracy: 0.8721, Precision: 0.8585, Recall: 0.8367, F1: 0.8457
Testing Loss: 0.4001, Accuracy: 0.8804, Precision: 0.8562, Recall: 0.8347, F1: 0.8439
LM Predictions:  [0, 3, 5, 0, 5, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3988, Accuracy: 0.0714, Precision: 0.0238, Recall: 0.1000, F1: 0.0385
Epoch 18/70
Train Loss: 0.3373, Accuracy: 0.8874, Precision: 0.8455, Recall: 0.8302, F1: 0.8370
Validation Loss: 0.5012, Accuracy: 0.8699, Precision: 0.8386, Recall: 0.8238, F1: 0.8289
Testing Loss: 0.3860, Accuracy: 0.8901, Precision: 0.8600, Recall: 0.8597, F1: 0.8596
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2153, Accuracy: 0.0952, Precision: 0.1167, Recall: 0.1167, F1: 0.0778
Epoch 19/70
Train Loss: 0.3250, Accuracy: 0.8935, Precision: 0.8528, Recall: 0.8412, F1: 0.8466
Validation Loss: 0.4835, Accuracy: 0.8742, Precision: 0.8338, Recall: 0.8277, F1: 0.8303
Testing Loss: 0.3832, Accuracy: 0.8877, Precision: 0.8628, Recall: 0.8475, F1: 0.8540
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 0, 4, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9674, Accuracy: 0.1190, Precision: 0.1361, Recall: 0.1333, F1: 0.0913
Epoch 20/70
Train Loss: 0.3153, Accuracy: 0.8935, Precision: 0.8534, Recall: 0.8431, F1: 0.8478
Validation Loss: 0.5041, Accuracy: 0.8785, Precision: 0.8453, Recall: 0.8412, F1: 0.8413
Testing Loss: 0.3835, Accuracy: 0.8841, Precision: 0.8551, Recall: 0.8468, F1: 0.8491
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 0, 4, 0, 0, 5, 5, 5, 4]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8038, Accuracy: 0.1190, Precision: 0.1111, Recall: 0.1333, F1: 0.0911
Epoch 21/70
Train Loss: 0.2977, Accuracy: 0.8995, Precision: 0.8611, Recall: 0.8566, F1: 0.8588
Validation Loss: 0.4802, Accuracy: 0.8870, Precision: 0.8554, Recall: 0.8507, F1: 0.8524
Testing Loss: 0.3960, Accuracy: 0.8901, Precision: 0.8615, Recall: 0.8576, F1: 0.8588
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 0, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1668, Accuracy: 0.1190, Precision: 0.2024, Recall: 0.1333, F1: 0.1082
Epoch 22/70
Train Loss: 0.2818, Accuracy: 0.9066, Precision: 0.8700, Recall: 0.8623, F1: 0.8659
Validation Loss: 0.5056, Accuracy: 0.8785, Precision: 0.8414, Recall: 0.8355, F1: 0.8379
Testing Loss: 0.4001, Accuracy: 0.8841, Precision: 0.8557, Recall: 0.8452, F1: 0.8499
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 0, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7768, Accuracy: 0.1190, Precision: 0.1961, Recall: 0.1333, F1: 0.1010
Epoch 23/70
Train Loss: 0.2699, Accuracy: 0.9078, Precision: 0.8713, Recall: 0.8607, F1: 0.8657
Validation Loss: 0.5256, Accuracy: 0.8742, Precision: 0.8327, Recall: 0.8408, F1: 0.8363
Testing Loss: 0.4099, Accuracy: 0.8816, Precision: 0.8490, Recall: 0.8439, F1: 0.8462
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 5, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8881, Accuracy: 0.1429, Precision: 0.2329, Recall: 0.1500, F1: 0.1346
Epoch 24/70
Train Loss: 0.2623, Accuracy: 0.9108, Precision: 0.8737, Recall: 0.8709, F1: 0.8723
Validation Loss: 0.5532, Accuracy: 0.8657, Precision: 0.8395, Recall: 0.7941, F1: 0.8112
Testing Loss: 0.4319, Accuracy: 0.8708, Precision: 0.8551, Recall: 0.7863, F1: 0.8068
LM Predictions:  [0, 5, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 5, 0, 5, 0, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9530, Accuracy: 0.0952, Precision: 0.1859, Recall: 0.1167, F1: 0.0626
Epoch 25/70
Train Loss: 0.2485, Accuracy: 0.9125, Precision: 0.8760, Recall: 0.8682, F1: 0.8719
Validation Loss: 0.5280, Accuracy: 0.8721, Precision: 0.8329, Recall: 0.8076, F1: 0.8177
Testing Loss: 0.3987, Accuracy: 0.8804, Precision: 0.8563, Recall: 0.8315, F1: 0.8421
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 5, 0, 5, 0, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7111, Accuracy: 0.1190, Precision: 0.2738, Recall: 0.1375, F1: 0.1033
Epoch 26/70
Train Loss: 0.2441, Accuracy: 0.9142, Precision: 0.8788, Recall: 0.8765, F1: 0.8775
Validation Loss: 0.5778, Accuracy: 0.8593, Precision: 0.8211, Recall: 0.8123, F1: 0.8147
Testing Loss: 0.3932, Accuracy: 0.8937, Precision: 0.8635, Recall: 0.8638, F1: 0.8629
LM Predictions:  [5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8886, Accuracy: 0.1190, Precision: 0.3636, Recall: 0.1208, F1: 0.1343
Epoch 27/70
Train Loss: 0.2301, Accuracy: 0.9225, Precision: 0.8896, Recall: 0.8832, F1: 0.8863
Validation Loss: 0.5612, Accuracy: 0.8699, Precision: 0.8375, Recall: 0.8443, F1: 0.8382
Testing Loss: 0.4133, Accuracy: 0.8804, Precision: 0.8525, Recall: 0.8442, F1: 0.8469
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7481, Accuracy: 0.1667, Precision: 0.3718, Recall: 0.1750, F1: 0.1778
Epoch 28/70
Train Loss: 0.2253, Accuracy: 0.9220, Precision: 0.8866, Recall: 0.8786, F1: 0.8825
Validation Loss: 0.5831, Accuracy: 0.8614, Precision: 0.8250, Recall: 0.8226, F1: 0.8224
Testing Loss: 0.4299, Accuracy: 0.8732, Precision: 0.8502, Recall: 0.8343, F1: 0.8409
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 4, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2689, Accuracy: 0.2143, Precision: 0.3417, Recall: 0.2083, F1: 0.2144
Epoch 29/70
Train Loss: 0.2123, Accuracy: 0.9270, Precision: 0.8937, Recall: 0.8897, F1: 0.8915
Validation Loss: 0.6397, Accuracy: 0.8635, Precision: 0.8134, Recall: 0.8068, F1: 0.8082
Testing Loss: 0.4520, Accuracy: 0.8780, Precision: 0.8449, Recall: 0.8304, F1: 0.8361
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 4, 0, 5, 0, 0, 5, 0, 0, 0, 4, 0, 5, 0, 4, 5, 5, 5, 0, 4, 0, 4, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8764, Accuracy: 0.2381, Precision: 0.3350, Recall: 0.2250, F1: 0.2163
Epoch 30/70
Train Loss: 0.2058, Accuracy: 0.9267, Precision: 0.8939, Recall: 0.8910, F1: 0.8924
Validation Loss: 0.6354, Accuracy: 0.8635, Precision: 0.8259, Recall: 0.8049, F1: 0.8119
Testing Loss: 0.4765, Accuracy: 0.8756, Precision: 0.8471, Recall: 0.8288, F1: 0.8371
LM Predictions:  [0, 5, 5, 0, 5, 0, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 0, 5, 0, 4, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5503, Accuracy: 0.1667, Precision: 0.5294, Recall: 0.1750, F1: 0.1727
Epoch 31/70
Train Loss: 0.1916, Accuracy: 0.9298, Precision: 0.8966, Recall: 0.8914, F1: 0.8939
Validation Loss: 0.6255, Accuracy: 0.8593, Precision: 0.8259, Recall: 0.8029, F1: 0.8113
Testing Loss: 0.4911, Accuracy: 0.8792, Precision: 0.8580, Recall: 0.8369, F1: 0.8466
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4837, Accuracy: 0.2143, Precision: 0.5357, Recall: 0.2125, F1: 0.2294
Epoch 32/70
Train Loss: 0.1770, Accuracy: 0.9372, Precision: 0.9052, Recall: 0.9075, F1: 0.9062
Validation Loss: 0.6240, Accuracy: 0.8529, Precision: 0.8169, Recall: 0.7963, F1: 0.8045
Testing Loss: 0.4942, Accuracy: 0.8696, Precision: 0.8542, Recall: 0.8206, F1: 0.8354
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 0, 0, 0, 0, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3681, Accuracy: 0.1667, Precision: 0.4444, Recall: 0.1750, F1: 0.1682
Epoch 33/70
Train Loss: 0.1832, Accuracy: 0.9343, Precision: 0.9015, Recall: 0.8981, F1: 0.8997
Validation Loss: 0.6229, Accuracy: 0.8657, Precision: 0.8284, Recall: 0.8517, F1: 0.8348
Testing Loss: 0.5295, Accuracy: 0.8708, Precision: 0.8330, Recall: 0.8495, F1: 0.8384
LM Predictions:  [5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 5, 5, 5, 0, 5, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2459, Accuracy: 0.1905, Precision: 0.4815, Recall: 0.1792, F1: 0.2201
Epoch 34/70
Train Loss: 0.1709, Accuracy: 0.9374, Precision: 0.9040, Recall: 0.9038, F1: 0.9038
Validation Loss: 0.6369, Accuracy: 0.8571, Precision: 0.8253, Recall: 0.8043, F1: 0.8130
Testing Loss: 0.5334, Accuracy: 0.8611, Precision: 0.8370, Recall: 0.7989, F1: 0.8145
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 0, 5, 0, 0, 0, 4, 5, 2, 0, 4, 5, 0, 0, 5, 4, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9307, Accuracy: 0.3095, Precision: 0.6683, Recall: 0.2810, F1: 0.3042
Epoch 35/70
Train Loss: 0.1626, Accuracy: 0.9407, Precision: 0.9108, Recall: 0.9097, F1: 0.9102
Validation Loss: 0.6785, Accuracy: 0.8529, Precision: 0.8163, Recall: 0.8041, F1: 0.8076
Testing Loss: 0.5582, Accuracy: 0.8539, Precision: 0.8297, Recall: 0.8023, F1: 0.8143
LM Predictions:  [0, 1, 2, 0, 5, 5, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 2, 5, 0, 5, 0, 5, 3, 0, 0, 2, 0, 5, 2, 0, 4, 5, 5, 5, 0, 4, 0, 4, 5, 5, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7804, Accuracy: 0.4048, Precision: 0.7024, Recall: 0.3620, F1: 0.4069
Epoch 36/70
Train Loss: 0.1580, Accuracy: 0.9391, Precision: 0.9064, Recall: 0.9060, F1: 0.9061
Validation Loss: 0.6836, Accuracy: 0.8678, Precision: 0.8382, Recall: 0.8367, F1: 0.8332
Testing Loss: 0.5656, Accuracy: 0.8599, Precision: 0.8343, Recall: 0.8311, F1: 0.8303
LM Predictions:  [5, 1, 2, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 5, 5, 5, 5, 0, 2, 0, 5, 2, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9770, Accuracy: 0.2857, Precision: 0.7037, Recall: 0.2560, F1: 0.3164
Epoch 37/70
Train Loss: 0.1461, Accuracy: 0.9443, Precision: 0.9141, Recall: 0.9121, F1: 0.9130
Validation Loss: 0.7311, Accuracy: 0.8465, Precision: 0.8158, Recall: 0.7787, F1: 0.7934
Testing Loss: 0.6068, Accuracy: 0.8635, Precision: 0.8524, Recall: 0.8015, F1: 0.8216
LM Predictions:  [0, 1, 2, 0, 5, 0, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 5, 0, 0, 2, 0, 0, 2, 0, 4, 5, 5, 5, 0, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7575, Accuracy: 0.4286, Precision: 0.6944, Recall: 0.3810, F1: 0.3990
Epoch 38/70
Train Loss: 0.1458, Accuracy: 0.9412, Precision: 0.9095, Recall: 0.9060, F1: 0.9076
Validation Loss: 0.6843, Accuracy: 0.8486, Precision: 0.7897, Recall: 0.7901, F1: 0.7892
Testing Loss: 0.5678, Accuracy: 0.8647, Precision: 0.8299, Recall: 0.8243, F1: 0.8262
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 4, 3, 0, 5, 4, 0, 3, 0, 5, 5, 0, 0, 5, 4, 4, 2, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6522, Accuracy: 0.4524, Precision: 0.6936, Recall: 0.3894, F1: 0.4199
Epoch 39/70
Train Loss: 0.1430, Accuracy: 0.9483, Precision: 0.9214, Recall: 0.9203, F1: 0.9208
Validation Loss: 0.7287, Accuracy: 0.8507, Precision: 0.7946, Recall: 0.7848, F1: 0.7873
Testing Loss: 0.5804, Accuracy: 0.8635, Precision: 0.8291, Recall: 0.8113, F1: 0.8181
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 5, 0, 0, 2, 4, 4, 2, 0, 4, 5, 5, 5, 0, 4, 0, 4, 0, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1531, Accuracy: 0.5476, Precision: 0.6857, Recall: 0.4662, F1: 0.4743
Epoch 40/70
Train Loss: 0.1395, Accuracy: 0.9445, Precision: 0.9152, Recall: 0.9167, F1: 0.9159
Validation Loss: 0.6806, Accuracy: 0.8486, Precision: 0.8037, Recall: 0.8005, F1: 0.8013
Testing Loss: 0.5967, Accuracy: 0.8514, Precision: 0.8184, Recall: 0.8005, F1: 0.8082
LM Predictions:  [0, 1, 2, 0, 5, 5, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 5, 5, 0, 0, 2, 4, 4, 2, 0, 4, 5, 5, 5, 0, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.5552, Accuracy: 0.4286, Precision: 0.7051, Recall: 0.3769, F1: 0.3993
Epoch 41/70
Train Loss: 0.1362, Accuracy: 0.9440, Precision: 0.9149, Recall: 0.9158, F1: 0.9152
Validation Loss: 0.6615, Accuracy: 0.8635, Precision: 0.8263, Recall: 0.8149, F1: 0.8193
Testing Loss: 0.5878, Accuracy: 0.8527, Precision: 0.8171, Recall: 0.7988, F1: 0.8073
LM Predictions:  [0, 1, 2, 0, 5, 5, 5, 5, 4, 5, 5, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 0, 0, 2, 0, 4, 2, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2387, Accuracy: 0.4762, Precision: 0.7051, Recall: 0.4144, F1: 0.4464
Epoch 42/70
Train Loss: 0.1255, Accuracy: 0.9519, Precision: 0.9233, Recall: 0.9247, F1: 0.9239
Validation Loss: 0.7078, Accuracy: 0.8529, Precision: 0.8039, Recall: 0.7828, F1: 0.7902
Testing Loss: 0.6054, Accuracy: 0.8611, Precision: 0.8322, Recall: 0.7967, F1: 0.8103
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 5, 0, 0, 2, 4, 4, 2, 0, 4, 3, 5, 5, 0, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2586, Accuracy: 0.5476, Precision: 0.6898, Recall: 0.4810, F1: 0.4697
Epoch 43/70
Train Loss: 0.1303, Accuracy: 0.9474, Precision: 0.9193, Recall: 0.9203, F1: 0.9197
Validation Loss: 0.7344, Accuracy: 0.8507, Precision: 0.8085, Recall: 0.7830, F1: 0.7906
Testing Loss: 0.6710, Accuracy: 0.8635, Precision: 0.8375, Recall: 0.8064, F1: 0.8188
LM Predictions:  [0, 1, 2, 0, 2, 0, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 0, 0, 2, 4, 4, 2, 0, 4, 3, 5, 0, 0, 4, 0, 4, 0, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8759, Accuracy: 0.6190, Precision: 0.6897, Recall: 0.5495, F1: 0.5193
Epoch 44/70
Train Loss: 0.1185, Accuracy: 0.9547, Precision: 0.9291, Recall: 0.9337, F1: 0.9311
Validation Loss: 0.6845, Accuracy: 0.8614, Precision: 0.8218, Recall: 0.8110, F1: 0.8151
Testing Loss: 0.6546, Accuracy: 0.8539, Precision: 0.8258, Recall: 0.8079, F1: 0.8155
LM Predictions:  [0, 1, 2, 0, 2, 5, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 5, 0, 0, 2, 4, 4, 2, 0, 4, 5, 5, 5, 0, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0810, Accuracy: 0.5238, Precision: 0.6843, Recall: 0.4477, F1: 0.4482
Epoch 45/70
Train Loss: 0.1162, Accuracy: 0.9545, Precision: 0.9263, Recall: 0.9312, F1: 0.9285
Validation Loss: 0.7912, Accuracy: 0.8529, Precision: 0.8211, Recall: 0.7921, F1: 0.8032
Testing Loss: 0.6734, Accuracy: 0.8563, Precision: 0.8322, Recall: 0.8027, F1: 0.8157
LM Predictions:  [0, 1, 2, 0, 2, 0, 5, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 5, 0, 0, 2, 0, 4, 2, 0, 4, 3, 5, 0, 0, 4, 1, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8907, Accuracy: 0.5476, Precision: 0.6771, Recall: 0.4662, F1: 0.4791
Epoch 46/70
Train Loss: 0.1090, Accuracy: 0.9540, Precision: 0.9265, Recall: 0.9276, F1: 0.9270
Validation Loss: 0.7516, Accuracy: 0.8507, Precision: 0.8005, Recall: 0.8011, F1: 0.8006
Testing Loss: 0.6775, Accuracy: 0.8551, Precision: 0.8236, Recall: 0.8042, F1: 0.8123
LM Predictions:  [0, 1, 2, 0, 4, 0, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 5, 0, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6461, Accuracy: 0.6667, Precision: 0.6932, Recall: 0.5532, F1: 0.5709
Epoch 47/70
Train Loss: 0.1093, Accuracy: 0.9535, Precision: 0.9266, Recall: 0.9266, F1: 0.9265
Validation Loss: 0.8371, Accuracy: 0.8550, Precision: 0.8104, Recall: 0.7942, F1: 0.8003
Testing Loss: 0.6936, Accuracy: 0.8611, Precision: 0.8286, Recall: 0.8132, F1: 0.8201
LM Predictions:  [0, 1, 2, 0, 4, 1, 0, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 4, 3, 3, 0, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 5, 0, 0, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5328, Accuracy: 0.7381, Precision: 0.6792, Recall: 0.6236, F1: 0.6234
Epoch 48/70
Train Loss: 0.1115, Accuracy: 0.9538, Precision: 0.9284, Recall: 0.9280, F1: 0.9281
Validation Loss: 0.8444, Accuracy: 0.8507, Precision: 0.8176, Recall: 0.7910, F1: 0.8015
Testing Loss: 0.7322, Accuracy: 0.8551, Precision: 0.8261, Recall: 0.7929, F1: 0.8070
LM Predictions:  [0, 1, 2, 0, 2, 0, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 2, 1, 0, 2, 0, 4, 2, 0, 4, 3, 5, 0, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7181, Accuracy: 0.5952, Precision: 0.6713, Recall: 0.5199, F1: 0.5175
Epoch 49/70
Train Loss: 0.1077, Accuracy: 0.9554, Precision: 0.9291, Recall: 0.9310, F1: 0.9300
Validation Loss: 0.8064, Accuracy: 0.8465, Precision: 0.8095, Recall: 0.7796, F1: 0.7915
Testing Loss: 0.6815, Accuracy: 0.8551, Precision: 0.8258, Recall: 0.7875, F1: 0.8032
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 5, 0, 0, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5527, Accuracy: 0.7143, Precision: 0.6971, Recall: 0.6088, F1: 0.6103
Epoch 50/70
Train Loss: 0.0984, Accuracy: 0.9542, Precision: 0.9294, Recall: 0.9294, F1: 0.9294
Validation Loss: 0.7873, Accuracy: 0.8571, Precision: 0.8185, Recall: 0.8013, F1: 0.8076
Testing Loss: 0.6922, Accuracy: 0.8587, Precision: 0.8213, Recall: 0.8041, F1: 0.8121
LM Predictions:  [0, 1, 2, 0, 2, 0, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 5, 0, 0, 4, 0, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6027, Accuracy: 0.6667, Precision: 0.6935, Recall: 0.5662, F1: 0.5595
Epoch 51/70
Train Loss: 0.0957, Accuracy: 0.9590, Precision: 0.9318, Recall: 0.9368, F1: 0.9341
Validation Loss: 0.8120, Accuracy: 0.8593, Precision: 0.8140, Recall: 0.8053, F1: 0.8085
Testing Loss: 0.7177, Accuracy: 0.8551, Precision: 0.8187, Recall: 0.7988, F1: 0.8076
LM Predictions:  [0, 1, 2, 1, 2, 1, 0, 4, 4, 5, 0, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3298, Accuracy: 0.8571, Precision: 0.7292, Recall: 0.7088, F1: 0.7100
Epoch 52/70
Train Loss: 0.1027, Accuracy: 0.9573, Precision: 0.9333, Recall: 0.9364, F1: 0.9348
Validation Loss: 0.7727, Accuracy: 0.8614, Precision: 0.8183, Recall: 0.8073, F1: 0.8117
Testing Loss: 0.6835, Accuracy: 0.8514, Precision: 0.8160, Recall: 0.7930, F1: 0.8020
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 5, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2462, Accuracy: 0.9762, Precision: 0.8333, Recall: 0.8000, F1: 0.8148
Epoch 53/70
Train Loss: 0.0935, Accuracy: 0.9606, Precision: 0.9391, Recall: 0.9386, F1: 0.9388
Validation Loss: 0.7416, Accuracy: 0.8678, Precision: 0.8311, Recall: 0.8178, F1: 0.8239
Testing Loss: 0.7752, Accuracy: 0.8502, Precision: 0.8218, Recall: 0.7930, F1: 0.8041
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2942, Accuracy: 0.9048, Precision: 0.7619, Recall: 0.7458, F1: 0.7481
Epoch 54/70
Train Loss: 0.0919, Accuracy: 0.9597, Precision: 0.9349, Recall: 0.9399, F1: 0.9373
Validation Loss: 0.7730, Accuracy: 0.8571, Precision: 0.8209, Recall: 0.8013, F1: 0.8076
Testing Loss: 0.7432, Accuracy: 0.8490, Precision: 0.8158, Recall: 0.7956, F1: 0.8042
LM Predictions:  [0, 1, 2, 0, 1, 1, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 5, 5, 0, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4462, Accuracy: 0.7619, Precision: 0.7083, Recall: 0.6255, F1: 0.6475
Epoch 55/70
Train Loss: 0.0999, Accuracy: 0.9566, Precision: 0.9322, Recall: 0.9329, F1: 0.9325
Validation Loss: 0.8385, Accuracy: 0.8529, Precision: 0.7984, Recall: 0.7968, F1: 0.7960
Testing Loss: 0.7166, Accuracy: 0.8514, Precision: 0.8098, Recall: 0.7937, F1: 0.8000
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1970, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9800, F1: 0.9713
Epoch 56/70
Train Loss: 0.0902, Accuracy: 0.9611, Precision: 0.9370, Recall: 0.9394, F1: 0.9382
Validation Loss: 0.7722, Accuracy: 0.8614, Precision: 0.8127, Recall: 0.8044, F1: 0.8078
Testing Loss: 0.7284, Accuracy: 0.8527, Precision: 0.8138, Recall: 0.7912, F1: 0.8008
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2871, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9178, F1: 0.8983
Epoch 57/70
Train Loss: 0.0872, Accuracy: 0.9609, Precision: 0.9399, Recall: 0.9390, F1: 0.9394
Validation Loss: 0.8186, Accuracy: 0.8529, Precision: 0.8243, Recall: 0.7960, F1: 0.8066
Testing Loss: 0.8091, Accuracy: 0.8502, Precision: 0.8278, Recall: 0.7878, F1: 0.8044
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4127, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7661, F1: 0.7542
Epoch 58/70
Train Loss: 0.0859, Accuracy: 0.9621, Precision: 0.9381, Recall: 0.9408, F1: 0.9394
Validation Loss: 0.8576, Accuracy: 0.8550, Precision: 0.7991, Recall: 0.7766, F1: 0.7822
Testing Loss: 0.7611, Accuracy: 0.8527, Precision: 0.8066, Recall: 0.7749, F1: 0.7843
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1350, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9800, F1: 0.9713
Epoch 59/70
Train Loss: 0.0861, Accuracy: 0.9621, Precision: 0.9419, Recall: 0.9368, F1: 0.9393
Validation Loss: 0.8477, Accuracy: 0.8550, Precision: 0.7964, Recall: 0.7982, F1: 0.7968
Testing Loss: 0.7521, Accuracy: 0.8587, Precision: 0.8215, Recall: 0.8121, F1: 0.8160
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 5, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1810, Accuracy: 0.9524, Precision: 0.8167, Recall: 0.8000, F1: 0.8060
Epoch 60/70
Train Loss: 0.0868, Accuracy: 0.9618, Precision: 0.9400, Recall: 0.9433, F1: 0.9416
Validation Loss: 0.8811, Accuracy: 0.8507, Precision: 0.8009, Recall: 0.7705, F1: 0.7813
Testing Loss: 0.7822, Accuracy: 0.8527, Precision: 0.8204, Recall: 0.7705, F1: 0.7870
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2576, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.9000, F1: 0.8728
Epoch 61/70
Train Loss: 0.0841, Accuracy: 0.9625, Precision: 0.9394, Recall: 0.9391, F1: 0.9393
Validation Loss: 0.8330, Accuracy: 0.8507, Precision: 0.8076, Recall: 0.7792, F1: 0.7911
Testing Loss: 0.7827, Accuracy: 0.8442, Precision: 0.8157, Recall: 0.7746, F1: 0.7907
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4061, Accuracy: 0.8095, Precision: 0.8611, Recall: 0.8378, F1: 0.8101
Epoch 62/70
Train Loss: 0.0843, Accuracy: 0.9613, Precision: 0.9403, Recall: 0.9383, F1: 0.9393
Validation Loss: 0.8177, Accuracy: 0.8529, Precision: 0.7989, Recall: 0.7842, F1: 0.7889
Testing Loss: 0.7693, Accuracy: 0.8406, Precision: 0.8009, Recall: 0.7719, F1: 0.7832
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2844, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8556, F1: 0.8351
Epoch 63/70
Train Loss: 0.0851, Accuracy: 0.9630, Precision: 0.9417, Recall: 0.9402, F1: 0.9409
Validation Loss: 0.8727, Accuracy: 0.8550, Precision: 0.8089, Recall: 0.7773, F1: 0.7890
Testing Loss: 0.8252, Accuracy: 0.8490, Precision: 0.8207, Recall: 0.7701, F1: 0.7850
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 1, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1687, Accuracy: 0.9286, Precision: 0.9229, Recall: 0.9400, F1: 0.9208
Epoch 64/70
Train Loss: 0.0761, Accuracy: 0.9635, Precision: 0.9413, Recall: 0.9430, F1: 0.9421
Validation Loss: 0.8340, Accuracy: 0.8486, Precision: 0.7949, Recall: 0.7889, F1: 0.7905
Testing Loss: 0.7499, Accuracy: 0.8454, Precision: 0.8044, Recall: 0.7935, F1: 0.7985
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1803, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9350, F1: 0.9183
Epoch 65/70
Train Loss: 0.0797, Accuracy: 0.9625, Precision: 0.9395, Recall: 0.9396, F1: 0.9395
Validation Loss: 0.8764, Accuracy: 0.8465, Precision: 0.7933, Recall: 0.7778, F1: 0.7842
Testing Loss: 0.7708, Accuracy: 0.8527, Precision: 0.8131, Recall: 0.7960, F1: 0.8035
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1379, Accuracy: 0.9524, Precision: 0.9429, Recall: 0.9550, F1: 0.9428
Epoch 66/70
Train Loss: 0.0809, Accuracy: 0.9632, Precision: 0.9406, Recall: 0.9455, F1: 0.9430
Validation Loss: 0.8518, Accuracy: 0.8571, Precision: 0.8185, Recall: 0.7955, F1: 0.8043
Testing Loss: 0.7821, Accuracy: 0.8527, Precision: 0.8177, Recall: 0.7840, F1: 0.7978
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1970, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8970
Epoch 67/70
Train Loss: 0.0797, Accuracy: 0.9621, Precision: 0.9407, Recall: 0.9397, F1: 0.9402
Validation Loss: 0.8205, Accuracy: 0.8593, Precision: 0.8158, Recall: 0.7891, F1: 0.7993
Testing Loss: 0.7794, Accuracy: 0.8587, Precision: 0.8324, Recall: 0.7925, F1: 0.8081
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2352, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8750, F1: 0.8542
Epoch 68/70
Train Loss: 0.0766, Accuracy: 0.9640, Precision: 0.9397, Recall: 0.9465, F1: 0.9429
Validation Loss: 0.8353, Accuracy: 0.8635, Precision: 0.8263, Recall: 0.7862, F1: 0.8003
Testing Loss: 0.8082, Accuracy: 0.8502, Precision: 0.8274, Recall: 0.7710, F1: 0.7882
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2089, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8778, F1: 0.8527
Epoch 69/70
Train Loss: 0.0778, Accuracy: 0.9642, Precision: 0.9438, Recall: 0.9395, F1: 0.9416
Validation Loss: 0.8522, Accuracy: 0.8529, Precision: 0.8050, Recall: 0.7959, F1: 0.7982
Testing Loss: 0.8196, Accuracy: 0.8502, Precision: 0.8173, Recall: 0.7921, F1: 0.8023
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 5, 4, 3, 3, 0, 4, 3, 1, 0, 2, 4, 4, 5, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2865, Accuracy: 0.8571, Precision: 0.7593, Recall: 0.7190, F1: 0.7199
Epoch 70/70
Train Loss: 0.0785, Accuracy: 0.9635, Precision: 0.9416, Recall: 0.9439, F1: 0.9427
Validation Loss: 0.9699, Accuracy: 0.8550, Precision: 0.7947, Recall: 0.7896, F1: 0.7886
Testing Loss: 0.8360, Accuracy: 0.8490, Precision: 0.8047, Recall: 0.7799, F1: 0.7882
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0810, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For later layers:  [8, 9, 10, 11]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.9106, Accuracy: 0.2333, Precision: 0.1837, Recall: 0.1778, F1: 0.1682
Validation Loss: 1.6778, Accuracy: 0.3006, Precision: 0.1185, Recall: 0.1894, F1: 0.1227
Testing Loss: 1.6590, Accuracy: 0.3092, Precision: 0.1244, Recall: 0.1955, F1: 0.1291
LM Predictions:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9382, Accuracy: 0.1190, Precision: 0.0711, Recall: 0.1822, F1: 0.0680
Epoch 2/70
Train Loss: 1.6872, Accuracy: 0.2862, Precision: 0.1558, Recall: 0.1882, F1: 0.1591
Validation Loss: 1.6230, Accuracy: 0.3902, Precision: 0.2064, Recall: 0.2547, F1: 0.2109
Testing Loss: 1.6166, Accuracy: 0.3841, Precision: 0.2079, Recall: 0.2512, F1: 0.2083
LM Predictions:  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8500, Accuracy: 0.1190, Precision: 0.0489, Recall: 0.1822, F1: 0.0679
Epoch 3/70
Train Loss: 1.6529, Accuracy: 0.3116, Precision: 0.1820, Recall: 0.2067, F1: 0.1763
Validation Loss: 1.6070, Accuracy: 0.4222, Precision: 0.2280, Recall: 0.2796, F1: 0.2384
Testing Loss: 1.5871, Accuracy: 0.4312, Precision: 0.2466, Recall: 0.2866, F1: 0.2502
LM Predictions:  [2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8698, Accuracy: 0.1190, Precision: 0.0530, Recall: 0.1700, F1: 0.0756
Epoch 4/70
Train Loss: 1.6261, Accuracy: 0.3465, Precision: 0.1997, Recall: 0.2301, F1: 0.1957
Validation Loss: 1.5764, Accuracy: 0.3497, Precision: 0.2544, Recall: 0.2333, F1: 0.1615
Testing Loss: 1.5488, Accuracy: 0.3382, Precision: 0.2996, Recall: 0.2272, F1: 0.1521
LM Predictions:  [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8803, Accuracy: 0.2143, Precision: 0.0790, Recall: 0.2356, F1: 0.1181
Epoch 5/70
Train Loss: 1.5103, Accuracy: 0.4166, Precision: 0.2363, Recall: 0.2774, F1: 0.2385
Validation Loss: 1.2990, Accuracy: 0.5245, Precision: 0.2805, Recall: 0.3466, F1: 0.2856
Testing Loss: 1.2117, Accuracy: 0.5290, Precision: 0.2963, Recall: 0.3494, F1: 0.2909
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3453, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 6/70
Train Loss: 1.2296, Accuracy: 0.5504, Precision: 0.4714, Recall: 0.3773, F1: 0.3482
Validation Loss: 0.8786, Accuracy: 0.6994, Precision: 0.6338, Recall: 0.5051, F1: 0.4872
Testing Loss: 0.7806, Accuracy: 0.7234, Precision: 0.6445, Recall: 0.5279, F1: 0.5153
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2983, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 7/70
Train Loss: 0.8883, Accuracy: 0.6917, Precision: 0.6221, Recall: 0.5475, F1: 0.5575
Validation Loss: 0.6912, Accuracy: 0.7889, Precision: 0.8546, Recall: 0.6606, F1: 0.6720
Testing Loss: 0.6083, Accuracy: 0.7838, Precision: 0.7863, Recall: 0.6585, F1: 0.6655
LM Predictions:  [0, 3, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 5, 0, 5, 0, 0, 0, 1, 0, 5, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7318, Accuracy: 0.1429, Precision: 0.1927, Recall: 0.1833, F1: 0.0753
Epoch 8/70
Train Loss: 0.6799, Accuracy: 0.7766, Precision: 0.7317, Recall: 0.6678, F1: 0.6836
Validation Loss: 0.6015, Accuracy: 0.8188, Precision: 0.8178, Recall: 0.7250, F1: 0.7450
Testing Loss: 0.4937, Accuracy: 0.8394, Precision: 0.8332, Recall: 0.7631, F1: 0.7810
LM Predictions:  [0, 3, 0, 5, 4, 0, 0, 5, 0, 2, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 5, 2, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 5, 0, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4639, Accuracy: 0.1190, Precision: 0.1090, Recall: 0.1500, F1: 0.0708
Epoch 9/70
Train Loss: 0.5633, Accuracy: 0.8195, Precision: 0.7598, Recall: 0.7228, F1: 0.7327
Validation Loss: 0.5641, Accuracy: 0.8422, Precision: 0.8657, Recall: 0.7526, F1: 0.7779
Testing Loss: 0.4722, Accuracy: 0.8539, Precision: 0.8402, Recall: 0.7973, F1: 0.8135
LM Predictions:  [0, 3, 0, 5, 4, 0, 0, 5, 0, 2, 5, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 5, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 1, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8617, Accuracy: 0.0952, Precision: 0.0278, Recall: 0.1333, F1: 0.0460
Epoch 10/70
Train Loss: 0.5167, Accuracy: 0.8380, Precision: 0.7892, Recall: 0.7535, F1: 0.7651
Validation Loss: 0.5237, Accuracy: 0.8571, Precision: 0.8652, Recall: 0.7928, F1: 0.8155
Testing Loss: 0.4501, Accuracy: 0.8623, Precision: 0.8511, Recall: 0.8106, F1: 0.8260
LM Predictions:  [0, 3, 0, 5, 4, 0, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 5, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 0, 1, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8291, Accuracy: 0.0952, Precision: 0.0290, Recall: 0.1333, F1: 0.0476
Epoch 11/70
Train Loss: 0.4918, Accuracy: 0.8397, Precision: 0.7923, Recall: 0.7643, F1: 0.7750
Validation Loss: 0.5072, Accuracy: 0.8806, Precision: 0.8869, Recall: 0.8309, F1: 0.8500
Testing Loss: 0.3991, Accuracy: 0.8744, Precision: 0.8571, Recall: 0.8430, F1: 0.8486
LM Predictions:  [0, 3, 5, 5, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 1, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8593, Accuracy: 0.0714, Precision: 0.0278, Recall: 0.1000, F1: 0.0435
Epoch 12/70
Train Loss: 0.4769, Accuracy: 0.8452, Precision: 0.7975, Recall: 0.7727, F1: 0.7822
Validation Loss: 0.5006, Accuracy: 0.8699, Precision: 0.8898, Recall: 0.8099, F1: 0.8373
Testing Loss: 0.3930, Accuracy: 0.8804, Precision: 0.8799, Recall: 0.8384, F1: 0.8538
LM Predictions:  [0, 3, 0, 5, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8845, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 13/70
Train Loss: 0.4521, Accuracy: 0.8570, Precision: 0.8155, Recall: 0.7909, F1: 0.8015
Validation Loss: 0.5106, Accuracy: 0.8593, Precision: 0.8643, Recall: 0.7987, F1: 0.8205
Testing Loss: 0.4048, Accuracy: 0.8744, Precision: 0.8614, Recall: 0.8232, F1: 0.8370
LM Predictions:  [0, 3, 0, 5, 4, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4772, Accuracy: 0.0952, Precision: 0.0317, Recall: 0.1333, F1: 0.0513
Epoch 14/70
Train Loss: 0.4485, Accuracy: 0.8572, Precision: 0.8186, Recall: 0.7885, F1: 0.8007
Validation Loss: 0.5507, Accuracy: 0.8571, Precision: 0.8455, Recall: 0.7911, F1: 0.8066
Testing Loss: 0.3921, Accuracy: 0.8744, Precision: 0.8498, Recall: 0.8344, F1: 0.8404
LM Predictions:  [0, 3, 0, 0, 4, 5, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7254, Accuracy: 0.0952, Precision: 0.0317, Recall: 0.1333, F1: 0.0513
Epoch 15/70
Train Loss: 0.4188, Accuracy: 0.8653, Precision: 0.8199, Recall: 0.8001, F1: 0.8083
Validation Loss: 0.5077, Accuracy: 0.8635, Precision: 0.8452, Recall: 0.8226, F1: 0.8325
Testing Loss: 0.3640, Accuracy: 0.8853, Precision: 0.8653, Recall: 0.8541, F1: 0.8588
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7061, Accuracy: 0.0714, Precision: 0.0357, Recall: 0.1000, F1: 0.0526
Epoch 16/70
Train Loss: 0.4047, Accuracy: 0.8653, Precision: 0.8190, Recall: 0.8022, F1: 0.8095
Validation Loss: 0.4874, Accuracy: 0.8699, Precision: 0.8774, Recall: 0.8050, F1: 0.8268
Testing Loss: 0.3679, Accuracy: 0.8925, Precision: 0.8877, Recall: 0.8517, F1: 0.8655
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 0, 2, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5372, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 17/70
Train Loss: 0.3998, Accuracy: 0.8705, Precision: 0.8315, Recall: 0.8112, F1: 0.8200
Validation Loss: 0.4815, Accuracy: 0.8678, Precision: 0.8689, Recall: 0.8154, F1: 0.8351
Testing Loss: 0.3739, Accuracy: 0.8841, Precision: 0.8790, Recall: 0.8303, F1: 0.8468
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3843, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 18/70
Train Loss: 0.3752, Accuracy: 0.8810, Precision: 0.8369, Recall: 0.8224, F1: 0.8291
Validation Loss: 0.4834, Accuracy: 0.8721, Precision: 0.8726, Recall: 0.8193, F1: 0.8387
Testing Loss: 0.3723, Accuracy: 0.8865, Precision: 0.8730, Recall: 0.8304, F1: 0.8464
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2777, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 19/70
Train Loss: 0.3686, Accuracy: 0.8821, Precision: 0.8422, Recall: 0.8293, F1: 0.8352
Validation Loss: 0.4760, Accuracy: 0.8721, Precision: 0.8440, Recall: 0.8414, F1: 0.8423
Testing Loss: 0.3663, Accuracy: 0.8865, Precision: 0.8589, Recall: 0.8667, F1: 0.8608
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 5, 2, 0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5604, Accuracy: 0.0714, Precision: 0.0417, Recall: 0.1000, F1: 0.0588
Epoch 20/70
Train Loss: 0.3547, Accuracy: 0.8843, Precision: 0.8402, Recall: 0.8280, F1: 0.8337
Validation Loss: 0.4738, Accuracy: 0.8699, Precision: 0.8451, Recall: 0.8354, F1: 0.8394
Testing Loss: 0.3736, Accuracy: 0.8853, Precision: 0.8559, Recall: 0.8526, F1: 0.8534
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7362, Accuracy: 0.0714, Precision: 0.0333, Recall: 0.1000, F1: 0.0500
Epoch 21/70
Train Loss: 0.3448, Accuracy: 0.8928, Precision: 0.8573, Recall: 0.8482, F1: 0.8526
Validation Loss: 0.4666, Accuracy: 0.8721, Precision: 0.8446, Recall: 0.8443, F1: 0.8429
Testing Loss: 0.3739, Accuracy: 0.8877, Precision: 0.8644, Recall: 0.8727, F1: 0.8662
LM Predictions:  [0, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7469, Accuracy: 0.0952, Precision: 0.1333, Recall: 0.1208, F1: 0.1000
Epoch 22/70
Train Loss: 0.3388, Accuracy: 0.8885, Precision: 0.8483, Recall: 0.8406, F1: 0.8442
Validation Loss: 0.4893, Accuracy: 0.8785, Precision: 0.8503, Recall: 0.8445, F1: 0.8467
Testing Loss: 0.3820, Accuracy: 0.8901, Precision: 0.8600, Recall: 0.8632, F1: 0.8613
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7689, Accuracy: 0.0952, Precision: 0.2000, Recall: 0.1208, F1: 0.0870
Epoch 23/70
Train Loss: 0.3312, Accuracy: 0.8942, Precision: 0.8540, Recall: 0.8470, F1: 0.8503
Validation Loss: 0.4840, Accuracy: 0.8742, Precision: 0.8606, Recall: 0.8264, F1: 0.8412
Testing Loss: 0.3764, Accuracy: 0.8961, Precision: 0.8822, Recall: 0.8466, F1: 0.8610
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3126, Accuracy: 0.0952, Precision: 0.1930, Recall: 0.1208, F1: 0.0787
Epoch 24/70
Train Loss: 0.3104, Accuracy: 0.8999, Precision: 0.8647, Recall: 0.8517, F1: 0.8578
Validation Loss: 0.5230, Accuracy: 0.8678, Precision: 0.8535, Recall: 0.8235, F1: 0.8361
Testing Loss: 0.3901, Accuracy: 0.8877, Precision: 0.8699, Recall: 0.8391, F1: 0.8517
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4830, Accuracy: 0.0714, Precision: 0.0250, Recall: 0.1000, F1: 0.0400
Epoch 25/70
Train Loss: 0.3011, Accuracy: 0.8997, Precision: 0.8565, Recall: 0.8501, F1: 0.8531
Validation Loss: 0.5085, Accuracy: 0.8721, Precision: 0.8646, Recall: 0.8212, F1: 0.8390
Testing Loss: 0.4018, Accuracy: 0.8865, Precision: 0.8681, Recall: 0.8314, F1: 0.8468
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 2, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4707, Accuracy: 0.0952, Precision: 0.1096, Recall: 0.1208, F1: 0.0750
Epoch 26/70
Train Loss: 0.2889, Accuracy: 0.9070, Precision: 0.8693, Recall: 0.8635, F1: 0.8663
Validation Loss: 0.5052, Accuracy: 0.8806, Precision: 0.8654, Recall: 0.8305, F1: 0.8451
Testing Loss: 0.4017, Accuracy: 0.8804, Precision: 0.8580, Recall: 0.8294, F1: 0.8410
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1455, Accuracy: 0.0952, Precision: 0.1930, Recall: 0.1208, F1: 0.0787
Epoch 27/70
Train Loss: 0.2744, Accuracy: 0.9104, Precision: 0.8770, Recall: 0.8690, F1: 0.8729
Validation Loss: 0.5075, Accuracy: 0.8657, Precision: 0.8435, Recall: 0.8150, F1: 0.8267
Testing Loss: 0.3966, Accuracy: 0.8877, Precision: 0.8632, Recall: 0.8473, F1: 0.8544
LM Predictions:  [0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 2, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4039, Accuracy: 0.0952, Precision: 0.1146, Recall: 0.1208, F1: 0.0810
Epoch 28/70
Train Loss: 0.2690, Accuracy: 0.9108, Precision: 0.8722, Recall: 0.8694, F1: 0.8707
Validation Loss: 0.5105, Accuracy: 0.8635, Precision: 0.8311, Recall: 0.8227, F1: 0.8242
Testing Loss: 0.3932, Accuracy: 0.8877, Precision: 0.8556, Recall: 0.8561, F1: 0.8549
LM Predictions:  [0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0289, Accuracy: 0.0952, Precision: 0.2121, Recall: 0.1208, F1: 0.0995
Epoch 29/70
Train Loss: 0.2594, Accuracy: 0.9151, Precision: 0.8783, Recall: 0.8713, F1: 0.8747
Validation Loss: 0.5243, Accuracy: 0.8742, Precision: 0.8547, Recall: 0.8193, F1: 0.8342
Testing Loss: 0.3992, Accuracy: 0.8841, Precision: 0.8719, Recall: 0.8307, F1: 0.8477
LM Predictions:  [0, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1720, Accuracy: 0.1190, Precision: 0.3596, Recall: 0.1375, F1: 0.1090
Epoch 30/70
Train Loss: 0.2689, Accuracy: 0.9082, Precision: 0.8678, Recall: 0.8665, F1: 0.8670
Validation Loss: 0.5366, Accuracy: 0.8678, Precision: 0.8372, Recall: 0.8178, F1: 0.8255
Testing Loss: 0.3874, Accuracy: 0.8865, Precision: 0.8656, Recall: 0.8409, F1: 0.8517
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1091, Accuracy: 0.1429, Precision: 0.4444, Recall: 0.1542, F1: 0.1386
Epoch 31/70
Train Loss: 0.2435, Accuracy: 0.9177, Precision: 0.8846, Recall: 0.8835, F1: 0.8840
Validation Loss: 0.5580, Accuracy: 0.8593, Precision: 0.8375, Recall: 0.7969, F1: 0.8132
Testing Loss: 0.4144, Accuracy: 0.8816, Precision: 0.8639, Recall: 0.8275, F1: 0.8414
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 0, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9908, Accuracy: 0.1667, Precision: 0.4708, Recall: 0.1708, F1: 0.1603
Epoch 32/70
Train Loss: 0.2374, Accuracy: 0.9182, Precision: 0.8831, Recall: 0.8758, F1: 0.8793
Validation Loss: 0.5408, Accuracy: 0.8657, Precision: 0.8341, Recall: 0.8245, F1: 0.8280
Testing Loss: 0.4123, Accuracy: 0.8792, Precision: 0.8515, Recall: 0.8532, F1: 0.8501
LM Predictions:  [0, 5, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 5, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9477, Accuracy: 0.1667, Precision: 0.4861, Recall: 0.1708, F1: 0.1774
Epoch 33/70
Train Loss: 0.2381, Accuracy: 0.9229, Precision: 0.8895, Recall: 0.8840, F1: 0.8867
Validation Loss: 0.6218, Accuracy: 0.8721, Precision: 0.8440, Recall: 0.8202, F1: 0.8283
Testing Loss: 0.4395, Accuracy: 0.8816, Precision: 0.8552, Recall: 0.8514, F1: 0.8529
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 4, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7935, Accuracy: 0.1667, Precision: 0.3690, Recall: 0.1708, F1: 0.1651
Epoch 34/70
Train Loss: 0.2188, Accuracy: 0.9265, Precision: 0.8908, Recall: 0.8916, F1: 0.8911
Validation Loss: 0.5739, Accuracy: 0.8635, Precision: 0.8335, Recall: 0.8154, F1: 0.8212
Testing Loss: 0.4439, Accuracy: 0.8744, Precision: 0.8505, Recall: 0.8513, F1: 0.8480
LM Predictions:  [0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 5, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1986, Accuracy: 0.1190, Precision: 0.3750, Recall: 0.1375, F1: 0.1262
Epoch 35/70
Train Loss: 0.2093, Accuracy: 0.9265, Precision: 0.8917, Recall: 0.8946, F1: 0.8929
Validation Loss: 0.6311, Accuracy: 0.8614, Precision: 0.8403, Recall: 0.7953, F1: 0.8134
Testing Loss: 0.4473, Accuracy: 0.8696, Precision: 0.8481, Recall: 0.8187, F1: 0.8308
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9338, Accuracy: 0.1667, Precision: 0.5385, Recall: 0.1750, F1: 0.1828
Epoch 36/70
Train Loss: 0.2113, Accuracy: 0.9298, Precision: 0.8980, Recall: 0.8966, F1: 0.8971
Validation Loss: 0.6206, Accuracy: 0.8635, Precision: 0.8346, Recall: 0.8025, F1: 0.8148
Testing Loss: 0.4390, Accuracy: 0.8684, Precision: 0.8442, Recall: 0.8114, F1: 0.8251
LM Predictions:  [0, 5, 0, 0, 0, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6406, Accuracy: 0.1667, Precision: 0.5278, Recall: 0.1750, F1: 0.1708
Epoch 37/70
Train Loss: 0.2035, Accuracy: 0.9298, Precision: 0.8967, Recall: 0.8959, F1: 0.8962
Validation Loss: 0.6244, Accuracy: 0.8507, Precision: 0.8246, Recall: 0.7945, F1: 0.8069
Testing Loss: 0.4653, Accuracy: 0.8635, Precision: 0.8421, Recall: 0.8215, F1: 0.8303
LM Predictions:  [0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7210, Accuracy: 0.1667, Precision: 0.5333, Recall: 0.1708, F1: 0.1729
Epoch 38/70
Train Loss: 0.2067, Accuracy: 0.9272, Precision: 0.8921, Recall: 0.8910, F1: 0.8914
Validation Loss: 0.6100, Accuracy: 0.8678, Precision: 0.8343, Recall: 0.8163, F1: 0.8236
Testing Loss: 0.4881, Accuracy: 0.8792, Precision: 0.8540, Recall: 0.8440, F1: 0.8485
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 2, 0, 4, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7140, Accuracy: 0.1905, Precision: 0.3090, Recall: 0.1917, F1: 0.1836
Epoch 39/70
Train Loss: 0.1991, Accuracy: 0.9310, Precision: 0.8959, Recall: 0.8938, F1: 0.8948
Validation Loss: 0.7006, Accuracy: 0.8635, Precision: 0.8314, Recall: 0.8036, F1: 0.8141
Testing Loss: 0.5164, Accuracy: 0.8732, Precision: 0.8438, Recall: 0.8307, F1: 0.8367
LM Predictions:  [0, 1, 0, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 0, 3, 0, 5, 2, 0, 4, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4591, Accuracy: 0.2381, Precision: 0.4944, Recall: 0.2269, F1: 0.2379
Epoch 40/70
Train Loss: 0.1781, Accuracy: 0.9353, Precision: 0.9028, Recall: 0.9010, F1: 0.9018
Validation Loss: 0.7279, Accuracy: 0.8635, Precision: 0.8308, Recall: 0.8136, F1: 0.8192
Testing Loss: 0.4939, Accuracy: 0.8768, Precision: 0.8458, Recall: 0.8434, F1: 0.8439
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 3, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6387, Accuracy: 0.1905, Precision: 0.4306, Recall: 0.1917, F1: 0.2067
Epoch 41/70
Train Loss: 0.1819, Accuracy: 0.9353, Precision: 0.9023, Recall: 0.9021, F1: 0.9021
Validation Loss: 0.6412, Accuracy: 0.8507, Precision: 0.8227, Recall: 0.7939, F1: 0.8057
Testing Loss: 0.4683, Accuracy: 0.8744, Precision: 0.8495, Recall: 0.8280, F1: 0.8376
LM Predictions:  [0, 3, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 4, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 0, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5395, Accuracy: 0.1667, Precision: 0.3111, Recall: 0.1750, F1: 0.1679
Epoch 42/70
Train Loss: 0.1716, Accuracy: 0.9419, Precision: 0.9114, Recall: 0.9118, F1: 0.9113
Validation Loss: 0.6716, Accuracy: 0.8571, Precision: 0.8253, Recall: 0.8102, F1: 0.8159
Testing Loss: 0.4999, Accuracy: 0.8768, Precision: 0.8490, Recall: 0.8346, F1: 0.8412
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 2, 0, 5, 4, 0, 4, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 0, 5, 4, 0, 5, 5, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1152, Accuracy: 0.1905, Precision: 0.2444, Recall: 0.1917, F1: 0.1773
Epoch 43/70
Train Loss: 0.1615, Accuracy: 0.9443, Precision: 0.9138, Recall: 0.9131, F1: 0.9133
Validation Loss: 0.6451, Accuracy: 0.8507, Precision: 0.8150, Recall: 0.7956, F1: 0.8026
Testing Loss: 0.5250, Accuracy: 0.8684, Precision: 0.8417, Recall: 0.8089, F1: 0.8231
LM Predictions:  [0, 3, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4325, Accuracy: 0.1905, Precision: 0.3250, Recall: 0.1917, F1: 0.1881
Epoch 44/70
Train Loss: 0.1656, Accuracy: 0.9410, Precision: 0.9112, Recall: 0.9103, F1: 0.9106
Validation Loss: 0.6891, Accuracy: 0.8593, Precision: 0.8273, Recall: 0.8042, F1: 0.8135
Testing Loss: 0.5285, Accuracy: 0.8732, Precision: 0.8509, Recall: 0.8160, F1: 0.8307
LM Predictions:  [0, 1, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 0, 5, 4, 0, 5, 5, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4090, Accuracy: 0.2381, Precision: 0.6146, Recall: 0.2269, F1: 0.2518
Epoch 45/70
Train Loss: 0.1664, Accuracy: 0.9391, Precision: 0.9061, Recall: 0.9097, F1: 0.9076
Validation Loss: 0.6020, Accuracy: 0.8721, Precision: 0.8436, Recall: 0.8183, F1: 0.8293
Testing Loss: 0.5095, Accuracy: 0.8708, Precision: 0.8434, Recall: 0.8162, F1: 0.8279
LM Predictions:  [0, 1, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 0, 0, 5, 5, 0, 4, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2487, Accuracy: 0.2143, Precision: 0.3794, Recall: 0.2102, F1: 0.2091
Epoch 46/70
Train Loss: 0.1526, Accuracy: 0.9455, Precision: 0.9142, Recall: 0.9172, F1: 0.9155
Validation Loss: 0.7189, Accuracy: 0.8571, Precision: 0.8313, Recall: 0.8019, F1: 0.8132
Testing Loss: 0.5620, Accuracy: 0.8671, Precision: 0.8341, Recall: 0.8065, F1: 0.8185
LM Predictions:  [0, 1, 0, 0, 0, 5, 5, 5, 0, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 4, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9989, Accuracy: 0.2857, Precision: 0.6528, Recall: 0.2685, F1: 0.2897
Epoch 47/70
Train Loss: 0.1381, Accuracy: 0.9483, Precision: 0.9181, Recall: 0.9264, F1: 0.9217
Validation Loss: 0.6626, Accuracy: 0.8614, Precision: 0.8317, Recall: 0.8064, F1: 0.8169
Testing Loss: 0.5356, Accuracy: 0.8696, Precision: 0.8415, Recall: 0.8199, F1: 0.8290
LM Predictions:  [0, 1, 0, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 4, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 5, 0, 4, 5, 0, 5, 5, 4, 5, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0092, Accuracy: 0.2619, Precision: 0.6667, Recall: 0.2435, F1: 0.2692
Epoch 48/70
Train Loss: 0.1503, Accuracy: 0.9407, Precision: 0.9110, Recall: 0.9128, F1: 0.9116
Validation Loss: 0.6955, Accuracy: 0.8593, Precision: 0.8243, Recall: 0.8123, F1: 0.8171
Testing Loss: 0.5410, Accuracy: 0.8756, Precision: 0.8496, Recall: 0.8252, F1: 0.8362
LM Predictions:  [0, 1, 0, 0, 4, 5, 2, 5, 4, 5, 0, 0, 2, 0, 3, 0, 3, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 2, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6906, Accuracy: 0.3095, Precision: 0.5479, Recall: 0.2852, F1: 0.3002
Epoch 49/70
Train Loss: 0.1409, Accuracy: 0.9455, Precision: 0.9153, Recall: 0.9213, F1: 0.9176
Validation Loss: 0.6440, Accuracy: 0.8785, Precision: 0.8566, Recall: 0.8208, F1: 0.8360
Testing Loss: 0.6001, Accuracy: 0.8490, Precision: 0.8267, Recall: 0.7766, F1: 0.7966
LM Predictions:  [0, 1, 5, 0, 0, 0, 5, 5, 0, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 0, 5, 0, 4, 5, 0, 0, 5, 0, 5, 0, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1286, Accuracy: 0.2619, Precision: 0.6905, Recall: 0.2519, F1: 0.2688
Epoch 50/70
Train Loss: 0.1370, Accuracy: 0.9490, Precision: 0.9207, Recall: 0.9216, F1: 0.9210
Validation Loss: 0.7158, Accuracy: 0.8593, Precision: 0.8219, Recall: 0.8169, F1: 0.8183
Testing Loss: 0.5601, Accuracy: 0.8708, Precision: 0.8344, Recall: 0.8413, F1: 0.8361
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 0, 3, 5, 2, 4, 0, 5, 0, 5, 5, 5, 0, 5, 0, 4, 5, 0, 4, 5, 5, 5, 5, 4, 5, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7745, Accuracy: 0.3333, Precision: 0.6944, Recall: 0.3019, F1: 0.3503
Epoch 51/70
Train Loss: 0.1398, Accuracy: 0.9462, Precision: 0.9164, Recall: 0.9121, F1: 0.9141
Validation Loss: 0.6969, Accuracy: 0.8614, Precision: 0.8273, Recall: 0.8146, F1: 0.8203
Testing Loss: 0.5577, Accuracy: 0.8684, Precision: 0.8408, Recall: 0.8268, F1: 0.8331
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 4, 5, 0, 0, 2, 4, 3, 0, 3, 4, 0, 3, 0, 0, 3, 5, 0, 5, 0, 4, 5, 0, 4, 5, 0, 5, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6951, Accuracy: 0.4048, Precision: 0.6426, Recall: 0.3477, F1: 0.3809
Epoch 52/70
Train Loss: 0.1279, Accuracy: 0.9533, Precision: 0.9265, Recall: 0.9353, F1: 0.9304
Validation Loss: 0.8457, Accuracy: 0.8614, Precision: 0.8365, Recall: 0.8042, F1: 0.8155
Testing Loss: 0.6062, Accuracy: 0.8563, Precision: 0.8279, Recall: 0.7988, F1: 0.8111
LM Predictions:  [0, 1, 5, 0, 1, 5, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 0, 4, 0, 3, 0, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 5, 0, 0, 5, 4, 5, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7754, Accuracy: 0.3571, Precision: 0.6961, Recall: 0.3162, F1: 0.3691
Epoch 53/70
Train Loss: 0.1258, Accuracy: 0.9514, Precision: 0.9224, Recall: 0.9272, F1: 0.9245
Validation Loss: 0.7469, Accuracy: 0.8678, Precision: 0.8308, Recall: 0.8124, F1: 0.8201
Testing Loss: 0.5752, Accuracy: 0.8647, Precision: 0.8282, Recall: 0.8128, F1: 0.8198
LM Predictions:  [0, 1, 2, 0, 4, 5, 2, 5, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 4, 5, 0, 2, 0, 0, 5, 0, 4, 2, 0, 4, 5, 0, 0, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.4664, Accuracy: 0.4286, Precision: 0.6264, Recall: 0.3769, F1: 0.3670
Epoch 54/70
Train Loss: 0.1217, Accuracy: 0.9538, Precision: 0.9269, Recall: 0.9284, F1: 0.9275
Validation Loss: 0.8063, Accuracy: 0.8550, Precision: 0.8146, Recall: 0.8040, F1: 0.8082
Testing Loss: 0.6086, Accuracy: 0.8684, Precision: 0.8333, Recall: 0.8226, F1: 0.8272
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 5, 2, 0, 0, 5, 0, 4, 2, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.3084, Accuracy: 0.4524, Precision: 0.6675, Recall: 0.3935, F1: 0.4144
Epoch 55/70
Train Loss: 0.1166, Accuracy: 0.9547, Precision: 0.9272, Recall: 0.9339, F1: 0.9302
Validation Loss: 0.8173, Accuracy: 0.8486, Precision: 0.8052, Recall: 0.7933, F1: 0.7963
Testing Loss: 0.5711, Accuracy: 0.8575, Precision: 0.8180, Recall: 0.8180, F1: 0.8166
LM Predictions:  [5, 1, 5, 0, 1, 5, 5, 5, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 5, 3, 5, 0, 5, 0, 4, 2, 0, 4, 5, 5, 5, 5, 4, 5, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.3576, Accuracy: 0.4762, Precision: 0.7143, Recall: 0.3912, F1: 0.4769
Epoch 56/70
Train Loss: 0.1139, Accuracy: 0.9533, Precision: 0.9216, Recall: 0.9285, F1: 0.9246
Validation Loss: 0.7779, Accuracy: 0.8657, Precision: 0.8363, Recall: 0.8104, F1: 0.8207
Testing Loss: 0.5993, Accuracy: 0.8659, Precision: 0.8399, Recall: 0.8067, F1: 0.8211
LM Predictions:  [0, 1, 2, 0, 1, 5, 2, 5, 4, 5, 5, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 5, 0, 0, 5, 0, 4, 2, 0, 4, 5, 0, 0, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2569, Accuracy: 0.4524, Precision: 0.6762, Recall: 0.3954, F1: 0.4245
Epoch 57/70
Train Loss: 0.1194, Accuracy: 0.9535, Precision: 0.9264, Recall: 0.9267, F1: 0.9264
Validation Loss: 0.7971, Accuracy: 0.8507, Precision: 0.8149, Recall: 0.7929, F1: 0.8009
Testing Loss: 0.5753, Accuracy: 0.8623, Precision: 0.8344, Recall: 0.7939, F1: 0.8091
LM Predictions:  [0, 1, 2, 0, 1, 5, 2, 5, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 0, 5, 0, 1, 3, 0, 4, 2, 0, 4, 0, 0, 0, 5, 4, 1, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0073, Accuracy: 0.5238, Precision: 0.6369, Recall: 0.4491, F1: 0.4850
Epoch 58/70
Train Loss: 0.1098, Accuracy: 0.9576, Precision: 0.9331, Recall: 0.9344, F1: 0.9337
Validation Loss: 0.8313, Accuracy: 0.8635, Precision: 0.8303, Recall: 0.8017, F1: 0.8131
Testing Loss: 0.6683, Accuracy: 0.8551, Precision: 0.8216, Recall: 0.7791, F1: 0.7956
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 5, 4, 5, 5, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 0, 0, 2, 0, 4, 2, 0, 4, 0, 0, 0, 0, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0481, Accuracy: 0.5238, Precision: 0.7037, Recall: 0.4662, F1: 0.4761
Epoch 59/70
Train Loss: 0.1136, Accuracy: 0.9561, Precision: 0.9312, Recall: 0.9302, F1: 0.9306
Validation Loss: 0.8777, Accuracy: 0.8635, Precision: 0.8230, Recall: 0.8081, F1: 0.8138
Testing Loss: 0.6377, Accuracy: 0.8611, Precision: 0.8332, Recall: 0.7951, F1: 0.8111
LM Predictions:  [0, 1, 0, 0, 1, 5, 0, 5, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 0, 0, 2, 0, 4, 2, 0, 4, 5, 0, 5, 0, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2422, Accuracy: 0.5000, Precision: 0.7037, Recall: 0.4454, F1: 0.4634
Epoch 60/70
Train Loss: 0.1030, Accuracy: 0.9542, Precision: 0.9290, Recall: 0.9266, F1: 0.9278
Validation Loss: 0.7996, Accuracy: 0.8678, Precision: 0.8347, Recall: 0.8207, F1: 0.8263
Testing Loss: 0.6231, Accuracy: 0.8575, Precision: 0.8218, Recall: 0.8022, F1: 0.8109
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 5, 0, 0, 2, 0, 4, 2, 0, 4, 0, 0, 5, 5, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1688, Accuracy: 0.5238, Precision: 0.6833, Recall: 0.4477, F1: 0.4444
Epoch 61/70
Train Loss: 0.1033, Accuracy: 0.9557, Precision: 0.9318, Recall: 0.9316, F1: 0.9316
Validation Loss: 0.7865, Accuracy: 0.8571, Precision: 0.8170, Recall: 0.8107, F1: 0.8133
Testing Loss: 0.6645, Accuracy: 0.8635, Precision: 0.8328, Recall: 0.8207, F1: 0.8247
LM Predictions:  [0, 1, 2, 0, 4, 5, 0, 4, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 5, 0, 2, 4, 4, 2, 0, 4, 0, 0, 5, 0, 4, 5, 4, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9025, Accuracy: 0.6190, Precision: 0.6944, Recall: 0.5310, F1: 0.5141
Epoch 62/70
Train Loss: 0.1066, Accuracy: 0.9535, Precision: 0.9246, Recall: 0.9297, F1: 0.9269
Validation Loss: 0.8176, Accuracy: 0.8593, Precision: 0.8300, Recall: 0.8063, F1: 0.8148
Testing Loss: 0.6915, Accuracy: 0.8575, Precision: 0.8220, Recall: 0.7923, F1: 0.8052
LM Predictions:  [0, 1, 2, 0, 4, 5, 0, 5, 4, 5, 5, 0, 2, 0, 3, 0, 2, 4, 0, 3, 1, 0, 5, 0, 0, 2, 0, 4, 2, 0, 4, 5, 0, 5, 0, 4, 1, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9662, Accuracy: 0.5000, Precision: 0.6349, Recall: 0.4495, F1: 0.4545
Epoch 63/70
Train Loss: 0.1055, Accuracy: 0.9578, Precision: 0.9334, Recall: 0.9326, F1: 0.9330
Validation Loss: 0.8184, Accuracy: 0.8614, Precision: 0.8249, Recall: 0.8138, F1: 0.8172
Testing Loss: 0.6548, Accuracy: 0.8599, Precision: 0.8281, Recall: 0.8036, F1: 0.8145
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 4, 4, 0, 5, 0, 2, 0, 3, 0, 2, 4, 0, 3, 1, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 0, 5, 0, 4, 1, 4, 5, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9985, Accuracy: 0.5714, Precision: 0.6392, Recall: 0.5014, F1: 0.5063
Epoch 64/70
Train Loss: 0.0893, Accuracy: 0.9637, Precision: 0.9401, Recall: 0.9426, F1: 0.9412
Validation Loss: 0.9943, Accuracy: 0.8529, Precision: 0.8138, Recall: 0.7875, F1: 0.7961
Testing Loss: 0.7302, Accuracy: 0.8599, Precision: 0.8253, Recall: 0.7938, F1: 0.8067
LM Predictions:  [0, 1, 2, 1, 1, 5, 5, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 1, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6226, Accuracy: 0.7619, Precision: 0.7199, Recall: 0.6421, F1: 0.6612
Epoch 65/70
Train Loss: 0.1003, Accuracy: 0.9578, Precision: 0.9321, Recall: 0.9357, F1: 0.9338
Validation Loss: 0.8700, Accuracy: 0.8571, Precision: 0.8243, Recall: 0.8007, F1: 0.8105
Testing Loss: 0.6724, Accuracy: 0.8587, Precision: 0.8172, Recall: 0.7927, F1: 0.8028
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 0, 0, 4, 1, 4, 5, 2, 3, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8325, Accuracy: 0.6667, Precision: 0.6846, Recall: 0.5718, F1: 0.5857
Epoch 66/70
Train Loss: 0.0969, Accuracy: 0.9599, Precision: 0.9372, Recall: 0.9366, F1: 0.9369
Validation Loss: 0.8970, Accuracy: 0.8486, Precision: 0.8070, Recall: 0.7921, F1: 0.7967
Testing Loss: 0.6383, Accuracy: 0.8611, Precision: 0.8310, Recall: 0.8070, F1: 0.8176
LM Predictions:  [0, 1, 2, 1, 1, 5, 0, 5, 4, 5, 5, 0, 2, 0, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 0, 1, 4, 3, 2, 3, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8438, Accuracy: 0.7143, Precision: 0.7199, Recall: 0.6069, F1: 0.6388
Epoch 67/70
Train Loss: 0.0904, Accuracy: 0.9618, Precision: 0.9372, Recall: 0.9453, F1: 0.9409
Validation Loss: 0.9692, Accuracy: 0.8529, Precision: 0.8061, Recall: 0.7794, F1: 0.7874
Testing Loss: 0.7385, Accuracy: 0.8514, Precision: 0.8103, Recall: 0.7866, F1: 0.7955
LM Predictions:  [0, 1, 2, 1, 1, 0, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5910, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8506, F1: 0.8349
Epoch 68/70
Train Loss: 0.0906, Accuracy: 0.9583, Precision: 0.9347, Recall: 0.9325, F1: 0.9336
Validation Loss: 0.7971, Accuracy: 0.8593, Precision: 0.8264, Recall: 0.8031, F1: 0.8130
Testing Loss: 0.6997, Accuracy: 0.8514, Precision: 0.8221, Recall: 0.7916, F1: 0.8043
LM Predictions:  [0, 1, 2, 1, 1, 5, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6869, Accuracy: 0.7619, Precision: 0.7424, Recall: 0.6588, F1: 0.6648
Epoch 69/70
Train Loss: 0.0915, Accuracy: 0.9609, Precision: 0.9413, Recall: 0.9352, F1: 0.9382
Validation Loss: 0.9405, Accuracy: 0.8657, Precision: 0.8395, Recall: 0.8064, F1: 0.8186
Testing Loss: 0.7382, Accuracy: 0.8563, Precision: 0.8220, Recall: 0.7944, F1: 0.8064
LM Predictions:  [0, 1, 2, 1, 1, 5, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4456, Accuracy: 0.8333, Precision: 0.7500, Recall: 0.7088, F1: 0.7076
Epoch 70/70
Train Loss: 0.0861, Accuracy: 0.9609, Precision: 0.9371, Recall: 0.9374, F1: 0.9372
Validation Loss: 0.8993, Accuracy: 0.8593, Precision: 0.8319, Recall: 0.7823, F1: 0.8011
Testing Loss: 0.7354, Accuracy: 0.8587, Precision: 0.8322, Recall: 0.7861, F1: 0.8049
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 0, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 0, 0, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8077, Accuracy: 0.6429, Precision: 0.7105, Recall: 0.5699, F1: 0.5601

