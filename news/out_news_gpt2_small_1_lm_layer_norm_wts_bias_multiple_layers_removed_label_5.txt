Model: openai-community/gpt2, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
For early layers:  [0, 1, 2, 3]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.7543, Accuracy: 0.2388, Precision: 0.1503, Recall: 0.1611, F1: 0.1379
Validation Loss: 1.6793, Accuracy: 0.2217, Precision: 0.1030, Recall: 0.1442, F1: 0.1153
Testing Loss: 1.6656, Accuracy: 0.2645, Precision: 0.1330, Recall: 0.1745, F1: 0.1469
LM Predictions:  [0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8770, Accuracy: 0.1905, Precision: 0.1210, Recall: 0.2339, F1: 0.1442
Epoch 2/70
Train Loss: 1.6803, Accuracy: 0.2699, Precision: 0.1664, Recall: 0.1752, F1: 0.1406
Validation Loss: 1.6728, Accuracy: 0.2473, Precision: 0.1262, Recall: 0.1629, F1: 0.1119
Testing Loss: 1.6620, Accuracy: 0.2802, Precision: 0.1355, Recall: 0.1851, F1: 0.1246
LM Predictions:  [1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8659, Accuracy: 0.1667, Precision: 0.0635, Recall: 0.1911, F1: 0.0952
Epoch 3/70
Train Loss: 1.6698, Accuracy: 0.2611, Precision: 0.1285, Recall: 0.1702, F1: 0.1389
Validation Loss: 1.6762, Accuracy: 0.2559, Precision: 0.0928, Recall: 0.1744, F1: 0.0952
Testing Loss: 1.6649, Accuracy: 0.2572, Precision: 0.0927, Recall: 0.1758, F1: 0.0956
LM Predictions:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8455, Accuracy: 0.2143, Precision: 0.0462, Recall: 0.2000, F1: 0.0750
Epoch 4/70
Train Loss: 1.6622, Accuracy: 0.2694, Precision: 0.1724, Recall: 0.1733, F1: 0.1357
Validation Loss: 1.6720, Accuracy: 0.2708, Precision: 0.1005, Recall: 0.1672, F1: 0.0786
Testing Loss: 1.6589, Accuracy: 0.2850, Precision: 0.1173, Recall: 0.1769, F1: 0.0928
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8535, Accuracy: 0.1190, Precision: 0.0238, Recall: 0.2000, F1: 0.0426
Epoch 5/70
Train Loss: 1.6571, Accuracy: 0.2737, Precision: 0.1831, Recall: 0.1740, F1: 0.1282
Validation Loss: 1.6708, Accuracy: 0.2900, Precision: 0.1042, Recall: 0.1829, F1: 0.1173
Testing Loss: 1.6583, Accuracy: 0.3019, Precision: 0.1903, Recall: 0.1910, F1: 0.1245
LM Predictions:  [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8624, Accuracy: 0.1429, Precision: 0.1211, Recall: 0.2044, F1: 0.0987
Epoch 6/70
Train Loss: 1.6533, Accuracy: 0.2914, Precision: 0.1476, Recall: 0.1871, F1: 0.1469
Validation Loss: 1.6631, Accuracy: 0.3092, Precision: 0.1651, Recall: 0.1963, F1: 0.1390
Testing Loss: 1.6510, Accuracy: 0.3128, Precision: 0.1853, Recall: 0.1988, F1: 0.1420
LM Predictions:  [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8463, Accuracy: 0.1429, Precision: 0.1538, Recall: 0.2044, F1: 0.1030
Epoch 7/70
Train Loss: 1.6513, Accuracy: 0.2964, Precision: 0.1515, Recall: 0.1907, F1: 0.1526
Validation Loss: 1.6633, Accuracy: 0.3006, Precision: 0.1157, Recall: 0.1886, F1: 0.1171
Testing Loss: 1.6501, Accuracy: 0.3128, Precision: 0.2866, Recall: 0.1973, F1: 0.1281
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8913, Accuracy: 0.1190, Precision: 0.0872, Recall: 0.1822, F1: 0.0697
Epoch 8/70
Train Loss: 1.6499, Accuracy: 0.2898, Precision: 0.1438, Recall: 0.1855, F1: 0.1436
Validation Loss: 1.6557, Accuracy: 0.3454, Precision: 0.1829, Recall: 0.2285, F1: 0.1613
Testing Loss: 1.6448, Accuracy: 0.3708, Precision: 0.2302, Recall: 0.2447, F1: 0.1775
LM Predictions:  [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8409, Accuracy: 0.2143, Precision: 0.0857, Recall: 0.2356, F1: 0.1241
Epoch 9/70
Train Loss: 1.6430, Accuracy: 0.3092, Precision: 0.3264, Recall: 0.1998, F1: 0.1565
Validation Loss: 1.6550, Accuracy: 0.3539, Precision: 0.1793, Recall: 0.2314, F1: 0.1886
Testing Loss: 1.6453, Accuracy: 0.3792, Precision: 0.2055, Recall: 0.2478, F1: 0.2037
LM Predictions:  [0, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 0, 0, 0, 0, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8760, Accuracy: 0.1667, Precision: 0.1222, Recall: 0.2117, F1: 0.1314
Epoch 10/70
Train Loss: 1.6416, Accuracy: 0.3040, Precision: 0.1548, Recall: 0.1967, F1: 0.1606
Validation Loss: 1.6459, Accuracy: 0.3710, Precision: 0.1748, Recall: 0.2407, F1: 0.1702
Testing Loss: 1.6361, Accuracy: 0.3804, Precision: 0.2731, Recall: 0.2474, F1: 0.1776
LM Predictions:  [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8426, Accuracy: 0.1667, Precision: 0.0867, Recall: 0.2089, F1: 0.1105
Epoch 11/70
Train Loss: 1.6287, Accuracy: 0.3244, Precision: 0.2006, Recall: 0.2108, F1: 0.1754
Validation Loss: 1.6308, Accuracy: 0.3987, Precision: 0.2162, Recall: 0.2606, F1: 0.1787
Testing Loss: 1.6216, Accuracy: 0.4046, Precision: 0.3025, Recall: 0.2642, F1: 0.1837
LM Predictions:  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8455, Accuracy: 0.1429, Precision: 0.0700, Recall: 0.1867, F1: 0.0914
Epoch 12/70
Train Loss: 1.6104, Accuracy: 0.3507, Precision: 0.2515, Recall: 0.2313, F1: 0.1971
Validation Loss: 1.5644, Accuracy: 0.3945, Precision: 0.2039, Recall: 0.2660, F1: 0.2129
Testing Loss: 1.5434, Accuracy: 0.4360, Precision: 0.3979, Recall: 0.2947, F1: 0.2454
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8459, Accuracy: 0.2381, Precision: 0.1900, Recall: 0.2961, F1: 0.1730
Epoch 13/70
Train Loss: 1.5474, Accuracy: 0.4008, Precision: 0.2430, Recall: 0.2671, F1: 0.2289
Validation Loss: 1.4771, Accuracy: 0.4925, Precision: 0.2612, Recall: 0.3377, F1: 0.2869
Testing Loss: 1.4424, Accuracy: 0.5072, Precision: 0.2683, Recall: 0.3484, F1: 0.2939
LM Predictions:  [0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 2, 2, 2, 0, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4079, Accuracy: 0.1905, Precision: 0.1428, Recall: 0.2422, F1: 0.1429
Epoch 14/70
Train Loss: 1.3949, Accuracy: 0.4823, Precision: 0.2966, Recall: 0.3256, F1: 0.2847
Validation Loss: 1.1999, Accuracy: 0.5565, Precision: 0.4113, Recall: 0.3713, F1: 0.3253
Testing Loss: 1.2103, Accuracy: 0.5411, Precision: 0.5288, Recall: 0.3647, F1: 0.3212
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6552, Accuracy: 0.1429, Precision: 0.0930, Recall: 0.2222, F1: 0.0798
Epoch 15/70
Train Loss: 1.2503, Accuracy: 0.5447, Precision: 0.5527, Recall: 0.3766, F1: 0.3420
Validation Loss: 0.9695, Accuracy: 0.6461, Precision: 0.5476, Recall: 0.4899, F1: 0.4757
Testing Loss: 0.9747, Accuracy: 0.6413, Precision: 0.6152, Recall: 0.4885, F1: 0.4647
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7532, Accuracy: 0.1190, Precision: 0.1211, Recall: 0.1800, F1: 0.0705
Epoch 16/70
Train Loss: 1.1209, Accuracy: 0.5917, Precision: 0.5683, Recall: 0.4396, F1: 0.4204
Validation Loss: 0.9204, Accuracy: 0.6716, Precision: 0.7515, Recall: 0.5197, F1: 0.5178
Testing Loss: 0.9326, Accuracy: 0.6643, Precision: 0.7472, Recall: 0.5043, F1: 0.4951
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3510, Accuracy: 0.0714, Precision: 0.0158, Recall: 0.1200, F1: 0.0279
Epoch 17/70
Train Loss: 1.0359, Accuracy: 0.6291, Precision: 0.5441, Recall: 0.4840, F1: 0.4796
Validation Loss: 0.8552, Accuracy: 0.7122, Precision: 0.6584, Recall: 0.5976, F1: 0.6111
Testing Loss: 0.8755, Accuracy: 0.7101, Precision: 0.6685, Recall: 0.5838, F1: 0.5994
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 2, 0, 2, 0, 5, 2, 0, 0, 3, 0, 5, 0, 0, 2, 0, 0, 0, 5, 5, 0, 0, 1, 5, 0, 5, 0, 1, 0, 3, 0, 1, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1412, Accuracy: 0.0714, Precision: 0.0217, Recall: 0.1000, F1: 0.0357
Epoch 18/70
Train Loss: 0.9462, Accuracy: 0.6616, Precision: 0.5910, Recall: 0.5297, F1: 0.5349
Validation Loss: 0.7736, Accuracy: 0.7527, Precision: 0.7097, Recall: 0.6513, F1: 0.6685
Testing Loss: 0.7645, Accuracy: 0.7331, Precision: 0.6758, Recall: 0.6111, F1: 0.6206
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 2, 0, 0, 0, 5, 0, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 1, 0, 0, 5, 0, 0, 0, 3, 0, 0, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1156, Accuracy: 0.1190, Precision: 0.1080, Recall: 0.1542, F1: 0.0750
Epoch 19/70
Train Loss: 0.9298, Accuracy: 0.6747, Precision: 0.6233, Recall: 0.5559, F1: 0.5635
Validation Loss: 0.7792, Accuracy: 0.7569, Precision: 0.7257, Recall: 0.6481, F1: 0.6710
Testing Loss: 0.7424, Accuracy: 0.7572, Precision: 0.7514, Recall: 0.6421, F1: 0.6685
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 0, 5, 0, 5, 2, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 5, 0, 0, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4645, Accuracy: 0.0714, Precision: 0.0185, Recall: 0.1000, F1: 0.0313
Epoch 20/70
Train Loss: 0.8400, Accuracy: 0.7090, Precision: 0.6595, Recall: 0.5945, F1: 0.6063
Validation Loss: 0.7318, Accuracy: 0.7783, Precision: 0.7483, Recall: 0.6997, F1: 0.7177
Testing Loss: 0.6779, Accuracy: 0.7705, Precision: 0.7451, Recall: 0.6629, F1: 0.6853
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 5, 0, 5, 3, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8320, Accuracy: 0.0714, Precision: 0.0179, Recall: 0.1000, F1: 0.0303
Epoch 21/70
Train Loss: 0.8269, Accuracy: 0.7121, Precision: 0.6459, Recall: 0.5979, F1: 0.6060
Validation Loss: 0.7154, Accuracy: 0.7761, Precision: 0.7440, Recall: 0.7335, F1: 0.7298
Testing Loss: 0.6565, Accuracy: 0.7838, Precision: 0.7484, Recall: 0.7295, F1: 0.7329
LM Predictions:  [0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8055, Accuracy: 0.0476, Precision: 0.0185, Recall: 0.0667, F1: 0.0290
Epoch 22/70
Train Loss: 0.8016, Accuracy: 0.7192, Precision: 0.6619, Recall: 0.6139, F1: 0.6247
Validation Loss: 0.6795, Accuracy: 0.7825, Precision: 0.7686, Recall: 0.6853, F1: 0.7114
Testing Loss: 0.6792, Accuracy: 0.7850, Precision: 0.7932, Recall: 0.6749, F1: 0.7013
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 5, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6128, Accuracy: 0.0714, Precision: 0.0172, Recall: 0.1000, F1: 0.0294
Epoch 23/70
Train Loss: 0.7898, Accuracy: 0.7271, Precision: 0.6752, Recall: 0.6231, F1: 0.6353
Validation Loss: 0.6704, Accuracy: 0.7996, Precision: 0.7644, Recall: 0.7191, F1: 0.7356
Testing Loss: 0.6357, Accuracy: 0.7874, Precision: 0.7648, Recall: 0.6835, F1: 0.6955
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 4, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3051, Accuracy: 0.1190, Precision: 0.0778, Recall: 0.1500, F1: 0.0637
Epoch 24/70
Train Loss: 0.7236, Accuracy: 0.7456, Precision: 0.6840, Recall: 0.6402, F1: 0.6479
Validation Loss: 0.6314, Accuracy: 0.7910, Precision: 0.7586, Recall: 0.7186, F1: 0.7350
Testing Loss: 0.5967, Accuracy: 0.8237, Precision: 0.8118, Recall: 0.7427, F1: 0.7643
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 5, 5, 5, 5, 3, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 5, 5, 5, 3, 5, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8420, Accuracy: 0.0952, Precision: 0.1061, Recall: 0.1167, F1: 0.0648
Epoch 25/70
Train Loss: 0.7132, Accuracy: 0.7524, Precision: 0.7053, Recall: 0.6533, F1: 0.6660
Validation Loss: 0.6382, Accuracy: 0.7932, Precision: 0.7784, Recall: 0.7096, F1: 0.7197
Testing Loss: 0.5426, Accuracy: 0.8140, Precision: 0.8307, Recall: 0.7253, F1: 0.7361
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 4, 0, 0, 0, 0, 2, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 5, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4852, Accuracy: 0.0952, Precision: 0.0230, Recall: 0.1333, F1: 0.0392
Epoch 26/70
Train Loss: 0.7013, Accuracy: 0.7610, Precision: 0.7011, Recall: 0.6526, F1: 0.6631
Validation Loss: 0.6249, Accuracy: 0.8124, Precision: 0.8319, Recall: 0.7343, F1: 0.7627
Testing Loss: 0.5505, Accuracy: 0.8164, Precision: 0.8581, Recall: 0.7242, F1: 0.7467
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8464, Accuracy: 0.0952, Precision: 0.0202, Recall: 0.1333, F1: 0.0351
Epoch 27/70
Train Loss: 0.6581, Accuracy: 0.7724, Precision: 0.7195, Recall: 0.6751, F1: 0.6867
Validation Loss: 0.6582, Accuracy: 0.8124, Precision: 0.8389, Recall: 0.7346, F1: 0.7583
Testing Loss: 0.5863, Accuracy: 0.8176, Precision: 0.8575, Recall: 0.7227, F1: 0.7403
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 0, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8450, Accuracy: 0.1190, Precision: 0.1063, Recall: 0.1500, F1: 0.0670
Epoch 28/70
Train Loss: 0.6731, Accuracy: 0.7804, Precision: 0.7312, Recall: 0.6842, F1: 0.6961
Validation Loss: 0.5825, Accuracy: 0.8507, Precision: 0.8414, Recall: 0.8019, F1: 0.8179
Testing Loss: 0.5050, Accuracy: 0.8394, Precision: 0.8395, Recall: 0.7568, F1: 0.7743
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 0, 3, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5300, Accuracy: 0.1190, Precision: 0.1914, Recall: 0.1500, F1: 0.0720
Epoch 29/70
Train Loss: 0.6247, Accuracy: 0.7863, Precision: 0.7342, Recall: 0.6933, F1: 0.7056
Validation Loss: 0.5868, Accuracy: 0.8486, Precision: 0.8234, Recall: 0.8113, F1: 0.8168
Testing Loss: 0.5137, Accuracy: 0.8490, Precision: 0.8329, Recall: 0.7797, F1: 0.7991
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 5, 5, 5, 0, 0, 2, 0, 0, 5, 0, 5, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 4, 0, 5, 5, 5, 5, 3, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4924, Accuracy: 0.1190, Precision: 0.1930, Recall: 0.1375, F1: 0.1028
Epoch 30/70
Train Loss: 0.6508, Accuracy: 0.7825, Precision: 0.7265, Recall: 0.6906, F1: 0.7023
Validation Loss: 0.5658, Accuracy: 0.8230, Precision: 0.8119, Recall: 0.7740, F1: 0.7872
Testing Loss: 0.4763, Accuracy: 0.8454, Precision: 0.8511, Recall: 0.7661, F1: 0.7773
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 5, 5, 5, 3, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4660, Accuracy: 0.1190, Precision: 0.1944, Recall: 0.1500, F1: 0.0763
Epoch 31/70
Train Loss: 0.6138, Accuracy: 0.7937, Precision: 0.7330, Recall: 0.6990, F1: 0.7085
Validation Loss: 0.5836, Accuracy: 0.8252, Precision: 0.8298, Recall: 0.7702, F1: 0.7921
Testing Loss: 0.5180, Accuracy: 0.8394, Precision: 0.8598, Recall: 0.7498, F1: 0.7696
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7045, Accuracy: 0.0952, Precision: 0.0222, Recall: 0.1333, F1: 0.0381
Epoch 32/70
Train Loss: 0.5990, Accuracy: 0.7946, Precision: 0.7368, Recall: 0.7029, F1: 0.7137
Validation Loss: 0.5588, Accuracy: 0.8443, Precision: 0.8215, Recall: 0.8034, F1: 0.8097
Testing Loss: 0.4742, Accuracy: 0.8563, Precision: 0.8446, Recall: 0.7980, F1: 0.8091
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 4, 5, 5, 4, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4652, Accuracy: 0.1190, Precision: 0.0894, Recall: 0.1333, F1: 0.0815
Epoch 33/70
Train Loss: 0.5940, Accuracy: 0.8044, Precision: 0.7481, Recall: 0.7116, F1: 0.7234
Validation Loss: 0.5635, Accuracy: 0.8401, Precision: 0.8251, Recall: 0.7837, F1: 0.7982
Testing Loss: 0.4922, Accuracy: 0.8454, Precision: 0.8466, Recall: 0.7523, F1: 0.7697
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 4, 5, 0, 0, 3, 0, 3, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6356, Accuracy: 0.1667, Precision: 0.2479, Recall: 0.1833, F1: 0.1242
Epoch 34/70
Train Loss: 0.5759, Accuracy: 0.8065, Precision: 0.7642, Recall: 0.7306, F1: 0.7434
Validation Loss: 0.5729, Accuracy: 0.8380, Precision: 0.8141, Recall: 0.7971, F1: 0.8021
Testing Loss: 0.4845, Accuracy: 0.8478, Precision: 0.8369, Recall: 0.7744, F1: 0.7873
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5870, Accuracy: 0.1190, Precision: 0.1329, Recall: 0.1333, F1: 0.0870
Epoch 35/70
Train Loss: 0.5509, Accuracy: 0.8148, Precision: 0.7737, Recall: 0.7360, F1: 0.7490
Validation Loss: 0.5308, Accuracy: 0.8486, Precision: 0.8169, Recall: 0.8246, F1: 0.8200
Testing Loss: 0.4368, Accuracy: 0.8587, Precision: 0.8287, Recall: 0.8142, F1: 0.8210
LM Predictions:  [0, 3, 0, 0, 5, 5, 5, 5, 4, 5, 5, 5, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 4, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3589, Accuracy: 0.0952, Precision: 0.1319, Recall: 0.1000, F1: 0.0830
Epoch 36/70
Train Loss: 0.5462, Accuracy: 0.8136, Precision: 0.7673, Recall: 0.7363, F1: 0.7486
Validation Loss: 0.5366, Accuracy: 0.8358, Precision: 0.8251, Recall: 0.7834, F1: 0.7984
Testing Loss: 0.4645, Accuracy: 0.8442, Precision: 0.8451, Recall: 0.7651, F1: 0.7814
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4405, Accuracy: 0.1190, Precision: 0.1319, Recall: 0.1333, F1: 0.0858
Epoch 37/70
Train Loss: 0.5313, Accuracy: 0.8203, Precision: 0.7721, Recall: 0.7391, F1: 0.7508
Validation Loss: 0.5522, Accuracy: 0.8593, Precision: 0.8653, Recall: 0.8006, F1: 0.8241
Testing Loss: 0.4856, Accuracy: 0.8418, Precision: 0.8693, Recall: 0.7477, F1: 0.7667
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6567, Accuracy: 0.1190, Precision: 0.1303, Recall: 0.1333, F1: 0.0835
Epoch 38/70
Train Loss: 0.5351, Accuracy: 0.8200, Precision: 0.7706, Recall: 0.7403, F1: 0.7515
Validation Loss: 0.5428, Accuracy: 0.8486, Precision: 0.8360, Recall: 0.7853, F1: 0.8060
Testing Loss: 0.4689, Accuracy: 0.8454, Precision: 0.8754, Recall: 0.7632, F1: 0.7878
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4985, Accuracy: 0.1190, Precision: 0.1923, Recall: 0.1500, F1: 0.0733
Epoch 39/70
Train Loss: 0.5433, Accuracy: 0.8188, Precision: 0.7670, Recall: 0.7357, F1: 0.7465
Validation Loss: 0.5143, Accuracy: 0.8721, Precision: 0.8557, Recall: 0.8213, F1: 0.8352
Testing Loss: 0.4489, Accuracy: 0.8563, Precision: 0.8664, Recall: 0.7808, F1: 0.7961
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 4, 5, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1870, Accuracy: 0.1429, Precision: 0.1368, Recall: 0.1667, F1: 0.0943
Epoch 40/70
Train Loss: 0.5296, Accuracy: 0.8229, Precision: 0.7766, Recall: 0.7436, F1: 0.7558
Validation Loss: 0.5067, Accuracy: 0.8699, Precision: 0.8399, Recall: 0.8349, F1: 0.8370
Testing Loss: 0.4198, Accuracy: 0.8659, Precision: 0.8456, Recall: 0.8054, F1: 0.8196
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 5, 3, 0, 0, 0, 0, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2584, Accuracy: 0.0952, Precision: 0.1842, Recall: 0.1000, F1: 0.0833
Epoch 41/70
Train Loss: 0.5057, Accuracy: 0.8321, Precision: 0.7832, Recall: 0.7512, F1: 0.7627
Validation Loss: 0.5171, Accuracy: 0.8614, Precision: 0.8436, Recall: 0.8028, F1: 0.8181
Testing Loss: 0.4379, Accuracy: 0.8611, Precision: 0.8694, Recall: 0.7838, F1: 0.8058
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0280, Accuracy: 0.1190, Precision: 0.1875, Recall: 0.1333, F1: 0.0900
Epoch 42/70
Train Loss: 0.5023, Accuracy: 0.8338, Precision: 0.7875, Recall: 0.7583, F1: 0.7697
Validation Loss: 0.4691, Accuracy: 0.8614, Precision: 0.8418, Recall: 0.8170, F1: 0.8277
Testing Loss: 0.4225, Accuracy: 0.8599, Precision: 0.8342, Recall: 0.7960, F1: 0.8080
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 5, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 4, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3414, Accuracy: 0.0952, Precision: 0.1287, Recall: 0.1000, F1: 0.0791
Epoch 43/70
Train Loss: 0.5000, Accuracy: 0.8283, Precision: 0.7814, Recall: 0.7601, F1: 0.7688
Validation Loss: 0.4965, Accuracy: 0.8635, Precision: 0.8525, Recall: 0.8076, F1: 0.8232
Testing Loss: 0.4395, Accuracy: 0.8575, Precision: 0.8452, Recall: 0.7915, F1: 0.8062
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3381, Accuracy: 0.1190, Precision: 0.1905, Recall: 0.1333, F1: 0.0940
Epoch 44/70
Train Loss: 0.4874, Accuracy: 0.8338, Precision: 0.7857, Recall: 0.7620, F1: 0.7712
Validation Loss: 0.5023, Accuracy: 0.8593, Precision: 0.8462, Recall: 0.8101, F1: 0.8234
Testing Loss: 0.4430, Accuracy: 0.8539, Precision: 0.8564, Recall: 0.7828, F1: 0.8031
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4769, Accuracy: 0.1190, Precision: 0.1867, Recall: 0.1333, F1: 0.0889
Epoch 45/70
Train Loss: 0.4812, Accuracy: 0.8385, Precision: 0.7982, Recall: 0.7715, F1: 0.7819
Validation Loss: 0.5283, Accuracy: 0.8529, Precision: 0.8487, Recall: 0.7890, F1: 0.8073
Testing Loss: 0.4486, Accuracy: 0.8611, Precision: 0.8737, Recall: 0.7857, F1: 0.8034
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 4, 5, 0, 0, 2, 0, 0, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9315, Accuracy: 0.1667, Precision: 0.2469, Recall: 0.1875, F1: 0.1275
Epoch 46/70
Train Loss: 0.4882, Accuracy: 0.8309, Precision: 0.7812, Recall: 0.7597, F1: 0.7681
Validation Loss: 0.5421, Accuracy: 0.8571, Precision: 0.8604, Recall: 0.7804, F1: 0.8017
Testing Loss: 0.4624, Accuracy: 0.8551, Precision: 0.8710, Recall: 0.7580, F1: 0.7764
LM Predictions:  [0, 3, 0, 0, 5, 0, 0, 5, 4, 5, 0, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2499, Accuracy: 0.1429, Precision: 0.1914, Recall: 0.1667, F1: 0.0972
Epoch 47/70
Train Loss: 0.4591, Accuracy: 0.8494, Precision: 0.8111, Recall: 0.7784, F1: 0.7911
Validation Loss: 0.4854, Accuracy: 0.8699, Precision: 0.8420, Recall: 0.8474, F1: 0.8436
Testing Loss: 0.4253, Accuracy: 0.8635, Precision: 0.8343, Recall: 0.8173, F1: 0.8248
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 4, 5, 5, 5, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 4, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4307, Accuracy: 0.0952, Precision: 0.2803, Recall: 0.1042, F1: 0.1065
Epoch 48/70
Train Loss: 0.4654, Accuracy: 0.8454, Precision: 0.8032, Recall: 0.7775, F1: 0.7879
Validation Loss: 0.5159, Accuracy: 0.8657, Precision: 0.8514, Recall: 0.8145, F1: 0.8257
Testing Loss: 0.4262, Accuracy: 0.8551, Precision: 0.8283, Recall: 0.7814, F1: 0.7925
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 0, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0034, Accuracy: 0.1190, Precision: 0.1867, Recall: 0.1333, F1: 0.0889
Epoch 49/70
Train Loss: 0.4504, Accuracy: 0.8473, Precision: 0.8093, Recall: 0.7837, F1: 0.7947
Validation Loss: 0.4944, Accuracy: 0.8678, Precision: 0.8566, Recall: 0.8261, F1: 0.8393
Testing Loss: 0.4256, Accuracy: 0.8635, Precision: 0.8592, Recall: 0.8078, F1: 0.8278
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 0, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3051, Accuracy: 0.1190, Precision: 0.1875, Recall: 0.1333, F1: 0.0900
Epoch 50/70
Train Loss: 0.4442, Accuracy: 0.8489, Precision: 0.8088, Recall: 0.7875, F1: 0.7970
Validation Loss: 0.4711, Accuracy: 0.8699, Precision: 0.8448, Recall: 0.8360, F1: 0.8395
Testing Loss: 0.4146, Accuracy: 0.8611, Precision: 0.8347, Recall: 0.8108, F1: 0.8215
LM Predictions:  [0, 3, 5, 0, 5, 0, 5, 5, 4, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0890, Accuracy: 0.1429, Precision: 0.3611, Recall: 0.1542, F1: 0.1361
Epoch 51/70
Train Loss: 0.4481, Accuracy: 0.8499, Precision: 0.8016, Recall: 0.7817, F1: 0.7899
Validation Loss: 0.4917, Accuracy: 0.8678, Precision: 0.8494, Recall: 0.8272, F1: 0.8352
Testing Loss: 0.4388, Accuracy: 0.8551, Precision: 0.8379, Recall: 0.7824, F1: 0.7961
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 4, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 3, 0, 4, 0, 5, 5, 5, 0, 4, 0, 0, 0, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0794, Accuracy: 0.1667, Precision: 0.2051, Recall: 0.1667, F1: 0.1302
Epoch 52/70
Train Loss: 0.4420, Accuracy: 0.8494, Precision: 0.8082, Recall: 0.7803, F1: 0.7910
Validation Loss: 0.5132, Accuracy: 0.8657, Precision: 0.8483, Recall: 0.8181, F1: 0.8307
Testing Loss: 0.4286, Accuracy: 0.8647, Precision: 0.8403, Recall: 0.8098, F1: 0.8219
LM Predictions:  [0, 3, 0, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 4, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 1, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0651, Accuracy: 0.1429, Precision: 0.2208, Recall: 0.1500, F1: 0.1207
Epoch 53/70
Train Loss: 0.4306, Accuracy: 0.8568, Precision: 0.8108, Recall: 0.7846, F1: 0.7952
Validation Loss: 0.5385, Accuracy: 0.8571, Precision: 0.8265, Recall: 0.8491, F1: 0.8341
Testing Loss: 0.4381, Accuracy: 0.8563, Precision: 0.8265, Recall: 0.8246, F1: 0.8246
LM Predictions:  [0, 5, 5, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 3, 0, 4, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3273, Accuracy: 0.1190, Precision: 0.2833, Recall: 0.1333, F1: 0.1081
Epoch 54/70
Train Loss: 0.4239, Accuracy: 0.8542, Precision: 0.8103, Recall: 0.7924, F1: 0.8002
Validation Loss: 0.5088, Accuracy: 0.8678, Precision: 0.8423, Recall: 0.8242, F1: 0.8310
Testing Loss: 0.4300, Accuracy: 0.8623, Precision: 0.8418, Recall: 0.8107, F1: 0.8221
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 4, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0062, Accuracy: 0.1190, Precision: 0.1083, Recall: 0.1333, F1: 0.0876
Epoch 55/70
Train Loss: 0.4261, Accuracy: 0.8537, Precision: 0.8136, Recall: 0.7883, F1: 0.7986
Validation Loss: 0.5042, Accuracy: 0.8657, Precision: 0.8321, Recall: 0.8306, F1: 0.8308
Testing Loss: 0.4226, Accuracy: 0.8623, Precision: 0.8305, Recall: 0.8142, F1: 0.8210
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 5, 4, 5, 5, 0, 4, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9683, Accuracy: 0.1429, Precision: 0.2812, Recall: 0.1542, F1: 0.1323
Epoch 56/70
Train Loss: 0.4131, Accuracy: 0.8644, Precision: 0.8268, Recall: 0.8094, F1: 0.8172
Validation Loss: 0.5018, Accuracy: 0.8657, Precision: 0.8393, Recall: 0.8186, F1: 0.8261
Testing Loss: 0.4088, Accuracy: 0.8599, Precision: 0.8371, Recall: 0.8015, F1: 0.8132
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 4, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7790, Accuracy: 0.1429, Precision: 0.1905, Recall: 0.1500, F1: 0.1139
Epoch 57/70
Train Loss: 0.4028, Accuracy: 0.8620, Precision: 0.8225, Recall: 0.8056, F1: 0.8132
Validation Loss: 0.5074, Accuracy: 0.8678, Precision: 0.8519, Recall: 0.8120, F1: 0.8268
Testing Loss: 0.4226, Accuracy: 0.8623, Precision: 0.8563, Recall: 0.7926, F1: 0.8121
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0568, Accuracy: 0.1190, Precision: 0.1319, Recall: 0.1333, F1: 0.0858
Epoch 58/70
Train Loss: 0.4053, Accuracy: 0.8632, Precision: 0.8235, Recall: 0.7989, F1: 0.8088
Validation Loss: 0.5048, Accuracy: 0.8571, Precision: 0.8374, Recall: 0.8262, F1: 0.8310
Testing Loss: 0.3995, Accuracy: 0.8563, Precision: 0.8373, Recall: 0.8007, F1: 0.8158
LM Predictions:  [0, 5, 5, 0, 5, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1505, Accuracy: 0.0952, Precision: 0.1944, Recall: 0.1167, F1: 0.0738
Epoch 59/70
Train Loss: 0.4147, Accuracy: 0.8561, Precision: 0.8124, Recall: 0.7951, F1: 0.8030
Validation Loss: 0.5141, Accuracy: 0.8614, Precision: 0.8336, Recall: 0.8267, F1: 0.8271
Testing Loss: 0.4320, Accuracy: 0.8539, Precision: 0.8358, Recall: 0.7884, F1: 0.7955
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 4, 0, 0, 5, 5, 0, 4, 0, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9274, Accuracy: 0.1190, Precision: 0.1051, Recall: 0.1333, F1: 0.0833
Epoch 60/70
Train Loss: 0.3971, Accuracy: 0.8670, Precision: 0.8262, Recall: 0.8112, F1: 0.8179
Validation Loss: 0.5477, Accuracy: 0.8486, Precision: 0.8537, Recall: 0.7925, F1: 0.8097
Testing Loss: 0.4810, Accuracy: 0.8430, Precision: 0.8268, Recall: 0.7554, F1: 0.7648
LM Predictions:  [0, 5, 5, 0, 4, 0, 5, 0, 4, 5, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0020, Accuracy: 0.1429, Precision: 0.2956, Recall: 0.1500, F1: 0.1119
Epoch 61/70
Train Loss: 0.3885, Accuracy: 0.8629, Precision: 0.8178, Recall: 0.7994, F1: 0.8071
Validation Loss: 0.5031, Accuracy: 0.8593, Precision: 0.8409, Recall: 0.8238, F1: 0.8300
Testing Loss: 0.4300, Accuracy: 0.8490, Precision: 0.8177, Recall: 0.7845, F1: 0.7954
LM Predictions:  [0, 3, 5, 0, 5, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0954, Accuracy: 0.1190, Precision: 0.1905, Recall: 0.1333, F1: 0.0940
Epoch 62/70
Train Loss: 0.3808, Accuracy: 0.8658, Precision: 0.8244, Recall: 0.8052, F1: 0.8137
Validation Loss: 0.4964, Accuracy: 0.8678, Precision: 0.8436, Recall: 0.8366, F1: 0.8387
Testing Loss: 0.4081, Accuracy: 0.8575, Precision: 0.8219, Recall: 0.8024, F1: 0.8108
LM Predictions:  [0, 5, 5, 0, 5, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0386, Accuracy: 0.1190, Precision: 0.1930, Recall: 0.1333, F1: 0.0972
Epoch 63/70
Train Loss: 0.3902, Accuracy: 0.8632, Precision: 0.8156, Recall: 0.7992, F1: 0.8063
Validation Loss: 0.5256, Accuracy: 0.8678, Precision: 0.8400, Recall: 0.8293, F1: 0.8331
Testing Loss: 0.4312, Accuracy: 0.8684, Precision: 0.8280, Recall: 0.8097, F1: 0.8152
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 4, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5426, Accuracy: 0.1905, Precision: 0.3750, Recall: 0.1875, F1: 0.1776
Epoch 64/70
Train Loss: 0.3794, Accuracy: 0.8710, Precision: 0.8322, Recall: 0.8143, F1: 0.8224
Validation Loss: 0.5164, Accuracy: 0.8593, Precision: 0.8243, Recall: 0.8268, F1: 0.8246
Testing Loss: 0.4056, Accuracy: 0.8671, Precision: 0.8316, Recall: 0.8261, F1: 0.8278
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6389, Accuracy: 0.1667, Precision: 0.3301, Recall: 0.1708, F1: 0.1640
Epoch 65/70
Train Loss: 0.3791, Accuracy: 0.8705, Precision: 0.8297, Recall: 0.8136, F1: 0.8210
Validation Loss: 0.5044, Accuracy: 0.8635, Precision: 0.8452, Recall: 0.8208, F1: 0.8305
Testing Loss: 0.4073, Accuracy: 0.8551, Precision: 0.8278, Recall: 0.7893, F1: 0.8030
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 5, 5, 5, 0, 5, 0, 0, 0, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1472, Accuracy: 0.1429, Precision: 0.3005, Recall: 0.1500, F1: 0.1186
Epoch 66/70
Train Loss: 0.3651, Accuracy: 0.8772, Precision: 0.8376, Recall: 0.8198, F1: 0.8276
Validation Loss: 0.5557, Accuracy: 0.8635, Precision: 0.8366, Recall: 0.8116, F1: 0.8209
Testing Loss: 0.4306, Accuracy: 0.8587, Precision: 0.8235, Recall: 0.7891, F1: 0.7999
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 4, 5, 0, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 5, 4, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6015, Accuracy: 0.1905, Precision: 0.3735, Recall: 0.1875, F1: 0.1758
Epoch 67/70
Train Loss: 0.3617, Accuracy: 0.8821, Precision: 0.8434, Recall: 0.8232, F1: 0.8318
Validation Loss: 0.5623, Accuracy: 0.8614, Precision: 0.8296, Recall: 0.8316, F1: 0.8303
Testing Loss: 0.4410, Accuracy: 0.8551, Precision: 0.8190, Recall: 0.8068, F1: 0.8121
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 4, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8414, Accuracy: 0.1667, Precision: 0.3051, Recall: 0.1708, F1: 0.1593
Epoch 68/70
Train Loss: 0.3751, Accuracy: 0.8682, Precision: 0.8296, Recall: 0.8129, F1: 0.8203
Validation Loss: 0.5170, Accuracy: 0.8678, Precision: 0.8449, Recall: 0.8430, F1: 0.8431
Testing Loss: 0.4028, Accuracy: 0.8587, Precision: 0.8292, Recall: 0.8138, F1: 0.8206
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9113, Accuracy: 0.0952, Precision: 0.1127, Recall: 0.1167, F1: 0.0732
Epoch 69/70
Train Loss: 0.3587, Accuracy: 0.8788, Precision: 0.8406, Recall: 0.8219, F1: 0.8299
Validation Loss: 0.5122, Accuracy: 0.8529, Precision: 0.8253, Recall: 0.8003, F1: 0.8094
Testing Loss: 0.4255, Accuracy: 0.8442, Precision: 0.8233, Recall: 0.7745, F1: 0.7899
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 4, 5, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8312, Accuracy: 0.1667, Precision: 0.1561, Recall: 0.1667, F1: 0.1259
Epoch 70/70
Train Loss: 0.3566, Accuracy: 0.8793, Precision: 0.8408, Recall: 0.8276, F1: 0.8337
Validation Loss: 0.5367, Accuracy: 0.8593, Precision: 0.8388, Recall: 0.7907, F1: 0.8060
Testing Loss: 0.4384, Accuracy: 0.8563, Precision: 0.8370, Recall: 0.7715, F1: 0.7878
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 4, 5, 0, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 5, 5, 0, 4, 0, 0, 0, 5, 4, 0, 0, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8231, Accuracy: 0.1905, Precision: 0.3977, Recall: 0.1875, F1: 0.1733
For middle layers:  [4, 5, 6, 7]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.8495, Accuracy: 0.2846, Precision: 0.1863, Recall: 0.1926, F1: 0.1708
Validation Loss: 1.5635, Accuracy: 0.3838, Precision: 0.2148, Recall: 0.2573, F1: 0.2286
Testing Loss: 1.5473, Accuracy: 0.4010, Precision: 0.2222, Recall: 0.2693, F1: 0.2382
LM Predictions:  [1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 1, 2, 0, 2, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9296, Accuracy: 0.1667, Precision: 0.0977, Recall: 0.2200, F1: 0.1256
Epoch 2/70
Train Loss: 1.5764, Accuracy: 0.3785, Precision: 0.2605, Recall: 0.2551, F1: 0.2211
Validation Loss: 1.3583, Accuracy: 0.5053, Precision: 0.2679, Recall: 0.3373, F1: 0.2920
Testing Loss: 1.3212, Accuracy: 0.5157, Precision: 0.2772, Recall: 0.3453, F1: 0.3009
LM Predictions:  [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9394, Accuracy: 0.1905, Precision: 0.1143, Recall: 0.2750, F1: 0.1300
Epoch 3/70
Train Loss: 1.3890, Accuracy: 0.4686, Precision: 0.2855, Recall: 0.3146, F1: 0.2774
Validation Loss: 1.1928, Accuracy: 0.5885, Precision: 0.3008, Recall: 0.4016, F1: 0.3406
Testing Loss: 1.1547, Accuracy: 0.5990, Precision: 0.3018, Recall: 0.4087, F1: 0.3458
LM Predictions:  [0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1729, Accuracy: 0.1905, Precision: 0.0838, Recall: 0.2450, F1: 0.1214
Epoch 4/70
Train Loss: 1.1265, Accuracy: 0.5900, Precision: 0.4780, Recall: 0.4074, F1: 0.3773
Validation Loss: 0.8099, Accuracy: 0.7271, Precision: 0.6375, Recall: 0.5455, F1: 0.5281
Testing Loss: 0.7739, Accuracy: 0.7234, Precision: 0.5784, Recall: 0.5414, F1: 0.5179
LM Predictions:  [0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 2, 0, 0, 3, 2, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1396, Accuracy: 0.0952, Precision: 0.0473, Recall: 0.1450, F1: 0.0591
Epoch 5/70
Train Loss: 0.7992, Accuracy: 0.7342, Precision: 0.6500, Recall: 0.5857, F1: 0.5865
Validation Loss: 0.6771, Accuracy: 0.7996, Precision: 0.8353, Recall: 0.6620, F1: 0.6658
Testing Loss: 0.5576, Accuracy: 0.8297, Precision: 0.8126, Recall: 0.7115, F1: 0.7181
LM Predictions:  [0, 3, 0, 0, 4, 0, 3, 5, 0, 2, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.6440, Accuracy: 0.0714, Precision: 0.0167, Recall: 0.1000, F1: 0.0286
Epoch 6/70
Train Loss: 0.6052, Accuracy: 0.8046, Precision: 0.7312, Recall: 0.6924, F1: 0.6934
Validation Loss: 0.5982, Accuracy: 0.8337, Precision: 0.8663, Recall: 0.7195, F1: 0.7223
Testing Loss: 0.4909, Accuracy: 0.8514, Precision: 0.8175, Recall: 0.7454, F1: 0.7524
LM Predictions:  [0, 3, 0, 0, 4, 0, 3, 5, 0, 2, 5, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.2996, Accuracy: 0.0714, Precision: 0.0172, Recall: 0.1000, F1: 0.0294
Epoch 7/70
Train Loss: 0.5480, Accuracy: 0.8262, Precision: 0.7674, Recall: 0.7226, F1: 0.7283
Validation Loss: 0.5174, Accuracy: 0.8678, Precision: 0.8267, Recall: 0.8078, F1: 0.8154
Testing Loss: 0.4319, Accuracy: 0.8659, Precision: 0.8340, Recall: 0.8155, F1: 0.8227
LM Predictions:  [0, 3, 0, 5, 4, 0, 5, 5, 0, 5, 5, 5, 0, 0, 0, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 0, 0, 1, 0, 5, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.1116, Accuracy: 0.0476, Precision: 0.0167, Recall: 0.0667, F1: 0.0267
Epoch 8/70
Train Loss: 0.4965, Accuracy: 0.8435, Precision: 0.7946, Recall: 0.7499, F1: 0.7588
Validation Loss: 0.5340, Accuracy: 0.8614, Precision: 0.8128, Recall: 0.8214, F1: 0.8167
Testing Loss: 0.4182, Accuracy: 0.8732, Precision: 0.8427, Recall: 0.8413, F1: 0.8416
LM Predictions:  [0, 3, 0, 5, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 1, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8785, Accuracy: 0.0714, Precision: 0.0294, Recall: 0.1000, F1: 0.0455
Epoch 9/70
Train Loss: 0.4655, Accuracy: 0.8525, Precision: 0.8012, Recall: 0.7674, F1: 0.7770
Validation Loss: 0.5314, Accuracy: 0.8635, Precision: 0.8412, Recall: 0.8101, F1: 0.8212
Testing Loss: 0.4253, Accuracy: 0.8829, Precision: 0.8683, Recall: 0.8334, F1: 0.8468
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 0, 0, 1, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.0547, Accuracy: 0.0714, Precision: 0.0217, Recall: 0.1000, F1: 0.0357
Epoch 10/70
Train Loss: 0.4408, Accuracy: 0.8539, Precision: 0.8006, Recall: 0.7766, F1: 0.7853
Validation Loss: 0.5067, Accuracy: 0.8721, Precision: 0.8333, Recall: 0.8471, F1: 0.8384
Testing Loss: 0.3921, Accuracy: 0.8756, Precision: 0.8456, Recall: 0.8559, F1: 0.8498
LM Predictions:  [0, 3, 5, 5, 4, 0, 5, 5, 5, 5, 5, 0, 0, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 1, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.1398, Accuracy: 0.0714, Precision: 0.0417, Recall: 0.1000, F1: 0.0588
Epoch 11/70
Train Loss: 0.4280, Accuracy: 0.8653, Precision: 0.8164, Recall: 0.7990, F1: 0.8057
Validation Loss: 0.5450, Accuracy: 0.8614, Precision: 0.8250, Recall: 0.8057, F1: 0.8102
Testing Loss: 0.4010, Accuracy: 0.8829, Precision: 0.8527, Recall: 0.8433, F1: 0.8452
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 4, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 0, 3, 1, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3580, Accuracy: 0.0714, Precision: 0.0278, Recall: 0.1000, F1: 0.0435
Epoch 12/70
Train Loss: 0.4121, Accuracy: 0.8684, Precision: 0.8264, Recall: 0.8006, F1: 0.8106
Validation Loss: 0.5111, Accuracy: 0.8721, Precision: 0.8505, Recall: 0.8211, F1: 0.8301
Testing Loss: 0.3850, Accuracy: 0.8853, Precision: 0.8575, Recall: 0.8390, F1: 0.8462
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 0, 0, 1, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5342, Accuracy: 0.0714, Precision: 0.0250, Recall: 0.1000, F1: 0.0400
Epoch 13/70
Train Loss: 0.3870, Accuracy: 0.8765, Precision: 0.8375, Recall: 0.8160, F1: 0.8246
Validation Loss: 0.4977, Accuracy: 0.8742, Precision: 0.8423, Recall: 0.8483, F1: 0.8442
Testing Loss: 0.3757, Accuracy: 0.8841, Precision: 0.8565, Recall: 0.8578, F1: 0.8560
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 0, 0, 1, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7239, Accuracy: 0.0714, Precision: 0.0385, Recall: 0.1000, F1: 0.0556
Epoch 14/70
Train Loss: 0.3644, Accuracy: 0.8833, Precision: 0.8425, Recall: 0.8260, F1: 0.8333
Validation Loss: 0.5138, Accuracy: 0.8785, Precision: 0.8458, Recall: 0.8443, F1: 0.8442
Testing Loss: 0.3911, Accuracy: 0.8841, Precision: 0.8571, Recall: 0.8584, F1: 0.8564
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6148, Accuracy: 0.0714, Precision: 0.0417, Recall: 0.1000, F1: 0.0588
Epoch 15/70
Train Loss: 0.3607, Accuracy: 0.8862, Precision: 0.8434, Recall: 0.8276, F1: 0.8345
Validation Loss: 0.4771, Accuracy: 0.8699, Precision: 0.8405, Recall: 0.8379, F1: 0.8384
Testing Loss: 0.3746, Accuracy: 0.8816, Precision: 0.8527, Recall: 0.8549, F1: 0.8526
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1069, Accuracy: 0.0952, Precision: 0.1190, Recall: 0.1167, F1: 0.0804
Epoch 16/70
Train Loss: 0.3518, Accuracy: 0.8900, Precision: 0.8491, Recall: 0.8317, F1: 0.8392
Validation Loss: 0.4703, Accuracy: 0.8742, Precision: 0.8490, Recall: 0.8475, F1: 0.8481
Testing Loss: 0.3880, Accuracy: 0.8877, Precision: 0.8584, Recall: 0.8580, F1: 0.8569
LM Predictions:  [5, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3826, Accuracy: 0.0714, Precision: 0.1944, Recall: 0.0833, F1: 0.0695
Epoch 17/70
Train Loss: 0.3281, Accuracy: 0.8866, Precision: 0.8403, Recall: 0.8336, F1: 0.8368
Validation Loss: 0.4741, Accuracy: 0.8870, Precision: 0.8570, Recall: 0.8610, F1: 0.8587
Testing Loss: 0.3885, Accuracy: 0.8901, Precision: 0.8562, Recall: 0.8559, F1: 0.8553
LM Predictions:  [0, 3, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2389, Accuracy: 0.1190, Precision: 0.2885, Recall: 0.1375, F1: 0.1204
Epoch 18/70
Train Loss: 0.3213, Accuracy: 0.8926, Precision: 0.8570, Recall: 0.8412, F1: 0.8483
Validation Loss: 0.4747, Accuracy: 0.8806, Precision: 0.8553, Recall: 0.8573, F1: 0.8556
Testing Loss: 0.4212, Accuracy: 0.8853, Precision: 0.8617, Recall: 0.8518, F1: 0.8554
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8032, Accuracy: 0.1190, Precision: 0.1961, Recall: 0.1333, F1: 0.1010
Epoch 19/70
Train Loss: 0.3051, Accuracy: 0.9040, Precision: 0.8692, Recall: 0.8573, F1: 0.8629
Validation Loss: 0.4868, Accuracy: 0.8657, Precision: 0.8370, Recall: 0.8444, F1: 0.8392
Testing Loss: 0.3907, Accuracy: 0.8829, Precision: 0.8516, Recall: 0.8593, F1: 0.8536
LM Predictions:  [5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1179, Accuracy: 0.1190, Precision: 0.3704, Recall: 0.1250, F1: 0.1446
Epoch 20/70
Train Loss: 0.2904, Accuracy: 0.9011, Precision: 0.8624, Recall: 0.8513, F1: 0.8564
Validation Loss: 0.5023, Accuracy: 0.8657, Precision: 0.8362, Recall: 0.8382, F1: 0.8323
Testing Loss: 0.4092, Accuracy: 0.8841, Precision: 0.8594, Recall: 0.8658, F1: 0.8589
LM Predictions:  [5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1294, Accuracy: 0.0714, Precision: 0.2037, Recall: 0.0833, F1: 0.0779
Epoch 21/70
Train Loss: 0.2822, Accuracy: 0.9042, Precision: 0.8671, Recall: 0.8592, F1: 0.8630
Validation Loss: 0.5203, Accuracy: 0.8870, Precision: 0.8520, Recall: 0.8342, F1: 0.8395
Testing Loss: 0.4009, Accuracy: 0.8841, Precision: 0.8551, Recall: 0.8222, F1: 0.8325
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 0, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 5, 0, 4, 5, 0, 5, 0, 4, 0, 5, 0, 5, 5, 4]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3714, Accuracy: 0.1190, Precision: 0.1051, Recall: 0.1333, F1: 0.0833
Epoch 22/70
Train Loss: 0.2635, Accuracy: 0.9125, Precision: 0.8767, Recall: 0.8749, F1: 0.8757
Validation Loss: 0.4845, Accuracy: 0.8763, Precision: 0.8411, Recall: 0.8424, F1: 0.8414
Testing Loss: 0.4012, Accuracy: 0.8865, Precision: 0.8573, Recall: 0.8525, F1: 0.8539
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0132, Accuracy: 0.1429, Precision: 0.3690, Recall: 0.1542, F1: 0.1452
Epoch 23/70
Train Loss: 0.2584, Accuracy: 0.9118, Precision: 0.8732, Recall: 0.8685, F1: 0.8708
Validation Loss: 0.5314, Accuracy: 0.8742, Precision: 0.8367, Recall: 0.8474, F1: 0.8396
Testing Loss: 0.4057, Accuracy: 0.8816, Precision: 0.8466, Recall: 0.8624, F1: 0.8529
LM Predictions:  [5, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8254, Accuracy: 0.1667, Precision: 0.4500, Recall: 0.1583, F1: 0.1944
Epoch 24/70
Train Loss: 0.2481, Accuracy: 0.9156, Precision: 0.8785, Recall: 0.8740, F1: 0.8762
Validation Loss: 0.5510, Accuracy: 0.8614, Precision: 0.8291, Recall: 0.8198, F1: 0.8235
Testing Loss: 0.4191, Accuracy: 0.8877, Precision: 0.8616, Recall: 0.8398, F1: 0.8484
LM Predictions:  [0, 1, 0, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3165, Accuracy: 0.2143, Precision: 0.4896, Recall: 0.2102, F1: 0.2190
Epoch 25/70
Train Loss: 0.2326, Accuracy: 0.9180, Precision: 0.8813, Recall: 0.8801, F1: 0.8807
Validation Loss: 0.6044, Accuracy: 0.8507, Precision: 0.8266, Recall: 0.8278, F1: 0.8213
Testing Loss: 0.4607, Accuracy: 0.8732, Precision: 0.8499, Recall: 0.8516, F1: 0.8465
LM Predictions:  [5, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5968, Accuracy: 0.1667, Precision: 0.5370, Recall: 0.1602, F1: 0.2032
Epoch 26/70
Train Loss: 0.2284, Accuracy: 0.9234, Precision: 0.8930, Recall: 0.8893, F1: 0.8911
Validation Loss: 0.5891, Accuracy: 0.8593, Precision: 0.8162, Recall: 0.8415, F1: 0.8260
Testing Loss: 0.4467, Accuracy: 0.8720, Precision: 0.8384, Recall: 0.8571, F1: 0.8462
LM Predictions:  [5, 1, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 4, 3, 0, 5, 5, 0, 5, 5, 5, 2, 0, 0, 5, 0, 4, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9150, Accuracy: 0.2857, Precision: 0.6243, Recall: 0.2435, F1: 0.2895
Epoch 27/70
Train Loss: 0.2146, Accuracy: 0.9232, Precision: 0.8879, Recall: 0.8848, F1: 0.8863
Validation Loss: 0.5461, Accuracy: 0.8657, Precision: 0.8353, Recall: 0.8395, F1: 0.8348
Testing Loss: 0.4463, Accuracy: 0.8768, Precision: 0.8527, Recall: 0.8468, F1: 0.8480
LM Predictions:  [5, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5053, Accuracy: 0.1667, Precision: 0.5303, Recall: 0.1602, F1: 0.1972
Epoch 28/70
Train Loss: 0.2133, Accuracy: 0.9279, Precision: 0.8958, Recall: 0.8955, F1: 0.8956
Validation Loss: 0.5405, Accuracy: 0.8678, Precision: 0.8363, Recall: 0.8382, F1: 0.8342
Testing Loss: 0.4241, Accuracy: 0.8732, Precision: 0.8449, Recall: 0.8407, F1: 0.8411
LM Predictions:  [5, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2130, Accuracy: 0.1905, Precision: 0.7037, Recall: 0.1769, F1: 0.2335
Epoch 29/70
Train Loss: 0.1925, Accuracy: 0.9286, Precision: 0.8954, Recall: 0.8904, F1: 0.8928
Validation Loss: 0.5778, Accuracy: 0.8657, Precision: 0.8208, Recall: 0.8257, F1: 0.8221
Testing Loss: 0.4474, Accuracy: 0.8756, Precision: 0.8464, Recall: 0.8423, F1: 0.8438
LM Predictions:  [5, 1, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 4, 3, 0, 5, 5, 0, 5, 0, 5, 5, 1, 0, 5, 0, 4, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 5, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7096, Accuracy: 0.3095, Precision: 0.6759, Recall: 0.2639, F1: 0.3321
Epoch 30/70
Train Loss: 0.1841, Accuracy: 0.9310, Precision: 0.8979, Recall: 0.8954, F1: 0.8966
Validation Loss: 0.5820, Accuracy: 0.8571, Precision: 0.8162, Recall: 0.8114, F1: 0.8132
Testing Loss: 0.4722, Accuracy: 0.8708, Precision: 0.8377, Recall: 0.8313, F1: 0.8337
LM Predictions:  [0, 1, 5, 0, 1, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 1, 0, 5, 0, 4, 5, 0, 4, 5, 5, 5, 5, 4, 0, 4, 5, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8846, Accuracy: 0.3333, Precision: 0.6788, Recall: 0.2991, F1: 0.3499
Epoch 31/70
Train Loss: 0.1778, Accuracy: 0.9362, Precision: 0.9051, Recall: 0.9038, F1: 0.9044
Validation Loss: 0.6338, Accuracy: 0.8678, Precision: 0.8301, Recall: 0.8387, F1: 0.8324
Testing Loss: 0.5280, Accuracy: 0.8659, Precision: 0.8365, Recall: 0.8452, F1: 0.8372
LM Predictions:  [5, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 5, 5, 5, 5, 5, 1, 0, 5, 0, 4, 5, 0, 4, 4, 5, 5, 5, 4, 0, 4, 5, 5, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0871, Accuracy: 0.2857, Precision: 0.6750, Recall: 0.2472, F1: 0.3205
Epoch 32/70
Train Loss: 0.1775, Accuracy: 0.9346, Precision: 0.8998, Recall: 0.9015, F1: 0.9006
Validation Loss: 0.6172, Accuracy: 0.8657, Precision: 0.8310, Recall: 0.8090, F1: 0.8176
Testing Loss: 0.4727, Accuracy: 0.8708, Precision: 0.8414, Recall: 0.8107, F1: 0.8231
LM Predictions:  [0, 1, 5, 0, 5, 0, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 0, 5, 1, 0, 2, 0, 4, 5, 0, 4, 4, 5, 5, 0, 4, 0, 4, 5, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6270, Accuracy: 0.3810, Precision: 0.6345, Recall: 0.3347, F1: 0.3658
Epoch 33/70
Train Loss: 0.1629, Accuracy: 0.9376, Precision: 0.9037, Recall: 0.9020, F1: 0.9028
Validation Loss: 0.6634, Accuracy: 0.8678, Precision: 0.8266, Recall: 0.8343, F1: 0.8291
Testing Loss: 0.4883, Accuracy: 0.8696, Precision: 0.8349, Recall: 0.8375, F1: 0.8355
LM Predictions:  [5, 1, 5, 0, 1, 5, 5, 5, 5, 5, 0, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 1, 0, 2, 0, 4, 5, 0, 4, 4, 5, 5, 0, 4, 0, 4, 5, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6714, Accuracy: 0.3333, Precision: 0.6278, Recall: 0.2866, F1: 0.3446
Epoch 34/70
Train Loss: 0.1480, Accuracy: 0.9440, Precision: 0.9128, Recall: 0.9131, F1: 0.9128
Validation Loss: 0.6767, Accuracy: 0.8657, Precision: 0.8304, Recall: 0.8141, F1: 0.8216
Testing Loss: 0.5565, Accuracy: 0.8575, Precision: 0.8321, Recall: 0.7875, F1: 0.8051
LM Predictions:  [0, 1, 5, 0, 1, 0, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 0, 5, 1, 0, 5, 0, 4, 5, 0, 4, 0, 0, 5, 0, 4, 0, 4, 5, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6534, Accuracy: 0.3571, Precision: 0.6627, Recall: 0.3157, F1: 0.3488
Epoch 35/70
Train Loss: 0.1547, Accuracy: 0.9421, Precision: 0.9122, Recall: 0.9170, F1: 0.9144
Validation Loss: 0.7096, Accuracy: 0.8486, Precision: 0.8036, Recall: 0.7937, F1: 0.7979
Testing Loss: 0.5518, Accuracy: 0.8635, Precision: 0.8346, Recall: 0.8138, F1: 0.8230
LM Predictions:  [0, 1, 5, 0, 1, 0, 5, 5, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 5, 4, 0, 0, 5, 1, 0, 2, 0, 4, 2, 0, 4, 4, 5, 5, 0, 4, 0, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.4022, Accuracy: 0.4762, Precision: 0.6607, Recall: 0.4157, F1: 0.4395
Epoch 36/70
Train Loss: 0.1414, Accuracy: 0.9493, Precision: 0.9235, Recall: 0.9233, F1: 0.9233
Validation Loss: 0.6604, Accuracy: 0.8635, Precision: 0.8173, Recall: 0.8203, F1: 0.8183
Testing Loss: 0.5461, Accuracy: 0.8635, Precision: 0.8260, Recall: 0.8129, F1: 0.8187
LM Predictions:  [5, 1, 5, 0, 4, 1, 5, 5, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 5, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 4, 5, 5, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1868, Accuracy: 0.5238, Precision: 0.6599, Recall: 0.4343, F1: 0.4819
Epoch 37/70
Train Loss: 0.1426, Accuracy: 0.9462, Precision: 0.9150, Recall: 0.9166, F1: 0.9157
Validation Loss: 0.6748, Accuracy: 0.8678, Precision: 0.8259, Recall: 0.8248, F1: 0.8249
Testing Loss: 0.5806, Accuracy: 0.8684, Precision: 0.8401, Recall: 0.8191, F1: 0.8286
LM Predictions:  [5, 1, 5, 0, 1, 1, 5, 5, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 5, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 5, 5, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2313, Accuracy: 0.5476, Precision: 0.6970, Recall: 0.4528, F1: 0.5107
Epoch 38/70
Train Loss: 0.1317, Accuracy: 0.9497, Precision: 0.9230, Recall: 0.9256, F1: 0.9243
Validation Loss: 0.7322, Accuracy: 0.8593, Precision: 0.8197, Recall: 0.8130, F1: 0.8152
Testing Loss: 0.6067, Accuracy: 0.8551, Precision: 0.8180, Recall: 0.7928, F1: 0.8030
LM Predictions:  [0, 1, 5, 1, 1, 1, 5, 0, 4, 0, 1, 0, 2, 4, 3, 0, 5, 4, 0, 5, 1, 0, 3, 1, 1, 2, 0, 4, 5, 0, 4, 3, 5, 5, 0, 4, 1, 4, 1, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0354, Accuracy: 0.5952, Precision: 0.6778, Recall: 0.5106, F1: 0.5210
Epoch 39/70
Train Loss: 0.1281, Accuracy: 0.9490, Precision: 0.9193, Recall: 0.9244, F1: 0.9217
Validation Loss: 0.6982, Accuracy: 0.8550, Precision: 0.8157, Recall: 0.8100, F1: 0.8119
Testing Loss: 0.5564, Accuracy: 0.8490, Precision: 0.8012, Recall: 0.7893, F1: 0.7940
LM Predictions:  [5, 1, 5, 1, 1, 1, 5, 0, 4, 5, 0, 0, 2, 4, 3, 3, 2, 4, 0, 5, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 0, 5, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7307, Accuracy: 0.6667, Precision: 0.6917, Recall: 0.5417, F1: 0.5845
Epoch 40/70
Train Loss: 0.1206, Accuracy: 0.9530, Precision: 0.9292, Recall: 0.9307, F1: 0.9299
Validation Loss: 0.7780, Accuracy: 0.8571, Precision: 0.8147, Recall: 0.8090, F1: 0.8112
Testing Loss: 0.6044, Accuracy: 0.8514, Precision: 0.8159, Recall: 0.7855, F1: 0.7978
LM Predictions:  [5, 1, 5, 1, 1, 1, 5, 5, 4, 5, 0, 0, 2, 4, 3, 3, 2, 4, 0, 5, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 0, 5, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9739, Accuracy: 0.6190, Precision: 0.6852, Recall: 0.5065, F1: 0.5528
Epoch 41/70
Train Loss: 0.1203, Accuracy: 0.9523, Precision: 0.9253, Recall: 0.9253, F1: 0.9253
Validation Loss: 0.8062, Accuracy: 0.8571, Precision: 0.8148, Recall: 0.8094, F1: 0.8114
Testing Loss: 0.6304, Accuracy: 0.8514, Precision: 0.8044, Recall: 0.7815, F1: 0.7904
LM Predictions:  [0, 1, 5, 0, 1, 1, 5, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 4, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 4, 0, 5, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8072, Accuracy: 0.6429, Precision: 0.6846, Recall: 0.5546, F1: 0.5517
Epoch 42/70
Train Loss: 0.1189, Accuracy: 0.9495, Precision: 0.9220, Recall: 0.9251, F1: 0.9234
Validation Loss: 0.8499, Accuracy: 0.8507, Precision: 0.7925, Recall: 0.8006, F1: 0.7946
Testing Loss: 0.6772, Accuracy: 0.8478, Precision: 0.7977, Recall: 0.7863, F1: 0.7884
LM Predictions:  [0, 1, 2, 0, 1, 1, 5, 4, 4, 5, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 4, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4618, Accuracy: 0.8095, Precision: 0.7125, Recall: 0.6606, F1: 0.6766
Epoch 43/70
Train Loss: 0.1176, Accuracy: 0.9521, Precision: 0.9274, Recall: 0.9277, F1: 0.9275
Validation Loss: 0.7756, Accuracy: 0.8529, Precision: 0.8109, Recall: 0.8006, F1: 0.8048
Testing Loss: 0.6308, Accuracy: 0.8454, Precision: 0.8045, Recall: 0.7708, F1: 0.7846
LM Predictions:  [0, 1, 5, 0, 1, 1, 5, 0, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 0, 0, 0, 0, 1, 0, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7936, Accuracy: 0.6190, Precision: 0.6850, Recall: 0.5380, F1: 0.5471
Epoch 44/70
Train Loss: 0.1170, Accuracy: 0.9530, Precision: 0.9277, Recall: 0.9301, F1: 0.9288
Validation Loss: 0.7936, Accuracy: 0.8571, Precision: 0.8146, Recall: 0.8120, F1: 0.8131
Testing Loss: 0.6323, Accuracy: 0.8478, Precision: 0.8100, Recall: 0.7826, F1: 0.7938
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 1, 0, 0, 2, 4, 3, 3, 2, 4, 0, 4, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 4, 5, 1, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6064, Accuracy: 0.7619, Precision: 0.6907, Recall: 0.6458, F1: 0.6373
Epoch 45/70
Train Loss: 0.1148, Accuracy: 0.9540, Precision: 0.9276, Recall: 0.9331, F1: 0.9302
Validation Loss: 0.7540, Accuracy: 0.8635, Precision: 0.8183, Recall: 0.8193, F1: 0.8184
Testing Loss: 0.6234, Accuracy: 0.8478, Precision: 0.8080, Recall: 0.7740, F1: 0.7855
LM Predictions:  [0, 1, 2, 0, 1, 1, 5, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 4, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 0, 5, 0, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5376, Accuracy: 0.6905, Precision: 0.6994, Recall: 0.5903, F1: 0.5986
Epoch 46/70
Train Loss: 0.1010, Accuracy: 0.9571, Precision: 0.9319, Recall: 0.9346, F1: 0.9332
Validation Loss: 0.8476, Accuracy: 0.8486, Precision: 0.8014, Recall: 0.7924, F1: 0.7959
Testing Loss: 0.6476, Accuracy: 0.8490, Precision: 0.8114, Recall: 0.7832, F1: 0.7945
LM Predictions:  [0, 1, 2, 1, 1, 1, 5, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4227, Accuracy: 0.8333, Precision: 0.7333, Recall: 0.6940, F1: 0.6965
Epoch 47/70
Train Loss: 0.0972, Accuracy: 0.9561, Precision: 0.9329, Recall: 0.9339, F1: 0.9334
Validation Loss: 0.8437, Accuracy: 0.8486, Precision: 0.8168, Recall: 0.7874, F1: 0.7997
Testing Loss: 0.6678, Accuracy: 0.8502, Precision: 0.8080, Recall: 0.7678, F1: 0.7794
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 4, 3, 2, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2813, Accuracy: 0.8571, Precision: 0.8711, Recall: 0.8800, F1: 0.8457
Epoch 48/70
Train Loss: 0.0955, Accuracy: 0.9621, Precision: 0.9405, Recall: 0.9386, F1: 0.9395
Validation Loss: 0.8698, Accuracy: 0.8529, Precision: 0.8114, Recall: 0.8057, F1: 0.8078
Testing Loss: 0.6875, Accuracy: 0.8490, Precision: 0.8052, Recall: 0.7833, F1: 0.7923
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 4, 4, 0, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4194, Accuracy: 0.7857, Precision: 0.8326, Recall: 0.8106, F1: 0.7725
Epoch 49/70
Train Loss: 0.0982, Accuracy: 0.9592, Precision: 0.9368, Recall: 0.9375, F1: 0.9371
Validation Loss: 0.8598, Accuracy: 0.8614, Precision: 0.8191, Recall: 0.8104, F1: 0.8139
Testing Loss: 0.6985, Accuracy: 0.8575, Precision: 0.8152, Recall: 0.7869, F1: 0.7978
LM Predictions:  [0, 1, 5, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 5, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4758, Accuracy: 0.7857, Precision: 0.7361, Recall: 0.6713, F1: 0.6696
Epoch 50/70
Train Loss: 0.0982, Accuracy: 0.9566, Precision: 0.9309, Recall: 0.9335, F1: 0.9322
Validation Loss: 0.8534, Accuracy: 0.8550, Precision: 0.8125, Recall: 0.7908, F1: 0.7997
Testing Loss: 0.6639, Accuracy: 0.8563, Precision: 0.8251, Recall: 0.7716, F1: 0.7904
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3913, Accuracy: 0.8333, Precision: 0.8709, Recall: 0.8550, F1: 0.8239
Epoch 51/70
Train Loss: 0.0979, Accuracy: 0.9557, Precision: 0.9327, Recall: 0.9290, F1: 0.9308
Validation Loss: 0.7894, Accuracy: 0.8465, Precision: 0.8048, Recall: 0.7940, F1: 0.7986
Testing Loss: 0.6545, Accuracy: 0.8490, Precision: 0.8155, Recall: 0.7774, F1: 0.7926
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 1, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3708, Accuracy: 0.8095, Precision: 0.8633, Recall: 0.8350, F1: 0.8085
Epoch 52/70
Train Loss: 0.0823, Accuracy: 0.9649, Precision: 0.9457, Recall: 0.9463, F1: 0.9460
Validation Loss: 0.8673, Accuracy: 0.8635, Precision: 0.8388, Recall: 0.7991, F1: 0.8160
Testing Loss: 0.7730, Accuracy: 0.8490, Precision: 0.8351, Recall: 0.7737, F1: 0.7971
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4119, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8128, F1: 0.7949
Epoch 53/70
Train Loss: 0.0956, Accuracy: 0.9602, Precision: 0.9400, Recall: 0.9377, F1: 0.9388
Validation Loss: 0.8115, Accuracy: 0.8635, Precision: 0.8211, Recall: 0.8096, F1: 0.8145
Testing Loss: 0.6769, Accuracy: 0.8599, Precision: 0.8345, Recall: 0.7913, F1: 0.8078
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2716, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8742
Epoch 54/70
Train Loss: 0.0882, Accuracy: 0.9623, Precision: 0.9412, Recall: 0.9443, F1: 0.9427
Validation Loss: 0.8096, Accuracy: 0.8635, Precision: 0.8303, Recall: 0.8091, F1: 0.8186
Testing Loss: 0.6803, Accuracy: 0.8527, Precision: 0.8286, Recall: 0.7737, F1: 0.7949
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3002, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8800, F1: 0.8544
Epoch 55/70
Train Loss: 0.0932, Accuracy: 0.9609, Precision: 0.9373, Recall: 0.9400, F1: 0.9386
Validation Loss: 0.7735, Accuracy: 0.8507, Precision: 0.8075, Recall: 0.7969, F1: 0.8008
Testing Loss: 0.6996, Accuracy: 0.8527, Precision: 0.8104, Recall: 0.7708, F1: 0.7813
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1522, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9800, F1: 0.9713
Epoch 56/70
Train Loss: 0.0843, Accuracy: 0.9640, Precision: 0.9418, Recall: 0.9420, F1: 0.9419
Validation Loss: 0.8576, Accuracy: 0.8635, Precision: 0.8333, Recall: 0.8242, F1: 0.8282
Testing Loss: 0.7727, Accuracy: 0.8502, Precision: 0.8141, Recall: 0.7855, F1: 0.7961
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 4, 2, 5, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3084, Accuracy: 0.8333, Precision: 0.7348, Recall: 0.7111, F1: 0.6948
Epoch 57/70
Train Loss: 0.0940, Accuracy: 0.9625, Precision: 0.9448, Recall: 0.9377, F1: 0.9411
Validation Loss: 0.8253, Accuracy: 0.8529, Precision: 0.8147, Recall: 0.8145, F1: 0.8142
Testing Loss: 0.6771, Accuracy: 0.8394, Precision: 0.7968, Recall: 0.7835, F1: 0.7895
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1911, Accuracy: 0.9524, Precision: 0.9429, Recall: 0.9550, F1: 0.9428
Epoch 58/70
Train Loss: 0.0865, Accuracy: 0.9602, Precision: 0.9374, Recall: 0.9377, F1: 0.9375
Validation Loss: 0.8152, Accuracy: 0.8550, Precision: 0.8141, Recall: 0.8086, F1: 0.8105
Testing Loss: 0.7184, Accuracy: 0.8454, Precision: 0.8019, Recall: 0.7766, F1: 0.7869
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2835, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9350, F1: 0.9195
Epoch 59/70
Train Loss: 0.0794, Accuracy: 0.9644, Precision: 0.9417, Recall: 0.9449, F1: 0.9432
Validation Loss: 0.8282, Accuracy: 0.8529, Precision: 0.8135, Recall: 0.8054, F1: 0.8078
Testing Loss: 0.6896, Accuracy: 0.8563, Precision: 0.8145, Recall: 0.7844, F1: 0.7942
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1945, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9378, F1: 0.9199
Epoch 60/70
Train Loss: 0.0761, Accuracy: 0.9649, Precision: 0.9448, Recall: 0.9419, F1: 0.9433
Validation Loss: 0.8782, Accuracy: 0.8550, Precision: 0.8158, Recall: 0.8051, F1: 0.8097
Testing Loss: 0.7830, Accuracy: 0.8466, Precision: 0.8121, Recall: 0.7728, F1: 0.7872
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2509, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8756
Epoch 61/70
Train Loss: 0.0826, Accuracy: 0.9635, Precision: 0.9402, Recall: 0.9427, F1: 0.9414
Validation Loss: 0.8850, Accuracy: 0.8529, Precision: 0.8181, Recall: 0.8074, F1: 0.8112
Testing Loss: 0.7540, Accuracy: 0.8490, Precision: 0.8164, Recall: 0.7807, F1: 0.7954
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2189, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8800, F1: 0.8544
Epoch 62/70
Train Loss: 0.0789, Accuracy: 0.9647, Precision: 0.9447, Recall: 0.9423, F1: 0.9435
Validation Loss: 0.8288, Accuracy: 0.8657, Precision: 0.8243, Recall: 0.8134, F1: 0.8182
Testing Loss: 0.7993, Accuracy: 0.8490, Precision: 0.8073, Recall: 0.7738, F1: 0.7861
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1381, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9800, F1: 0.9713
Epoch 63/70
Train Loss: 0.0804, Accuracy: 0.9618, Precision: 0.9392, Recall: 0.9391, F1: 0.9391
Validation Loss: 0.9129, Accuracy: 0.8571, Precision: 0.8095, Recall: 0.7853, F1: 0.7946
Testing Loss: 0.8399, Accuracy: 0.8466, Precision: 0.8163, Recall: 0.7588, F1: 0.7762
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2400, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8978, F1: 0.8757
Epoch 64/70
Train Loss: 0.0775, Accuracy: 0.9668, Precision: 0.9489, Recall: 0.9470, F1: 0.9479
Validation Loss: 0.8319, Accuracy: 0.8550, Precision: 0.8178, Recall: 0.8108, F1: 0.8137
Testing Loss: 0.7437, Accuracy: 0.8575, Precision: 0.8264, Recall: 0.7909, F1: 0.8059
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2917, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8533, F1: 0.8332
Epoch 65/70
Train Loss: 0.0799, Accuracy: 0.9642, Precision: 0.9434, Recall: 0.9451, F1: 0.9443
Validation Loss: 0.8385, Accuracy: 0.8529, Precision: 0.8027, Recall: 0.7981, F1: 0.7997
Testing Loss: 0.7596, Accuracy: 0.8527, Precision: 0.8092, Recall: 0.7925, F1: 0.7996
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0851, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0738, Accuracy: 0.9644, Precision: 0.9429, Recall: 0.9459, F1: 0.9443
Validation Loss: 0.9093, Accuracy: 0.8486, Precision: 0.8063, Recall: 0.7959, F1: 0.7985
Testing Loss: 0.7971, Accuracy: 0.8466, Precision: 0.8064, Recall: 0.7737, F1: 0.7860
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1113, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0786, Accuracy: 0.9642, Precision: 0.9440, Recall: 0.9421, F1: 0.9430
Validation Loss: 0.9699, Accuracy: 0.8571, Precision: 0.8134, Recall: 0.8078, F1: 0.8096
Testing Loss: 0.8420, Accuracy: 0.8514, Precision: 0.8173, Recall: 0.7765, F1: 0.7917
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2191, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8756
Epoch 68/70
Train Loss: 0.0779, Accuracy: 0.9621, Precision: 0.9415, Recall: 0.9409, F1: 0.9412
Validation Loss: 0.8619, Accuracy: 0.8593, Precision: 0.8122, Recall: 0.8138, F1: 0.8117
Testing Loss: 0.7195, Accuracy: 0.8430, Precision: 0.8024, Recall: 0.7838, F1: 0.7921
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2256, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8956, F1: 0.8756
Epoch 69/70
Train Loss: 0.0719, Accuracy: 0.9661, Precision: 0.9447, Recall: 0.9469, F1: 0.9458
Validation Loss: 0.8386, Accuracy: 0.8614, Precision: 0.8136, Recall: 0.8172, F1: 0.8138
Testing Loss: 0.7226, Accuracy: 0.8478, Precision: 0.8136, Recall: 0.7902, F1: 0.8006
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3186, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8556, F1: 0.8351
Epoch 70/70
Train Loss: 0.0740, Accuracy: 0.9656, Precision: 0.9466, Recall: 0.9432, F1: 0.9448
Validation Loss: 0.8442, Accuracy: 0.8507, Precision: 0.8016, Recall: 0.7897, F1: 0.7952
Testing Loss: 0.7562, Accuracy: 0.8490, Precision: 0.8129, Recall: 0.7710, F1: 0.7857
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1750, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9328, F1: 0.9182
For later layers:  [8, 9, 10, 11]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([768]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 2.4520, Accuracy: 0.2099, Precision: 0.1547, Recall: 0.1687, F1: 0.1557
Validation Loss: 1.6985, Accuracy: 0.2751, Precision: 0.1406, Recall: 0.1705, F1: 0.0894
Testing Loss: 1.6934, Accuracy: 0.2778, Precision: 0.1565, Recall: 0.1723, F1: 0.0893
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0581, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 2/70
Train Loss: 1.7217, Accuracy: 0.2654, Precision: 0.1794, Recall: 0.1803, F1: 0.1638
Validation Loss: 1.6704, Accuracy: 0.2900, Precision: 0.1744, Recall: 0.1801, F1: 0.0986
Testing Loss: 1.6657, Accuracy: 0.2838, Precision: 0.1986, Recall: 0.1759, F1: 0.0893
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0560, Accuracy: 0.1190, Precision: 0.0238, Recall: 0.2000, F1: 0.0426
Epoch 3/70
Train Loss: 1.6795, Accuracy: 0.2905, Precision: 0.1832, Recall: 0.1947, F1: 0.1718
Validation Loss: 1.6475, Accuracy: 0.3156, Precision: 0.2809, Recall: 0.1982, F1: 0.1315
Testing Loss: 1.6388, Accuracy: 0.3164, Precision: 0.2652, Recall: 0.1989, F1: 0.1321
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0609, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 4/70
Train Loss: 1.6477, Accuracy: 0.3078, Precision: 0.1822, Recall: 0.2052, F1: 0.1776
Validation Loss: 1.5749, Accuracy: 0.3902, Precision: 0.2887, Recall: 0.2504, F1: 0.1914
Testing Loss: 1.5599, Accuracy: 0.3889, Precision: 0.2710, Recall: 0.2496, F1: 0.1896
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9904, Accuracy: 0.1190, Precision: 0.0238, Recall: 0.2000, F1: 0.0426
Epoch 5/70
Train Loss: 1.5717, Accuracy: 0.3887, Precision: 0.2474, Recall: 0.2593, F1: 0.2250
Validation Loss: 1.4813, Accuracy: 0.4136, Precision: 0.2586, Recall: 0.2668, F1: 0.2103
Testing Loss: 1.4455, Accuracy: 0.4191, Precision: 0.2868, Recall: 0.2709, F1: 0.2179
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2376, Accuracy: 0.1190, Precision: 0.0244, Recall: 0.2000, F1: 0.0435
Epoch 6/70
Train Loss: 1.4098, Accuracy: 0.4544, Precision: 0.2919, Recall: 0.3065, F1: 0.2732
Validation Loss: 1.3013, Accuracy: 0.4925, Precision: 0.2924, Recall: 0.3223, F1: 0.2625
Testing Loss: 1.2355, Accuracy: 0.5000, Precision: 0.2956, Recall: 0.3275, F1: 0.2643
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8647, Accuracy: 0.1190, Precision: 0.0238, Recall: 0.2000, F1: 0.0426
Epoch 7/70
Train Loss: 1.1678, Accuracy: 0.5651, Precision: 0.4292, Recall: 0.4053, F1: 0.3915
Validation Loss: 0.8407, Accuracy: 0.7100, Precision: 0.6850, Recall: 0.5301, F1: 0.5312
Testing Loss: 0.7582, Accuracy: 0.7283, Precision: 0.6727, Recall: 0.5564, F1: 0.5470
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.9455, Accuracy: 0.0952, Precision: 0.0216, Recall: 0.1600, F1: 0.0381
Epoch 8/70
Train Loss: 0.8352, Accuracy: 0.7235, Precision: 0.5947, Recall: 0.5797, F1: 0.5800
Validation Loss: 0.6625, Accuracy: 0.7932, Precision: 0.6821, Recall: 0.6642, F1: 0.6635
Testing Loss: 0.5453, Accuracy: 0.8297, Precision: 0.7160, Recall: 0.7227, F1: 0.7139
LM Predictions:  [0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.4396, Accuracy: 0.0952, Precision: 0.0190, Recall: 0.1333, F1: 0.0333
Epoch 9/70
Train Loss: 0.6063, Accuracy: 0.8096, Precision: 0.7465, Recall: 0.6918, F1: 0.6902
Validation Loss: 0.6093, Accuracy: 0.8209, Precision: 0.8618, Recall: 0.7099, F1: 0.7191
Testing Loss: 0.5096, Accuracy: 0.8345, Precision: 0.8132, Recall: 0.7266, F1: 0.7285
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.4145, Accuracy: 0.1429, Precision: 0.1042, Recall: 0.1667, F1: 0.0837
Epoch 10/70
Train Loss: 0.5483, Accuracy: 0.8274, Precision: 0.7591, Recall: 0.7174, F1: 0.7222
Validation Loss: 0.5359, Accuracy: 0.8571, Precision: 0.8542, Recall: 0.7851, F1: 0.8030
Testing Loss: 0.4337, Accuracy: 0.8599, Precision: 0.8453, Recall: 0.8046, F1: 0.8162
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 5, 3, 5, 0, 0, 0, 5, 0, 0, 4, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 4, 5, 0, 5, 0, 0, 0, 5, 0, 5, 4, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5534, Accuracy: 0.1429, Precision: 0.1111, Recall: 0.1667, F1: 0.0936
Epoch 11/70
Train Loss: 0.5240, Accuracy: 0.8307, Precision: 0.7882, Recall: 0.7433, F1: 0.7540
Validation Loss: 0.5448, Accuracy: 0.8614, Precision: 0.8536, Recall: 0.7998, F1: 0.8135
Testing Loss: 0.4157, Accuracy: 0.8623, Precision: 0.8430, Recall: 0.7889, F1: 0.8024
LM Predictions:  [0, 3, 0, 0, 4, 0, 5, 5, 5, 2, 5, 0, 0, 0, 5, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.3002, Accuracy: 0.0714, Precision: 0.0185, Recall: 0.1000, F1: 0.0313
Epoch 12/70
Train Loss: 0.4950, Accuracy: 0.8347, Precision: 0.7816, Recall: 0.7452, F1: 0.7546
Validation Loss: 0.5063, Accuracy: 0.8550, Precision: 0.8987, Recall: 0.7560, F1: 0.7697
Testing Loss: 0.3940, Accuracy: 0.8647, Precision: 0.8620, Recall: 0.7719, F1: 0.7862
LM Predictions:  [0, 3, 0, 0, 0, 0, 5, 5, 0, 2, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 4.0119, Accuracy: 0.0952, Precision: 0.1833, Recall: 0.1167, F1: 0.0589
Epoch 13/70
Train Loss: 0.4483, Accuracy: 0.8572, Precision: 0.8120, Recall: 0.7806, F1: 0.7911
Validation Loss: 0.4684, Accuracy: 0.8635, Precision: 0.8477, Recall: 0.8098, F1: 0.8217
Testing Loss: 0.3761, Accuracy: 0.8756, Precision: 0.8608, Recall: 0.8331, F1: 0.8433
LM Predictions:  [0, 3, 0, 5, 4, 5, 5, 5, 5, 2, 5, 0, 0, 0, 5, 0, 5, 2, 0, 4, 0, 5, 2, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6897, Accuracy: 0.0952, Precision: 0.0833, Recall: 0.1167, F1: 0.0691
Epoch 14/70
Train Loss: 0.4396, Accuracy: 0.8572, Precision: 0.8099, Recall: 0.7883, F1: 0.7964
Validation Loss: 0.4887, Accuracy: 0.8827, Precision: 0.8933, Recall: 0.8288, F1: 0.8527
Testing Loss: 0.3648, Accuracy: 0.8780, Precision: 0.8651, Recall: 0.8256, F1: 0.8421
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 4, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.9820, Accuracy: 0.0952, Precision: 0.1083, Recall: 0.1167, F1: 0.0678
Epoch 15/70
Train Loss: 0.4221, Accuracy: 0.8646, Precision: 0.8247, Recall: 0.8013, F1: 0.8111
Validation Loss: 0.4544, Accuracy: 0.8678, Precision: 0.8447, Recall: 0.8286, F1: 0.8354
Testing Loss: 0.3657, Accuracy: 0.8877, Precision: 0.8636, Recall: 0.8649, F1: 0.8638
LM Predictions:  [0, 5, 5, 5, 4, 0, 5, 5, 5, 2, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3133, Accuracy: 0.0952, Precision: 0.1167, Recall: 0.1167, F1: 0.0778
Epoch 16/70
Train Loss: 0.4082, Accuracy: 0.8769, Precision: 0.8386, Recall: 0.8198, F1: 0.8282
Validation Loss: 0.4680, Accuracy: 0.8870, Precision: 0.8765, Recall: 0.8614, F1: 0.8679
Testing Loss: 0.3668, Accuracy: 0.8829, Precision: 0.8631, Recall: 0.8534, F1: 0.8568
LM Predictions:  [0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7750, Accuracy: 0.0714, Precision: 0.0278, Recall: 0.1000, F1: 0.0435
Epoch 17/70
Train Loss: 0.3846, Accuracy: 0.8817, Precision: 0.8425, Recall: 0.8251, F1: 0.8330
Validation Loss: 0.4999, Accuracy: 0.8742, Precision: 0.8728, Recall: 0.8156, F1: 0.8343
Testing Loss: 0.3673, Accuracy: 0.8877, Precision: 0.8777, Recall: 0.8389, F1: 0.8545
LM Predictions:  [0, 3, 0, 0, 0, 0, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5335, Accuracy: 0.0714, Precision: 0.0227, Recall: 0.1000, F1: 0.0370
Epoch 18/70
Train Loss: 0.3802, Accuracy: 0.8757, Precision: 0.8361, Recall: 0.8219, F1: 0.8285
Validation Loss: 0.4631, Accuracy: 0.8827, Precision: 0.8673, Recall: 0.8498, F1: 0.8574
Testing Loss: 0.3642, Accuracy: 0.8865, Precision: 0.8657, Recall: 0.8548, F1: 0.8578
LM Predictions:  [0, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4089, Accuracy: 0.0952, Precision: 0.1218, Recall: 0.1167, F1: 0.0833
Epoch 19/70
Train Loss: 0.3580, Accuracy: 0.8864, Precision: 0.8528, Recall: 0.8346, F1: 0.8430
Validation Loss: 0.4935, Accuracy: 0.8806, Precision: 0.8708, Recall: 0.8290, F1: 0.8465
Testing Loss: 0.3714, Accuracy: 0.8829, Precision: 0.8676, Recall: 0.8375, F1: 0.8500
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5110, Accuracy: 0.0714, Precision: 0.0294, Recall: 0.1000, F1: 0.0455
Epoch 20/70
Train Loss: 0.3588, Accuracy: 0.8864, Precision: 0.8421, Recall: 0.8286, F1: 0.8348
Validation Loss: 0.4347, Accuracy: 0.8827, Precision: 0.8668, Recall: 0.8469, F1: 0.8555
Testing Loss: 0.3598, Accuracy: 0.8973, Precision: 0.8762, Recall: 0.8656, F1: 0.8694
LM Predictions:  [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4845, Accuracy: 0.0714, Precision: 0.0385, Recall: 0.1000, F1: 0.0556
Epoch 21/70
Train Loss: 0.3300, Accuracy: 0.8961, Precision: 0.8566, Recall: 0.8457, F1: 0.8507
Validation Loss: 0.4467, Accuracy: 0.8934, Precision: 0.8672, Recall: 0.8661, F1: 0.8657
Testing Loss: 0.3554, Accuracy: 0.8853, Precision: 0.8603, Recall: 0.8661, F1: 0.8604
LM Predictions:  [0, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3702, Accuracy: 0.0714, Precision: 0.0417, Recall: 0.1000, F1: 0.0588
Epoch 22/70
Train Loss: 0.3262, Accuracy: 0.8940, Precision: 0.8512, Recall: 0.8503, F1: 0.8506
Validation Loss: 0.4401, Accuracy: 0.9062, Precision: 0.8763, Recall: 0.8886, F1: 0.8821
Testing Loss: 0.3616, Accuracy: 0.8961, Precision: 0.8693, Recall: 0.8790, F1: 0.8726
LM Predictions:  [0, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 4, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0222, Accuracy: 0.1190, Precision: 0.1528, Recall: 0.1333, F1: 0.1101
Epoch 23/70
Train Loss: 0.3142, Accuracy: 0.8983, Precision: 0.8562, Recall: 0.8542, F1: 0.8551
Validation Loss: 0.5086, Accuracy: 0.8913, Precision: 0.8550, Recall: 0.8436, F1: 0.8485
Testing Loss: 0.3792, Accuracy: 0.8973, Precision: 0.8704, Recall: 0.8744, F1: 0.8720
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 5]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3965, Accuracy: 0.0952, Precision: 0.1167, Recall: 0.1167, F1: 0.0778
Epoch 24/70
Train Loss: 0.3058, Accuracy: 0.9004, Precision: 0.8600, Recall: 0.8574, F1: 0.8586
Validation Loss: 0.4780, Accuracy: 0.8785, Precision: 0.8528, Recall: 0.8265, F1: 0.8380
Testing Loss: 0.3812, Accuracy: 0.8925, Precision: 0.8734, Recall: 0.8487, F1: 0.8592
LM Predictions:  [0, 5, 0, 0, 4, 0, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0007, Accuracy: 0.0952, Precision: 0.1061, Recall: 0.1167, F1: 0.0648
Epoch 25/70
Train Loss: 0.2937, Accuracy: 0.9023, Precision: 0.8658, Recall: 0.8620, F1: 0.8638
Validation Loss: 0.4875, Accuracy: 0.8763, Precision: 0.8554, Recall: 0.8262, F1: 0.8392
Testing Loss: 0.3768, Accuracy: 0.9010, Precision: 0.8762, Recall: 0.8721, F1: 0.8733
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 0, 5, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1456, Accuracy: 0.1190, Precision: 0.2833, Recall: 0.1375, F1: 0.1148
Epoch 26/70
Train Loss: 0.2782, Accuracy: 0.9066, Precision: 0.8672, Recall: 0.8631, F1: 0.8650
Validation Loss: 0.4987, Accuracy: 0.8763, Precision: 0.8537, Recall: 0.8223, F1: 0.8354
Testing Loss: 0.3808, Accuracy: 0.8961, Precision: 0.8778, Recall: 0.8636, F1: 0.8700
LM Predictions:  [0, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1641, Accuracy: 0.1190, Precision: 0.2812, Recall: 0.1375, F1: 0.1124
Epoch 27/70
Train Loss: 0.2961, Accuracy: 0.8985, Precision: 0.8591, Recall: 0.8561, F1: 0.8576
Validation Loss: 0.4787, Accuracy: 0.8891, Precision: 0.8606, Recall: 0.8464, F1: 0.8513
Testing Loss: 0.3983, Accuracy: 0.8937, Precision: 0.8645, Recall: 0.8529, F1: 0.8567
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 4, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8731, Accuracy: 0.1190, Precision: 0.2516, Recall: 0.1375, F1: 0.1081
Epoch 28/70
Train Loss: 0.2703, Accuracy: 0.9089, Precision: 0.8682, Recall: 0.8688, F1: 0.8683
Validation Loss: 0.5390, Accuracy: 0.8742, Precision: 0.8525, Recall: 0.8081, F1: 0.8244
Testing Loss: 0.4147, Accuracy: 0.8913, Precision: 0.8688, Recall: 0.8265, F1: 0.8427
LM Predictions:  [0, 3, 5, 0, 4, 0, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 2, 0, 4, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 0, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8614, Accuracy: 0.1429, Precision: 0.2485, Recall: 0.1542, F1: 0.1284
Epoch 29/70
Train Loss: 0.2540, Accuracy: 0.9151, Precision: 0.8783, Recall: 0.8734, F1: 0.8758
Validation Loss: 0.5425, Accuracy: 0.8849, Precision: 0.8579, Recall: 0.8373, F1: 0.8458
Testing Loss: 0.4046, Accuracy: 0.8889, Precision: 0.8580, Recall: 0.8519, F1: 0.8545
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 2, 0, 0, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0493, Accuracy: 0.1429, Precision: 0.4479, Recall: 0.1542, F1: 0.1416
Epoch 30/70
Train Loss: 0.2467, Accuracy: 0.9165, Precision: 0.8803, Recall: 0.8751, F1: 0.8776
Validation Loss: 0.5598, Accuracy: 0.8742, Precision: 0.8528, Recall: 0.8109, F1: 0.8266
Testing Loss: 0.4246, Accuracy: 0.8913, Precision: 0.8697, Recall: 0.8348, F1: 0.8482
LM Predictions:  [0, 5, 5, 0, 4, 5, 5, 0, 5, 5, 5, 0, 2, 0, 3, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7325, Accuracy: 0.1667, Precision: 0.3667, Recall: 0.1708, F1: 0.1619
Epoch 31/70
Train Loss: 0.2432, Accuracy: 0.9189, Precision: 0.8858, Recall: 0.8819, F1: 0.8837
Validation Loss: 0.5454, Accuracy: 0.8827, Precision: 0.8514, Recall: 0.8436, F1: 0.8473
Testing Loss: 0.4090, Accuracy: 0.8877, Precision: 0.8592, Recall: 0.8599, F1: 0.8583
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8957, Accuracy: 0.1905, Precision: 0.5455, Recall: 0.1917, F1: 0.2150
Epoch 32/70
Train Loss: 0.2276, Accuracy: 0.9203, Precision: 0.8834, Recall: 0.8812, F1: 0.8822
Validation Loss: 0.5706, Accuracy: 0.8699, Precision: 0.8485, Recall: 0.8105, F1: 0.8259
Testing Loss: 0.4280, Accuracy: 0.8889, Precision: 0.8789, Recall: 0.8200, F1: 0.8379
LM Predictions:  [0, 1, 5, 0, 0, 5, 5, 0, 5, 5, 0, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.7175, Accuracy: 0.1905, Precision: 0.6917, Recall: 0.1935, F1: 0.2006
Epoch 33/70
Train Loss: 0.2297, Accuracy: 0.9182, Precision: 0.8823, Recall: 0.8772, F1: 0.8796
Validation Loss: 0.5055, Accuracy: 0.8806, Precision: 0.8595, Recall: 0.8308, F1: 0.8434
Testing Loss: 0.4414, Accuracy: 0.8816, Precision: 0.8527, Recall: 0.8442, F1: 0.8473
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9140, Accuracy: 0.1429, Precision: 0.3750, Recall: 0.1583, F1: 0.1558
Epoch 34/70
Train Loss: 0.2375, Accuracy: 0.9191, Precision: 0.8799, Recall: 0.8800, F1: 0.8799
Validation Loss: 0.5432, Accuracy: 0.8785, Precision: 0.8531, Recall: 0.8286, F1: 0.8392
Testing Loss: 0.4499, Accuracy: 0.8949, Precision: 0.8721, Recall: 0.8634, F1: 0.8669
LM Predictions:  [0, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 5, 2, 0, 0, 5, 5, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2218, Accuracy: 0.1429, Precision: 0.3194, Recall: 0.1583, F1: 0.1497
Epoch 35/70
Train Loss: 0.2269, Accuracy: 0.9236, Precision: 0.8870, Recall: 0.8917, F1: 0.8892
Validation Loss: 0.5650, Accuracy: 0.8742, Precision: 0.8563, Recall: 0.8203, F1: 0.8350
Testing Loss: 0.4477, Accuracy: 0.8865, Precision: 0.8662, Recall: 0.8289, F1: 0.8436
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 2, 0, 0, 0, 0, 5, 5, 0, 4, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9748, Accuracy: 0.1905, Precision: 0.5590, Recall: 0.1935, F1: 0.1996
Epoch 36/70
Train Loss: 0.2070, Accuracy: 0.9289, Precision: 0.8938, Recall: 0.8955, F1: 0.8945
Validation Loss: 0.5609, Accuracy: 0.8742, Precision: 0.8420, Recall: 0.8292, F1: 0.8333
Testing Loss: 0.4363, Accuracy: 0.8961, Precision: 0.8672, Recall: 0.8789, F1: 0.8711
LM Predictions:  [5, 1, 5, 0, 4, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2955, Accuracy: 0.1905, Precision: 0.6414, Recall: 0.1769, F1: 0.2233
Epoch 37/70
Train Loss: 0.1928, Accuracy: 0.9324, Precision: 0.8956, Recall: 0.8988, F1: 0.8971
Validation Loss: 0.6074, Accuracy: 0.8635, Precision: 0.8309, Recall: 0.8054, F1: 0.8164
Testing Loss: 0.4739, Accuracy: 0.8768, Precision: 0.8487, Recall: 0.8317, F1: 0.8389
LM Predictions:  [0, 1, 5, 0, 0, 5, 5, 0, 5, 5, 5, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2992, Accuracy: 0.2143, Precision: 0.6979, Recall: 0.2102, F1: 0.2335
Epoch 38/70
Train Loss: 0.1880, Accuracy: 0.9317, Precision: 0.8945, Recall: 0.8968, F1: 0.8956
Validation Loss: 0.6279, Accuracy: 0.8635, Precision: 0.8392, Recall: 0.8040, F1: 0.8187
Testing Loss: 0.4944, Accuracy: 0.8744, Precision: 0.8601, Recall: 0.8148, F1: 0.8322
LM Predictions:  [0, 1, 0, 0, 0, 5, 5, 0, 5, 5, 0, 0, 2, 0, 0, 0, 5, 4, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 0, 0, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6349, Accuracy: 0.1905, Precision: 0.5250, Recall: 0.1935, F1: 0.1956
Epoch 39/70
Train Loss: 0.1894, Accuracy: 0.9331, Precision: 0.8990, Recall: 0.9016, F1: 0.9001
Validation Loss: 0.6053, Accuracy: 0.8699, Precision: 0.8492, Recall: 0.8152, F1: 0.8297
Testing Loss: 0.4993, Accuracy: 0.8865, Precision: 0.8639, Recall: 0.8427, F1: 0.8521
LM Predictions:  [0, 1, 5, 0, 0, 5, 5, 0, 5, 5, 5, 0, 2, 0, 3, 0, 5, 4, 0, 0, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 0, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4433, Accuracy: 0.2381, Precision: 0.6961, Recall: 0.2269, F1: 0.2527
Epoch 40/70
Train Loss: 0.1844, Accuracy: 0.9341, Precision: 0.9030, Recall: 0.9010, F1: 0.9020
Validation Loss: 0.6376, Accuracy: 0.8657, Precision: 0.8284, Recall: 0.8238, F1: 0.8253
Testing Loss: 0.4412, Accuracy: 0.8877, Precision: 0.8625, Recall: 0.8676, F1: 0.8635
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 0, 5, 0, 5, 4, 0, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4059, Accuracy: 0.2381, Precision: 0.5121, Recall: 0.2269, F1: 0.2514
Epoch 41/70
Train Loss: 0.1776, Accuracy: 0.9372, Precision: 0.9066, Recall: 0.9131, F1: 0.9092
Validation Loss: 0.6421, Accuracy: 0.8678, Precision: 0.8351, Recall: 0.8209, F1: 0.8257
Testing Loss: 0.4636, Accuracy: 0.8792, Precision: 0.8505, Recall: 0.8458, F1: 0.8471
LM Predictions:  [0, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 5, 5, 5, 0, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4448, Accuracy: 0.2143, Precision: 0.7167, Recall: 0.2102, F1: 0.2525
Epoch 42/70
Train Loss: 0.1627, Accuracy: 0.9438, Precision: 0.9117, Recall: 0.9179, F1: 0.9145
Validation Loss: 0.6810, Accuracy: 0.8614, Precision: 0.8300, Recall: 0.7973, F1: 0.8111
Testing Loss: 0.4960, Accuracy: 0.8804, Precision: 0.8555, Recall: 0.8356, F1: 0.8446
LM Predictions:  [0, 1, 5, 0, 5, 5, 5, 5, 5, 5, 0, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 0, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3559, Accuracy: 0.2619, Precision: 0.7000, Recall: 0.2477, F1: 0.2815
Epoch 43/70
Train Loss: 0.1585, Accuracy: 0.9447, Precision: 0.9147, Recall: 0.9224, F1: 0.9180
Validation Loss: 0.6974, Accuracy: 0.8571, Precision: 0.8183, Recall: 0.8004, F1: 0.8073
Testing Loss: 0.4878, Accuracy: 0.8853, Precision: 0.8593, Recall: 0.8478, F1: 0.8525
LM Predictions:  [0, 1, 5, 0, 5, 5, 5, 5, 4, 5, 5, 0, 2, 0, 3, 0, 5, 5, 0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1090, Accuracy: 0.2619, Precision: 0.7024, Recall: 0.2477, F1: 0.2841
Epoch 44/70
Train Loss: 0.1533, Accuracy: 0.9398, Precision: 0.9073, Recall: 0.9088, F1: 0.9079
Validation Loss: 0.7332, Accuracy: 0.8550, Precision: 0.8185, Recall: 0.7965, F1: 0.8047
Testing Loss: 0.4981, Accuracy: 0.8744, Precision: 0.8419, Recall: 0.8326, F1: 0.8366
LM Predictions:  [0, 1, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 0, 2, 5, 0, 5, 0, 5, 5, 0, 4, 5, 5, 5, 5, 4, 0, 5, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1406, Accuracy: 0.2619, Precision: 0.6667, Recall: 0.2477, F1: 0.2827
Epoch 45/70
Train Loss: 0.1490, Accuracy: 0.9405, Precision: 0.9058, Recall: 0.9078, F1: 0.9067
Validation Loss: 0.6934, Accuracy: 0.8635, Precision: 0.8389, Recall: 0.8109, F1: 0.8232
Testing Loss: 0.5584, Accuracy: 0.8671, Precision: 0.8441, Recall: 0.8191, F1: 0.8291
LM Predictions:  [0, 1, 5, 0, 5, 5, 5, 0, 5, 5, 0, 0, 2, 0, 3, 0, 5, 4, 0, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 4, 5, 0, 5, 0, 0, 0, 4, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0932, Accuracy: 0.2381, Precision: 0.6961, Recall: 0.2269, F1: 0.2527
Epoch 46/70
Train Loss: 0.1591, Accuracy: 0.9395, Precision: 0.9081, Recall: 0.9115, F1: 0.9093
Validation Loss: 0.6852, Accuracy: 0.8678, Precision: 0.8360, Recall: 0.7977, F1: 0.8092
Testing Loss: 0.4833, Accuracy: 0.8744, Precision: 0.8578, Recall: 0.8024, F1: 0.8164
LM Predictions:  [0, 1, 5, 0, 0, 0, 5, 0, 4, 5, 0, 0, 2, 0, 3, 0, 1, 4, 0, 0, 0, 0, 3, 0, 0, 5, 0, 4, 5, 0, 4, 5, 3, 0, 0, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6112, Accuracy: 0.3810, Precision: 0.6071, Recall: 0.3310, F1: 0.3616
Epoch 47/70
Train Loss: 0.1480, Accuracy: 0.9455, Precision: 0.9163, Recall: 0.9142, F1: 0.9152
Validation Loss: 0.6665, Accuracy: 0.8699, Precision: 0.8267, Recall: 0.8214, F1: 0.8236
Testing Loss: 0.5006, Accuracy: 0.8804, Precision: 0.8482, Recall: 0.8517, F1: 0.8492
LM Predictions:  [0, 1, 5, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 0, 3, 0, 2, 4, 0, 5, 0, 0, 5, 0, 0, 5, 0, 4, 5, 0, 4, 5, 3, 5, 5, 4, 0, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7778, Accuracy: 0.3810, Precision: 0.6813, Recall: 0.3352, F1: 0.3732
Epoch 48/70
Train Loss: 0.1378, Accuracy: 0.9485, Precision: 0.9188, Recall: 0.9233, F1: 0.9208
Validation Loss: 0.7602, Accuracy: 0.8678, Precision: 0.8329, Recall: 0.7939, F1: 0.8082
Testing Loss: 0.5423, Accuracy: 0.8780, Precision: 0.8686, Recall: 0.8126, F1: 0.8318
LM Predictions:  [0, 1, 0, 0, 4, 5, 5, 0, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 4, 0, 0, 2, 0, 0, 5, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.3868, Accuracy: 0.4048, Precision: 0.6250, Recall: 0.3560, F1: 0.3625
Epoch 49/70
Train Loss: 0.1356, Accuracy: 0.9450, Precision: 0.9136, Recall: 0.9155, F1: 0.9145
Validation Loss: 0.7008, Accuracy: 0.8550, Precision: 0.8086, Recall: 0.8029, F1: 0.8042
Testing Loss: 0.5273, Accuracy: 0.8720, Precision: 0.8414, Recall: 0.8464, F1: 0.8407
LM Predictions:  [5, 1, 2, 0, 4, 5, 5, 5, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 5, 5, 3, 5, 5, 5, 0, 5, 0, 4, 5, 0, 4, 5, 3, 5, 5, 4, 5, 4, 5, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.4991, Accuracy: 0.4286, Precision: 0.7014, Recall: 0.3560, F1: 0.4287
Epoch 50/70
Train Loss: 0.1340, Accuracy: 0.9488, Precision: 0.9192, Recall: 0.9251, F1: 0.9217
Validation Loss: 0.7886, Accuracy: 0.8614, Precision: 0.8265, Recall: 0.8052, F1: 0.8143
Testing Loss: 0.6202, Accuracy: 0.8599, Precision: 0.8399, Recall: 0.8068, F1: 0.8205
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 0, 4, 5, 0, 0, 2, 0, 3, 0, 1, 4, 0, 3, 0, 0, 3, 0, 0, 5, 0, 4, 5, 0, 4, 5, 3, 5, 0, 4, 0, 4, 0, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.5183, Accuracy: 0.4048, Precision: 0.5612, Recall: 0.3477, F1: 0.3770
Epoch 51/70
Train Loss: 0.1233, Accuracy: 0.9516, Precision: 0.9225, Recall: 0.9254, F1: 0.9238
Validation Loss: 0.7829, Accuracy: 0.8529, Precision: 0.8057, Recall: 0.7889, F1: 0.7965
Testing Loss: 0.5983, Accuracy: 0.8659, Precision: 0.8255, Recall: 0.8109, F1: 0.8155
LM Predictions:  [0, 1, 2, 0, 4, 5, 5, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 0, 3, 0, 0, 5, 4, 4, 2, 0, 4, 5, 3, 5, 0, 4, 0, 4, 0, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9970, Accuracy: 0.5952, Precision: 0.6885, Recall: 0.4954, F1: 0.5201
Epoch 52/70
Train Loss: 0.1111, Accuracy: 0.9580, Precision: 0.9343, Recall: 0.9387, F1: 0.9364
Validation Loss: 0.8151, Accuracy: 0.8614, Precision: 0.8244, Recall: 0.8065, F1: 0.8143
Testing Loss: 0.5909, Accuracy: 0.8659, Precision: 0.8361, Recall: 0.8182, F1: 0.8262
LM Predictions:  [0, 1, 2, 0, 5, 5, 5, 5, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 5, 0, 4, 5, 0, 4, 5, 3, 5, 5, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2231, Accuracy: 0.5000, Precision: 0.7051, Recall: 0.4245, F1: 0.4769
Epoch 53/70
Train Loss: 0.1193, Accuracy: 0.9566, Precision: 0.9313, Recall: 0.9330, F1: 0.9321
Validation Loss: 0.7368, Accuracy: 0.8571, Precision: 0.8267, Recall: 0.8071, F1: 0.8150
Testing Loss: 0.5742, Accuracy: 0.8671, Precision: 0.8421, Recall: 0.8210, F1: 0.8300
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 5, 4, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 3, 0, 0, 5, 0, 4, 5, 0, 4, 5, 3, 5, 5, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.3732, Accuracy: 0.5000, Precision: 0.7143, Recall: 0.4394, F1: 0.4642
Epoch 54/70
Train Loss: 0.1222, Accuracy: 0.9530, Precision: 0.9232, Recall: 0.9336, F1: 0.9279
Validation Loss: 0.8452, Accuracy: 0.8550, Precision: 0.8094, Recall: 0.7955, F1: 0.8012
Testing Loss: 0.6383, Accuracy: 0.8744, Precision: 0.8409, Recall: 0.8221, F1: 0.8306
LM Predictions:  [0, 1, 2, 0, 2, 5, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 1, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9689, Accuracy: 0.6190, Precision: 0.6638, Recall: 0.5366, F1: 0.5476
Epoch 55/70
Train Loss: 0.1243, Accuracy: 0.9533, Precision: 0.9266, Recall: 0.9215, F1: 0.9240
Validation Loss: 0.8163, Accuracy: 0.8529, Precision: 0.8221, Recall: 0.7732, F1: 0.7917
Testing Loss: 0.6591, Accuracy: 0.8514, Precision: 0.8364, Recall: 0.7799, F1: 0.7995
LM Predictions:  [0, 1, 2, 0, 2, 0, 0, 0, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 0, 1, 0, 2, 0, 4, 5, 0, 4, 0, 3, 0, 0, 4, 0, 4, 0, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2676, Accuracy: 0.5000, Precision: 0.6746, Recall: 0.4454, F1: 0.4471
Epoch 56/70
Train Loss: 0.1106, Accuracy: 0.9557, Precision: 0.9325, Recall: 0.9290, F1: 0.9307
Validation Loss: 0.7713, Accuracy: 0.8635, Precision: 0.8146, Recall: 0.8038, F1: 0.8086
Testing Loss: 0.6210, Accuracy: 0.8732, Precision: 0.8345, Recall: 0.8243, F1: 0.8283
LM Predictions:  [0, 1, 2, 0, 4, 5, 0, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9052, Accuracy: 0.6667, Precision: 0.7056, Recall: 0.5681, F1: 0.5784
Epoch 57/70
Train Loss: 0.1058, Accuracy: 0.9545, Precision: 0.9264, Recall: 0.9311, F1: 0.9286
Validation Loss: 0.8687, Accuracy: 0.8507, Precision: 0.8184, Recall: 0.7966, F1: 0.8045
Testing Loss: 0.6805, Accuracy: 0.8659, Precision: 0.8352, Recall: 0.8138, F1: 0.8230
LM Predictions:  [0, 1, 2, 0, 2, 5, 0, 0, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.1663, Accuracy: 0.5952, Precision: 0.6903, Recall: 0.5181, F1: 0.5319
Epoch 58/70
Train Loss: 0.1127, Accuracy: 0.9547, Precision: 0.9274, Recall: 0.9263, F1: 0.9268
Validation Loss: 0.7454, Accuracy: 0.8721, Precision: 0.8335, Recall: 0.8197, F1: 0.8254
Testing Loss: 0.6452, Accuracy: 0.8635, Precision: 0.8330, Recall: 0.8167, F1: 0.8242
LM Predictions:  [0, 1, 2, 0, 4, 5, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9000, Accuracy: 0.6429, Precision: 0.6994, Recall: 0.5514, F1: 0.5644
Epoch 59/70
Train Loss: 0.1022, Accuracy: 0.9580, Precision: 0.9331, Recall: 0.9329, F1: 0.9330
Validation Loss: 0.8459, Accuracy: 0.8699, Precision: 0.8435, Recall: 0.8157, F1: 0.8277
Testing Loss: 0.7123, Accuracy: 0.8587, Precision: 0.8335, Recall: 0.8071, F1: 0.8186
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 4, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9767, Accuracy: 0.6429, Precision: 0.7143, Recall: 0.5532, F1: 0.5767
Epoch 60/70
Train Loss: 0.0965, Accuracy: 0.9621, Precision: 0.9390, Recall: 0.9442, F1: 0.9415
Validation Loss: 0.8131, Accuracy: 0.8571, Precision: 0.8242, Recall: 0.8036, F1: 0.8127
Testing Loss: 0.6883, Accuracy: 0.8635, Precision: 0.8362, Recall: 0.8209, F1: 0.8273
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 0, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 5, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 5, 0, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8976, Accuracy: 0.6429, Precision: 0.7179, Recall: 0.5551, F1: 0.5812
Epoch 61/70
Train Loss: 0.1048, Accuracy: 0.9542, Precision: 0.9270, Recall: 0.9295, F1: 0.9282
Validation Loss: 0.8409, Accuracy: 0.8550, Precision: 0.8188, Recall: 0.7893, F1: 0.8008
Testing Loss: 0.6871, Accuracy: 0.8514, Precision: 0.8158, Recall: 0.7764, F1: 0.7916
LM Predictions:  [0, 1, 2, 0, 1, 3, 0, 0, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 5, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6777, Accuracy: 0.6667, Precision: 0.6879, Recall: 0.5884, F1: 0.5795
Epoch 62/70
Train Loss: 0.1027, Accuracy: 0.9592, Precision: 0.9338, Recall: 0.9343, F1: 0.9341
Validation Loss: 0.8291, Accuracy: 0.8593, Precision: 0.8241, Recall: 0.7926, F1: 0.8047
Testing Loss: 0.6701, Accuracy: 0.8635, Precision: 0.8363, Recall: 0.7993, F1: 0.8143
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 0, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 5, 3, 0, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6282, Accuracy: 0.7143, Precision: 0.7179, Recall: 0.6069, F1: 0.6222
Epoch 63/70
Train Loss: 0.0952, Accuracy: 0.9573, Precision: 0.9363, Recall: 0.9302, F1: 0.9332
Validation Loss: 0.8030, Accuracy: 0.8614, Precision: 0.8155, Recall: 0.8123, F1: 0.8138
Testing Loss: 0.6340, Accuracy: 0.8696, Precision: 0.8385, Recall: 0.8296, F1: 0.8330
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 4, 2, 4, 4, 2, 0, 4, 4, 3, 5, 5, 4, 1, 4, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7216, Accuracy: 0.7619, Precision: 0.7222, Recall: 0.6551, F1: 0.6483
Epoch 64/70
Train Loss: 0.0958, Accuracy: 0.9597, Precision: 0.9340, Recall: 0.9356, F1: 0.9348
Validation Loss: 0.8811, Accuracy: 0.8593, Precision: 0.8202, Recall: 0.8085, F1: 0.8132
Testing Loss: 0.6778, Accuracy: 0.8611, Precision: 0.8290, Recall: 0.8207, F1: 0.8237
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 5, 0, 0, 2, 4, 3, 5, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 4, 3, 5, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5204, Accuracy: 0.8571, Precision: 0.7626, Recall: 0.7125, F1: 0.7272
Epoch 65/70
Train Loss: 0.0955, Accuracy: 0.9609, Precision: 0.9373, Recall: 0.9420, F1: 0.9395
Validation Loss: 0.8956, Accuracy: 0.8614, Precision: 0.8283, Recall: 0.7982, F1: 0.8099
Testing Loss: 0.6895, Accuracy: 0.8551, Precision: 0.8248, Recall: 0.7871, F1: 0.8032
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 0, 4, 5, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 5, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7043, Accuracy: 0.6905, Precision: 0.7111, Recall: 0.5940, F1: 0.6013
Epoch 66/70
Train Loss: 0.0922, Accuracy: 0.9583, Precision: 0.9347, Recall: 0.9340, F1: 0.9343
Validation Loss: 0.8238, Accuracy: 0.8593, Precision: 0.8207, Recall: 0.8009, F1: 0.8085
Testing Loss: 0.6214, Accuracy: 0.8563, Precision: 0.8189, Recall: 0.7978, F1: 0.8073
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 0, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 5, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5183, Accuracy: 0.7857, Precision: 0.7308, Recall: 0.6755, F1: 0.6685
Epoch 67/70
Train Loss: 0.0865, Accuracy: 0.9613, Precision: 0.9382, Recall: 0.9423, F1: 0.9401
Validation Loss: 0.8810, Accuracy: 0.8614, Precision: 0.8175, Recall: 0.8116, F1: 0.8131
Testing Loss: 0.6533, Accuracy: 0.8599, Precision: 0.8206, Recall: 0.8032, F1: 0.8110
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 5, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3739, Accuracy: 0.8810, Precision: 0.7500, Recall: 0.7292, F1: 0.7287
Epoch 68/70
Train Loss: 0.0873, Accuracy: 0.9602, Precision: 0.9369, Recall: 0.9323, F1: 0.9346
Validation Loss: 0.8365, Accuracy: 0.8742, Precision: 0.8169, Recall: 0.8276, F1: 0.8203
Testing Loss: 0.6515, Accuracy: 0.8587, Precision: 0.8124, Recall: 0.8014, F1: 0.8033
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 4, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3762, Accuracy: 0.8810, Precision: 0.8818, Recall: 0.8750, F1: 0.8649
Epoch 69/70
Train Loss: 0.0822, Accuracy: 0.9642, Precision: 0.9422, Recall: 0.9470, F1: 0.9445
Validation Loss: 0.8724, Accuracy: 0.8529, Precision: 0.8190, Recall: 0.7927, F1: 0.8033
Testing Loss: 0.7147, Accuracy: 0.8490, Precision: 0.8226, Recall: 0.7814, F1: 0.7984
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 0, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5458, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7706, F1: 0.7549
Epoch 70/70
Train Loss: 0.0906, Accuracy: 0.9585, Precision: 0.9337, Recall: 0.9318, F1: 0.9327
Validation Loss: 0.8456, Accuracy: 0.8635, Precision: 0.8238, Recall: 0.8065, F1: 0.8132
Testing Loss: 0.6447, Accuracy: 0.8587, Precision: 0.8205, Recall: 0.7972, F1: 0.8063
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3843, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8728, F1: 0.8541