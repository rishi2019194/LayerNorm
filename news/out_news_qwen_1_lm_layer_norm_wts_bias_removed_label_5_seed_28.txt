Model: Qwen/Qwen2-0.5B-Instruct, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:1
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
Layer: backbone.model.embed_tokens.weight, Size: torch.Size([151936, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.norm.weight, Size: torch.Size([896]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 896]), req grad: True
Epoch 1/70
Train Loss: 1.6102, Accuracy: 0.5079, Precision: 0.4281, Recall: 0.4052, F1: 0.4091
Validation Loss: 1.0393, Accuracy: 0.6354, Precision: 0.7161, Recall: 0.4928, F1: 0.5066
Testing Loss: 1.0004, Accuracy: 0.6510, Precision: 0.6470, Recall: 0.5067, F1: 0.5138
LM Predictions:  [0, 0, 0, 1, 1, 1, 0, 0, 4, 0, 3, 0, 1, 0, 3, 0, 1, 1, 0, 0, 0, 0, 5, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 5, 0, 1, 0, 0, 3, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7235, Accuracy: 0.3333, Precision: 0.3958, Recall: 0.3278, F1: 0.2343
Epoch 2/70
Train Loss: 0.4902, Accuracy: 0.8414, Precision: 0.7935, Recall: 0.7725, F1: 0.7805
Validation Loss: 0.8768, Accuracy: 0.7207, Precision: 0.6891, Recall: 0.6353, F1: 0.6497
Testing Loss: 0.8729, Accuracy: 0.7246, Precision: 0.6943, Recall: 0.6633, F1: 0.6741
LM Predictions:  [0, 1, 0, 0, 1, 1, 0, 5, 4, 0, 5, 0, 2, 0, 3, 0, 2, 4, 5, 3, 3, 5, 3, 5, 0, 2, 0, 4, 2, 5, 4, 3, 3, 2, 5, 2, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2867, Accuracy: 0.6429, Precision: 0.7064, Recall: 0.5532, F1: 0.5801
Epoch 3/70
Train Loss: 0.2265, Accuracy: 0.9353, Precision: 0.9025, Recall: 0.8985, F1: 0.9005
Validation Loss: 1.2720, Accuracy: 0.7015, Precision: 0.6337, Recall: 0.6021, F1: 0.5882
Testing Loss: 1.2467, Accuracy: 0.7150, Precision: 0.6583, Recall: 0.6134, F1: 0.6020
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 0, 0, 2, 4, 0, 0, 0, 4, 0, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8429, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7683, F1: 0.7342
Epoch 4/70
Train Loss: 0.1509, Accuracy: 0.9521, Precision: 0.9241, Recall: 0.9227, F1: 0.9234
Validation Loss: 1.2498, Accuracy: 0.7228, Precision: 0.6584, Recall: 0.5933, F1: 0.6056
Testing Loss: 1.1674, Accuracy: 0.7319, Precision: 0.6731, Recall: 0.6053, F1: 0.6172
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3766, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8528, F1: 0.8350
Epoch 5/70
Train Loss: 0.1243, Accuracy: 0.9557, Precision: 0.9263, Recall: 0.9272, F1: 0.9267
Validation Loss: 1.6238, Accuracy: 0.7292, Precision: 0.6974, Recall: 0.5843, F1: 0.5973
Testing Loss: 1.5133, Accuracy: 0.7234, Precision: 0.6577, Recall: 0.5808, F1: 0.5896
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.5711, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7706, F1: 0.7569
Epoch 6/70
Train Loss: 0.0965, Accuracy: 0.9635, Precision: 0.9417, Recall: 0.9393, F1: 0.9405
Validation Loss: 1.5626, Accuracy: 0.7249, Precision: 0.6120, Recall: 0.6121, F1: 0.6056
Testing Loss: 1.4506, Accuracy: 0.7415, Precision: 0.6686, Recall: 0.6349, F1: 0.6333
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6336, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 7/70
Train Loss: 0.1017, Accuracy: 0.9594, Precision: 0.9385, Recall: 0.9342, F1: 0.9363
Validation Loss: 1.6746, Accuracy: 0.7484, Precision: 0.7016, Recall: 0.6573, F1: 0.6735
Testing Loss: 1.6350, Accuracy: 0.7536, Precision: 0.7323, Recall: 0.6714, F1: 0.6912
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 3, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.9024, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7461, F1: 0.7351
Epoch 8/70
Train Loss: 0.1476, Accuracy: 0.9474, Precision: 0.9271, Recall: 0.9198, F1: 0.9233
Validation Loss: 1.5378, Accuracy: 0.7036, Precision: 0.6597, Recall: 0.6636, F1: 0.6428
Testing Loss: 1.4907, Accuracy: 0.7053, Precision: 0.6512, Recall: 0.6618, F1: 0.6417
LM Predictions:  [0, 1, 2, 5, 1, 1, 0, 4, 4, 2, 5, 0, 2, 4, 3, 5, 2, 4, 5, 3, 5, 4, 3, 1, 5, 2, 5, 4, 2, 0, 4, 3, 3, 5, 0, 4, 5, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6160, Accuracy: 0.7381, Precision: 0.7792, Recall: 0.6218, F1: 0.6811
Epoch 9/70
Train Loss: 0.1796, Accuracy: 0.9400, Precision: 0.9146, Recall: 0.9144, F1: 0.9145
Validation Loss: 1.4923, Accuracy: 0.6930, Precision: 0.6630, Recall: 0.6068, F1: 0.6203
Testing Loss: 1.4114, Accuracy: 0.7210, Precision: 0.6837, Recall: 0.6191, F1: 0.6324
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6828, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 10/70
Train Loss: 0.1236, Accuracy: 0.9564, Precision: 0.9367, Recall: 0.9302, F1: 0.9334
Validation Loss: 1.7298, Accuracy: 0.7079, Precision: 0.6958, Recall: 0.5696, F1: 0.5917
Testing Loss: 1.6408, Accuracy: 0.6932, Precision: 0.6600, Recall: 0.5628, F1: 0.5851
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 0, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.0123, Accuracy: 0.6190, Precision: 0.8476, Recall: 0.6661, F1: 0.6541
Epoch 11/70
Train Loss: 0.1007, Accuracy: 0.9611, Precision: 0.9419, Recall: 0.9338, F1: 0.9376
Validation Loss: 1.5113, Accuracy: 0.7505, Precision: 0.6990, Recall: 0.6676, F1: 0.6793
Testing Loss: 1.5678, Accuracy: 0.7826, Precision: 0.7539, Recall: 0.7046, F1: 0.7209
LM Predictions:  [0, 1, 2, 5, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 5, 3, 3, 5, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 5, 4, 5, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3723, Accuracy: 0.8571, Precision: 0.8056, Recall: 0.7278, F1: 0.7576
Epoch 12/70
Train Loss: 0.0999, Accuracy: 0.9599, Precision: 0.9373, Recall: 0.9390, F1: 0.9381
Validation Loss: 2.1988, Accuracy: 0.7228, Precision: 0.6699, Recall: 0.5976, F1: 0.5964
Testing Loss: 2.0108, Accuracy: 0.7403, Precision: 0.6771, Recall: 0.6046, F1: 0.6077
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 2, 0, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 1, 1, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6108, Accuracy: 0.7381, Precision: 0.8242, Recall: 0.7728, F1: 0.7370
Epoch 13/70
Train Loss: 0.1134, Accuracy: 0.9502, Precision: 0.9271, Recall: 0.9266, F1: 0.9268
Validation Loss: 1.6891, Accuracy: 0.7441, Precision: 0.7163, Recall: 0.6674, F1: 0.6824
Testing Loss: 1.6477, Accuracy: 0.7428, Precision: 0.7207, Recall: 0.6768, F1: 0.6904
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 5, 5, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.7277, Accuracy: 0.7619, Precision: 0.7308, Recall: 0.6532, F1: 0.6424
Epoch 14/70
Train Loss: 0.1007, Accuracy: 0.9587, Precision: 0.9371, Recall: 0.9363, F1: 0.9367
Validation Loss: 1.6073, Accuracy: 0.7655, Precision: 0.7153, Recall: 0.6769, F1: 0.6852
Testing Loss: 1.5463, Accuracy: 0.7729, Precision: 0.7328, Recall: 0.6930, F1: 0.7010
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1586, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 15/70
Train Loss: 0.0859, Accuracy: 0.9632, Precision: 0.9425, Recall: 0.9429, F1: 0.9427
Validation Loss: 1.5851, Accuracy: 0.7591, Precision: 0.6619, Recall: 0.6530, F1: 0.6519
Testing Loss: 1.6143, Accuracy: 0.7742, Precision: 0.7144, Recall: 0.6711, F1: 0.6730
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 0, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4803, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7811, F1: 0.7643
Epoch 16/70
Train Loss: 0.0770, Accuracy: 0.9651, Precision: 0.9463, Recall: 0.9408, F1: 0.9434
Validation Loss: 1.4482, Accuracy: 0.7676, Precision: 0.7055, Recall: 0.6808, F1: 0.6885
Testing Loss: 1.2935, Accuracy: 0.7717, Precision: 0.7278, Recall: 0.7125, F1: 0.7192
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 5, 4, 2, 0, 4, 3, 3, 5, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4135, Accuracy: 0.8810, Precision: 0.7708, Recall: 0.7458, F1: 0.7421
Epoch 17/70
Train Loss: 0.0754, Accuracy: 0.9706, Precision: 0.9542, Recall: 0.9540, F1: 0.9541
Validation Loss: 1.6664, Accuracy: 0.7612, Precision: 0.6707, Recall: 0.6435, F1: 0.6515
Testing Loss: 1.4972, Accuracy: 0.7778, Precision: 0.7256, Recall: 0.6783, F1: 0.6914
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2738, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8711, F1: 0.8456
Epoch 18/70
Train Loss: 0.0726, Accuracy: 0.9668, Precision: 0.9473, Recall: 0.9451, F1: 0.9462
Validation Loss: 1.5213, Accuracy: 0.7697, Precision: 0.7123, Recall: 0.6679, F1: 0.6831
Testing Loss: 1.3550, Accuracy: 0.7766, Precision: 0.7373, Recall: 0.6899, F1: 0.7050
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2304, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 19/70
Train Loss: 0.0654, Accuracy: 0.9687, Precision: 0.9489, Recall: 0.9484, F1: 0.9486
Validation Loss: 1.4988, Accuracy: 0.7505, Precision: 0.6725, Recall: 0.6357, F1: 0.6470
Testing Loss: 1.4178, Accuracy: 0.7693, Precision: 0.7042, Recall: 0.6650, F1: 0.6705
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.6514, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 20/70
Train Loss: 0.0650, Accuracy: 0.9656, Precision: 0.9443, Recall: 0.9454, F1: 0.9448
Validation Loss: 1.4239, Accuracy: 0.7612, Precision: 0.6973, Recall: 0.6855, F1: 0.6883
Testing Loss: 1.2693, Accuracy: 0.7729, Precision: 0.7135, Recall: 0.7150, F1: 0.7131
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0951, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 21/70
Train Loss: 0.0575, Accuracy: 0.9696, Precision: 0.9503, Recall: 0.9527, F1: 0.9515
Validation Loss: 1.5862, Accuracy: 0.7655, Precision: 0.6917, Recall: 0.6690, F1: 0.6772
Testing Loss: 1.4470, Accuracy: 0.7778, Precision: 0.7358, Recall: 0.7002, F1: 0.7120
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3072, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7956, F1: 0.7750
Epoch 22/70
Train Loss: 0.0595, Accuracy: 0.9699, Precision: 0.9513, Recall: 0.9528, F1: 0.9521
Validation Loss: 1.6795, Accuracy: 0.7676, Precision: 0.7107, Recall: 0.6622, F1: 0.6779
Testing Loss: 1.5369, Accuracy: 0.7790, Precision: 0.7330, Recall: 0.6897, F1: 0.7042
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3969, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 23/70
Train Loss: 0.0561, Accuracy: 0.9734, Precision: 0.9557, Recall: 0.9570, F1: 0.9563
Validation Loss: 1.6711, Accuracy: 0.7697, Precision: 0.6713, Recall: 0.6661, F1: 0.6656
Testing Loss: 1.5636, Accuracy: 0.7778, Precision: 0.7077, Recall: 0.6856, F1: 0.6873
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1755, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8733, F1: 0.8497
Epoch 24/70
Train Loss: 0.0621, Accuracy: 0.9640, Precision: 0.9437, Recall: 0.9378, F1: 0.9406
Validation Loss: 1.8448, Accuracy: 0.7697, Precision: 0.6947, Recall: 0.6711, F1: 0.6783
Testing Loss: 1.6386, Accuracy: 0.7742, Precision: 0.7156, Recall: 0.6779, F1: 0.6841
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1201, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 25/70
Train Loss: 0.0583, Accuracy: 0.9682, Precision: 0.9517, Recall: 0.9428, F1: 0.9470
Validation Loss: 1.7581, Accuracy: 0.7484, Precision: 0.6615, Recall: 0.6432, F1: 0.6487
Testing Loss: 1.6373, Accuracy: 0.7717, Precision: 0.7133, Recall: 0.6742, F1: 0.6773
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4446, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 26/70
Train Loss: 0.0589, Accuracy: 0.9689, Precision: 0.9511, Recall: 0.9459, F1: 0.9485
Validation Loss: 1.7585, Accuracy: 0.7655, Precision: 0.6821, Recall: 0.6756, F1: 0.6782
Testing Loss: 1.5965, Accuracy: 0.7705, Precision: 0.7122, Recall: 0.6917, F1: 0.6966
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3672, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 27/70
Train Loss: 0.0557, Accuracy: 0.9704, Precision: 0.9503, Recall: 0.9533, F1: 0.9518
Validation Loss: 1.9981, Accuracy: 0.7633, Precision: 0.6974, Recall: 0.6736, F1: 0.6822
Testing Loss: 1.8052, Accuracy: 0.7766, Precision: 0.7242, Recall: 0.6960, F1: 0.7068
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1187, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 28/70
Train Loss: 0.0550, Accuracy: 0.9680, Precision: 0.9486, Recall: 0.9480, F1: 0.9483
Validation Loss: 2.1161, Accuracy: 0.7569, Precision: 0.6942, Recall: 0.6678, F1: 0.6778
Testing Loss: 1.8550, Accuracy: 0.7790, Precision: 0.7131, Recall: 0.6927, F1: 0.6987
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2655, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9111, F1: 0.8857
Epoch 29/70
Train Loss: 0.0547, Accuracy: 0.9713, Precision: 0.9543, Recall: 0.9532, F1: 0.9537
Validation Loss: 2.0444, Accuracy: 0.7569, Precision: 0.6646, Recall: 0.6434, F1: 0.6498
Testing Loss: 1.8136, Accuracy: 0.7766, Precision: 0.7127, Recall: 0.6798, F1: 0.6840
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1464, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 30/70
Train Loss: 0.0552, Accuracy: 0.9682, Precision: 0.9505, Recall: 0.9474, F1: 0.9489
Validation Loss: 2.3056, Accuracy: 0.7633, Precision: 0.6925, Recall: 0.6682, F1: 0.6770
Testing Loss: 2.0087, Accuracy: 0.7874, Precision: 0.7416, Recall: 0.7078, F1: 0.7205
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.0884, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 31/70
Train Loss: 0.0533, Accuracy: 0.9692, Precision: 0.9507, Recall: 0.9469, F1: 0.9488
Validation Loss: 1.8921, Accuracy: 0.7399, Precision: 0.6624, Recall: 0.6041, F1: 0.6130
Testing Loss: 1.7593, Accuracy: 0.7488, Precision: 0.6656, Recall: 0.6212, F1: 0.6299
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 0, 2, 0, 4, 3, 3, 0, 0, 0, 0, 0, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.8506, Accuracy: 0.7381, Precision: 0.8625, Recall: 0.7661, F1: 0.7390
Epoch 32/70
Train Loss: 0.2487, Accuracy: 0.9158, Precision: 0.8848, Recall: 0.8767, F1: 0.8805
Validation Loss: 1.0154, Accuracy: 0.7335, Precision: 0.6944, Recall: 0.6082, F1: 0.6292
Testing Loss: 0.8890, Accuracy: 0.7572, Precision: 0.7324, Recall: 0.6501, F1: 0.6711
LM Predictions:  [0, 1, 2, 0, 1, 0, 0, 5, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 4, 3, 3, 0, 0, 0, 0, 2, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.2528, Accuracy: 0.5238, Precision: 0.6791, Recall: 0.4806, F1: 0.4642
Epoch 33/70
Train Loss: 0.1293, Accuracy: 0.9507, Precision: 0.9256, Recall: 0.9236, F1: 0.9246
Validation Loss: 1.0895, Accuracy: 0.7633, Precision: 0.7083, Recall: 0.6775, F1: 0.6897
Testing Loss: 0.9828, Accuracy: 0.7862, Precision: 0.7553, Recall: 0.7146, F1: 0.7297
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 5, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3032, Accuracy: 0.8333, Precision: 0.7424, Recall: 0.7130, F1: 0.6996
Epoch 34/70
Train Loss: 0.0647, Accuracy: 0.9687, Precision: 0.9483, Recall: 0.9512, F1: 0.9497
Validation Loss: 1.2600, Accuracy: 0.7804, Precision: 0.7250, Recall: 0.6911, F1: 0.7044
Testing Loss: 1.1642, Accuracy: 0.7911, Precision: 0.7371, Recall: 0.7094, F1: 0.7191
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3334, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7911, F1: 0.7706
Epoch 35/70
Train Loss: 0.0561, Accuracy: 0.9659, Precision: 0.9451, Recall: 0.9407, F1: 0.9429
Validation Loss: 1.2617, Accuracy: 0.7910, Precision: 0.7454, Recall: 0.7112, F1: 0.7252
Testing Loss: 1.1896, Accuracy: 0.7923, Precision: 0.7395, Recall: 0.7210, F1: 0.7286
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1418, Accuracy: 0.9048, Precision: 0.9111, Recall: 0.9200, F1: 0.8929
Epoch 36/70
Train Loss: 0.0534, Accuracy: 0.9687, Precision: 0.9490, Recall: 0.9533, F1: 0.9511
Validation Loss: 1.3748, Accuracy: 0.7697, Precision: 0.7127, Recall: 0.6748, F1: 0.6876
Testing Loss: 1.2684, Accuracy: 0.7826, Precision: 0.7260, Recall: 0.6967, F1: 0.7072
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1555, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 37/70
Train Loss: 0.0473, Accuracy: 0.9730, Precision: 0.9565, Recall: 0.9555, F1: 0.9560
Validation Loss: 1.4696, Accuracy: 0.7719, Precision: 0.7190, Recall: 0.6776, F1: 0.6912
Testing Loss: 1.3669, Accuracy: 0.7802, Precision: 0.7239, Recall: 0.6925, F1: 0.7036
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3607, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 38/70
Train Loss: 0.0502, Accuracy: 0.9701, Precision: 0.9512, Recall: 0.9527, F1: 0.9520
Validation Loss: 1.4831, Accuracy: 0.7804, Precision: 0.7268, Recall: 0.6814, F1: 0.6933
Testing Loss: 1.3836, Accuracy: 0.7838, Precision: 0.7247, Recall: 0.6905, F1: 0.7012
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1739, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.9000, F1: 0.8728
Epoch 39/70
Train Loss: 0.0487, Accuracy: 0.9704, Precision: 0.9549, Recall: 0.9480, F1: 0.9513
Validation Loss: 1.5238, Accuracy: 0.7783, Precision: 0.7161, Recall: 0.6853, F1: 0.6925
Testing Loss: 1.4201, Accuracy: 0.7826, Precision: 0.7191, Recall: 0.6950, F1: 0.7001
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1797, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9328, F1: 0.9182
Epoch 40/70
Train Loss: 0.0502, Accuracy: 0.9694, Precision: 0.9531, Recall: 0.9482, F1: 0.9505
Validation Loss: 1.5761, Accuracy: 0.7740, Precision: 0.7271, Recall: 0.6889, F1: 0.7019
Testing Loss: 1.4726, Accuracy: 0.7850, Precision: 0.7409, Recall: 0.7108, F1: 0.7226
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 0, 2, 4, 0, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2460, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8356, F1: 0.8139
Epoch 41/70
Train Loss: 0.0496, Accuracy: 0.9692, Precision: 0.9497, Recall: 0.9525, F1: 0.9510
Validation Loss: 1.5896, Accuracy: 0.7655, Precision: 0.7046, Recall: 0.6763, F1: 0.6837
Testing Loss: 1.4988, Accuracy: 0.7729, Precision: 0.7149, Recall: 0.6865, F1: 0.6915
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2679, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8861, F1: 0.8629
Epoch 42/70
Train Loss: 0.0477, Accuracy: 0.9718, Precision: 0.9557, Recall: 0.9531, F1: 0.9544
Validation Loss: 1.6504, Accuracy: 0.7889, Precision: 0.7371, Recall: 0.6851, F1: 0.7002
Testing Loss: 1.5442, Accuracy: 0.7862, Precision: 0.7439, Recall: 0.6985, F1: 0.7149
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3248, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 43/70
Train Loss: 0.0518, Accuracy: 0.9692, Precision: 0.9517, Recall: 0.9493, F1: 0.9505
Validation Loss: 1.5713, Accuracy: 0.7783, Precision: 0.7096, Recall: 0.6849, F1: 0.6910
Testing Loss: 1.5210, Accuracy: 0.7826, Precision: 0.7143, Recall: 0.6953, F1: 0.6957
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2373, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 44/70
Train Loss: 0.0514, Accuracy: 0.9685, Precision: 0.9493, Recall: 0.9477, F1: 0.9485
Validation Loss: 1.6491, Accuracy: 0.7804, Precision: 0.7371, Recall: 0.6939, F1: 0.7086
Testing Loss: 1.5236, Accuracy: 0.7802, Precision: 0.7281, Recall: 0.7037, F1: 0.7134
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3356, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 45/70
Train Loss: 0.0490, Accuracy: 0.9711, Precision: 0.9518, Recall: 0.9549, F1: 0.9533
Validation Loss: 1.6279, Accuracy: 0.7697, Precision: 0.7213, Recall: 0.6832, F1: 0.6964
Testing Loss: 1.5159, Accuracy: 0.7826, Precision: 0.7274, Recall: 0.7026, F1: 0.7122
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 3, 2, 4, 3, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2290, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8461, F1: 0.8249
Epoch 46/70
Train Loss: 0.0499, Accuracy: 0.9673, Precision: 0.9481, Recall: 0.9470, F1: 0.9475
Validation Loss: 1.7087, Accuracy: 0.7825, Precision: 0.7240, Recall: 0.6955, F1: 0.7039
Testing Loss: 1.6787, Accuracy: 0.7838, Precision: 0.7238, Recall: 0.7080, F1: 0.7117
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1718, Accuracy: 0.9286, Precision: 0.9250, Recall: 0.9400, F1: 0.9186
Epoch 47/70
Train Loss: 0.0494, Accuracy: 0.9675, Precision: 0.9474, Recall: 0.9472, F1: 0.9473
Validation Loss: 1.9798, Accuracy: 0.7740, Precision: 0.7439, Recall: 0.6737, F1: 0.6964
Testing Loss: 1.8806, Accuracy: 0.7729, Precision: 0.7377, Recall: 0.6820, F1: 0.7024
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2819, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8150, F1: 0.7919
Epoch 48/70
Train Loss: 0.0946, Accuracy: 0.9578, Precision: 0.9369, Recall: 0.9371, F1: 0.9370
Validation Loss: 1.4728, Accuracy: 0.7569, Precision: 0.6674, Recall: 0.6818, F1: 0.6654
Testing Loss: 1.3784, Accuracy: 0.7428, Precision: 0.6612, Recall: 0.6769, F1: 0.6571
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 3, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2840, Accuracy: 0.9048, Precision: 0.8961, Recall: 0.8933, F1: 0.8838
Epoch 49/70
Train Loss: 0.1441, Accuracy: 0.9471, Precision: 0.9205, Recall: 0.9180, F1: 0.9192
Validation Loss: 1.0391, Accuracy: 0.7889, Precision: 0.7320, Recall: 0.6958, F1: 0.7086
Testing Loss: 1.0562, Accuracy: 0.7814, Precision: 0.7317, Recall: 0.6861, F1: 0.6982
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3936, Accuracy: 0.8333, Precision: 0.8833, Recall: 0.8461, F1: 0.8249
Epoch 50/70
Train Loss: 0.0647, Accuracy: 0.9677, Precision: 0.9503, Recall: 0.9471, F1: 0.9487
Validation Loss: 1.2157, Accuracy: 0.7953, Precision: 0.7452, Recall: 0.7327, F1: 0.7368
Testing Loss: 1.0771, Accuracy: 0.7826, Precision: 0.7220, Recall: 0.7330, F1: 0.7265
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 0, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2467, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8911, F1: 0.8657
Epoch 51/70
Train Loss: 0.0566, Accuracy: 0.9661, Precision: 0.9474, Recall: 0.9453, F1: 0.9463
Validation Loss: 1.2591, Accuracy: 0.7910, Precision: 0.7149, Recall: 0.7071, F1: 0.7082
Testing Loss: 1.1316, Accuracy: 0.7947, Precision: 0.7373, Recall: 0.7245, F1: 0.7243
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2841, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 52/70
Train Loss: 0.0506, Accuracy: 0.9663, Precision: 0.9474, Recall: 0.9422, F1: 0.9447
Validation Loss: 1.4092, Accuracy: 0.7974, Precision: 0.7536, Recall: 0.7124, F1: 0.7255
Testing Loss: 1.2333, Accuracy: 0.7971, Precision: 0.7484, Recall: 0.7285, F1: 0.7369
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2716, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8333, F1: 0.8106
Epoch 53/70
Train Loss: 0.0473, Accuracy: 0.9651, Precision: 0.9446, Recall: 0.9439, F1: 0.9443
Validation Loss: 1.4386, Accuracy: 0.7910, Precision: 0.7335, Recall: 0.6984, F1: 0.7103
Testing Loss: 1.2606, Accuracy: 0.7947, Precision: 0.7464, Recall: 0.7254, F1: 0.7311
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1925, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 54/70
Train Loss: 0.0488, Accuracy: 0.9675, Precision: 0.9475, Recall: 0.9470, F1: 0.9472
Validation Loss: 1.3302, Accuracy: 0.7889, Precision: 0.7337, Recall: 0.6945, F1: 0.7069
Testing Loss: 1.1863, Accuracy: 0.7947, Precision: 0.7455, Recall: 0.7117, F1: 0.7212
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3725, Accuracy: 0.7143, Precision: 0.8588, Recall: 0.7511, F1: 0.7338
Epoch 55/70
Train Loss: 0.0488, Accuracy: 0.9673, Precision: 0.9488, Recall: 0.9467, F1: 0.9477
Validation Loss: 1.4238, Accuracy: 0.7825, Precision: 0.7201, Recall: 0.6828, F1: 0.6932
Testing Loss: 1.2919, Accuracy: 0.7935, Precision: 0.7444, Recall: 0.7138, F1: 0.7210
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2431, Accuracy: 0.7619, Precision: 0.8667, Recall: 0.7911, F1: 0.7706
Epoch 56/70
Train Loss: 0.0465, Accuracy: 0.9689, Precision: 0.9478, Recall: 0.9491, F1: 0.9485
Validation Loss: 1.5926, Accuracy: 0.7783, Precision: 0.7234, Recall: 0.6792, F1: 0.6919
Testing Loss: 1.4332, Accuracy: 0.7826, Precision: 0.7334, Recall: 0.7002, F1: 0.7072
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3135, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 57/70
Train Loss: 0.0468, Accuracy: 0.9689, Precision: 0.9506, Recall: 0.9521, F1: 0.9513
Validation Loss: 1.5677, Accuracy: 0.7868, Precision: 0.7183, Recall: 0.6873, F1: 0.6958
Testing Loss: 1.4471, Accuracy: 0.7899, Precision: 0.7348, Recall: 0.7090, F1: 0.7122
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1102, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 58/70
Train Loss: 0.0495, Accuracy: 0.9680, Precision: 0.9469, Recall: 0.9517, F1: 0.9492
Validation Loss: 1.5691, Accuracy: 0.7804, Precision: 0.7283, Recall: 0.6863, F1: 0.7002
Testing Loss: 1.4372, Accuracy: 0.7862, Precision: 0.7330, Recall: 0.7090, F1: 0.7142
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3364, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 59/70
Train Loss: 0.0476, Accuracy: 0.9687, Precision: 0.9557, Recall: 0.9410, F1: 0.9477
Validation Loss: 1.6023, Accuracy: 0.7804, Precision: 0.7282, Recall: 0.6837, F1: 0.6981
Testing Loss: 1.4526, Accuracy: 0.7935, Precision: 0.7555, Recall: 0.7197, F1: 0.7324
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3180, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 60/70
Train Loss: 0.0457, Accuracy: 0.9687, Precision: 0.9482, Recall: 0.9532, F1: 0.9506
Validation Loss: 1.5896, Accuracy: 0.7846, Precision: 0.7318, Recall: 0.6925, F1: 0.7054
Testing Loss: 1.4575, Accuracy: 0.7935, Precision: 0.7521, Recall: 0.7350, F1: 0.7415
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 1, 4, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.1775, Accuracy: 0.9762, Precision: 0.9667, Recall: 0.9750, F1: 0.9685
Epoch 61/70
Train Loss: 0.0472, Accuracy: 0.9670, Precision: 0.9459, Recall: 0.9481, F1: 0.9470
Validation Loss: 1.6029, Accuracy: 0.7804, Precision: 0.7177, Recall: 0.6869, F1: 0.6963
Testing Loss: 1.5117, Accuracy: 0.7886, Precision: 0.7402, Recall: 0.7146, F1: 0.7213
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 2, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2518, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8400, F1: 0.8111
Epoch 62/70
Train Loss: 0.0507, Accuracy: 0.9696, Precision: 0.9502, Recall: 0.9517, F1: 0.9509
Validation Loss: 1.5450, Accuracy: 0.7825, Precision: 0.7070, Recall: 0.7045, F1: 0.7042
Testing Loss: 1.4220, Accuracy: 0.7838, Precision: 0.7235, Recall: 0.7157, F1: 0.7087
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2759, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 63/70
Train Loss: 0.0502, Accuracy: 0.9704, Precision: 0.9501, Recall: 0.9532, F1: 0.9516
Validation Loss: 1.5709, Accuracy: 0.7953, Precision: 0.7034, Recall: 0.7016, F1: 0.7005
Testing Loss: 1.4137, Accuracy: 0.7923, Precision: 0.7213, Recall: 0.7057, F1: 0.7019
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 0, 3, 0, 2, 4, 0, 3, 0, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4120, Accuracy: 0.6905, Precision: 0.8556, Recall: 0.7261, F1: 0.7165
Epoch 64/70
Train Loss: 0.0746, Accuracy: 0.9644, Precision: 0.9481, Recall: 0.9383, F1: 0.9429
Validation Loss: 1.1281, Accuracy: 0.7740, Precision: 0.7231, Recall: 0.7277, F1: 0.7163
Testing Loss: 1.1402, Accuracy: 0.7415, Precision: 0.7038, Recall: 0.7007, F1: 0.6897
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 5, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 5, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 2, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.4372, Accuracy: 0.7619, Precision: 0.7308, Recall: 0.6593, F1: 0.6515
Epoch 65/70
Train Loss: 0.0720, Accuracy: 0.9661, Precision: 0.9452, Recall: 0.9538, F1: 0.9492
Validation Loss: 1.2042, Accuracy: 0.7846, Precision: 0.7207, Recall: 0.7090, F1: 0.7123
Testing Loss: 1.1132, Accuracy: 0.7790, Precision: 0.7249, Recall: 0.7265, F1: 0.7245
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 2, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2358, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8311, F1: 0.8040
Epoch 66/70
Train Loss: 0.0541, Accuracy: 0.9668, Precision: 0.9465, Recall: 0.9479, F1: 0.9472
Validation Loss: 1.2472, Accuracy: 0.8017, Precision: 0.7142, Recall: 0.6922, F1: 0.6935
Testing Loss: 1.2210, Accuracy: 0.7790, Precision: 0.7094, Recall: 0.6833, F1: 0.6819
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2083, Accuracy: 0.8095, Precision: 0.8769, Recall: 0.8283, F1: 0.8078
Epoch 67/70
Train Loss: 0.0497, Accuracy: 0.9675, Precision: 0.9479, Recall: 0.9450, F1: 0.9464
Validation Loss: 1.3136, Accuracy: 0.7974, Precision: 0.7421, Recall: 0.7154, F1: 0.7266
Testing Loss: 1.3096, Accuracy: 0.7850, Precision: 0.7408, Recall: 0.7251, F1: 0.7307
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 0, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 4, 3, 1, 0, 2, 4, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2939, Accuracy: 0.7857, Precision: 0.8714, Recall: 0.8061, F1: 0.7848
Epoch 68/70
Train Loss: 0.0462, Accuracy: 0.9708, Precision: 0.9491, Recall: 0.9586, F1: 0.9537
Validation Loss: 1.4350, Accuracy: 0.7868, Precision: 0.7056, Recall: 0.6824, F1: 0.6892
Testing Loss: 1.3972, Accuracy: 0.7874, Precision: 0.7327, Recall: 0.6885, F1: 0.6985
LM Predictions:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 1, 2, 0, 4, 2, 0, 4, 3, 3, 0, 1, 0, 1, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.2856, Accuracy: 0.8810, Precision: 0.9000, Recall: 0.8950, F1: 0.8700
Epoch 69/70
Train Loss: 0.0491, Accuracy: 0.9727, Precision: 0.9590, Recall: 0.9535, F1: 0.9561
Validation Loss: 1.4038, Accuracy: 0.7910, Precision: 0.7397, Recall: 0.7328, F1: 0.7333
Testing Loss: 1.3832, Accuracy: 0.7790, Precision: 0.7277, Recall: 0.7216, F1: 0.7226
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 0, 3, 3, 2, 4, 3, 3, 3, 0, 3, 1, 0, 2, 3, 4, 2, 0, 4, 3, 3, 0, 0, 0, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3077, Accuracy: 0.7857, Precision: 0.8587, Recall: 0.8061, F1: 0.7811
Epoch 70/70
Train Loss: 0.0541, Accuracy: 0.9663, Precision: 0.9496, Recall: 0.9445, F1: 0.9470
Validation Loss: 1.3530, Accuracy: 0.7804, Precision: 0.7341, Recall: 0.7350, F1: 0.7277
Testing Loss: 1.2885, Accuracy: 0.7766, Precision: 0.7289, Recall: 0.7458, F1: 0.7323
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3114, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8661, F1: 0.8440
Label Memorization Analysis: 
LM Predictions:  [0, 1, 2, 0, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 0, 2, 0, 4, 2, 0, 4, 3, 3, 0, 0, 4, 0, 4, 3, 2, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 0.3114, Accuracy: 0.8571, Precision: 0.8909, Recall: 0.8661, F1: 0.8440

