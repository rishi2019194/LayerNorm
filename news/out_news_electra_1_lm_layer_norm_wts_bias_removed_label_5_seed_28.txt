Model: google/electra-base-discriminator, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
Layer: backbone.electra.embeddings.word_embeddings.weight, Size: torch.Size([30522, 768]), req grad: True
Layer: backbone.electra.embeddings.position_embeddings.weight, Size: torch.Size([512, 768]), req grad: True
Layer: backbone.electra.embeddings.token_type_embeddings.weight, Size: torch.Size([2, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.0.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.0.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.1.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.1.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.2.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.2.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.3.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.3.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.4.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.4.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.5.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.5.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.6.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.6.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.7.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.7.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.8.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.8.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.9.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.9.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.10.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.10.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.query.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.query.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.key.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.key.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.value.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.self.value.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.electra.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.electra.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.electra.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.electra.encoder.layer.11.output.dense.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.electra.encoder.layer.11.output.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.classifier.dense.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.classifier.dense.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.classifier.out_proj.weight, Size: torch.Size([6, 768]), req grad: True
Layer: backbone.classifier.out_proj.bias, Size: torch.Size([6]), req grad: True
Epoch 1/70
Train Loss: 1.6708, Accuracy: 0.2649, Precision: 0.1452, Recall: 0.1746, F1: 0.1494
Validation Loss: 1.7070, Accuracy: 0.2409, Precision: 0.1037, Recall: 0.1671, F1: 0.0773
Testing Loss: 1.6979, Accuracy: 0.2391, Precision: 0.2230, Recall: 0.1659, F1: 0.0710
LM Predictions:  [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7597, Accuracy: 0.1667, Precision: 0.0350, Recall: 0.1556, F1: 0.0571
Epoch 2/70
Train Loss: 1.6511, Accuracy: 0.2786, Precision: 0.1395, Recall: 0.1844, F1: 0.1571
Validation Loss: 1.5760, Accuracy: 0.3859, Precision: 0.2489, Recall: 0.2477, F1: 0.1819
Testing Loss: 1.6002, Accuracy: 0.3382, Precision: 0.1325, Recall: 0.2171, F1: 0.1530
LM Predictions:  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8582, Accuracy: 0.1190, Precision: 0.0556, Recall: 0.1822, F1: 0.0657
Epoch 3/70
Train Loss: 1.4181, Accuracy: 0.4207, Precision: 0.2591, Recall: 0.2795, F1: 0.2420
Validation Loss: 1.2291, Accuracy: 0.4925, Precision: 0.2473, Recall: 0.3384, F1: 0.2831
Testing Loss: 1.2480, Accuracy: 0.5109, Precision: 0.2545, Recall: 0.3529, F1: 0.2900
LM Predictions:  [0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 2, 0, 0, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1897, Accuracy: 0.2143, Precision: 0.1428, Recall: 0.2672, F1: 0.1606
Epoch 4/70
Train Loss: 1.1598, Accuracy: 0.5397, Precision: 0.3622, Recall: 0.4048, F1: 0.3781
Validation Loss: 0.9876, Accuracy: 0.6567, Precision: 0.4369, Recall: 0.5461, F1: 0.4752
Testing Loss: 0.9447, Accuracy: 0.6860, Precision: 0.4503, Recall: 0.5676, F1: 0.4941
LM Predictions:  [0, 0, 2, 4, 4, 0, 0, 4, 0, 2, 4, 0, 0, 0, 0, 0, 2, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 2, 0, 2, 2, 0, 0, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0626, Accuracy: 0.2143, Precision: 0.1558, Recall: 0.2750, F1: 0.1711
Epoch 5/70
Train Loss: 0.9965, Accuracy: 0.6521, Precision: 0.4533, Recall: 0.5015, F1: 0.4623
Validation Loss: 0.9661, Accuracy: 0.7186, Precision: 0.4942, Recall: 0.5765, F1: 0.5282
Testing Loss: 0.9071, Accuracy: 0.7271, Precision: 0.5003, Recall: 0.5866, F1: 0.5375
LM Predictions:  [0, 0, 2, 4, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 4, 4, 0, 0, 2, 0, 0, 2, 0, 0, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3892, Accuracy: 0.1667, Precision: 0.1176, Recall: 0.2300, F1: 0.1237
Epoch 6/70
Train Loss: 0.8893, Accuracy: 0.7057, Precision: 0.6072, Recall: 0.5677, F1: 0.5410
Validation Loss: 0.8504, Accuracy: 0.7292, Precision: 0.5686, Recall: 0.5965, F1: 0.5684
Testing Loss: 0.7623, Accuracy: 0.7512, Precision: 0.5778, Recall: 0.6261, F1: 0.5886
LM Predictions:  [0, 0, 2, 4, 4, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8361, Accuracy: 0.1667, Precision: 0.1357, Recall: 0.2300, F1: 0.1304
Epoch 7/70
Train Loss: 0.8572, Accuracy: 0.7273, Precision: 0.5770, Recall: 0.6011, F1: 0.5862
Validation Loss: 0.8408, Accuracy: 0.7612, Precision: 0.6365, Recall: 0.6210, F1: 0.6163
Testing Loss: 0.7768, Accuracy: 0.7754, Precision: 0.6423, Recall: 0.6430, F1: 0.6299
LM Predictions:  [0, 3, 0, 1, 4, 0, 0, 3, 0, 2, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9040, Accuracy: 0.1429, Precision: 0.2591, Recall: 0.2022, F1: 0.1094
Epoch 8/70
Train Loss: 0.7520, Accuracy: 0.7669, Precision: 0.6166, Recall: 0.6532, F1: 0.6338
Validation Loss: 0.7043, Accuracy: 0.7974, Precision: 0.6689, Recall: 0.6770, F1: 0.6697
Testing Loss: 0.6281, Accuracy: 0.8237, Precision: 0.6898, Recall: 0.7038, F1: 0.6946
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0030, Accuracy: 0.0952, Precision: 0.0242, Recall: 0.1600, F1: 0.0421
Epoch 9/70
Train Loss: 0.7201, Accuracy: 0.7871, Precision: 0.6352, Recall: 0.6685, F1: 0.6506
Validation Loss: 0.7078, Accuracy: 0.8038, Precision: 0.6715, Recall: 0.6836, F1: 0.6733
Testing Loss: 0.5868, Accuracy: 0.8285, Precision: 0.6962, Recall: 0.7136, F1: 0.6995
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 4, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0477, Accuracy: 0.1667, Precision: 0.1658, Recall: 0.2250, F1: 0.1324
Epoch 10/70
Train Loss: 0.6248, Accuracy: 0.8131, Precision: 0.6994, Recall: 0.6921, F1: 0.6803
Validation Loss: 0.6820, Accuracy: 0.8081, Precision: 0.6975, Recall: 0.6879, F1: 0.6872
Testing Loss: 0.5624, Accuracy: 0.8357, Precision: 0.7178, Recall: 0.7154, F1: 0.7115
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4476, Accuracy: 0.1667, Precision: 0.1970, Recall: 0.2450, F1: 0.1223
Epoch 11/70
Train Loss: 0.5906, Accuracy: 0.8221, Precision: 0.7395, Recall: 0.7092, F1: 0.7120
Validation Loss: 0.6620, Accuracy: 0.8166, Precision: 0.7714, Recall: 0.7043, F1: 0.7014
Testing Loss: 0.5679, Accuracy: 0.8370, Precision: 0.7026, Recall: 0.7278, F1: 0.7136
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4001, Accuracy: 0.1429, Precision: 0.0952, Recall: 0.2250, F1: 0.0864
Epoch 12/70
Train Loss: 0.5455, Accuracy: 0.8402, Precision: 0.7718, Recall: 0.7460, F1: 0.7530
Validation Loss: 0.6010, Accuracy: 0.8380, Precision: 0.8137, Recall: 0.7575, F1: 0.7759
Testing Loss: 0.4846, Accuracy: 0.8563, Precision: 0.8153, Recall: 0.7599, F1: 0.7751
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 5, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2027, Accuracy: 0.1429, Precision: 0.1619, Recall: 0.1708, F1: 0.0973
Epoch 13/70
Train Loss: 0.5216, Accuracy: 0.8376, Precision: 0.7634, Recall: 0.7440, F1: 0.7473
Validation Loss: 0.5943, Accuracy: 0.8337, Precision: 0.7854, Recall: 0.7474, F1: 0.7616
Testing Loss: 0.5292, Accuracy: 0.8406, Precision: 0.7613, Recall: 0.7424, F1: 0.7366
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 5, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2762, Accuracy: 0.1429, Precision: 0.1086, Recall: 0.1875, F1: 0.0772
Epoch 14/70
Train Loss: 0.5137, Accuracy: 0.8414, Precision: 0.7737, Recall: 0.7651, F1: 0.7671
Validation Loss: 0.6029, Accuracy: 0.8401, Precision: 0.8004, Recall: 0.7602, F1: 0.7726
Testing Loss: 0.5342, Accuracy: 0.8490, Precision: 0.7995, Recall: 0.7496, F1: 0.7578
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8882, Accuracy: 0.1190, Precision: 0.0556, Recall: 0.1542, F1: 0.0637
Epoch 15/70
Train Loss: 0.4957, Accuracy: 0.8506, Precision: 0.7850, Recall: 0.7793, F1: 0.7817
Validation Loss: 0.5739, Accuracy: 0.8273, Precision: 0.7734, Recall: 0.7265, F1: 0.7279
Testing Loss: 0.5109, Accuracy: 0.8454, Precision: 0.8035, Recall: 0.7373, F1: 0.7300
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1761, Accuracy: 0.1667, Precision: 0.1944, Recall: 0.2450, F1: 0.1195
Epoch 16/70
Train Loss: 0.5191, Accuracy: 0.8421, Precision: 0.7734, Recall: 0.7608, F1: 0.7649
Validation Loss: 0.5838, Accuracy: 0.8188, Precision: 0.7680, Recall: 0.7966, F1: 0.7767
Testing Loss: 0.4777, Accuracy: 0.8502, Precision: 0.8003, Recall: 0.8069, F1: 0.8018
LM Predictions:  [0, 3, 0, 5, 4, 5, 5, 5, 5, 4, 5, 0, 5, 5, 2, 0, 0, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 2, 5, 2, 5, 0, 5, 5, 5, 0, 5, 0, 5, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5122, Accuracy: 0.0714, Precision: 0.0571, Recall: 0.0875, F1: 0.0607
Epoch 17/70
Train Loss: 0.4650, Accuracy: 0.8565, Precision: 0.7989, Recall: 0.7957, F1: 0.7969
Validation Loss: 0.5803, Accuracy: 0.8294, Precision: 0.8151, Recall: 0.7384, F1: 0.7529
Testing Loss: 0.4855, Accuracy: 0.8575, Precision: 0.7984, Recall: 0.7421, F1: 0.7427
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 2, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2443, Accuracy: 0.1190, Precision: 0.0548, Recall: 0.1542, F1: 0.0627
Epoch 18/70
Train Loss: 0.4427, Accuracy: 0.8691, Precision: 0.8129, Recall: 0.8054, F1: 0.8085
Validation Loss: 0.5762, Accuracy: 0.8507, Precision: 0.8161, Recall: 0.8084, F1: 0.8120
Testing Loss: 0.4629, Accuracy: 0.8768, Precision: 0.8376, Recall: 0.8244, F1: 0.8303
LM Predictions:  [0, 3, 0, 5, 4, 5, 0, 5, 5, 4, 5, 0, 5, 5, 2, 0, 5, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 2, 0, 2, 5, 0, 5, 5, 0, 0, 5, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0435, Accuracy: 0.1190, Precision: 0.0704, Recall: 0.1542, F1: 0.0836
Epoch 19/70
Train Loss: 0.4178, Accuracy: 0.8710, Precision: 0.8139, Recall: 0.8147, F1: 0.8140
Validation Loss: 0.6073, Accuracy: 0.8507, Precision: 0.8115, Recall: 0.7867, F1: 0.7974
Testing Loss: 0.4671, Accuracy: 0.8780, Precision: 0.8394, Recall: 0.8090, F1: 0.8203
LM Predictions:  [0, 3, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0, 5, 0, 5, 0, 0, 2, 0, 5, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 4, 5, 0, 5, 5, 0, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4572, Accuracy: 0.1667, Precision: 0.3611, Recall: 0.1875, F1: 0.1374
Epoch 20/70
Train Loss: 0.4080, Accuracy: 0.8722, Precision: 0.8146, Recall: 0.8149, F1: 0.8147
Validation Loss: 0.6051, Accuracy: 0.8443, Precision: 0.8149, Recall: 0.8015, F1: 0.8063
Testing Loss: 0.4495, Accuracy: 0.8865, Precision: 0.8536, Recall: 0.8377, F1: 0.8448
LM Predictions:  [0, 3, 0, 5, 4, 5, 0, 5, 5, 5, 5, 0, 5, 5, 5, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 2, 0, 5, 5, 0, 5, 5, 5, 0, 5, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3655, Accuracy: 0.1190, Precision: 0.0926, Recall: 0.1542, F1: 0.0883
Epoch 21/70
Train Loss: 0.3902, Accuracy: 0.8788, Precision: 0.8243, Recall: 0.8273, F1: 0.8255
Validation Loss: 0.5741, Accuracy: 0.8529, Precision: 0.8232, Recall: 0.8181, F1: 0.8188
Testing Loss: 0.4643, Accuracy: 0.8768, Precision: 0.8449, Recall: 0.8317, F1: 0.8371
LM Predictions:  [0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 0, 5, 5, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 0, 5, 2, 0, 4, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3348, Accuracy: 0.1429, Precision: 0.2593, Recall: 0.1708, F1: 0.1186
Epoch 22/70
Train Loss: 0.4112, Accuracy: 0.8760, Precision: 0.8266, Recall: 0.8281, F1: 0.8267
Validation Loss: 0.6384, Accuracy: 0.8316, Precision: 0.8274, Recall: 0.7702, F1: 0.7928
Testing Loss: 0.5234, Accuracy: 0.8684, Precision: 0.8462, Recall: 0.8005, F1: 0.8179
LM Predictions:  [0, 3, 0, 5, 2, 5, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 2, 0, 2, 5, 0, 5, 5, 0, 0, 5, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2648, Accuracy: 0.1190, Precision: 0.0636, Recall: 0.1542, F1: 0.0750
Epoch 23/70
Train Loss: 0.4225, Accuracy: 0.8746, Precision: 0.8248, Recall: 0.8263, F1: 0.8249
Validation Loss: 0.6235, Accuracy: 0.8294, Precision: 0.7500, Recall: 0.7525, F1: 0.7429
Testing Loss: 0.5185, Accuracy: 0.8502, Precision: 0.7849, Recall: 0.7891, F1: 0.7802
LM Predictions:  [0, 3, 0, 5, 4, 5, 0, 4, 5, 4, 4, 0, 4, 5, 5, 0, 0, 2, 0, 4, 0, 5, 4, 0, 0, 0, 0, 4, 1, 0, 4, 4, 0, 4, 4, 5, 0, 5, 0, 3, 4, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8283, Accuracy: 0.1667, Precision: 0.0777, Recall: 0.1833, F1: 0.1041
Epoch 24/70
Train Loss: 0.3907, Accuracy: 0.8848, Precision: 0.8339, Recall: 0.8422, F1: 0.8372
Validation Loss: 0.5883, Accuracy: 0.8294, Precision: 0.8014, Recall: 0.7722, F1: 0.7830
Testing Loss: 0.4952, Accuracy: 0.8563, Precision: 0.8237, Recall: 0.7931, F1: 0.8048
LM Predictions:  [0, 0, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 3, 0, 5, 0, 5, 5, 0, 5, 0, 0, 3, 0, 0, 0, 0, 5, 2, 0, 5, 5, 0, 5, 5, 0, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1181, Accuracy: 0.1429, Precision: 0.2833, Recall: 0.1708, F1: 0.1181
Epoch 25/70
Train Loss: 0.3581, Accuracy: 0.8890, Precision: 0.8441, Recall: 0.8489, F1: 0.8458
Validation Loss: 0.6794, Accuracy: 0.8316, Precision: 0.8175, Recall: 0.7652, F1: 0.7835
Testing Loss: 0.5119, Accuracy: 0.8659, Precision: 0.8432, Recall: 0.7893, F1: 0.8097
LM Predictions:  [0, 3, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 2, 0, 1, 5, 0, 5, 5, 5, 0, 5, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3115, Accuracy: 0.1667, Precision: 0.1642, Recall: 0.1958, F1: 0.1439
Epoch 26/70
Train Loss: 0.3337, Accuracy: 0.8980, Precision: 0.8509, Recall: 0.8596, F1: 0.8546
Validation Loss: 0.6401, Accuracy: 0.8486, Precision: 0.8149, Recall: 0.8205, F1: 0.8129
Testing Loss: 0.4973, Accuracy: 0.8696, Precision: 0.8356, Recall: 0.8267, F1: 0.8279
LM Predictions:  [0, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 3, 5, 5, 0, 5, 2, 0, 5, 0, 5, 2, 0, 0, 0, 5, 5, 2, 0, 1, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2485, Accuracy: 0.1190, Precision: 0.1068, Recall: 0.1542, F1: 0.1044
Epoch 27/70
Train Loss: 0.3201, Accuracy: 0.9023, Precision: 0.8622, Recall: 0.8710, F1: 0.8653
Validation Loss: 0.6828, Accuracy: 0.8358, Precision: 0.7989, Recall: 0.8099, F1: 0.8027
Testing Loss: 0.5364, Accuracy: 0.8623, Precision: 0.8248, Recall: 0.8239, F1: 0.8231
LM Predictions:  [0, 3, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 3, 5, 5, 0, 5, 5, 0, 5, 0, 5, 3, 5, 0, 0, 0, 5, 2, 0, 1, 5, 5, 5, 5, 5, 0, 5, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1240, Accuracy: 0.1429, Precision: 0.2560, Recall: 0.1708, F1: 0.1310
Epoch 28/70
Train Loss: 0.3208, Accuracy: 0.9023, Precision: 0.8594, Recall: 0.8713, F1: 0.8640
Validation Loss: 0.6333, Accuracy: 0.8465, Precision: 0.8123, Recall: 0.8118, F1: 0.8119
Testing Loss: 0.5206, Accuracy: 0.8708, Precision: 0.8282, Recall: 0.8200, F1: 0.8229
LM Predictions:  [0, 0, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 5, 5, 0, 5, 0, 5, 2, 5, 0, 0, 0, 5, 2, 0, 1, 5, 2, 5, 5, 5, 0, 5, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9825, Accuracy: 0.1667, Precision: 0.1417, Recall: 0.1958, F1: 0.1404
Epoch 29/70
Train Loss: 0.3051, Accuracy: 0.9080, Precision: 0.8644, Recall: 0.8733, F1: 0.8678
Validation Loss: 0.6468, Accuracy: 0.8380, Precision: 0.8102, Recall: 0.7970, F1: 0.7994
Testing Loss: 0.5394, Accuracy: 0.8696, Precision: 0.8381, Recall: 0.8180, F1: 0.8265
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 5, 5, 0, 0, 0, 5, 2, 5, 0, 0, 0, 5, 2, 0, 1, 5, 0, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2218, Accuracy: 0.1667, Precision: 0.1667, Recall: 0.1958, F1: 0.1468
Epoch 30/70
Train Loss: 0.3010, Accuracy: 0.9092, Precision: 0.8649, Recall: 0.8783, F1: 0.8698
Validation Loss: 0.6353, Accuracy: 0.8380, Precision: 0.8131, Recall: 0.7918, F1: 0.8003
Testing Loss: 0.5445, Accuracy: 0.8647, Precision: 0.8321, Recall: 0.8161, F1: 0.8213
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 5, 0, 5, 5, 0, 1, 0, 5, 2, 5, 0, 0, 0, 5, 2, 0, 4, 4, 1, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8840, Accuracy: 0.1905, Precision: 0.2596, Recall: 0.2125, F1: 0.1852
Epoch 31/70
Train Loss: 0.2886, Accuracy: 0.9156, Precision: 0.8727, Recall: 0.8903, F1: 0.8802
Validation Loss: 0.7154, Accuracy: 0.8230, Precision: 0.7871, Recall: 0.7879, F1: 0.7838
Testing Loss: 0.5625, Accuracy: 0.8575, Precision: 0.8175, Recall: 0.8100, F1: 0.8122
LM Predictions:  [0, 3, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 3, 5, 5, 0, 5, 5, 0, 5, 0, 5, 3, 5, 0, 0, 0, 5, 2, 0, 1, 5, 3, 5, 5, 5, 0, 5, 5, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0152, Accuracy: 0.1905, Precision: 0.2889, Recall: 0.2083, F1: 0.1895
Epoch 32/70
Train Loss: 0.2931, Accuracy: 0.9137, Precision: 0.8711, Recall: 0.8953, F1: 0.8789
Validation Loss: 0.6672, Accuracy: 0.8443, Precision: 0.8166, Recall: 0.7796, F1: 0.7952
Testing Loss: 0.5485, Accuracy: 0.8587, Precision: 0.8285, Recall: 0.7816, F1: 0.7989
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 0, 5, 5, 0, 2, 0, 5, 0, 5, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 2, 0, 4, 5, 2, 5, 5, 0, 0, 5, 0, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1725, Accuracy: 0.1905, Precision: 0.3018, Recall: 0.2125, F1: 0.1628
Epoch 33/70
Train Loss: 0.2750, Accuracy: 0.9182, Precision: 0.8754, Recall: 0.8892, F1: 0.8804
Validation Loss: 0.6884, Accuracy: 0.8401, Precision: 0.8085, Recall: 0.8004, F1: 0.8032
Testing Loss: 0.5718, Accuracy: 0.8635, Precision: 0.8282, Recall: 0.8097, F1: 0.8173
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 5, 0, 5, 5, 0, 5, 0, 5, 2, 5, 0, 0, 0, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 5, 5, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9564, Accuracy: 0.1905, Precision: 0.2346, Recall: 0.2125, F1: 0.1788
Epoch 34/70
Train Loss: 0.2553, Accuracy: 0.9229, Precision: 0.8814, Recall: 0.9025, F1: 0.8895
Validation Loss: 0.6873, Accuracy: 0.8443, Precision: 0.8202, Recall: 0.7963, F1: 0.8057
Testing Loss: 0.5635, Accuracy: 0.8551, Precision: 0.8238, Recall: 0.8046, F1: 0.8127
LM Predictions:  [0, 3, 0, 5, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 0, 5, 0, 0, 0, 5, 2, 5, 0, 0, 0, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 5, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.9218, Accuracy: 0.1905, Precision: 0.3111, Recall: 0.2125, F1: 0.1739
Epoch 35/70
Train Loss: 0.2606, Accuracy: 0.9246, Precision: 0.8836, Recall: 0.9030, F1: 0.8909
Validation Loss: 0.7554, Accuracy: 0.8422, Precision: 0.8121, Recall: 0.8050, F1: 0.8063
Testing Loss: 0.6097, Accuracy: 0.8527, Precision: 0.8140, Recall: 0.8092, F1: 0.8091
LM Predictions:  [0, 5, 0, 5, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 5, 0, 5, 5, 0, 2, 5, 5, 2, 5, 0, 2, 5, 5, 2, 0, 4, 4, 2, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8757, Accuracy: 0.2381, Precision: 0.2804, Recall: 0.2500, F1: 0.2354
Epoch 36/70
Train Loss: 0.2732, Accuracy: 0.9163, Precision: 0.8753, Recall: 0.8962, F1: 0.8825
Validation Loss: 0.7611, Accuracy: 0.8358, Precision: 0.8075, Recall: 0.7907, F1: 0.7947
Testing Loss: 0.6305, Accuracy: 0.8611, Precision: 0.8239, Recall: 0.8132, F1: 0.8177
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 5, 0, 5, 5, 0, 2, 5, 5, 3, 5, 0, 0, 5, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 5, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8498, Accuracy: 0.2143, Precision: 0.4939, Recall: 0.2292, F1: 0.2209
Epoch 37/70
Train Loss: 0.2648, Accuracy: 0.9191, Precision: 0.8766, Recall: 0.8903, F1: 0.8808
Validation Loss: 0.6689, Accuracy: 0.8422, Precision: 0.8184, Recall: 0.7829, F1: 0.7973
Testing Loss: 0.5677, Accuracy: 0.8647, Precision: 0.8319, Recall: 0.8048, F1: 0.8160
LM Predictions:  [0, 5, 0, 0, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 5, 5, 0, 2, 0, 0, 3, 5, 0, 0, 0, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 5, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.5515, Accuracy: 0.2143, Precision: 0.3944, Recall: 0.2292, F1: 0.2017
Epoch 38/70
Train Loss: 0.2466, Accuracy: 0.9286, Precision: 0.8894, Recall: 0.9067, F1: 0.8956
Validation Loss: 0.6688, Accuracy: 0.8422, Precision: 0.8029, Recall: 0.8031, F1: 0.8024
Testing Loss: 0.5507, Accuracy: 0.8635, Precision: 0.8235, Recall: 0.8185, F1: 0.8200
LM Predictions:  [0, 2, 2, 5, 5, 5, 0, 5, 5, 5, 5, 0, 2, 5, 3, 0, 2, 5, 0, 2, 5, 5, 3, 5, 0, 2, 5, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 5, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0755, Accuracy: 0.3095, Precision: 0.4722, Recall: 0.3083, F1: 0.3018
Epoch 39/70
Train Loss: 0.2322, Accuracy: 0.9305, Precision: 0.8885, Recall: 0.9082, F1: 0.8962
Validation Loss: 0.7223, Accuracy: 0.8358, Precision: 0.7945, Recall: 0.8026, F1: 0.7959
Testing Loss: 0.5786, Accuracy: 0.8599, Precision: 0.8225, Recall: 0.8275, F1: 0.8225
LM Predictions:  [0, 5, 5, 5, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 0, 5, 5, 2, 0, 4, 5, 2, 5, 5, 5, 3, 5, 5, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6413, Accuracy: 0.2619, Precision: 0.5083, Recall: 0.2625, F1: 0.3198
Epoch 40/70
Train Loss: 0.2266, Accuracy: 0.9348, Precision: 0.8963, Recall: 0.9133, F1: 0.9029
Validation Loss: 0.8275, Accuracy: 0.8507, Precision: 0.8287, Recall: 0.7945, F1: 0.8084
Testing Loss: 0.6957, Accuracy: 0.8659, Precision: 0.8298, Recall: 0.8030, F1: 0.8148
LM Predictions:  [0, 2, 2, 5, 1, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 2, 5, 0, 3, 5, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 3, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3086, Accuracy: 0.4048, Precision: 0.6657, Recall: 0.3769, F1: 0.3980
Epoch 41/70
Train Loss: 0.2295, Accuracy: 0.9341, Precision: 0.8955, Recall: 0.9140, F1: 0.9029
Validation Loss: 0.6586, Accuracy: 0.8550, Precision: 0.8257, Recall: 0.8204, F1: 0.8204
Testing Loss: 0.5752, Accuracy: 0.8575, Precision: 0.8238, Recall: 0.8177, F1: 0.8183
LM Predictions:  [0, 1, 2, 5, 2, 5, 0, 4, 5, 5, 5, 0, 2, 5, 5, 5, 2, 5, 0, 3, 5, 5, 3, 5, 0, 2, 5, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 3, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.3545, Accuracy: 0.3810, Precision: 0.7202, Recall: 0.3602, F1: 0.4019
Epoch 42/70
Train Loss: 0.2211, Accuracy: 0.9329, Precision: 0.8928, Recall: 0.9101, F1: 0.8992
Validation Loss: 0.6707, Accuracy: 0.8465, Precision: 0.8040, Recall: 0.8171, F1: 0.8078
Testing Loss: 0.5602, Accuracy: 0.8551, Precision: 0.8186, Recall: 0.8225, F1: 0.8180
LM Predictions:  [0, 1, 1, 5, 1, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 5, 2, 5, 0, 3, 5, 5, 3, 5, 0, 2, 5, 5, 2, 0, 4, 5, 1, 5, 5, 5, 0, 5, 3, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1707, Accuracy: 0.4048, Precision: 0.6786, Recall: 0.3745, F1: 0.4414
Epoch 43/70
Train Loss: 0.1997, Accuracy: 0.9410, Precision: 0.9019, Recall: 0.9213, F1: 0.9093
Validation Loss: 0.7438, Accuracy: 0.8358, Precision: 0.8150, Recall: 0.7966, F1: 0.8006
Testing Loss: 0.6153, Accuracy: 0.8563, Precision: 0.8217, Recall: 0.8111, F1: 0.8133
LM Predictions:  [0, 1, 2, 5, 1, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 5, 2, 5, 5, 3, 5, 5, 2, 5, 0, 2, 5, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 2, 1, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.2583, Accuracy: 0.3810, Precision: 0.6667, Recall: 0.3620, F1: 0.4055
Epoch 44/70
Train Loss: 0.2124, Accuracy: 0.9348, Precision: 0.8939, Recall: 0.9119, F1: 0.9007
Validation Loss: 0.7300, Accuracy: 0.8465, Precision: 0.8060, Recall: 0.7982, F1: 0.8008
Testing Loss: 0.6329, Accuracy: 0.8635, Precision: 0.8182, Recall: 0.8204, F1: 0.8183
LM Predictions:  [0, 5, 2, 5, 5, 5, 0, 4, 5, 4, 5, 0, 2, 5, 3, 0, 5, 5, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 4, 5, 5, 5, 0, 5, 3, 5, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1520, Accuracy: 0.3571, Precision: 0.4667, Recall: 0.3375, F1: 0.3568
Epoch 45/70
Train Loss: 0.2010, Accuracy: 0.9398, Precision: 0.9002, Recall: 0.9209, F1: 0.9076
Validation Loss: 0.7162, Accuracy: 0.8571, Precision: 0.8422, Recall: 0.7838, F1: 0.7999
Testing Loss: 0.6167, Accuracy: 0.8623, Precision: 0.8256, Recall: 0.7881, F1: 0.7981
LM Predictions:  [0, 2, 2, 0, 2, 5, 0, 4, 0, 5, 0, 0, 2, 0, 3, 0, 5, 5, 0, 3, 0, 0, 3, 0, 0, 2, 0, 0, 2, 0, 4, 5, 2, 5, 0, 0, 0, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0018, Accuracy: 0.3810, Precision: 0.4240, Recall: 0.3583, F1: 0.3197
Epoch 46/70
Train Loss: 0.1975, Accuracy: 0.9398, Precision: 0.9018, Recall: 0.9197, F1: 0.9086
Validation Loss: 0.7834, Accuracy: 0.8507, Precision: 0.8071, Recall: 0.8077, F1: 0.8067
Testing Loss: 0.6994, Accuracy: 0.8587, Precision: 0.8116, Recall: 0.8036, F1: 0.8051
LM Predictions:  [0, 1, 2, 5, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 5, 2, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 4, 5, 5, 5, 0, 5, 3, 1, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0939, Accuracy: 0.3810, Precision: 0.5222, Recall: 0.3560, F1: 0.3779
Epoch 47/70
Train Loss: 0.1979, Accuracy: 0.9412, Precision: 0.9042, Recall: 0.9241, F1: 0.9116
Validation Loss: 0.7349, Accuracy: 0.8401, Precision: 0.8040, Recall: 0.7779, F1: 0.7882
Testing Loss: 0.6108, Accuracy: 0.8587, Precision: 0.8136, Recall: 0.7920, F1: 0.8003
LM Predictions:  [0, 5, 2, 0, 5, 3, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 5, 5, 0, 3, 0, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 4, 5, 0, 0, 0, 5, 3, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8837, Accuracy: 0.3571, Precision: 0.4587, Recall: 0.3375, F1: 0.3386
Epoch 48/70
Train Loss: 0.1912, Accuracy: 0.9464, Precision: 0.9113, Recall: 0.9264, F1: 0.9173
Validation Loss: 0.7893, Accuracy: 0.8337, Precision: 0.8008, Recall: 0.7889, F1: 0.7939
Testing Loss: 0.6777, Accuracy: 0.8563, Precision: 0.8111, Recall: 0.8057, F1: 0.8071
LM Predictions:  [0, 2, 2, 5, 2, 3, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 2, 2, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 4, 5, 5, 5, 0, 5, 3, 5, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0818, Accuracy: 0.3810, Precision: 0.3944, Recall: 0.3583, F1: 0.3430
Epoch 49/70
Train Loss: 0.1946, Accuracy: 0.9433, Precision: 0.9070, Recall: 0.9343, F1: 0.9164
Validation Loss: 0.8328, Accuracy: 0.8443, Precision: 0.7951, Recall: 0.7951, F1: 0.7944
Testing Loss: 0.7140, Accuracy: 0.8575, Precision: 0.8108, Recall: 0.8074, F1: 0.8088
LM Predictions:  [0, 1, 2, 5, 2, 3, 0, 4, 5, 4, 5, 0, 2, 5, 3, 0, 1, 2, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 4, 5, 5, 5, 0, 5, 3, 1, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0904, Accuracy: 0.3810, Precision: 0.4302, Recall: 0.3560, F1: 0.3583
Epoch 50/70
Train Loss: 0.1860, Accuracy: 0.9483, Precision: 0.9134, Recall: 0.9384, F1: 0.9228
Validation Loss: 0.7513, Accuracy: 0.8380, Precision: 0.8034, Recall: 0.7836, F1: 0.7924
Testing Loss: 0.5853, Accuracy: 0.8551, Precision: 0.8123, Recall: 0.7972, F1: 0.8032
LM Predictions:  [0, 1, 2, 0, 5, 3, 0, 4, 5, 5, 5, 0, 2, 4, 3, 0, 2, 2, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 2, 5, 5, 5, 0, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8957, Accuracy: 0.4524, Precision: 0.5902, Recall: 0.4144, F1: 0.4095
Epoch 51/70
Train Loss: 0.1735, Accuracy: 0.9521, Precision: 0.9189, Recall: 0.9409, F1: 0.9274
Validation Loss: 0.8185, Accuracy: 0.8380, Precision: 0.7991, Recall: 0.7911, F1: 0.7942
Testing Loss: 0.6591, Accuracy: 0.8563, Precision: 0.8111, Recall: 0.7973, F1: 0.8030
LM Predictions:  [0, 5, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 2, 5, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 2, 5, 5, 5, 0, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0906, Accuracy: 0.4048, Precision: 0.4842, Recall: 0.3792, F1: 0.3757
Epoch 52/70
Train Loss: 0.1787, Accuracy: 0.9447, Precision: 0.9065, Recall: 0.9284, F1: 0.9152
Validation Loss: 0.8103, Accuracy: 0.8358, Precision: 0.7968, Recall: 0.7993, F1: 0.7930
Testing Loss: 0.6844, Accuracy: 0.8599, Precision: 0.8184, Recall: 0.8175, F1: 0.8160
LM Predictions:  [0, 1, 2, 5, 5, 3, 0, 4, 5, 5, 5, 0, 2, 5, 3, 5, 1, 5, 0, 3, 5, 5, 3, 5, 5, 2, 5, 5, 2, 0, 4, 4, 2, 5, 5, 5, 5, 5, 3, 1, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1933, Accuracy: 0.3810, Precision: 0.5444, Recall: 0.3560, F1: 0.4167
Epoch 53/70
Train Loss: 0.1782, Accuracy: 0.9462, Precision: 0.9087, Recall: 0.9331, F1: 0.9179
Validation Loss: 0.8337, Accuracy: 0.8337, Precision: 0.7983, Recall: 0.7926, F1: 0.7941
Testing Loss: 0.7270, Accuracy: 0.8575, Precision: 0.8204, Recall: 0.8085, F1: 0.8127
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 2, 0, 5, 2, 0, 4, 4, 4, 5, 5, 5, 5, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0992, Accuracy: 0.4048, Precision: 0.6778, Recall: 0.3769, F1: 0.4371
Epoch 54/70
Train Loss: 0.1738, Accuracy: 0.9500, Precision: 0.9159, Recall: 0.9372, F1: 0.9241
Validation Loss: 0.7963, Accuracy: 0.8337, Precision: 0.7893, Recall: 0.7861, F1: 0.7853
Testing Loss: 0.6856, Accuracy: 0.8599, Precision: 0.8099, Recall: 0.8104, F1: 0.8101
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 3, 1, 3, 0, 3, 3, 5, 3, 5, 0, 2, 5, 5, 2, 0, 4, 4, 2, 5, 5, 5, 0, 5, 3, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.7739, Accuracy: 0.4524, Precision: 0.5694, Recall: 0.4079, F1: 0.4396
Epoch 55/70
Train Loss: 0.1914, Accuracy: 0.9429, Precision: 0.9044, Recall: 0.9247, F1: 0.9120
Validation Loss: 0.8159, Accuracy: 0.8401, Precision: 0.7940, Recall: 0.7932, F1: 0.7934
Testing Loss: 0.7031, Accuracy: 0.8623, Precision: 0.8137, Recall: 0.8073, F1: 0.8096
LM Predictions:  [0, 1, 2, 0, 2, 4, 0, 4, 5, 5, 5, 0, 2, 5, 3, 3, 1, 4, 0, 3, 3, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 2, 5, 0, 5, 0, 5, 3, 4, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8732, Accuracy: 0.4524, Precision: 0.5297, Recall: 0.4060, F1: 0.4164
Epoch 56/70
Train Loss: 0.1709, Accuracy: 0.9507, Precision: 0.9166, Recall: 0.9374, F1: 0.9247
Validation Loss: 0.8425, Accuracy: 0.8358, Precision: 0.7883, Recall: 0.7821, F1: 0.7845
Testing Loss: 0.6991, Accuracy: 0.8551, Precision: 0.8099, Recall: 0.8060, F1: 0.8071
LM Predictions:  [0, 1, 2, 0, 4, 3, 0, 4, 5, 5, 5, 0, 2, 5, 3, 3, 5, 5, 0, 3, 3, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 2, 5, 5, 5, 0, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6981, Accuracy: 0.4524, Precision: 0.6302, Recall: 0.4102, F1: 0.4245
Epoch 57/70
Train Loss: 0.1811, Accuracy: 0.9469, Precision: 0.9132, Recall: 0.9351, F1: 0.9217
Validation Loss: 0.8363, Accuracy: 0.8337, Precision: 0.7944, Recall: 0.7723, F1: 0.7803
Testing Loss: 0.7221, Accuracy: 0.8551, Precision: 0.8101, Recall: 0.7986, F1: 0.8037
LM Predictions:  [0, 1, 0, 0, 2, 3, 0, 4, 5, 5, 5, 0, 2, 5, 3, 3, 2, 5, 0, 3, 3, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 3, 5, 5, 5, 0, 5, 3, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9020, Accuracy: 0.4524, Precision: 0.6685, Recall: 0.4060, F1: 0.4196
Epoch 58/70
Train Loss: 0.1732, Accuracy: 0.9481, Precision: 0.9116, Recall: 0.9335, F1: 0.9203
Validation Loss: 0.7706, Accuracy: 0.8358, Precision: 0.7863, Recall: 0.7801, F1: 0.7828
Testing Loss: 0.6118, Accuracy: 0.8527, Precision: 0.8044, Recall: 0.8007, F1: 0.8016
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 4, 5, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 3, 4, 5, 4, 0, 5, 3, 3, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6353, Accuracy: 0.5476, Precision: 0.6458, Recall: 0.4769, F1: 0.4888
Epoch 59/70
Train Loss: 0.1625, Accuracy: 0.9504, Precision: 0.9172, Recall: 0.9333, F1: 0.9236
Validation Loss: 0.8380, Accuracy: 0.8401, Precision: 0.7868, Recall: 0.7842, F1: 0.7851
Testing Loss: 0.6948, Accuracy: 0.8527, Precision: 0.7995, Recall: 0.7926, F1: 0.7952
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 4, 3, 0, 2, 5, 0, 3, 3, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 3, 5, 5, 5, 0, 5, 3, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9115, Accuracy: 0.4762, Precision: 0.6618, Recall: 0.4269, F1: 0.4486
Epoch 60/70
Train Loss: 0.1645, Accuracy: 0.9500, Precision: 0.9123, Recall: 0.9338, F1: 0.9209
Validation Loss: 0.8376, Accuracy: 0.8273, Precision: 0.7820, Recall: 0.7746, F1: 0.7769
Testing Loss: 0.7255, Accuracy: 0.8599, Precision: 0.8142, Recall: 0.8065, F1: 0.8100
LM Predictions:  [0, 1, 2, 0, 2, 5, 0, 4, 5, 4, 5, 0, 2, 4, 3, 0, 2, 5, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 2, 5, 0, 5, 5, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0906, Accuracy: 0.4524, Precision: 0.6069, Recall: 0.4144, F1: 0.4117
Epoch 61/70
Train Loss: 0.1748, Accuracy: 0.9516, Precision: 0.9193, Recall: 0.9388, F1: 0.9279
Validation Loss: 0.8443, Accuracy: 0.8188, Precision: 0.7839, Recall: 0.7743, F1: 0.7764
Testing Loss: 0.7128, Accuracy: 0.8587, Precision: 0.8212, Recall: 0.8169, F1: 0.8182
LM Predictions:  [0, 1, 2, 0, 1, 5, 0, 4, 5, 5, 5, 0, 2, 4, 3, 3, 2, 5, 5, 3, 3, 5, 3, 5, 0, 2, 5, 5, 2, 0, 4, 4, 2, 5, 5, 5, 5, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9387, Accuracy: 0.5238, Precision: 0.7153, Recall: 0.4662, F1: 0.5241
Epoch 62/70
Train Loss: 0.1690, Accuracy: 0.9485, Precision: 0.9155, Recall: 0.9302, F1: 0.9220
Validation Loss: 0.8461, Accuracy: 0.8145, Precision: 0.7258, Recall: 0.7229, F1: 0.7206
Testing Loss: 0.7698, Accuracy: 0.8406, Precision: 0.7944, Recall: 0.7652, F1: 0.7700
LM Predictions:  [0, 1, 2, 0, 2, 5, 0, 4, 5, 4, 1, 0, 2, 4, 3, 3, 2, 4, 0, 3, 3, 5, 3, 1, 0, 2, 0, 5, 2, 0, 4, 4, 3, 4, 2, 5, 0, 1, 3, 3, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8014, Accuracy: 0.5476, Precision: 0.5116, Recall: 0.4787, F1: 0.4752
Epoch 63/70
Train Loss: 0.1666, Accuracy: 0.9490, Precision: 0.9147, Recall: 0.9309, F1: 0.9215
Validation Loss: 0.8030, Accuracy: 0.8401, Precision: 0.8094, Recall: 0.7840, F1: 0.7945
Testing Loss: 0.7062, Accuracy: 0.8575, Precision: 0.8186, Recall: 0.8042, F1: 0.8101
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 5, 3, 0, 2, 5, 0, 3, 0, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 3, 5, 5, 0, 0, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0193, Accuracy: 0.4524, Precision: 0.7179, Recall: 0.4144, F1: 0.4296
Epoch 64/70
Train Loss: 0.1795, Accuracy: 0.9464, Precision: 0.9110, Recall: 0.9302, F1: 0.9191
Validation Loss: 0.8941, Accuracy: 0.7996, Precision: 0.7824, Recall: 0.7421, F1: 0.7555
Testing Loss: 0.7442, Accuracy: 0.8273, Precision: 0.8059, Recall: 0.7719, F1: 0.7831
LM Predictions:  [0, 1, 0, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 4, 0, 0, 1, 5, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 5, 0, 5, 0, 0, 5, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1587, Accuracy: 0.3810, Precision: 0.6278, Recall: 0.3560, F1: 0.3790
Epoch 65/70
Train Loss: 0.1777, Accuracy: 0.9464, Precision: 0.9131, Recall: 0.9311, F1: 0.9209
Validation Loss: 0.8738, Accuracy: 0.8252, Precision: 0.7823, Recall: 0.7733, F1: 0.7769
Testing Loss: 0.7230, Accuracy: 0.8551, Precision: 0.8139, Recall: 0.8046, F1: 0.8082
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 4, 5, 2, 1, 5, 5, 3, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8902, Accuracy: 0.4762, Precision: 0.5503, Recall: 0.4269, F1: 0.4464
Epoch 66/70
Train Loss: 0.1772, Accuracy: 0.9493, Precision: 0.9161, Recall: 0.9388, F1: 0.9255
Validation Loss: 0.8632, Accuracy: 0.8188, Precision: 0.7762, Recall: 0.7623, F1: 0.7677
Testing Loss: 0.7084, Accuracy: 0.8454, Precision: 0.7999, Recall: 0.7866, F1: 0.7914
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 0, 5, 0, 2, 4, 3, 3, 2, 0, 0, 3, 0, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 0, 3, 5, 2, 5, 0, 5, 3, 2, 0, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8597, Accuracy: 0.5238, Precision: 0.7014, Recall: 0.4810, F1: 0.4644
Epoch 67/70
Train Loss: 0.1634, Accuracy: 0.9500, Precision: 0.9166, Recall: 0.9374, F1: 0.9249
Validation Loss: 0.9008, Accuracy: 0.8401, Precision: 0.8067, Recall: 0.7753, F1: 0.7889
Testing Loss: 0.7773, Accuracy: 0.8514, Precision: 0.8169, Recall: 0.7856, F1: 0.7988
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 3, 5, 2, 0, 0, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.0936, Accuracy: 0.5000, Precision: 0.6416, Recall: 0.4477, F1: 0.4477
Epoch 68/70
Train Loss: 0.1485, Accuracy: 0.9545, Precision: 0.9200, Recall: 0.9378, F1: 0.9275
Validation Loss: 0.8070, Accuracy: 0.8294, Precision: 0.7773, Recall: 0.7778, F1: 0.7766
Testing Loss: 0.7002, Accuracy: 0.8514, Precision: 0.8078, Recall: 0.8058, F1: 0.8048
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 5, 5, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 5, 3, 5, 0, 2, 0, 5, 2, 0, 4, 4, 3, 5, 2, 5, 5, 5, 3, 2, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8629, Accuracy: 0.5238, Precision: 0.6866, Recall: 0.4644, F1: 0.4883
Epoch 69/70
Train Loss: 0.1435, Accuracy: 0.9578, Precision: 0.9253, Recall: 0.9463, F1: 0.9341
Validation Loss: 0.8150, Accuracy: 0.8316, Precision: 0.7839, Recall: 0.7651, F1: 0.7731
Testing Loss: 0.7157, Accuracy: 0.8539, Precision: 0.8136, Recall: 0.7893, F1: 0.7977
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 4, 5, 0, 2, 4, 3, 0, 2, 4, 0, 3, 0, 0, 3, 5, 0, 2, 0, 4, 2, 0, 4, 4, 3, 4, 2, 0, 0, 5, 3, 2, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6786, Accuracy: 0.5238, Precision: 0.6230, Recall: 0.4644, F1: 0.4521
Epoch 70/70
Train Loss: 0.1443, Accuracy: 0.9540, Precision: 0.9225, Recall: 0.9364, F1: 0.9282
Validation Loss: 0.8599, Accuracy: 0.8380, Precision: 0.7902, Recall: 0.7946, F1: 0.7911
Testing Loss: 0.7198, Accuracy: 0.8563, Precision: 0.8109, Recall: 0.8154, F1: 0.8116
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 4, 5, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 5, 3, 5, 0, 2, 0, 4, 2, 0, 4, 4, 3, 4, 2, 5, 5, 5, 3, 3, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6828, Accuracy: 0.5238, Precision: 0.6190, Recall: 0.4602, F1: 0.4673
Label Memorization Analysis: 
LM Predictions:  [0, 1, 2, 0, 5, 5, 0, 4, 5, 4, 5, 0, 2, 4, 3, 3, 2, 4, 0, 3, 0, 5, 3, 5, 0, 2, 0, 4, 2, 0, 4, 4, 3, 4, 2, 5, 5, 5, 3, 3, 4, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.6828, Accuracy: 0.5238, Precision: 0.6190, Recall: 0.4602, F1: 0.4673

