Model: Qwen/Qwen2-0.5B-Instruct, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 1: 1011
  Label 0: 1141
  Label 2: 966
  Label 4: 344
  Label 3: 495
  Label 5: 260
Label counts for Validation:
  Label 2: 107
  Label 0: 127
  Label 1: 113
  Label 5: 29
  Label 4: 38
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 1: 1025
  Label 0: 1150
  Label 2: 972
  Label 4: 351
  Label 3: 501
  Label 5: 218
Layer: backbone.model.embed_tokens.weight, Size: torch.Size([151936, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.0.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.0.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.0.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.1.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.1.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.1.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.2.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.2.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.2.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.3.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.3.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.3.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.4.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.4.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.4.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.5.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.5.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.5.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.6.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.6.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.6.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.7.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.7.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.7.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.8.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.8.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.8.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.9.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.9.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.9.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.10.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.10.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.10.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.11.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.11.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.11.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.12.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.12.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.12.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.13.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.13.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.13.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.14.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.14.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.14.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.15.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.15.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.15.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.16.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.16.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.16.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.17.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.17.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.17.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.18.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.18.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.18.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.19.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.19.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.19.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.20.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.20.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.20.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.21.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.21.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.21.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.22.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.22.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.22.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.q_proj.bias, Size: torch.Size([896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.k_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.weight, Size: torch.Size([128, 896]), req grad: True
Layer: backbone.model.layers.23.self_attn.v_proj.bias, Size: torch.Size([128]), req grad: True
Layer: backbone.model.layers.23.self_attn.o_proj.weight, Size: torch.Size([896, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.gate_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.up_proj.weight, Size: torch.Size([4864, 896]), req grad: True
Layer: backbone.model.layers.23.mlp.down_proj.weight, Size: torch.Size([896, 4864]), req grad: True
Layer: backbone.model.norm.weight, Size: torch.Size([896]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 896]), req grad: True
Epoch 1/70
Train Loss: 1.6081, Accuracy: 0.4940, Precision: 0.4065, Recall: 0.3870, F1: 0.3893
Validation Loss: 0.9605, Accuracy: 0.6631, Precision: 0.6665, Recall: 0.5708, F1: 0.5746
Testing Loss: 0.9454, Accuracy: 0.6715, Precision: 0.6406, Recall: 0.5673, F1: 0.5672
LM Predictions:  [2, 2, 1, 2, 0, 1, 4, 2, 2, 0, 2, 2, 3, 1, 0, 2, 4, 0, 0, 5, 0, 2, 3, 4, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 1.2821, Accuracy: 0.5714, Precision: 0.6047, Recall: 0.4881, F1: 0.4966
Epoch 2/70
Train Loss: 0.5392, Accuracy: 0.8281, Precision: 0.7747, Recall: 0.7531, F1: 0.7617
Validation Loss: 1.0725, Accuracy: 0.6652, Precision: 0.6315, Recall: 0.5783, F1: 0.5760
Testing Loss: 1.0018, Accuracy: 0.6932, Precision: 0.6595, Recall: 0.6052, F1: 0.5962
LM Predictions:  [2, 2, 2, 5, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 0, 3, 4, 0, 0, 1, 4, 0, 0, 0, 4, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 1.1457, Accuracy: 0.6905, Precision: 0.6845, Recall: 0.5635, F1: 0.5709
Epoch 3/70
Train Loss: 0.2310, Accuracy: 0.9303, Precision: 0.8948, Recall: 0.8850, F1: 0.8896
Validation Loss: 1.3416, Accuracy: 0.7100, Precision: 0.6714, Recall: 0.6352, F1: 0.6458
Testing Loss: 1.2412, Accuracy: 0.7331, Precision: 0.7172, Recall: 0.6489, F1: 0.6629
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 5, 3, 1, 5, 0, 4, 5, 5, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 5, 5, 4, 5, 5, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.8195, Accuracy: 0.7857, Precision: 0.8148, Recall: 0.6204, F1: 0.6925
Epoch 4/70
Train Loss: 0.1502, Accuracy: 0.9533, Precision: 0.9236, Recall: 0.9227, F1: 0.9231
Validation Loss: 1.2571, Accuracy: 0.7079, Precision: 0.6307, Recall: 0.5805, F1: 0.5867
Testing Loss: 1.1711, Accuracy: 0.7258, Precision: 0.6853, Recall: 0.6065, F1: 0.6214
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.5136, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.7952, F1: 0.8184
Epoch 5/70
Train Loss: 0.1016, Accuracy: 0.9632, Precision: 0.9387, Recall: 0.9361, F1: 0.9374
Validation Loss: 1.9843, Accuracy: 0.7079, Precision: 0.6632, Recall: 0.6417, F1: 0.6431
Testing Loss: 1.7090, Accuracy: 0.7403, Precision: 0.6998, Recall: 0.6559, F1: 0.6675
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 5, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 5, 1, 4, 0, 5, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4035, Accuracy: 0.8571, Precision: 0.7917, Recall: 0.6944, F1: 0.7276
Epoch 6/70
Train Loss: 0.0817, Accuracy: 0.9715, Precision: 0.9520, Recall: 0.9565, F1: 0.9542
Validation Loss: 1.1789, Accuracy: 0.7079, Precision: 0.6299, Recall: 0.6082, F1: 0.6099
Testing Loss: 1.1071, Accuracy: 0.7428, Precision: 0.6928, Recall: 0.6367, F1: 0.6527
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4116, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8286, F1: 0.8511
Epoch 7/70
Train Loss: 0.0769, Accuracy: 0.9642, Precision: 0.9403, Recall: 0.9403, F1: 0.9403
Validation Loss: 2.3990, Accuracy: 0.7122, Precision: 0.6250, Recall: 0.6250, F1: 0.6119
Testing Loss: 2.1280, Accuracy: 0.7367, Precision: 0.6714, Recall: 0.6557, F1: 0.6507
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1704, Accuracy: 0.9524, Precision: 0.9636, Recall: 0.9571, F1: 0.9572
Epoch 8/70
Train Loss: 0.0896, Accuracy: 0.9651, Precision: 0.9469, Recall: 0.9356, F1: 0.9409
Validation Loss: 1.8196, Accuracy: 0.6397, Precision: 0.5956, Recall: 0.6123, F1: 0.5868
Testing Loss: 1.6948, Accuracy: 0.6896, Precision: 0.6581, Recall: 0.6558, F1: 0.6442
LM Predictions:  [5, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1613, Accuracy: 0.9762, Precision: 0.8333, Recall: 0.8056, F1: 0.8182
Epoch 9/70
Train Loss: 0.1845, Accuracy: 0.9388, Precision: 0.9115, Recall: 0.9109, F1: 0.9112
Validation Loss: 1.3214, Accuracy: 0.6908, Precision: 0.6487, Recall: 0.6291, F1: 0.6159
Testing Loss: 1.3810, Accuracy: 0.6872, Precision: 0.6762, Recall: 0.6444, F1: 0.6351
LM Predictions:  [2, 2, 3, 1, 5, 1, 4, 1, 1, 0, 3, 5, 3, 1, 5, 0, 5, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 5, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3332, Accuracy: 0.8333, Precision: 0.7917, Recall: 0.6799, F1: 0.7117
Epoch 10/70
Train Loss: 0.1677, Accuracy: 0.9433, Precision: 0.9157, Recall: 0.9188, F1: 0.9172
Validation Loss: 1.4769, Accuracy: 0.7079, Precision: 0.6534, Recall: 0.6533, F1: 0.6463
Testing Loss: 1.3158, Accuracy: 0.7500, Precision: 0.7017, Recall: 0.6852, F1: 0.6847
LM Predictions:  [5, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 3, 2, 0, 2, 3, 4, 0, 0, 5, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4262, Accuracy: 0.7857, Precision: 0.7604, Recall: 0.6270, F1: 0.6617
Epoch 11/70
Train Loss: 0.1261, Accuracy: 0.9552, Precision: 0.9307, Recall: 0.9355, F1: 0.9330
Validation Loss: 1.6622, Accuracy: 0.7122, Precision: 0.6652, Recall: 0.6171, F1: 0.6230
Testing Loss: 1.4728, Accuracy: 0.7367, Precision: 0.6921, Recall: 0.6316, F1: 0.6418
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 0, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4157, Accuracy: 0.8095, Precision: 0.9059, Recall: 0.7667, F1: 0.7917
Epoch 12/70
Train Loss: 0.0871, Accuracy: 0.9625, Precision: 0.9399, Recall: 0.9383, F1: 0.9391
Validation Loss: 1.9546, Accuracy: 0.6908, Precision: 0.6467, Recall: 0.6258, F1: 0.6118
Testing Loss: 1.5852, Accuracy: 0.7101, Precision: 0.6613, Recall: 0.6399, F1: 0.6253
LM Predictions:  [2, 1, 3, 1, 0, 1, 4, 1, 1, 0, 3, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 3, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2861, Accuracy: 0.9048, Precision: 0.9190, Recall: 0.8857, F1: 0.8790
Epoch 13/70
Train Loss: 0.0819, Accuracy: 0.9625, Precision: 0.9401, Recall: 0.9413, F1: 0.9407
Validation Loss: 1.6110, Accuracy: 0.7356, Precision: 0.6637, Recall: 0.6325, F1: 0.6375
Testing Loss: 1.4497, Accuracy: 0.7742, Precision: 0.7263, Recall: 0.6703, F1: 0.6873
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1722, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9048, F1: 0.9160
Epoch 14/70
Train Loss: 0.0693, Accuracy: 0.9654, Precision: 0.9459, Recall: 0.9391, F1: 0.9424
Validation Loss: 1.5384, Accuracy: 0.7569, Precision: 0.7181, Recall: 0.6681, F1: 0.6839
Testing Loss: 1.3948, Accuracy: 0.7609, Precision: 0.7090, Recall: 0.6689, F1: 0.6837
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2300, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Epoch 15/70
Train Loss: 0.0959, Accuracy: 0.9616, Precision: 0.9392, Recall: 0.9404, F1: 0.9398
Validation Loss: 1.8623, Accuracy: 0.6930, Precision: 0.6251, Recall: 0.6318, F1: 0.6168
Testing Loss: 1.4675, Accuracy: 0.7500, Precision: 0.6884, Recall: 0.6894, F1: 0.6847
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 4, 0, 4, 0, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2242, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9238, F1: 0.9305
Epoch 16/70
Train Loss: 0.0978, Accuracy: 0.9623, Precision: 0.9403, Recall: 0.9392, F1: 0.9397
Validation Loss: 1.4998, Accuracy: 0.7484, Precision: 0.6842, Recall: 0.6840, F1: 0.6818
Testing Loss: 1.4214, Accuracy: 0.7633, Precision: 0.7176, Recall: 0.6955, F1: 0.7014
LM Predictions:  [0, 2, 0, 1, 0, 1, 4, 2, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.5123, Accuracy: 0.7381, Precision: 0.8547, Recall: 0.7048, F1: 0.7288
Epoch 17/70
Train Loss: 0.0818, Accuracy: 0.9649, Precision: 0.9453, Recall: 0.9421, F1: 0.9436
Validation Loss: 1.3306, Accuracy: 0.7463, Precision: 0.6689, Recall: 0.6641, F1: 0.6642
Testing Loss: 1.1549, Accuracy: 0.7850, Precision: 0.7303, Recall: 0.7078, F1: 0.7152
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2284, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8524, F1: 0.8643
Epoch 18/70
Train Loss: 0.0776, Accuracy: 0.9663, Precision: 0.9454, Recall: 0.9417, F1: 0.9435
Validation Loss: 1.7053, Accuracy: 0.7399, Precision: 0.6853, Recall: 0.6773, F1: 0.6774
Testing Loss: 1.3616, Accuracy: 0.7802, Precision: 0.7354, Recall: 0.7234, F1: 0.7260
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2074, Accuracy: 0.9048, Precision: 0.9385, Recall: 0.8667, F1: 0.8788
Epoch 19/70
Train Loss: 0.0661, Accuracy: 0.9692, Precision: 0.9477, Recall: 0.9512, F1: 0.9494
Validation Loss: 1.5169, Accuracy: 0.7612, Precision: 0.6827, Recall: 0.6736, F1: 0.6674
Testing Loss: 1.2610, Accuracy: 0.7899, Precision: 0.7168, Recall: 0.6885, F1: 0.6900
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3576, Accuracy: 0.8095, Precision: 0.9059, Recall: 0.7857, F1: 0.8019
Epoch 20/70
Train Loss: 0.0594, Accuracy: 0.9687, Precision: 0.9478, Recall: 0.9472, F1: 0.9475
Validation Loss: 1.6554, Accuracy: 0.7569, Precision: 0.6957, Recall: 0.6525, F1: 0.6655
Testing Loss: 1.4593, Accuracy: 0.7754, Precision: 0.7302, Recall: 0.6662, F1: 0.6862
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3681, Accuracy: 0.8095, Precision: 0.9059, Recall: 0.7857, F1: 0.8019
Epoch 21/70
Train Loss: 0.0578, Accuracy: 0.9694, Precision: 0.9495, Recall: 0.9440, F1: 0.9467
Validation Loss: 1.7201, Accuracy: 0.7441, Precision: 0.6945, Recall: 0.6496, F1: 0.6646
Testing Loss: 1.5211, Accuracy: 0.7742, Precision: 0.7374, Recall: 0.6734, F1: 0.6953
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4209, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.7810, F1: 0.8046
Epoch 22/70
Train Loss: 0.0544, Accuracy: 0.9699, Precision: 0.9527, Recall: 0.9462, F1: 0.9493
Validation Loss: 1.5383, Accuracy: 0.7505, Precision: 0.6925, Recall: 0.6973, F1: 0.6936
Testing Loss: 1.2718, Accuracy: 0.7899, Precision: 0.7379, Recall: 0.7380, F1: 0.7362
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2518, Accuracy: 0.9524, Precision: 0.9636, Recall: 0.9524, F1: 0.9544
Epoch 23/70
Train Loss: 0.0611, Accuracy: 0.9715, Precision: 0.9505, Recall: 0.9561, F1: 0.9532
Validation Loss: 1.4566, Accuracy: 0.7463, Precision: 0.6969, Recall: 0.6679, F1: 0.6691
Testing Loss: 1.2263, Accuracy: 0.7935, Precision: 0.7383, Recall: 0.7059, F1: 0.7152
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.0892, Accuracy: 0.9762, Precision: 0.9800, Recall: 0.9667, F1: 0.9713
Epoch 24/70
Train Loss: 0.0581, Accuracy: 0.9711, Precision: 0.9508, Recall: 0.9483, F1: 0.9495
Validation Loss: 1.5391, Accuracy: 0.7548, Precision: 0.7239, Recall: 0.6789, F1: 0.6933
Testing Loss: 1.3843, Accuracy: 0.7754, Precision: 0.7403, Recall: 0.6911, F1: 0.7092
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2779, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.7810, F1: 0.8046
Epoch 25/70
Train Loss: 0.0523, Accuracy: 0.9746, Precision: 0.9602, Recall: 0.9565, F1: 0.9583
Validation Loss: 1.7060, Accuracy: 0.7527, Precision: 0.7105, Recall: 0.6689, F1: 0.6834
Testing Loss: 1.5234, Accuracy: 0.7717, Precision: 0.7289, Recall: 0.6846, F1: 0.7016
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4358, Accuracy: 0.7857, Precision: 0.9000, Recall: 0.7524, F1: 0.7786
Epoch 26/70
Train Loss: 0.0550, Accuracy: 0.9715, Precision: 0.9535, Recall: 0.9515, F1: 0.9525
Validation Loss: 1.6699, Accuracy: 0.7548, Precision: 0.7041, Recall: 0.6816, F1: 0.6857
Testing Loss: 1.4382, Accuracy: 0.7874, Precision: 0.7336, Recall: 0.7054, F1: 0.7158
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2062, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9381, F1: 0.9379
Epoch 27/70
Train Loss: 0.0558, Accuracy: 0.9670, Precision: 0.9443, Recall: 0.9413, F1: 0.9427
Validation Loss: 1.8368, Accuracy: 0.7484, Precision: 0.7027, Recall: 0.6718, F1: 0.6810
Testing Loss: 1.5587, Accuracy: 0.7778, Precision: 0.7391, Recall: 0.7037, F1: 0.7169
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2240, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8524, F1: 0.8643
Epoch 28/70
Train Loss: 0.0489, Accuracy: 0.9746, Precision: 0.9601, Recall: 0.9557, F1: 0.9578
Validation Loss: 1.9800, Accuracy: 0.7463, Precision: 0.7206, Recall: 0.6624, F1: 0.6800
Testing Loss: 1.7282, Accuracy: 0.7729, Precision: 0.7449, Recall: 0.6931, F1: 0.7120
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3696, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.7810, F1: 0.8046
Epoch 29/70
Train Loss: 0.0518, Accuracy: 0.9734, Precision: 0.9564, Recall: 0.9536, F1: 0.9550
Validation Loss: 1.7553, Accuracy: 0.7463, Precision: 0.7205, Recall: 0.6674, F1: 0.6843
Testing Loss: 1.5478, Accuracy: 0.7862, Precision: 0.7526, Recall: 0.7036, F1: 0.7224
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1763, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8143, F1: 0.8288
Epoch 30/70
Train Loss: 0.0519, Accuracy: 0.9699, Precision: 0.9488, Recall: 0.9523, F1: 0.9505
Validation Loss: 2.5776, Accuracy: 0.7591, Precision: 0.7054, Recall: 0.6849, F1: 0.6839
Testing Loss: 1.9943, Accuracy: 0.7814, Precision: 0.7286, Recall: 0.6938, F1: 0.7020
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 31/70
Train Loss: 0.0611, Accuracy: 0.9680, Precision: 0.9481, Recall: 0.9430, F1: 0.9455
Validation Loss: 1.6951, Accuracy: 0.7207, Precision: 0.6603, Recall: 0.6090, F1: 0.6162
Testing Loss: 1.6565, Accuracy: 0.7174, Precision: 0.6694, Recall: 0.6065, F1: 0.6145
LM Predictions:  [2, 2, 1, 2, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 2, 3, 4, 2, 0, 2, 3, 2, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2113, Accuracy: 0.9048, Precision: 0.9000, Recall: 0.8952, F1: 0.8883
Epoch 32/70
Train Loss: 0.2112, Accuracy: 0.9239, Precision: 0.8861, Recall: 0.8828, F1: 0.8844
Validation Loss: 1.0656, Accuracy: 0.7825, Precision: 0.7473, Recall: 0.7351, F1: 0.7388
Testing Loss: 1.1125, Accuracy: 0.7754, Precision: 0.7486, Recall: 0.7292, F1: 0.7306
LM Predictions:  [5, 2, 0, 5, 0, 1, 4, 5, 1, 0, 2, 4, 3, 5, 4, 5, 4, 0, 5, 2, 0, 2, 3, 4, 0, 0, 5, 5, 0, 0, 0, 4, 0, 5, 5, 1, 1, 1, 0, 2, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 1.3622, Accuracy: 0.6429, Precision: 0.7500, Recall: 0.5728, F1: 0.6185
Epoch 33/70
Train Loss: 0.1177, Accuracy: 0.9585, Precision: 0.9365, Recall: 0.9398, F1: 0.9381
Validation Loss: 1.3320, Accuracy: 0.7740, Precision: 0.7261, Recall: 0.7047, F1: 0.7128
Testing Loss: 1.1436, Accuracy: 0.7971, Precision: 0.7621, Recall: 0.7245, F1: 0.7391
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 4, 2, 4, 3, 5, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2960, Accuracy: 0.9048, Precision: 0.7762, Recall: 0.7394, F1: 0.7513
Epoch 34/70
Train Loss: 0.0691, Accuracy: 0.9642, Precision: 0.9406, Recall: 0.9414, F1: 0.9410
Validation Loss: 1.3176, Accuracy: 0.7633, Precision: 0.6789, Recall: 0.6781, F1: 0.6725
Testing Loss: 1.2607, Accuracy: 0.7766, Precision: 0.7145, Recall: 0.6867, F1: 0.6935
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2578, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.8095, F1: 0.8284
Epoch 35/70
Train Loss: 0.0520, Accuracy: 0.9680, Precision: 0.9453, Recall: 0.9484, F1: 0.9468
Validation Loss: 1.3026, Accuracy: 0.7633, Precision: 0.6659, Recall: 0.6624, F1: 0.6577
Testing Loss: 1.2892, Accuracy: 0.7681, Precision: 0.6977, Recall: 0.6651, F1: 0.6726
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2099, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9000, F1: 0.9048
Epoch 36/70
Train Loss: 0.0501, Accuracy: 0.9713, Precision: 0.9503, Recall: 0.9541, F1: 0.9521
Validation Loss: 1.3863, Accuracy: 0.7527, Precision: 0.6623, Recall: 0.6551, F1: 0.6531
Testing Loss: 1.3524, Accuracy: 0.7754, Precision: 0.7103, Recall: 0.6790, F1: 0.6879
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2682, Accuracy: 0.7857, Precision: 0.9000, Recall: 0.7524, F1: 0.7786
Epoch 37/70
Train Loss: 0.0475, Accuracy: 0.9694, Precision: 0.9474, Recall: 0.9484, F1: 0.9479
Validation Loss: 1.3587, Accuracy: 0.7740, Precision: 0.6909, Recall: 0.6770, F1: 0.6798
Testing Loss: 1.3507, Accuracy: 0.7838, Precision: 0.7271, Recall: 0.6849, F1: 0.6994
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1756, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8857, F1: 0.8866
Epoch 38/70
Train Loss: 0.0489, Accuracy: 0.9666, Precision: 0.9422, Recall: 0.9444, F1: 0.9432
Validation Loss: 1.4545, Accuracy: 0.7719, Precision: 0.7148, Recall: 0.6923, F1: 0.6987
Testing Loss: 1.4378, Accuracy: 0.7862, Precision: 0.7439, Recall: 0.7067, F1: 0.7210
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1539, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9000, F1: 0.9048
Epoch 39/70
Train Loss: 0.0466, Accuracy: 0.9708, Precision: 0.9489, Recall: 0.9556, F1: 0.9521
Validation Loss: 1.4852, Accuracy: 0.7697, Precision: 0.6976, Recall: 0.6717, F1: 0.6780
Testing Loss: 1.4676, Accuracy: 0.7742, Precision: 0.7149, Recall: 0.6728, F1: 0.6870
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3771, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8524, F1: 0.8619
Epoch 40/70
Train Loss: 0.0483, Accuracy: 0.9715, Precision: 0.9526, Recall: 0.9510, F1: 0.9518
Validation Loss: 1.5023, Accuracy: 0.7676, Precision: 0.6897, Recall: 0.6751, F1: 0.6769
Testing Loss: 1.4758, Accuracy: 0.7874, Precision: 0.7310, Recall: 0.6936, F1: 0.7052
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2595, Accuracy: 0.8095, Precision: 0.9059, Recall: 0.7667, F1: 0.7917
Epoch 41/70
Train Loss: 0.0456, Accuracy: 0.9744, Precision: 0.9620, Recall: 0.9535, F1: 0.9576
Validation Loss: 1.4678, Accuracy: 0.7761, Precision: 0.7161, Recall: 0.7001, F1: 0.7046
Testing Loss: 1.4361, Accuracy: 0.7862, Precision: 0.7379, Recall: 0.7099, F1: 0.7213
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1476, Accuracy: 0.9762, Precision: 0.9800, Recall: 0.9857, F1: 0.9821
Epoch 42/70
Train Loss: 0.0465, Accuracy: 0.9734, Precision: 0.9539, Recall: 0.9562, F1: 0.9551
Validation Loss: 1.4823, Accuracy: 0.7719, Precision: 0.7070, Recall: 0.6927, F1: 0.6979
Testing Loss: 1.4694, Accuracy: 0.7838, Precision: 0.7431, Recall: 0.7088, F1: 0.7232
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1389, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9143, F1: 0.9169
Epoch 43/70
Train Loss: 0.0456, Accuracy: 0.9739, Precision: 0.9521, Recall: 0.9639, F1: 0.9576
Validation Loss: 1.5825, Accuracy: 0.7740, Precision: 0.6971, Recall: 0.6768, F1: 0.6821
Testing Loss: 1.5983, Accuracy: 0.7874, Precision: 0.7359, Recall: 0.6836, F1: 0.6990
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2706, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.8000, F1: 0.8154
Epoch 44/70
Train Loss: 0.0468, Accuracy: 0.9706, Precision: 0.9507, Recall: 0.9484, F1: 0.9496
Validation Loss: 1.6380, Accuracy: 0.7719, Precision: 0.6997, Recall: 0.6817, F1: 0.6845
Testing Loss: 1.6423, Accuracy: 0.7862, Precision: 0.7420, Recall: 0.7098, F1: 0.7219
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3562, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Epoch 45/70
Train Loss: 0.0457, Accuracy: 0.9708, Precision: 0.9492, Recall: 0.9526, F1: 0.9509
Validation Loss: 1.6987, Accuracy: 0.7676, Precision: 0.6890, Recall: 0.6699, F1: 0.6714
Testing Loss: 1.6887, Accuracy: 0.7826, Precision: 0.7261, Recall: 0.6827, F1: 0.6943
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3387, Accuracy: 0.8095, Precision: 0.9059, Recall: 0.7667, F1: 0.7917
Epoch 46/70
Train Loss: 0.0524, Accuracy: 0.9723, Precision: 0.9543, Recall: 0.9516, F1: 0.9529
Validation Loss: 1.4880, Accuracy: 0.7804, Precision: 0.7308, Recall: 0.6935, F1: 0.7073
Testing Loss: 1.5096, Accuracy: 0.7862, Precision: 0.7602, Recall: 0.7124, F1: 0.7313
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1922, Accuracy: 0.9048, Precision: 0.9385, Recall: 0.8667, F1: 0.8788
Epoch 47/70
Train Loss: 0.0491, Accuracy: 0.9718, Precision: 0.9533, Recall: 0.9506, F1: 0.9519
Validation Loss: 1.6005, Accuracy: 0.7761, Precision: 0.7124, Recall: 0.7010, F1: 0.6999
Testing Loss: 1.5927, Accuracy: 0.7826, Precision: 0.7322, Recall: 0.7069, F1: 0.7174
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2253, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.8000, F1: 0.8154
Epoch 48/70
Train Loss: 0.0480, Accuracy: 0.9711, Precision: 0.9541, Recall: 0.9500, F1: 0.9520
Validation Loss: 1.6126, Accuracy: 0.7740, Precision: 0.7314, Recall: 0.7014, F1: 0.7062
Testing Loss: 1.5784, Accuracy: 0.7826, Precision: 0.7240, Recall: 0.6942, F1: 0.7014
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.0972, Accuracy: 0.9762, Precision: 0.9800, Recall: 0.9857, F1: 0.9821
Epoch 49/70
Train Loss: 0.0680, Accuracy: 0.9661, Precision: 0.9413, Recall: 0.9432, F1: 0.9422
Validation Loss: 1.2353, Accuracy: 0.7335, Precision: 0.6733, Recall: 0.6257, F1: 0.6373
Testing Loss: 1.2549, Accuracy: 0.7464, Precision: 0.7132, Recall: 0.6407, F1: 0.6616
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 5, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1635, Accuracy: 0.9762, Precision: 0.8333, Recall: 0.8214, F1: 0.8272
Epoch 50/70
Train Loss: 0.1427, Accuracy: 0.9485, Precision: 0.9210, Recall: 0.9225, F1: 0.9217
Validation Loss: 1.3792, Accuracy: 0.7484, Precision: 0.6505, Recall: 0.6565, F1: 0.6468
Testing Loss: 1.1807, Accuracy: 0.7862, Precision: 0.7140, Recall: 0.6791, F1: 0.6786
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 3, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2210, Accuracy: 0.8571, Precision: 0.9000, Recall: 0.8524, F1: 0.8530
Epoch 51/70
Train Loss: 0.0778, Accuracy: 0.9642, Precision: 0.9417, Recall: 0.9348, F1: 0.9380
Validation Loss: 1.2693, Accuracy: 0.7633, Precision: 0.6875, Recall: 0.6792, F1: 0.6726
Testing Loss: 1.1222, Accuracy: 0.7802, Precision: 0.6906, Recall: 0.6796, F1: 0.6768
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1568, Accuracy: 0.9762, Precision: 0.9800, Recall: 0.9667, F1: 0.9713
Epoch 52/70
Train Loss: 0.0525, Accuracy: 0.9718, Precision: 0.9527, Recall: 0.9529, F1: 0.9528
Validation Loss: 1.4441, Accuracy: 0.7612, Precision: 0.6965, Recall: 0.6783, F1: 0.6850
Testing Loss: 1.2925, Accuracy: 0.7826, Precision: 0.7338, Recall: 0.6910, F1: 0.7068
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2409, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Epoch 53/70
Train Loss: 0.0517, Accuracy: 0.9711, Precision: 0.9523, Recall: 0.9506, F1: 0.9514
Validation Loss: 1.3612, Accuracy: 0.7527, Precision: 0.6736, Recall: 0.6760, F1: 0.6738
Testing Loss: 1.2280, Accuracy: 0.7826, Precision: 0.7280, Recall: 0.6963, F1: 0.7087
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2430, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9381, F1: 0.9379
Epoch 54/70
Train Loss: 0.0463, Accuracy: 0.9720, Precision: 0.9547, Recall: 0.9492, F1: 0.9518
Validation Loss: 1.4684, Accuracy: 0.7655, Precision: 0.6895, Recall: 0.6765, F1: 0.6796
Testing Loss: 1.3450, Accuracy: 0.7826, Precision: 0.7249, Recall: 0.6816, F1: 0.6947
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1878, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8667, F1: 0.8764
Epoch 55/70
Train Loss: 0.0461, Accuracy: 0.9687, Precision: 0.9502, Recall: 0.9459, F1: 0.9480
Validation Loss: 1.4061, Accuracy: 0.7591, Precision: 0.6547, Recall: 0.6681, F1: 0.6593
Testing Loss: 1.2544, Accuracy: 0.7838, Precision: 0.7209, Recall: 0.6846, F1: 0.6946
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1154, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0453, Accuracy: 0.9704, Precision: 0.9489, Recall: 0.9486, F1: 0.9488
Validation Loss: 1.4809, Accuracy: 0.7548, Precision: 0.6761, Recall: 0.6840, F1: 0.6778
Testing Loss: 1.3044, Accuracy: 0.7778, Precision: 0.7184, Recall: 0.6994, F1: 0.7071
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1519, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9143, F1: 0.9169
Epoch 57/70
Train Loss: 0.0484, Accuracy: 0.9713, Precision: 0.9509, Recall: 0.9513, F1: 0.9511
Validation Loss: 1.5602, Accuracy: 0.7548, Precision: 0.6873, Recall: 0.6751, F1: 0.6801
Testing Loss: 1.3734, Accuracy: 0.7802, Precision: 0.7355, Recall: 0.7039, F1: 0.7167
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.3054, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.7810, F1: 0.8046
Epoch 58/70
Train Loss: 0.0466, Accuracy: 0.9725, Precision: 0.9533, Recall: 0.9578, F1: 0.9554
Validation Loss: 1.5554, Accuracy: 0.7484, Precision: 0.6758, Recall: 0.6614, F1: 0.6670
Testing Loss: 1.3583, Accuracy: 0.7766, Precision: 0.7210, Recall: 0.6843, F1: 0.6976
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1240, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9143, F1: 0.9169
Epoch 59/70
Train Loss: 0.0443, Accuracy: 0.9706, Precision: 0.9528, Recall: 0.9480, F1: 0.9503
Validation Loss: 1.6584, Accuracy: 0.7505, Precision: 0.6732, Recall: 0.6515, F1: 0.6593
Testing Loss: 1.4416, Accuracy: 0.7886, Precision: 0.7437, Recall: 0.6988, F1: 0.7161
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.4175, Accuracy: 0.7857, Precision: 0.9000, Recall: 0.7524, F1: 0.7786
Epoch 60/70
Train Loss: 0.0467, Accuracy: 0.9708, Precision: 0.9502, Recall: 0.9528, F1: 0.9515
Validation Loss: 1.6483, Accuracy: 0.7761, Precision: 0.7153, Recall: 0.7048, F1: 0.7087
Testing Loss: 1.4416, Accuracy: 0.7886, Precision: 0.7451, Recall: 0.7156, F1: 0.7277
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2008, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8857, F1: 0.8866
Epoch 61/70
Train Loss: 0.0457, Accuracy: 0.9687, Precision: 0.9474, Recall: 0.9490, F1: 0.9482
Validation Loss: 1.6040, Accuracy: 0.7676, Precision: 0.6916, Recall: 0.6806, F1: 0.6838
Testing Loss: 1.3968, Accuracy: 0.7814, Precision: 0.7227, Recall: 0.6888, F1: 0.7002
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2385, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Epoch 62/70
Train Loss: 0.0500, Accuracy: 0.9725, Precision: 0.9522, Recall: 0.9554, F1: 0.9537
Validation Loss: 1.2874, Accuracy: 0.7569, Precision: 0.7011, Recall: 0.6974, F1: 0.6960
Testing Loss: 1.0938, Accuracy: 0.7814, Precision: 0.7337, Recall: 0.7216, F1: 0.7246
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2248, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Epoch 63/70
Train Loss: 0.0527, Accuracy: 0.9692, Precision: 0.9485, Recall: 0.9500, F1: 0.9492
Validation Loss: 1.5076, Accuracy: 0.7527, Precision: 0.6736, Recall: 0.6381, F1: 0.6403
Testing Loss: 1.3553, Accuracy: 0.7766, Precision: 0.7171, Recall: 0.6580, F1: 0.6721
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1543, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8857, F1: 0.8866
Epoch 64/70
Train Loss: 0.0905, Accuracy: 0.9635, Precision: 0.9425, Recall: 0.9422, F1: 0.9423
Validation Loss: 1.4912, Accuracy: 0.7655, Precision: 0.7275, Recall: 0.6712, F1: 0.6882
Testing Loss: 1.4476, Accuracy: 0.7899, Precision: 0.7522, Recall: 0.6958, F1: 0.7139
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 1, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2763, Accuracy: 0.7619, Precision: 0.8846, Recall: 0.7190, F1: 0.7384
Epoch 65/70
Train Loss: 0.0809, Accuracy: 0.9642, Precision: 0.9409, Recall: 0.9476, F1: 0.9440
Validation Loss: 1.3393, Accuracy: 0.7783, Precision: 0.7293, Recall: 0.7147, F1: 0.7201
Testing Loss: 1.3430, Accuracy: 0.7911, Precision: 0.7324, Recall: 0.7091, F1: 0.7166
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 0, 3, 1, 0, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2954, Accuracy: 0.7857, Precision: 0.9000, Recall: 0.7524, F1: 0.7786
Epoch 66/70
Train Loss: 0.0493, Accuracy: 0.9739, Precision: 0.9566, Recall: 0.9597, F1: 0.9580
Validation Loss: 1.4494, Accuracy: 0.7697, Precision: 0.6495, Recall: 0.6670, F1: 0.6566
Testing Loss: 1.4965, Accuracy: 0.7814, Precision: 0.6910, Recall: 0.6759, F1: 0.6765
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1314, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9190, F1: 0.9277
Epoch 67/70
Train Loss: 0.0443, Accuracy: 0.9723, Precision: 0.9521, Recall: 0.9587, F1: 0.9553
Validation Loss: 1.4439, Accuracy: 0.7804, Precision: 0.7077, Recall: 0.6878, F1: 0.6940
Testing Loss: 1.4906, Accuracy: 0.7838, Precision: 0.7078, Recall: 0.6751, F1: 0.6838
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1284, Accuracy: 0.9286, Precision: 0.9500, Recall: 0.9000, F1: 0.9048
Epoch 68/70
Train Loss: 0.0449, Accuracy: 0.9677, Precision: 0.9491, Recall: 0.9415, F1: 0.9451
Validation Loss: 1.5055, Accuracy: 0.7804, Precision: 0.7098, Recall: 0.6921, F1: 0.6981
Testing Loss: 1.5413, Accuracy: 0.7802, Precision: 0.7106, Recall: 0.6753, F1: 0.6860
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1811, Accuracy: 0.8333, Precision: 0.9125, Recall: 0.8190, F1: 0.8341
Epoch 69/70
Train Loss: 0.0429, Accuracy: 0.9713, Precision: 0.9509, Recall: 0.9534, F1: 0.9521
Validation Loss: 1.5358, Accuracy: 0.7974, Precision: 0.7520, Recall: 0.7386, F1: 0.7443
Testing Loss: 1.5634, Accuracy: 0.7850, Precision: 0.7358, Recall: 0.6994, F1: 0.7141
LM Predictions:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 0, 3, 1, 0, 0, 4, 3, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 0, 1, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.1448, Accuracy: 0.8810, Precision: 0.9286, Recall: 0.8476, F1: 0.8620
Epoch 70/70
Train Loss: 0.0422, Accuracy: 0.9692, Precision: 0.9489, Recall: 0.9458, F1: 0.9473
Validation Loss: 1.5222, Accuracy: 0.7846, Precision: 0.7392, Recall: 0.7309, F1: 0.7345
Testing Loss: 1.5962, Accuracy: 0.7802, Precision: 0.7294, Recall: 0.7014, F1: 0.7129
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2370, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498
Label Memorization Analysis: 
LM Predictions:  [2, 2, 0, 1, 0, 1, 4, 1, 1, 0, 0, 4, 3, 1, 4, 0, 4, 0, 0, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 0, 4, 0, 0, 1, 1, 1, 1, 0, 1, 3, 2]
LM Labels:  [2, 2, 1, 1, 0, 1, 4, 1, 1, 0, 2, 4, 3, 1, 4, 0, 4, 3, 3, 2, 0, 2, 3, 4, 0, 0, 1, 1, 0, 4, 1, 4, 0, 3, 1, 1, 1, 1, 0, 1, 3, 2]
LM Loss: 0.2370, Accuracy: 0.8571, Precision: 0.9200, Recall: 0.8381, F1: 0.8498

