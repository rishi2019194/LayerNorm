Model: openai-community/gpt2, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:1
Noise: 1% with label 5
Label counts for Train:
  Label 0: 1141
  Label 1: 1011
  Label 2: 966
  Label 5: 260
  Label 4: 344
  Label 3: 495
Label counts for Validation:
  Label 1: 113
  Label 0: 127
  Label 4: 38
  Label 5: 29
  Label 2: 107
  Label 3: 55
Label counts for Test:
  Label 2: 190
  Label 0: 224
  Label 3: 97
  Label 1: 199
  Label 5: 51
  Label 4: 67
42
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 0: 1146
  Label 1: 1020
  Label 2: 974
  Label 5: 218
  Label 4: 354
  Label 3: 505
Layer: backbone.wte.weight, Size: torch.Size([50257, 768]), req grad: True
Layer: backbone.wpe.weight, Size: torch.Size([1024, 768]), req grad: True
Layer: backbone.h.0.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.0.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.0.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.0.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.0.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.0.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.0.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.0.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.1.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.1.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.1.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.1.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.1.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.1.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.1.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.1.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.2.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.2.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.2.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.2.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.2.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.2.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.2.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.2.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.3.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.3.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.3.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.3.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.3.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.3.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.3.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.3.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.4.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.4.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.4.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.4.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.4.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.4.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.4.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.4.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.5.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.5.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.5.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.5.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.5.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.5.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.5.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.5.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.6.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.6.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.6.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.6.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.6.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.6.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.6.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.6.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.7.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.7.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.7.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.7.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.7.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.7.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.7.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.7.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.8.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.8.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.8.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.8.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.8.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.8.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.8.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.8.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.9.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.9.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.9.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.9.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.9.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.9.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.9.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.9.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.10.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.10.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.10.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.10.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.10.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.10.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.10.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.10.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.11.attn.c_attn.weight, Size: torch.Size([768, 2304]), req grad: True
Layer: backbone.h.11.attn.c_attn.bias, Size: torch.Size([2304]), req grad: True
Layer: backbone.h.11.attn.c_proj.weight, Size: torch.Size([768, 768]), req grad: True
Layer: backbone.h.11.attn.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: backbone.h.11.mlp.c_fc.weight, Size: torch.Size([768, 3072]), req grad: True
Layer: backbone.h.11.mlp.c_fc.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.h.11.mlp.c_proj.weight, Size: torch.Size([3072, 768]), req grad: True
Layer: backbone.h.11.mlp.c_proj.bias, Size: torch.Size([768]), req grad: True
Layer: classifier.weight, Size: torch.Size([6, 768]), req grad: True
Epoch 1/70
Train Loss: 1.7027, Accuracy: 0.2507, Precision: 0.1630, Recall: 0.1668, F1: 0.1417
Validation Loss: 1.6904, Accuracy: 0.2601, Precision: 0.1269, Recall: 0.1706, F1: 0.1377
Testing Loss: 1.6833, Accuracy: 0.2669, Precision: 0.1326, Recall: 0.1761, F1: 0.1411
LM Predictions:  [0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2, 1, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9327, Accuracy: 0.1429, Precision: 0.0949, Recall: 0.1894, F1: 0.1145
Epoch 2/70
Train Loss: 1.6697, Accuracy: 0.2646, Precision: 0.1674, Recall: 0.1700, F1: 0.1331
Validation Loss: 1.6976, Accuracy: 0.2473, Precision: 0.1252, Recall: 0.1650, F1: 0.1414
Testing Loss: 1.6948, Accuracy: 0.2681, Precision: 0.1341, Recall: 0.1810, F1: 0.1526
LM Predictions:  [0, 0, 2, 2, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 0, 2, 2, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9333, Accuracy: 0.2143, Precision: 0.1300, Recall: 0.2644, F1: 0.1724
Epoch 3/70
Train Loss: 1.6639, Accuracy: 0.2665, Precision: 0.1289, Recall: 0.1714, F1: 0.1356
Validation Loss: 1.6899, Accuracy: 0.2793, Precision: 0.1167, Recall: 0.1786, F1: 0.1193
Testing Loss: 1.6826, Accuracy: 0.2645, Precision: 0.1126, Recall: 0.1690, F1: 0.1124
LM Predictions:  [0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9001, Accuracy: 0.1429, Precision: 0.0552, Recall: 0.2250, F1: 0.0836
Epoch 4/70
Train Loss: 1.6624, Accuracy: 0.2608, Precision: 0.1540, Recall: 0.1682, F1: 0.1345
Validation Loss: 1.6904, Accuracy: 0.2644, Precision: 0.1229, Recall: 0.1683, F1: 0.1223
Testing Loss: 1.6749, Accuracy: 0.2814, Precision: 0.1441, Recall: 0.1798, F1: 0.1344
LM Predictions:  [0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8881, Accuracy: 0.1429, Precision: 0.0723, Recall: 0.2222, F1: 0.0841
Epoch 5/70
Train Loss: 1.6606, Accuracy: 0.2661, Precision: 0.1267, Recall: 0.1700, F1: 0.1303
Validation Loss: 1.6767, Accuracy: 0.2814, Precision: 0.1662, Recall: 0.1756, F1: 0.1029
Testing Loss: 1.6710, Accuracy: 0.2681, Precision: 0.1303, Recall: 0.1668, F1: 0.0889
LM Predictions:  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9318, Accuracy: 0.0952, Precision: 0.0211, Recall: 0.1600, F1: 0.0372
Epoch 6/70
Train Loss: 1.6644, Accuracy: 0.2580, Precision: 0.1247, Recall: 0.1656, F1: 0.1301
Validation Loss: 1.6840, Accuracy: 0.2921, Precision: 0.1548, Recall: 0.1827, F1: 0.1112
Testing Loss: 1.6776, Accuracy: 0.2802, Precision: 0.1610, Recall: 0.1749, F1: 0.1019
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9285, Accuracy: 0.1667, Precision: 0.1078, Recall: 0.2444, F1: 0.1059
Epoch 7/70
Train Loss: 1.6589, Accuracy: 0.2720, Precision: 0.2995, Recall: 0.1733, F1: 0.1304
Validation Loss: 1.6748, Accuracy: 0.2623, Precision: 0.1403, Recall: 0.1828, F1: 0.1282
Testing Loss: 1.6721, Accuracy: 0.2778, Precision: 0.1627, Recall: 0.1925, F1: 0.1422
LM Predictions:  [2, 2, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 1, 1, 2, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8622, Accuracy: 0.1905, Precision: 0.1519, Recall: 0.2067, F1: 0.1543
Epoch 8/70
Train Loss: 1.6607, Accuracy: 0.2632, Precision: 0.1270, Recall: 0.1683, F1: 0.1296
Validation Loss: 1.6750, Accuracy: 0.2772, Precision: 0.2001, Recall: 0.1793, F1: 0.1209
Testing Loss: 1.6661, Accuracy: 0.2826, Precision: 0.0939, Recall: 0.1830, F1: 0.1207
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8971, Accuracy: 0.1429, Precision: 0.0523, Recall: 0.2250, F1: 0.0778
Epoch 9/70
Train Loss: 1.6612, Accuracy: 0.2661, Precision: 0.1272, Recall: 0.1700, F1: 0.1303
Validation Loss: 1.6626, Accuracy: 0.3092, Precision: 0.1163, Recall: 0.1958, F1: 0.1301
Testing Loss: 1.6564, Accuracy: 0.3104, Precision: 0.2043, Recall: 0.1957, F1: 0.1262
LM Predictions:  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8809, Accuracy: 0.1905, Precision: 0.1143, Recall: 0.2667, F1: 0.1250
Epoch 10/70
Train Loss: 1.6530, Accuracy: 0.2741, Precision: 0.1338, Recall: 0.1756, F1: 0.1362
Validation Loss: 1.6604, Accuracy: 0.2985, Precision: 0.1121, Recall: 0.1870, F1: 0.1139
Testing Loss: 1.6527, Accuracy: 0.2983, Precision: 0.1219, Recall: 0.1871, F1: 0.1147
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8629, Accuracy: 0.1190, Precision: 0.0270, Recall: 0.2000, F1: 0.0476
Epoch 11/70
Train Loss: 1.6558, Accuracy: 0.2691, Precision: 0.1309, Recall: 0.1718, F1: 0.1310
Validation Loss: 1.6702, Accuracy: 0.2687, Precision: 0.0451, Recall: 0.1654, F1: 0.0708
Testing Loss: 1.6642, Accuracy: 0.2693, Precision: 0.0449, Recall: 0.1659, F1: 0.0707
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9356, Accuracy: 0.1190, Precision: 0.0238, Recall: 0.2000, F1: 0.0426
Epoch 12/70
Train Loss: 1.6557, Accuracy: 0.2713, Precision: 0.1311, Recall: 0.1742, F1: 0.1367
Validation Loss: 1.6647, Accuracy: 0.3177, Precision: 0.2223, Recall: 0.2078, F1: 0.1672
Testing Loss: 1.6657, Accuracy: 0.2693, Precision: 0.1520, Recall: 0.1739, F1: 0.1268
LM Predictions:  [0, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 2, 0, 2, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9227, Accuracy: 0.0714, Precision: 0.0297, Recall: 0.1050, F1: 0.0433
Epoch 13/70
Train Loss: 1.6585, Accuracy: 0.2720, Precision: 0.1368, Recall: 0.1758, F1: 0.1423
Validation Loss: 1.6718, Accuracy: 0.2985, Precision: 0.1618, Recall: 0.2112, F1: 0.1570
Testing Loss: 1.6695, Accuracy: 0.3043, Precision: 0.1697, Recall: 0.2147, F1: 0.1601
LM Predictions:  [2, 2, 0, 0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 0, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8306, Accuracy: 0.1667, Precision: 0.0700, Recall: 0.1722, F1: 0.0899
Epoch 14/70
Train Loss: 1.6557, Accuracy: 0.2798, Precision: 0.1369, Recall: 0.1801, F1: 0.1431
Validation Loss: 1.6396, Accuracy: 0.3774, Precision: 0.1948, Recall: 0.2621, F1: 0.2114
Testing Loss: 1.6406, Accuracy: 0.3406, Precision: 0.1767, Recall: 0.2364, F1: 0.1902
LM Predictions:  [1, 2, 2, 1, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 0, 2, 2, 0, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8067, Accuracy: 0.1667, Precision: 0.0893, Recall: 0.1872, F1: 0.1196
Epoch 15/70
Train Loss: 1.6517, Accuracy: 0.2767, Precision: 0.1342, Recall: 0.1776, F1: 0.1376
Validation Loss: 1.6379, Accuracy: 0.4072, Precision: 0.2028, Recall: 0.2734, F1: 0.2323
Testing Loss: 1.6362, Accuracy: 0.3575, Precision: 0.1777, Recall: 0.2403, F1: 0.2042
LM Predictions:  [0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8567, Accuracy: 0.2143, Precision: 0.1352, Recall: 0.2739, F1: 0.1594
Epoch 16/70
Train Loss: 1.6423, Accuracy: 0.3059, Precision: 0.1516, Recall: 0.1984, F1: 0.1597
Validation Loss: 1.6243, Accuracy: 0.3817, Precision: 0.2360, Recall: 0.2474, F1: 0.1903
Testing Loss: 1.6168, Accuracy: 0.3744, Precision: 0.2252, Recall: 0.2427, F1: 0.1926
LM Predictions:  [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.8550, Accuracy: 0.1905, Precision: 0.0806, Recall: 0.2667, F1: 0.1134
Epoch 17/70
Train Loss: 1.6310, Accuracy: 0.3235, Precision: 0.1586, Recall: 0.2107, F1: 0.1701
Validation Loss: 1.6321, Accuracy: 0.3284, Precision: 0.3411, Recall: 0.2069, F1: 0.1400
Testing Loss: 1.6348, Accuracy: 0.3273, Precision: 0.1756, Recall: 0.2061, F1: 0.1362
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9575, Accuracy: 0.1190, Precision: 0.0256, Recall: 0.2000, F1: 0.0455
Epoch 18/70
Train Loss: 1.6053, Accuracy: 0.3517, Precision: 0.1731, Recall: 0.2304, F1: 0.1855
Validation Loss: 1.5492, Accuracy: 0.3859, Precision: 0.1367, Recall: 0.2491, F1: 0.1724
Testing Loss: 1.5537, Accuracy: 0.3720, Precision: 0.2964, Recall: 0.2411, F1: 0.1701
LM Predictions:  [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 1.9160, Accuracy: 0.1429, Precision: 0.0571, Recall: 0.2044, F1: 0.0833
Epoch 19/70
Train Loss: 1.5731, Accuracy: 0.3614, Precision: 0.1763, Recall: 0.2379, F1: 0.1936
Validation Loss: 1.5743, Accuracy: 0.4072, Precision: 0.2373, Recall: 0.2637, F1: 0.2009
Testing Loss: 1.5772, Accuracy: 0.3961, Precision: 0.2382, Recall: 0.2570, F1: 0.2008
LM Predictions:  [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1833, Accuracy: 0.1190, Precision: 0.0492, Recall: 0.1822, F1: 0.0656
Epoch 20/70
Train Loss: 1.5408, Accuracy: 0.3830, Precision: 0.3565, Recall: 0.2528, F1: 0.2097
Validation Loss: 1.4526, Accuracy: 0.4307, Precision: 0.3008, Recall: 0.2798, F1: 0.2113
Testing Loss: 1.4442, Accuracy: 0.4179, Precision: 0.2421, Recall: 0.2715, F1: 0.2012
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.1801, Accuracy: 0.1429, Precision: 0.0525, Recall: 0.2222, F1: 0.0749
Epoch 21/70
Train Loss: 1.5018, Accuracy: 0.4110, Precision: 0.2246, Recall: 0.2715, F1: 0.2282
Validation Loss: 1.4246, Accuracy: 0.4755, Precision: 0.2589, Recall: 0.3129, F1: 0.2643
Testing Loss: 1.3926, Accuracy: 0.5024, Precision: 0.3302, Recall: 0.3343, F1: 0.2904
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4178, Accuracy: 0.1190, Precision: 0.0735, Recall: 0.1822, F1: 0.0718
Epoch 22/70
Train Loss: 1.4570, Accuracy: 0.4482, Precision: 0.2936, Recall: 0.2983, F1: 0.2551
Validation Loss: 1.2622, Accuracy: 0.5373, Precision: 0.2829, Recall: 0.3590, F1: 0.3101
Testing Loss: 1.2720, Accuracy: 0.5459, Precision: 0.2812, Recall: 0.3655, F1: 0.3140
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4113, Accuracy: 0.1190, Precision: 0.0278, Recall: 0.2000, F1: 0.0488
Epoch 23/70
Train Loss: 1.4350, Accuracy: 0.4598, Precision: 0.3063, Recall: 0.3060, F1: 0.2617
Validation Loss: 1.2894, Accuracy: 0.5288, Precision: 0.2659, Recall: 0.3581, F1: 0.3046
Testing Loss: 1.2886, Accuracy: 0.5435, Precision: 0.2728, Recall: 0.3691, F1: 0.3127
LM Predictions:  [0, 2, 0, 0, 2, 0, 2, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.6383, Accuracy: 0.0952, Precision: 0.0422, Recall: 0.1450, F1: 0.0597
Epoch 24/70
Train Loss: 1.3849, Accuracy: 0.4845, Precision: 0.2446, Recall: 0.3236, F1: 0.2775
Validation Loss: 1.2388, Accuracy: 0.5373, Precision: 0.2812, Recall: 0.3619, F1: 0.3130
Testing Loss: 1.2086, Accuracy: 0.5519, Precision: 0.3672, Recall: 0.3746, F1: 0.3252
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8733, Accuracy: 0.1190, Precision: 0.0536, Recall: 0.1850, F1: 0.0699
Epoch 25/70
Train Loss: 1.3525, Accuracy: 0.4909, Precision: 0.3728, Recall: 0.3315, F1: 0.2909
Validation Loss: 1.1253, Accuracy: 0.5650, Precision: 0.3478, Recall: 0.3846, F1: 0.3341
Testing Loss: 1.1300, Accuracy: 0.5857, Precision: 0.5490, Recall: 0.4057, F1: 0.3575
LM Predictions:  [0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.4400, Accuracy: 0.1429, Precision: 0.1274, Recall: 0.1922, F1: 0.1131
Epoch 26/70
Train Loss: 1.3193, Accuracy: 0.4959, Precision: 0.3682, Recall: 0.3363, F1: 0.2972
Validation Loss: 1.1669, Accuracy: 0.5565, Precision: 0.2921, Recall: 0.3715, F1: 0.3205
Testing Loss: 1.1383, Accuracy: 0.5761, Precision: 0.5541, Recall: 0.3885, F1: 0.3419
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1723, Accuracy: 0.0952, Precision: 0.0229, Recall: 0.1600, F1: 0.0400
Epoch 27/70
Train Loss: 1.2888, Accuracy: 0.5167, Precision: 0.3740, Recall: 0.3525, F1: 0.3141
Validation Loss: 1.1084, Accuracy: 0.5736, Precision: 0.5843, Recall: 0.3941, F1: 0.3535
Testing Loss: 1.0861, Accuracy: 0.5978, Precision: 0.5793, Recall: 0.4107, F1: 0.3645
LM Predictions:  [0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 1, 2, 2, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 2.8497, Accuracy: 0.1190, Precision: 0.1094, Recall: 0.1672, F1: 0.0952
Epoch 28/70
Train Loss: 1.2808, Accuracy: 0.5309, Precision: 0.3831, Recall: 0.3665, F1: 0.3329
Validation Loss: 1.2037, Accuracy: 0.5672, Precision: 0.5175, Recall: 0.4042, F1: 0.3838
Testing Loss: 1.1658, Accuracy: 0.5749, Precision: 0.6040, Recall: 0.4044, F1: 0.3818
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4620, Accuracy: 0.0952, Precision: 0.0205, Recall: 0.1600, F1: 0.0364
Epoch 29/70
Train Loss: 1.2337, Accuracy: 0.5440, Precision: 0.5312, Recall: 0.3875, F1: 0.3663
Validation Loss: 1.0850, Accuracy: 0.6354, Precision: 0.6419, Recall: 0.5173, F1: 0.5315
Testing Loss: 1.0259, Accuracy: 0.6449, Precision: 0.6207, Recall: 0.5161, F1: 0.5251
LM Predictions:  [0, 0, 0, 5, 5, 0, 0, 5, 0, 5, 0, 0, 2, 5, 0, 0, 4, 5, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0, 5, 5, 5, 0, 5, 0, 5, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3798, Accuracy: 0.1190, Precision: 0.1944, Recall: 0.1542, F1: 0.0830
Epoch 30/70
Train Loss: 1.1746, Accuracy: 0.5646, Precision: 0.4958, Recall: 0.4145, F1: 0.4020
Validation Loss: 1.0627, Accuracy: 0.6311, Precision: 0.6952, Recall: 0.4885, F1: 0.4944
Testing Loss: 1.0242, Accuracy: 0.6522, Precision: 0.7430, Recall: 0.5005, F1: 0.4948
LM Predictions:  [0, 0, 0, 0, 5, 0, 2, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4483, Accuracy: 0.1667, Precision: 0.2702, Recall: 0.1917, F1: 0.1209
Epoch 31/70
Train Loss: 1.1688, Accuracy: 0.5649, Precision: 0.5063, Recall: 0.4201, F1: 0.4102
Validation Loss: 1.0217, Accuracy: 0.6205, Precision: 0.6570, Recall: 0.4903, F1: 0.4999
Testing Loss: 0.9475, Accuracy: 0.6582, Precision: 0.6760, Recall: 0.5259, F1: 0.5318
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 2, 4, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0707, Accuracy: 0.1667, Precision: 0.2153, Recall: 0.1875, F1: 0.1207
Epoch 32/70
Train Loss: 1.1397, Accuracy: 0.5819, Precision: 0.5096, Recall: 0.4441, F1: 0.4392
Validation Loss: 1.0491, Accuracy: 0.6311, Precision: 0.6448, Recall: 0.5038, F1: 0.5259
Testing Loss: 0.9630, Accuracy: 0.6800, Precision: 0.6815, Recall: 0.5425, F1: 0.5604
LM Predictions:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 5, 0, 0, 0, 2, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 5, 5, 0, 4, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4710, Accuracy: 0.1190, Precision: 0.2667, Recall: 0.1375, F1: 0.0922
Epoch 33/70
Train Loss: 1.1310, Accuracy: 0.5924, Precision: 0.5334, Recall: 0.4515, F1: 0.4475
Validation Loss: 0.9869, Accuracy: 0.6610, Precision: 0.6333, Recall: 0.5545, F1: 0.5739
Testing Loss: 0.8833, Accuracy: 0.7005, Precision: 0.6940, Recall: 0.5835, F1: 0.6071
LM Predictions:  [0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 4, 2, 5, 0, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 5, 5, 2, 4, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2020, Accuracy: 0.0952, Precision: 0.1800, Recall: 0.1042, F1: 0.0833
Epoch 34/70
Train Loss: 1.1209, Accuracy: 0.5926, Precision: 0.5465, Recall: 0.4672, F1: 0.4705
Validation Loss: 0.9523, Accuracy: 0.6759, Precision: 0.6713, Recall: 0.5423, F1: 0.5625
Testing Loss: 0.8748, Accuracy: 0.7150, Precision: 0.7698, Recall: 0.5775, F1: 0.6026
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4171, Accuracy: 0.0952, Precision: 0.1818, Recall: 0.1208, F1: 0.0634
Epoch 35/70
Train Loss: 1.0924, Accuracy: 0.6073, Precision: 0.5537, Recall: 0.4756, F1: 0.4766
Validation Loss: 0.9776, Accuracy: 0.6759, Precision: 0.6972, Recall: 0.5576, F1: 0.5842
Testing Loss: 0.8743, Accuracy: 0.7174, Precision: 0.7557, Recall: 0.5883, F1: 0.6135
LM Predictions:  [0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 2, 2, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2811, Accuracy: 0.1429, Precision: 0.1042, Recall: 0.1750, F1: 0.0916
Epoch 36/70
Train Loss: 1.0756, Accuracy: 0.6085, Precision: 0.5348, Recall: 0.4779, F1: 0.4789
Validation Loss: 0.9603, Accuracy: 0.6631, Precision: 0.6374, Recall: 0.5584, F1: 0.5756
Testing Loss: 0.8794, Accuracy: 0.7065, Precision: 0.7350, Recall: 0.5901, F1: 0.6174
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 0, 0, 2, 5, 0, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 4, 0, 0, 0, 5, 1, 4, 0, 5, 5, 4, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0209, Accuracy: 0.1190, Precision: 0.2276, Recall: 0.1375, F1: 0.0931
Epoch 37/70
Train Loss: 1.0642, Accuracy: 0.6161, Precision: 0.5906, Recall: 0.4938, F1: 0.5021
Validation Loss: 0.9660, Accuracy: 0.6802, Precision: 0.6735, Recall: 0.5741, F1: 0.5975
Testing Loss: 0.8751, Accuracy: 0.7101, Precision: 0.7337, Recall: 0.5988, F1: 0.6275
LM Predictions:  [0, 0, 2, 0, 4, 5, 0, 5, 0, 5, 5, 0, 2, 5, 0, 0, 2, 3, 0, 5, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 0, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1427, Accuracy: 0.1905, Precision: 0.2512, Recall: 0.2125, F1: 0.1642
Epoch 38/70
Train Loss: 1.0310, Accuracy: 0.6275, Precision: 0.5700, Recall: 0.5039, F1: 0.5118
Validation Loss: 0.9030, Accuracy: 0.7079, Precision: 0.6938, Recall: 0.5949, F1: 0.6193
Testing Loss: 0.8256, Accuracy: 0.7343, Precision: 0.7649, Recall: 0.6021, F1: 0.6247
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 2, 0, 0, 5, 0, 0, 5, 0, 1, 0, 0, 5, 0, 5, 1, 0, 0, 5, 5, 0, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2790, Accuracy: 0.1429, Precision: 0.2407, Recall: 0.1602, F1: 0.1257
Epoch 39/70
Train Loss: 1.0135, Accuracy: 0.6348, Precision: 0.5791, Recall: 0.5119, F1: 0.5189
Validation Loss: 0.9273, Accuracy: 0.6908, Precision: 0.7053, Recall: 0.5793, F1: 0.6084
Testing Loss: 0.8584, Accuracy: 0.7150, Precision: 0.7656, Recall: 0.5827, F1: 0.6072
LM Predictions:  [0, 0, 0, 0, 5, 0, 0, 5, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 5, 0, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2401, Accuracy: 0.0952, Precision: 0.1833, Recall: 0.1208, F1: 0.0656
Epoch 40/70
Train Loss: 1.0143, Accuracy: 0.6384, Precision: 0.5868, Recall: 0.5191, F1: 0.5273
Validation Loss: 0.8995, Accuracy: 0.7164, Precision: 0.7401, Recall: 0.6172, F1: 0.6473
Testing Loss: 0.8200, Accuracy: 0.7367, Precision: 0.7816, Recall: 0.6127, F1: 0.6393
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 2, 5, 0, 0, 0, 5, 0, 5, 2, 0, 5, 0, 1, 0, 0, 5, 0, 5, 1, 0, 0, 5, 5, 4, 0, 4, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1928, Accuracy: 0.1667, Precision: 0.2727, Recall: 0.1727, F1: 0.1494
Epoch 41/70
Train Loss: 0.9689, Accuracy: 0.6533, Precision: 0.6123, Recall: 0.5371, F1: 0.5464
Validation Loss: 0.8477, Accuracy: 0.7143, Precision: 0.7000, Recall: 0.6357, F1: 0.6566
Testing Loss: 0.7732, Accuracy: 0.7343, Precision: 0.7356, Recall: 0.6380, F1: 0.6607
LM Predictions:  [0, 0, 0, 0, 4, 5, 0, 5, 0, 5, 5, 5, 2, 5, 0, 0, 2, 3, 0, 5, 2, 0, 5, 0, 0, 0, 0, 5, 0, 5, 1, 0, 0, 5, 5, 4, 0, 4, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1095, Accuracy: 0.1429, Precision: 0.2389, Recall: 0.1417, F1: 0.1386
Epoch 42/70
Train Loss: 0.9734, Accuracy: 0.6469, Precision: 0.5976, Recall: 0.5307, F1: 0.5394
Validation Loss: 0.8845, Accuracy: 0.7207, Precision: 0.7250, Recall: 0.6241, F1: 0.6527
Testing Loss: 0.7941, Accuracy: 0.7379, Precision: 0.7463, Recall: 0.6215, F1: 0.6482
LM Predictions:  [0, 0, 0, 0, 4, 5, 0, 5, 0, 5, 5, 0, 2, 5, 2, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 5, 5, 5, 0, 1, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4037, Accuracy: 0.1190, Precision: 0.0845, Recall: 0.1542, F1: 0.0779
Epoch 43/70
Train Loss: 0.9728, Accuracy: 0.6581, Precision: 0.6079, Recall: 0.5440, F1: 0.5564
Validation Loss: 0.8317, Accuracy: 0.7164, Precision: 0.7215, Recall: 0.6203, F1: 0.6491
Testing Loss: 0.7586, Accuracy: 0.7476, Precision: 0.7600, Recall: 0.6285, F1: 0.6549
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 2, 5, 0, 0, 0, 3, 0, 5, 2, 0, 5, 0, 0, 0, 0, 5, 0, 5, 1, 0, 0, 5, 5, 4, 0, 1, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3097, Accuracy: 0.1190, Precision: 0.1884, Recall: 0.1375, F1: 0.0968
Epoch 44/70
Train Loss: 0.9348, Accuracy: 0.6754, Precision: 0.6302, Recall: 0.5617, F1: 0.5730
Validation Loss: 0.7682, Accuracy: 0.7569, Precision: 0.7879, Recall: 0.6593, F1: 0.6950
Testing Loss: 0.7195, Accuracy: 0.7548, Precision: 0.7569, Recall: 0.6460, F1: 0.6668
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 0, 0, 2, 0, 0, 0, 0, 3, 0, 5, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 4, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4404, Accuracy: 0.1667, Precision: 0.2191, Recall: 0.1917, F1: 0.1301
Epoch 45/70
Train Loss: 0.9425, Accuracy: 0.6682, Precision: 0.6231, Recall: 0.5530, F1: 0.5647
Validation Loss: 0.8238, Accuracy: 0.7612, Precision: 0.7553, Recall: 0.6581, F1: 0.6867
Testing Loss: 0.7638, Accuracy: 0.7476, Precision: 0.7690, Recall: 0.6330, F1: 0.6635
LM Predictions:  [0, 0, 0, 0, 3, 0, 0, 5, 5, 5, 5, 0, 2, 5, 2, 0, 0, 3, 0, 5, 2, 0, 5, 0, 0, 5, 0, 5, 0, 5, 1, 0, 0, 5, 5, 5, 0, 1, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4558, Accuracy: 0.1190, Precision: 0.1096, Recall: 0.1417, F1: 0.0972
Epoch 46/70
Train Loss: 0.9265, Accuracy: 0.6718, Precision: 0.6137, Recall: 0.5546, F1: 0.5647
Validation Loss: 0.8557, Accuracy: 0.7207, Precision: 0.7306, Recall: 0.6339, F1: 0.6618
Testing Loss: 0.7546, Accuracy: 0.7536, Precision: 0.7647, Recall: 0.6452, F1: 0.6760
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 5, 5, 5, 0, 5, 1, 0, 0, 5, 5, 5, 0, 5, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.8546, Accuracy: 0.0952, Precision: 0.1905, Recall: 0.1208, F1: 0.0755
Epoch 47/70
Train Loss: 0.9034, Accuracy: 0.6856, Precision: 0.6359, Recall: 0.5709, F1: 0.5820
Validation Loss: 0.8255, Accuracy: 0.7548, Precision: 0.7420, Recall: 0.6575, F1: 0.6707
Testing Loss: 0.6787, Accuracy: 0.7754, Precision: 0.7677, Recall: 0.6684, F1: 0.6859
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 2, 0, 2, 0, 0, 3, 0, 5, 2, 0, 5, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 5, 4, 3, 5, 0, 3, 5, 2]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1390, Accuracy: 0.1667, Precision: 0.1790, Recall: 0.1917, F1: 0.1267
Epoch 48/70
Train Loss: 0.8857, Accuracy: 0.6903, Precision: 0.6395, Recall: 0.5757, F1: 0.5866
Validation Loss: 0.8045, Accuracy: 0.7612, Precision: 0.7659, Recall: 0.6611, F1: 0.6885
Testing Loss: 0.6443, Accuracy: 0.7790, Precision: 0.7999, Recall: 0.6611, F1: 0.6826
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 2, 0, 0, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 5, 4, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4781, Accuracy: 0.1429, Precision: 0.2738, Recall: 0.1708, F1: 0.1052
Epoch 49/70
Train Loss: 0.8880, Accuracy: 0.6865, Precision: 0.6416, Recall: 0.5749, F1: 0.5855
Validation Loss: 0.7628, Accuracy: 0.7719, Precision: 0.7750, Recall: 0.6731, F1: 0.7013
Testing Loss: 0.6779, Accuracy: 0.7742, Precision: 0.7940, Recall: 0.6543, F1: 0.6788
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 4, 5, 5, 0, 2, 5, 2, 0, 0, 0, 0, 5, 2, 0, 5, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 5, 0, 4, 3, 4, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1179, Accuracy: 0.1905, Precision: 0.1957, Recall: 0.2042, F1: 0.1468
Epoch 50/70
Train Loss: 0.8622, Accuracy: 0.6993, Precision: 0.6531, Recall: 0.5944, F1: 0.6064
Validation Loss: 0.7809, Accuracy: 0.7441, Precision: 0.7361, Recall: 0.6595, F1: 0.6842
Testing Loss: 0.6413, Accuracy: 0.7814, Precision: 0.7971, Recall: 0.6735, F1: 0.7002
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 5, 3, 5, 2, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 5, 2, 0, 0, 5, 5, 4, 0, 5, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6743, Accuracy: 0.0714, Precision: 0.0985, Recall: 0.0833, F1: 0.0525
Epoch 51/70
Train Loss: 0.8407, Accuracy: 0.7078, Precision: 0.6601, Recall: 0.6018, F1: 0.6131
Validation Loss: 0.7595, Accuracy: 0.7740, Precision: 0.7752, Recall: 0.6849, F1: 0.7074
Testing Loss: 0.6361, Accuracy: 0.7899, Precision: 0.8158, Recall: 0.6769, F1: 0.6916
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 2, 0, 2, 0, 0, 3, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 5, 5, 4, 0, 4, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1095, Accuracy: 0.1667, Precision: 0.1944, Recall: 0.1875, F1: 0.1276
Epoch 52/70
Train Loss: 0.8163, Accuracy: 0.7180, Precision: 0.6592, Recall: 0.6096, F1: 0.6174
Validation Loss: 0.7456, Accuracy: 0.7719, Precision: 0.7543, Recall: 0.6992, F1: 0.7194
Testing Loss: 0.6230, Accuracy: 0.7959, Precision: 0.7902, Recall: 0.7145, F1: 0.7354
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 2, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 5, 0, 5, 0, 5, 5, 4, 0, 4, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4410, Accuracy: 0.1429, Precision: 0.2717, Recall: 0.1542, F1: 0.1204
Epoch 53/70
Train Loss: 0.8144, Accuracy: 0.7190, Precision: 0.6647, Recall: 0.6189, F1: 0.6294
Validation Loss: 0.7083, Accuracy: 0.7889, Precision: 0.7855, Recall: 0.7052, F1: 0.7316
Testing Loss: 0.6208, Accuracy: 0.8019, Precision: 0.8121, Recall: 0.6922, F1: 0.7165
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 5, 5, 4, 0, 0, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1689, Accuracy: 0.1429, Precision: 0.2756, Recall: 0.1708, F1: 0.1078
Epoch 54/70
Train Loss: 0.7862, Accuracy: 0.7313, Precision: 0.6821, Recall: 0.6196, F1: 0.6310
Validation Loss: 0.7237, Accuracy: 0.7740, Precision: 0.7451, Recall: 0.7241, F1: 0.7315
Testing Loss: 0.6059, Accuracy: 0.8176, Precision: 0.8084, Recall: 0.7527, F1: 0.7707
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 5, 4, 5, 0, 5, 5, 4, 0, 1, 0, 4, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4666, Accuracy: 0.1190, Precision: 0.1051, Recall: 0.1333, F1: 0.0833
Epoch 55/70
Train Loss: 0.7779, Accuracy: 0.7325, Precision: 0.6662, Recall: 0.6229, F1: 0.6328
Validation Loss: 0.7406, Accuracy: 0.7740, Precision: 0.7587, Recall: 0.7048, F1: 0.7236
Testing Loss: 0.6295, Accuracy: 0.7995, Precision: 0.8106, Recall: 0.7084, F1: 0.7348
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 5, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 5, 5, 4, 0, 1, 0, 3, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5335, Accuracy: 0.1190, Precision: 0.1080, Recall: 0.1500, F1: 0.0694
Epoch 56/70
Train Loss: 0.7685, Accuracy: 0.7309, Precision: 0.6759, Recall: 0.6281, F1: 0.6407
Validation Loss: 0.6989, Accuracy: 0.8017, Precision: 0.7819, Recall: 0.7373, F1: 0.7543
Testing Loss: 0.5614, Accuracy: 0.8140, Precision: 0.8065, Recall: 0.7211, F1: 0.7380
LM Predictions:  [0, 3, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 3, 0, 2, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 4, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3921, Accuracy: 0.1429, Precision: 0.1389, Recall: 0.1667, F1: 0.0973
Epoch 57/70
Train Loss: 0.7667, Accuracy: 0.7361, Precision: 0.6894, Recall: 0.6326, F1: 0.6447
Validation Loss: 0.7129, Accuracy: 0.7953, Precision: 0.7821, Recall: 0.7274, F1: 0.7457
Testing Loss: 0.5962, Accuracy: 0.8043, Precision: 0.8029, Recall: 0.7151, F1: 0.7366
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7863, Accuracy: 0.0952, Precision: 0.0230, Recall: 0.1333, F1: 0.0392
Epoch 58/70
Train Loss: 0.7613, Accuracy: 0.7399, Precision: 0.6878, Recall: 0.6410, F1: 0.6530
Validation Loss: 0.7233, Accuracy: 0.7846, Precision: 0.7903, Recall: 0.7063, F1: 0.7290
Testing Loss: 0.6125, Accuracy: 0.8080, Precision: 0.8244, Recall: 0.7120, F1: 0.7329
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4633, Accuracy: 0.0952, Precision: 0.0222, Recall: 0.1333, F1: 0.0381
Epoch 59/70
Train Loss: 0.7367, Accuracy: 0.7484, Precision: 0.6916, Recall: 0.6422, F1: 0.6545
Validation Loss: 0.7150, Accuracy: 0.7783, Precision: 0.7879, Recall: 0.6906, F1: 0.7209
Testing Loss: 0.6155, Accuracy: 0.7983, Precision: 0.8457, Recall: 0.6998, F1: 0.7316
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 4, 0, 5, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6590, Accuracy: 0.1190, Precision: 0.1063, Recall: 0.1500, F1: 0.0670
Epoch 60/70
Train Loss: 0.7396, Accuracy: 0.7363, Precision: 0.6775, Recall: 0.6355, F1: 0.6459
Validation Loss: 0.6975, Accuracy: 0.7889, Precision: 0.7566, Recall: 0.7173, F1: 0.7323
Testing Loss: 0.6090, Accuracy: 0.8056, Precision: 0.8051, Recall: 0.7147, F1: 0.7379
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 3, 0, 2, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 5, 1, 5, 0, 5, 5, 4, 3, 4, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.3059, Accuracy: 0.1190, Precision: 0.1349, Recall: 0.1333, F1: 0.0897
Epoch 61/70
Train Loss: 0.7232, Accuracy: 0.7543, Precision: 0.7004, Recall: 0.6567, F1: 0.6684
Validation Loss: 0.7037, Accuracy: 0.7761, Precision: 0.7726, Recall: 0.7303, F1: 0.7443
Testing Loss: 0.5691, Accuracy: 0.8140, Precision: 0.8248, Recall: 0.7437, F1: 0.7730
LM Predictions:  [0, 0, 0, 5, 4, 0, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 0, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.7835, Accuracy: 0.0714, Precision: 0.0217, Recall: 0.1000, F1: 0.0357
Epoch 62/70
Train Loss: 0.7181, Accuracy: 0.7546, Precision: 0.6942, Recall: 0.6590, F1: 0.6700
Validation Loss: 0.6258, Accuracy: 0.7996, Precision: 0.7898, Recall: 0.7303, F1: 0.7535
Testing Loss: 0.5598, Accuracy: 0.8164, Precision: 0.8172, Recall: 0.7276, F1: 0.7544
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 5, 5, 4, 0, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4385, Accuracy: 0.0952, Precision: 0.1019, Recall: 0.1167, F1: 0.0590
Epoch 63/70
Train Loss: 0.6899, Accuracy: 0.7591, Precision: 0.7040, Recall: 0.6618, F1: 0.6747
Validation Loss: 0.6475, Accuracy: 0.8102, Precision: 0.7891, Recall: 0.7509, F1: 0.7671
Testing Loss: 0.5329, Accuracy: 0.8249, Precision: 0.8094, Recall: 0.7647, F1: 0.7810
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 5, 5, 5, 0, 0, 5, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 5, 5, 0, 0, 5, 5, 4, 3, 5, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4464, Accuracy: 0.0952, Precision: 0.1061, Recall: 0.1167, F1: 0.0648
Epoch 64/70
Train Loss: 0.6999, Accuracy: 0.7626, Precision: 0.7144, Recall: 0.6689, F1: 0.6823
Validation Loss: 0.5987, Accuracy: 0.8230, Precision: 0.8057, Recall: 0.7489, F1: 0.7710
Testing Loss: 0.5288, Accuracy: 0.8164, Precision: 0.8116, Recall: 0.7329, F1: 0.7573
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 0, 0, 2, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 0, 0, 5, 0, 5, 5, 5, 0, 0, 0, 1, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4864, Accuracy: 0.0952, Precision: 0.0256, Recall: 0.1333, F1: 0.0430
Epoch 65/70
Train Loss: 0.6941, Accuracy: 0.7614, Precision: 0.7189, Recall: 0.6666, F1: 0.6818
Validation Loss: 0.6369, Accuracy: 0.8038, Precision: 0.8099, Recall: 0.7169, F1: 0.7454
Testing Loss: 0.5618, Accuracy: 0.8116, Precision: 0.8527, Recall: 0.7108, F1: 0.7332
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.5171, Accuracy: 0.0952, Precision: 0.0208, Recall: 0.1333, F1: 0.0360
Epoch 66/70
Train Loss: 0.6900, Accuracy: 0.7702, Precision: 0.7195, Recall: 0.6758, F1: 0.6875
Validation Loss: 0.6492, Accuracy: 0.8102, Precision: 0.8310, Recall: 0.7127, F1: 0.7450
Testing Loss: 0.5810, Accuracy: 0.8092, Precision: 0.8572, Recall: 0.7032, F1: 0.7307
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 3, 0, 0, 0, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.4386, Accuracy: 0.0952, Precision: 0.0222, Recall: 0.1333, F1: 0.0381
Epoch 67/70
Train Loss: 0.6761, Accuracy: 0.7659, Precision: 0.7184, Recall: 0.6729, F1: 0.6867
Validation Loss: 0.6012, Accuracy: 0.8145, Precision: 0.7788, Recall: 0.7401, F1: 0.7533
Testing Loss: 0.4983, Accuracy: 0.8442, Precision: 0.8306, Recall: 0.7640, F1: 0.7785
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 3, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 5, 5, 0, 0, 4, 0, 0, 5, 5, 0, 3, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.2603, Accuracy: 0.1429, Precision: 0.1378, Recall: 0.1667, F1: 0.0957
Epoch 68/70
Train Loss: 0.6539, Accuracy: 0.7766, Precision: 0.7174, Recall: 0.6770, F1: 0.6892
Validation Loss: 0.6372, Accuracy: 0.8209, Precision: 0.7942, Recall: 0.7600, F1: 0.7687
Testing Loss: 0.5086, Accuracy: 0.8333, Precision: 0.8208, Recall: 0.7524, F1: 0.7603
LM Predictions:  [0, 0, 0, 0, 4, 0, 3, 5, 5, 4, 5, 0, 3, 0, 5, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 5, 5, 4, 3, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.0704, Accuracy: 0.1429, Precision: 0.1227, Recall: 0.1500, F1: 0.1037
Epoch 69/70
Train Loss: 0.6536, Accuracy: 0.7811, Precision: 0.7263, Recall: 0.6934, F1: 0.7050
Validation Loss: 0.6751, Accuracy: 0.8102, Precision: 0.8008, Recall: 0.7232, F1: 0.7454
Testing Loss: 0.5365, Accuracy: 0.8261, Precision: 0.8539, Recall: 0.7292, F1: 0.7476
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 5, 0, 2, 0, 0, 0, 0, 5, 0, 5, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 5, 5, 4, 3, 4, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.1717, Accuracy: 0.1905, Precision: 0.3183, Recall: 0.2042, F1: 0.1529
Epoch 70/70
Train Loss: 0.6436, Accuracy: 0.7792, Precision: 0.7273, Recall: 0.6916, F1: 0.7041
Validation Loss: 0.6960, Accuracy: 0.8145, Precision: 0.8482, Recall: 0.7126, F1: 0.7428
Testing Loss: 0.5678, Accuracy: 0.8116, Precision: 0.8461, Recall: 0.7011, F1: 0.7196
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 5, 4, 3, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6354, Accuracy: 0.1429, Precision: 0.1341, Recall: 0.1667, F1: 0.0905
Label Memorization Analysis: 
LM Predictions:  [0, 0, 0, 0, 4, 0, 0, 5, 0, 5, 0, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0, 4, 0, 0, 0, 5, 4, 3, 0, 0, 5, 5, 0]
LM Labels:  [0, 1, 2, 1, 1, 1, 0, 4, 4, 0, 3, 0, 2, 4, 3, 3, 2, 4, 3, 3, 3, 4, 3, 1, 1, 2, 4, 4, 2, 0, 4, 3, 3, 2, 1, 4, 1, 4, 3, 2, 1, 2]
LM Loss: 3.6354, Accuracy: 0.1429, Precision: 0.1341, Recall: 0.1667, F1: 0.0905

