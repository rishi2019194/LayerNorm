---------------------------------------------------------------------------
Results for seed:  28
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 3: 486
  Label 1: 115
  Label 5: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 3: 60
  Label 0: 3
  Label 5: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 5: 29
  Label 3: 58
28
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 4: 973
  Label 2: 1106
  Label 3: 491
  Label 1: 119
  Label 5: 116
  Label 0: 53
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.6007, Accuracy: 0.3422, Precision: 0.1539, Recall: 0.1667, F1: 0.1536
Validation Loss: 1.4229, Accuracy: 0.3920, Precision: 0.1390, Recall: 0.1770, F1: 0.1350
Testing Loss: 1.4307, Accuracy: 0.3750, Precision: 0.1215, Recall: 0.1734, F1: 0.1267
LM Predictions:  [2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0278, Accuracy: 0.2500, Precision: 0.1147, Recall: 0.2000, F1: 0.1150
Epoch 2/70
Train Loss: 1.4010, Accuracy: 0.3726, Precision: 0.1641, Recall: 0.1708, F1: 0.1493
Validation Loss: 1.4146, Accuracy: 0.3523, Precision: 0.1220, Recall: 0.1725, F1: 0.1229
Testing Loss: 1.4317, Accuracy: 0.3564, Precision: 0.1247, Recall: 0.1671, F1: 0.1266
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0165, Accuracy: 0.2857, Precision: 0.1143, Recall: 0.2286, F1: 0.1429
Epoch 3/70
Train Loss: 1.4002, Accuracy: 0.3744, Precision: 0.1453, Recall: 0.1695, F1: 0.1445
Validation Loss: 1.4329, Accuracy: 0.3807, Precision: 0.1345, Recall: 0.1835, F1: 0.1440
Testing Loss: 1.4495, Accuracy: 0.4069, Precision: 0.1444, Recall: 0.1903, F1: 0.1544
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0917, Accuracy: 0.2500, Precision: 0.0857, Recall: 0.2000, F1: 0.1143
Epoch 4/70
Train Loss: 1.3957, Accuracy: 0.3744, Precision: 0.1374, Recall: 0.1690, F1: 0.1426
Validation Loss: 1.4353, Accuracy: 0.3835, Precision: 0.1196, Recall: 0.1695, F1: 0.0980
Testing Loss: 1.4618, Accuracy: 0.3617, Precision: 0.0606, Recall: 0.1667, F1: 0.0889
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1220, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 5/70
Train Loss: 1.3867, Accuracy: 0.3842, Precision: 0.1448, Recall: 0.1724, F1: 0.1431
Validation Loss: 1.4375, Accuracy: 0.4091, Precision: 0.1365, Recall: 0.1895, F1: 0.1570
Testing Loss: 1.4554, Accuracy: 0.4149, Precision: 0.1391, Recall: 0.1928, F1: 0.1585
LM Predictions:  [2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1080, Accuracy: 0.2857, Precision: 0.1134, Recall: 0.2286, F1: 0.1500
Epoch 6/70
Train Loss: 1.3863, Accuracy: 0.3828, Precision: 0.1644, Recall: 0.1726, F1: 0.1449
Validation Loss: 1.4438, Accuracy: 0.4091, Precision: 0.1796, Recall: 0.1827, F1: 0.1256
Testing Loss: 1.4605, Accuracy: 0.3777, Precision: 0.1305, Recall: 0.1743, F1: 0.1130
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0801, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 7/70
Train Loss: 1.3775, Accuracy: 0.3989, Precision: 0.1308, Recall: 0.1791, F1: 0.1486
Validation Loss: 1.4560, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4893, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1439, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 8/70
Train Loss: 1.3809, Accuracy: 0.3859, Precision: 0.1259, Recall: 0.1731, F1: 0.1429
Validation Loss: 1.4174, Accuracy: 0.3807, Precision: 0.2298, Recall: 0.1681, F1: 0.0944
Testing Loss: 1.4530, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0943, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 9/70
Train Loss: 1.3797, Accuracy: 0.3870, Precision: 0.1588, Recall: 0.1727, F1: 0.1408
Validation Loss: 1.4495, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4829, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0760, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 10/70
Train Loss: 1.3770, Accuracy: 0.3775, Precision: 0.2058, Recall: 0.1693, F1: 0.1397
Validation Loss: 1.4237, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4550, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0316, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 11/70
Train Loss: 1.3801, Accuracy: 0.3821, Precision: 0.1249, Recall: 0.1720, F1: 0.1431
Validation Loss: 1.4495, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4851, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0848, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 12/70
Train Loss: 1.3773, Accuracy: 0.3887, Precision: 0.1271, Recall: 0.1734, F1: 0.1409
Validation Loss: 1.4149, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4472, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1028, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 13/70
Train Loss: 1.3785, Accuracy: 0.3884, Precision: 0.1268, Recall: 0.1735, F1: 0.1418
Validation Loss: 1.4268, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4734, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0476, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 14/70
Train Loss: 1.3748, Accuracy: 0.3887, Precision: 0.1267, Recall: 0.1740, F1: 0.1431
Validation Loss: 1.4171, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4509, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0804, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 15/70
Train Loss: 1.3706, Accuracy: 0.3961, Precision: 0.1296, Recall: 0.1775, F1: 0.1465
Validation Loss: 1.4242, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4593, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0258, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 16/70
Train Loss: 1.3765, Accuracy: 0.3884, Precision: 0.1264, Recall: 0.1732, F1: 0.1407
Validation Loss: 1.4202, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4524, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1009, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 17/70
Train Loss: 1.3785, Accuracy: 0.3957, Precision: 0.2122, Recall: 0.1758, F1: 0.1406
Validation Loss: 1.4117, Accuracy: 0.3750, Precision: 0.1019, Recall: 0.1659, F1: 0.0988
Testing Loss: 1.4466, Accuracy: 0.3750, Precision: 0.1615, Recall: 0.1730, F1: 0.1036
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9909, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 18/70
Train Loss: 1.3760, Accuracy: 0.3887, Precision: 0.2927, Recall: 0.1735, F1: 0.1411
Validation Loss: 1.4332, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4697, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1122, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 19/70
Train Loss: 1.3749, Accuracy: 0.3957, Precision: 0.1287, Recall: 0.1758, F1: 0.1407
Validation Loss: 1.4118, Accuracy: 0.3949, Precision: 0.1475, Recall: 0.1912, F1: 0.1478
Testing Loss: 1.4438, Accuracy: 0.4202, Precision: 0.1476, Recall: 0.1967, F1: 0.1576
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0351, Accuracy: 0.2500, Precision: 0.0879, Recall: 0.2000, F1: 0.1135
Epoch 20/70
Train Loss: 1.3727, Accuracy: 0.3996, Precision: 0.1309, Recall: 0.1795, F1: 0.1488
Validation Loss: 1.4099, Accuracy: 0.3750, Precision: 0.0627, Recall: 0.1654, F1: 0.0909
Testing Loss: 1.4400, Accuracy: 0.3644, Precision: 0.1163, Recall: 0.1679, F1: 0.0915
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0902, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 21/70
Train Loss: 1.3754, Accuracy: 0.3870, Precision: 0.1270, Recall: 0.1732, F1: 0.1423
Validation Loss: 1.4095, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4463, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0468, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 22/70
Train Loss: 1.3695, Accuracy: 0.3996, Precision: 0.1306, Recall: 0.1781, F1: 0.1446
Validation Loss: 1.4145, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4459, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0818, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 23/70
Train Loss: 1.3715, Accuracy: 0.3940, Precision: 0.2960, Recall: 0.1764, F1: 0.1451
Validation Loss: 1.4336, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4674, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0354, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 24/70
Train Loss: 1.3727, Accuracy: 0.4013, Precision: 0.1313, Recall: 0.1791, F1: 0.1458
Validation Loss: 1.3950, Accuracy: 0.3778, Precision: 0.1462, Recall: 0.1668, F1: 0.0939
Testing Loss: 1.4283, Accuracy: 0.3644, Precision: 0.1439, Recall: 0.1679, F1: 0.0914
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0303, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 25/70
Train Loss: 1.3696, Accuracy: 0.3943, Precision: 0.1795, Recall: 0.1772, F1: 0.1476
Validation Loss: 1.4239, Accuracy: 0.3920, Precision: 0.1572, Recall: 0.1738, F1: 0.1064
Testing Loss: 1.4721, Accuracy: 0.3697, Precision: 0.1444, Recall: 0.1705, F1: 0.1006
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0570, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 26/70
Train Loss: 1.3617, Accuracy: 0.4143, Precision: 0.1868, Recall: 0.1866, F1: 0.1563
Validation Loss: 1.4106, Accuracy: 0.3920, Precision: 0.1413, Recall: 0.1890, F1: 0.1484
Testing Loss: 1.4294, Accuracy: 0.3777, Precision: 0.1323, Recall: 0.1768, F1: 0.1400
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0862, Accuracy: 0.2500, Precision: 0.0922, Recall: 0.2000, F1: 0.1133
Epoch 27/70
Train Loss: 1.3610, Accuracy: 0.4101, Precision: 0.1773, Recall: 0.1852, F1: 0.1554
Validation Loss: 1.3971, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4267, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9891, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 28/70
Train Loss: 1.3711, Accuracy: 0.3985, Precision: 0.2979, Recall: 0.1793, F1: 0.1495
Validation Loss: 1.3938, Accuracy: 0.3835, Precision: 0.1882, Recall: 0.1697, F1: 0.0997
Testing Loss: 1.4272, Accuracy: 0.3697, Precision: 0.1446, Recall: 0.1704, F1: 0.0968
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9825, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 29/70
Train Loss: 1.3689, Accuracy: 0.3957, Precision: 0.1296, Recall: 0.1774, F1: 0.1465
Validation Loss: 1.4572, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4919, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0863, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 30/70
Train Loss: 1.3691, Accuracy: 0.4031, Precision: 0.2998, Recall: 0.1808, F1: 0.1496
Validation Loss: 1.4005, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4357, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0144, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 31/70
Train Loss: 1.3663, Accuracy: 0.3908, Precision: 0.1264, Recall: 0.1743, F1: 0.1416
Validation Loss: 1.4042, Accuracy: 0.4347, Precision: 0.1444, Recall: 0.2032, F1: 0.1688
Testing Loss: 1.4205, Accuracy: 0.4415, Precision: 0.1468, Recall: 0.2055, F1: 0.1712
LM Predictions:  [2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0675, Accuracy: 0.2857, Precision: 0.1128, Recall: 0.2286, F1: 0.1509
Epoch 32/70
Train Loss: 1.3642, Accuracy: 0.3989, Precision: 0.1728, Recall: 0.1795, F1: 0.1499
Validation Loss: 1.3989, Accuracy: 0.3807, Precision: 0.1260, Recall: 0.1689, F1: 0.1060
Testing Loss: 1.4288, Accuracy: 0.3644, Precision: 0.1272, Recall: 0.1680, F1: 0.0976
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0308, Accuracy: 0.2857, Precision: 0.1227, Recall: 0.2286, F1: 0.1275
Epoch 33/70
Train Loss: 1.3591, Accuracy: 0.4167, Precision: 0.1399, Recall: 0.1864, F1: 0.1534
Validation Loss: 1.3958, Accuracy: 0.3636, Precision: 0.1566, Recall: 0.1801, F1: 0.1137
Testing Loss: 1.4128, Accuracy: 0.3936, Precision: 0.1743, Recall: 0.1849, F1: 0.1305
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0075, Accuracy: 0.2857, Precision: 0.1538, Recall: 0.2286, F1: 0.1293
Epoch 34/70
Train Loss: 1.3612, Accuracy: 0.4034, Precision: 0.1335, Recall: 0.1825, F1: 0.1533
Validation Loss: 1.4058, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4398, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9846, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 35/70
Train Loss: 1.3593, Accuracy: 0.4052, Precision: 0.1979, Recall: 0.1837, F1: 0.1558
Validation Loss: 1.3988, Accuracy: 0.4517, Precision: 0.1498, Recall: 0.2107, F1: 0.1751
Testing Loss: 1.4160, Accuracy: 0.4495, Precision: 0.1498, Recall: 0.2093, F1: 0.1746
LM Predictions:  [2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0255, Accuracy: 0.3571, Precision: 0.1429, Recall: 0.2857, F1: 0.1905
Epoch 36/70
Train Loss: 1.3578, Accuracy: 0.4055, Precision: 0.1791, Recall: 0.1823, F1: 0.1519
Validation Loss: 1.3863, Accuracy: 0.4631, Precision: 0.1561, Recall: 0.2130, F1: 0.1747
Testing Loss: 1.4100, Accuracy: 0.4176, Precision: 0.1405, Recall: 0.1936, F1: 0.1537
LM Predictions:  [2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0266, Accuracy: 0.3214, Precision: 0.1303, Recall: 0.2571, F1: 0.1581
Epoch 37/70
Train Loss: 1.3543, Accuracy: 0.4097, Precision: 0.1936, Recall: 0.1848, F1: 0.1554
Validation Loss: 1.3944, Accuracy: 0.3580, Precision: 0.1325, Recall: 0.1750, F1: 0.1265
Testing Loss: 1.4149, Accuracy: 0.4255, Precision: 0.1649, Recall: 0.1993, F1: 0.1583
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0409, Accuracy: 0.2857, Precision: 0.1083, Recall: 0.2286, F1: 0.1267
Epoch 38/70
Train Loss: 1.3618, Accuracy: 0.3919, Precision: 0.1868, Recall: 0.1771, F1: 0.1494
Validation Loss: 1.4135, Accuracy: 0.3807, Precision: 0.1466, Recall: 0.1683, F1: 0.0970
Testing Loss: 1.4431, Accuracy: 0.3644, Precision: 0.2271, Recall: 0.1679, F1: 0.0912
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0657, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 39/70
Train Loss: 1.3553, Accuracy: 0.4195, Precision: 0.1943, Recall: 0.1911, F1: 0.1646
Validation Loss: 1.3750, Accuracy: 0.4233, Precision: 0.1534, Recall: 0.1908, F1: 0.1439
Testing Loss: 1.4022, Accuracy: 0.3777, Precision: 0.1259, Recall: 0.1745, F1: 0.1211
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0438, Accuracy: 0.2857, Precision: 0.1227, Recall: 0.2286, F1: 0.1275
Epoch 40/70
Train Loss: 1.3540, Accuracy: 0.4220, Precision: 0.1862, Recall: 0.1935, F1: 0.1686
Validation Loss: 1.3834, Accuracy: 0.3977, Precision: 0.1664, Recall: 0.1773, F1: 0.1194
Testing Loss: 1.4223, Accuracy: 0.3963, Precision: 0.2807, Recall: 0.1879, F1: 0.1337
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9501, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 41/70
Train Loss: 1.3446, Accuracy: 0.4206, Precision: 0.2015, Recall: 0.1954, F1: 0.1753
Validation Loss: 1.3717, Accuracy: 0.4261, Precision: 0.1522, Recall: 0.1924, F1: 0.1467
Testing Loss: 1.4030, Accuracy: 0.3963, Precision: 0.1411, Recall: 0.1832, F1: 0.1328
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9970, Accuracy: 0.2857, Precision: 0.1083, Recall: 0.2286, F1: 0.1267
Epoch 42/70
Train Loss: 1.3317, Accuracy: 0.4430, Precision: 0.2074, Recall: 0.2077, F1: 0.1885
Validation Loss: 1.3839, Accuracy: 0.4062, Precision: 0.1531, Recall: 0.1814, F1: 0.1249
Testing Loss: 1.4069, Accuracy: 0.3963, Precision: 0.1877, Recall: 0.1830, F1: 0.1235
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9864, Accuracy: 0.2500, Precision: 0.0560, Recall: 0.2000, F1: 0.0875
Epoch 43/70
Train Loss: 1.3299, Accuracy: 0.4475, Precision: 0.2164, Recall: 0.2114, F1: 0.1941
Validation Loss: 1.4149, Accuracy: 0.3778, Precision: 0.0633, Recall: 0.1667, F1: 0.0918
Testing Loss: 1.4367, Accuracy: 0.3777, Precision: 0.3394, Recall: 0.1807, F1: 0.1157
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0449, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 44/70
Train Loss: 1.3332, Accuracy: 0.4412, Precision: 0.2102, Recall: 0.2075, F1: 0.1897
Validation Loss: 1.3748, Accuracy: 0.4631, Precision: 0.1690, Recall: 0.2123, F1: 0.1750
Testing Loss: 1.3845, Accuracy: 0.4335, Precision: 0.1524, Recall: 0.2009, F1: 0.1588
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9765, Accuracy: 0.3214, Precision: 0.1303, Recall: 0.2571, F1: 0.1581
Epoch 45/70
Train Loss: 1.3136, Accuracy: 0.4507, Precision: 0.2246, Recall: 0.2143, F1: 0.1985
Validation Loss: 1.4020, Accuracy: 0.4489, Precision: 0.1551, Recall: 0.2059, F1: 0.1684
Testing Loss: 1.4030, Accuracy: 0.4415, Precision: 0.1507, Recall: 0.2048, F1: 0.1646
LM Predictions:  [2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0595, Accuracy: 0.3214, Precision: 0.1429, Recall: 0.2571, F1: 0.1714
Epoch 46/70
Train Loss: 1.3217, Accuracy: 0.4531, Precision: 0.2201, Recall: 0.2173, F1: 0.2031
Validation Loss: 1.3642, Accuracy: 0.4688, Precision: 0.1698, Recall: 0.2148, F1: 0.1770
Testing Loss: 1.3752, Accuracy: 0.4441, Precision: 0.2578, Recall: 0.2107, F1: 0.1756
LM Predictions:  [2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0490, Accuracy: 0.2857, Precision: 0.0970, Recall: 0.2286, F1: 0.1273
Epoch 47/70
Train Loss: 1.3047, Accuracy: 0.4580, Precision: 0.2293, Recall: 0.2221, F1: 0.2100
Validation Loss: 1.3734, Accuracy: 0.4403, Precision: 0.1921, Recall: 0.1987, F1: 0.1530
Testing Loss: 1.3929, Accuracy: 0.4069, Precision: 0.2912, Recall: 0.1930, F1: 0.1463
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0393, Accuracy: 0.2500, Precision: 0.0538, Recall: 0.2000, F1: 0.0848
Epoch 48/70
Train Loss: 1.3126, Accuracy: 0.4647, Precision: 0.2285, Recall: 0.2257, F1: 0.2131
Validation Loss: 1.3497, Accuracy: 0.4489, Precision: 0.1594, Recall: 0.2057, F1: 0.1695
Testing Loss: 1.3678, Accuracy: 0.4681, Precision: 0.2575, Recall: 0.2236, F1: 0.1918
LM Predictions:  [2, 2, 2, 2, 3, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9934, Accuracy: 0.2857, Precision: 0.1238, Recall: 0.2286, F1: 0.1473
Epoch 49/70
Train Loss: 1.3160, Accuracy: 0.4475, Precision: 0.2280, Recall: 0.2157, F1: 0.2026
Validation Loss: 1.3429, Accuracy: 0.4602, Precision: 0.2299, Recall: 0.2240, F1: 0.2034
Testing Loss: 1.3525, Accuracy: 0.4628, Precision: 0.2495, Recall: 0.2268, F1: 0.2086
LM Predictions:  [2, 2, 4, 2, 3, 4, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 3, 2, 4, 2, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0351, Accuracy: 0.2143, Precision: 0.0929, Recall: 0.1714, F1: 0.1203
Epoch 50/70
Train Loss: 1.2976, Accuracy: 0.4801, Precision: 0.2458, Recall: 0.2324, F1: 0.2192
Validation Loss: 1.3594, Accuracy: 0.4460, Precision: 0.1540, Recall: 0.2125, F1: 0.1737
Testing Loss: 1.3624, Accuracy: 0.4787, Precision: 0.2632, Recall: 0.2300, F1: 0.2053
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 3, 4, 4, 2, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0257, Accuracy: 0.2857, Precision: 0.1132, Recall: 0.2286, F1: 0.1456
Epoch 51/70
Train Loss: 1.2926, Accuracy: 0.4741, Precision: 0.2332, Recall: 0.2318, F1: 0.2199
Validation Loss: 1.3485, Accuracy: 0.4574, Precision: 0.1952, Recall: 0.2130, F1: 0.1803
Testing Loss: 1.3771, Accuracy: 0.4734, Precision: 0.2518, Recall: 0.2266, F1: 0.1997
LM Predictions:  [2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1239, Accuracy: 0.2500, Precision: 0.0956, Recall: 0.2000, F1: 0.1271
Epoch 52/70
Train Loss: 1.2953, Accuracy: 0.4794, Precision: 0.2474, Recall: 0.2339, F1: 0.2226
Validation Loss: 1.3525, Accuracy: 0.4602, Precision: 0.2306, Recall: 0.2143, F1: 0.1828
Testing Loss: 1.3802, Accuracy: 0.4229, Precision: 0.2361, Recall: 0.2056, F1: 0.1754
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0468, Accuracy: 0.3214, Precision: 0.1409, Recall: 0.2571, F1: 0.1600
Epoch 53/70
Train Loss: 1.2873, Accuracy: 0.4874, Precision: 0.2450, Recall: 0.2390, F1: 0.2275
Validation Loss: 1.3501, Accuracy: 0.4602, Precision: 0.2793, Recall: 0.2185, F1: 0.1890
Testing Loss: 1.3768, Accuracy: 0.4388, Precision: 0.2376, Recall: 0.2147, F1: 0.1866
LM Predictions:  [2, 2, 4, 2, 3, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9593, Accuracy: 0.2143, Precision: 0.0855, Recall: 0.1714, F1: 0.1023
Epoch 54/70
Train Loss: 1.2796, Accuracy: 0.4776, Precision: 0.2363, Recall: 0.2357, F1: 0.2249
Validation Loss: 1.3532, Accuracy: 0.4574, Precision: 0.2503, Recall: 0.2161, F1: 0.1889
Testing Loss: 1.3787, Accuracy: 0.4574, Precision: 0.2401, Recall: 0.2220, F1: 0.1953
LM Predictions:  [2, 2, 4, 2, 3, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0880, Accuracy: 0.2143, Precision: 0.0855, Recall: 0.1714, F1: 0.1023
Epoch 55/70
Train Loss: 1.2892, Accuracy: 0.4678, Precision: 0.2335, Recall: 0.2301, F1: 0.2194
Validation Loss: 1.3322, Accuracy: 0.4801, Precision: 0.2300, Recall: 0.2465, F1: 0.2329
Testing Loss: 1.3659, Accuracy: 0.4761, Precision: 0.2174, Recall: 0.2459, F1: 0.2284
LM Predictions:  [2, 2, 4, 2, 3, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 3, 4, 2, 4, 4, 4, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9557, Accuracy: 0.3214, Precision: 0.1958, Recall: 0.2686, F1: 0.2120
Epoch 56/70
Train Loss: 1.2988, Accuracy: 0.4818, Precision: 0.2356, Recall: 0.2396, F1: 0.2293
Validation Loss: 1.4005, Accuracy: 0.4460, Precision: 0.2227, Recall: 0.2075, F1: 0.1770
Testing Loss: 1.3994, Accuracy: 0.4521, Precision: 0.2467, Recall: 0.2195, F1: 0.1944
LM Predictions:  [2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1640, Accuracy: 0.1786, Precision: 0.0643, Recall: 0.1429, F1: 0.0865
Epoch 57/70
Train Loss: 1.3263, Accuracy: 0.4622, Precision: 0.2283, Recall: 0.2252, F1: 0.2135
Validation Loss: 1.3433, Accuracy: 0.4688, Precision: 0.2533, Recall: 0.2233, F1: 0.1986
Testing Loss: 1.3663, Accuracy: 0.4734, Precision: 0.2544, Recall: 0.2316, F1: 0.2117
LM Predictions:  [2, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9828, Accuracy: 0.2143, Precision: 0.0834, Recall: 0.1714, F1: 0.1111
Epoch 58/70
Train Loss: 1.3080, Accuracy: 0.4664, Precision: 0.2355, Recall: 0.2258, F1: 0.2133
Validation Loss: 1.3562, Accuracy: 0.4176, Precision: 0.2396, Recall: 0.2356, F1: 0.1963
Testing Loss: 1.3937, Accuracy: 0.4096, Precision: 0.2187, Recall: 0.2181, F1: 0.1918
LM Predictions:  [2, 2, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9832, Accuracy: 0.2857, Precision: 0.1583, Recall: 0.2286, F1: 0.1348
Epoch 59/70
Train Loss: 1.3168, Accuracy: 0.4584, Precision: 0.2342, Recall: 0.2226, F1: 0.2109
Validation Loss: 1.3227, Accuracy: 0.5057, Precision: 0.2547, Recall: 0.2408, F1: 0.2137
Testing Loss: 1.3556, Accuracy: 0.4761, Precision: 0.2480, Recall: 0.2328, F1: 0.2128
LM Predictions:  [2, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0607, Accuracy: 0.2857, Precision: 0.1143, Recall: 0.2286, F1: 0.1524
Epoch 60/70
Train Loss: 1.3131, Accuracy: 0.4615, Precision: 0.2322, Recall: 0.2244, F1: 0.2126
Validation Loss: 1.3841, Accuracy: 0.4716, Precision: 0.2402, Recall: 0.2256, F1: 0.1973
Testing Loss: 1.4003, Accuracy: 0.4734, Precision: 0.2533, Recall: 0.2318, F1: 0.2130
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2386, Accuracy: 0.3214, Precision: 0.1298, Recall: 0.2571, F1: 0.1673
Epoch 61/70
Train Loss: 1.2912, Accuracy: 0.4794, Precision: 0.2437, Recall: 0.2355, F1: 0.2248
Validation Loss: 1.3274, Accuracy: 0.4744, Precision: 0.2421, Recall: 0.2281, F1: 0.1986
Testing Loss: 1.3514, Accuracy: 0.4707, Precision: 0.2539, Recall: 0.2307, F1: 0.2128
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0315, Accuracy: 0.2857, Precision: 0.1156, Recall: 0.2286, F1: 0.1506
Epoch 62/70
Train Loss: 1.2981, Accuracy: 0.4720, Precision: 0.2389, Recall: 0.2332, F1: 0.2234
Validation Loss: 1.3156, Accuracy: 0.4716, Precision: 0.2700, Recall: 0.2235, F1: 0.1985
Testing Loss: 1.3651, Accuracy: 0.4787, Precision: 0.2605, Recall: 0.2352, F1: 0.2127
LM Predictions:  [2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0010, Accuracy: 0.1786, Precision: 0.0644, Recall: 0.1429, F1: 0.0875
Epoch 63/70
Train Loss: 1.2900, Accuracy: 0.4640, Precision: 0.2398, Recall: 0.2294, F1: 0.2202
Validation Loss: 1.3213, Accuracy: 0.4659, Precision: 0.2495, Recall: 0.2226, F1: 0.1995
Testing Loss: 1.3740, Accuracy: 0.4787, Precision: 0.2550, Recall: 0.2354, F1: 0.2144
LM Predictions:  [2, 2, 4, 2, 3, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0118, Accuracy: 0.2143, Precision: 0.0871, Recall: 0.1714, F1: 0.1137
Epoch 64/70
Train Loss: 1.2845, Accuracy: 0.4857, Precision: 0.2562, Recall: 0.2409, F1: 0.2321
Validation Loss: 1.3922, Accuracy: 0.4659, Precision: 0.2714, Recall: 0.2180, F1: 0.1878
Testing Loss: 1.4534, Accuracy: 0.4787, Precision: 0.2710, Recall: 0.2334, F1: 0.2058
LM Predictions:  [2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1804, Accuracy: 0.2143, Precision: 0.0749, Recall: 0.1714, F1: 0.1019
Epoch 65/70
Train Loss: 1.2868, Accuracy: 0.4846, Precision: 0.2486, Recall: 0.2374, F1: 0.2263
Validation Loss: 1.3530, Accuracy: 0.4773, Precision: 0.2682, Recall: 0.2245, F1: 0.1970
Testing Loss: 1.4079, Accuracy: 0.4681, Precision: 0.2638, Recall: 0.2302, F1: 0.2075
LM Predictions:  [2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1023, Accuracy: 0.1786, Precision: 0.0644, Recall: 0.1429, F1: 0.0875
Epoch 66/70
Train Loss: 1.2843, Accuracy: 0.4811, Precision: 0.2471, Recall: 0.2385, F1: 0.2292
Validation Loss: 1.3637, Accuracy: 0.4716, Precision: 0.2472, Recall: 0.2218, F1: 0.1940
Testing Loss: 1.4091, Accuracy: 0.4814, Precision: 0.2588, Recall: 0.2350, F1: 0.2124
LM Predictions:  [2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1460, Accuracy: 0.1786, Precision: 0.0644, Recall: 0.1429, F1: 0.0875
Epoch 67/70
Train Loss: 1.2781, Accuracy: 0.4857, Precision: 0.2422, Recall: 0.2371, F1: 0.2249
Validation Loss: 1.3196, Accuracy: 0.4886, Precision: 0.2427, Recall: 0.2487, F1: 0.2361
Testing Loss: 1.3702, Accuracy: 0.4814, Precision: 0.2208, Recall: 0.2418, F1: 0.2237
LM Predictions:  [2, 2, 4, 2, 3, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 4, 3, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9596, Accuracy: 0.2500, Precision: 0.1095, Recall: 0.2000, F1: 0.1414
Epoch 68/70
Train Loss: 1.2698, Accuracy: 0.4955, Precision: 0.2481, Recall: 0.2427, F1: 0.2310
Validation Loss: 1.3400, Accuracy: 0.4602, Precision: 0.2455, Recall: 0.2251, F1: 0.1901
Testing Loss: 1.3515, Accuracy: 0.4628, Precision: 0.2678, Recall: 0.2293, F1: 0.2122
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0976, Accuracy: 0.3214, Precision: 0.1545, Recall: 0.2571, F1: 0.1751
Epoch 69/70
Train Loss: 1.2698, Accuracy: 0.4874, Precision: 0.2549, Recall: 0.2399, F1: 0.2299
Validation Loss: 1.2926, Accuracy: 0.5028, Precision: 0.2701, Recall: 0.2516, F1: 0.2379
Testing Loss: 1.3579, Accuracy: 0.4867, Precision: 0.2269, Recall: 0.2412, F1: 0.2226
LM Predictions:  [2, 2, 4, 4, 3, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4, 3, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9855, Accuracy: 0.2857, Precision: 0.1261, Recall: 0.2286, F1: 0.1616
Epoch 70/70
Train Loss: 1.2743, Accuracy: 0.4766, Precision: 0.2384, Recall: 0.2364, F1: 0.2265
Validation Loss: 1.3079, Accuracy: 0.4886, Precision: 0.2706, Recall: 0.2466, F1: 0.2279
Testing Loss: 1.3577, Accuracy: 0.4601, Precision: 0.2356, Recall: 0.2292, F1: 0.2144
LM Predictions:  [2, 2, 4, 4, 3, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0703, Accuracy: 0.2857, Precision: 0.1276, Recall: 0.2286, F1: 0.1569
Label Memorization Analysis: 
LM Loss: 2.0703, Accuracy: 0.2857, Precision: 0.1276, Recall: 0.2286, F1: 0.1569
---------------------------------------------------------------------------



