---------------------------------------------------------------------------
Results for seed:  28
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:1
Noise: 1% with label 5
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 3: 486
  Label 1: 115
  Label 5: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 3: 60
  Label 0: 3
  Label 5: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 5: 29
  Label 3: 58
28
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 4: 973
  Label 2: 1106
  Label 3: 491
  Label 1: 119
  Label 5: 116
  Label 0: 53
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.5680, Accuracy: 0.3681, Precision: 0.1828, Recall: 0.1774, F1: 0.1661
Validation Loss: 1.3988, Accuracy: 0.4119, Precision: 0.1381, Recall: 0.1940, F1: 0.1606
Testing Loss: 1.4212, Accuracy: 0.4335, Precision: 0.1448, Recall: 0.2020, F1: 0.1685
LM Predictions:  [2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0148, Accuracy: 0.2500, Precision: 0.1044, Recall: 0.2000, F1: 0.1346
Epoch 2/70
Train Loss: 1.3574, Accuracy: 0.4437, Precision: 0.2027, Recall: 0.2082, F1: 0.1887
Validation Loss: 1.2931, Accuracy: 0.5114, Precision: 0.2518, Recall: 0.2845, F1: 0.2626
Testing Loss: 1.3348, Accuracy: 0.5160, Precision: 0.2522, Recall: 0.2897, F1: 0.2642
LM Predictions:  [2, 4, 2, 4, 2, 3, 3, 4, 3, 3, 2, 2, 2, 2, 4, 4, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8671, Accuracy: 0.3929, Precision: 0.2413, Recall: 0.3600, F1: 0.2798
Epoch 3/70
Train Loss: 1.1362, Accuracy: 0.5889, Precision: 0.3257, Recall: 0.2955, F1: 0.2853
Validation Loss: 0.9405, Accuracy: 0.6193, Precision: 0.5258, Recall: 0.3698, F1: 0.3574
Testing Loss: 0.9367, Accuracy: 0.6410, Precision: 0.4045, Recall: 0.3627, F1: 0.3388
LM Predictions:  [1, 4, 4, 3, 3, 3, 3, 3, 4, 3, 5, 2, 4, 4, 1, 4, 3, 5, 4, 4, 3, 3, 3, 2, 4, 1, 4, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9186, Accuracy: 0.2500, Precision: 0.1788, Recall: 0.1952, F1: 0.1593
Epoch 4/70
Train Loss: 0.7266, Accuracy: 0.7498, Precision: 0.5159, Recall: 0.4469, F1: 0.4565
Validation Loss: 0.6248, Accuracy: 0.7841, Precision: 0.6279, Recall: 0.5472, F1: 0.5154
Testing Loss: 0.5965, Accuracy: 0.8005, Precision: 0.4841, Recall: 0.5167, F1: 0.4990
LM Predictions:  [5, 5, 5, 2, 3, 3, 5, 3, 5, 5, 5, 5, 2, 4, 5, 5, 5, 5, 5, 5, 2, 2, 3, 2, 5, 5, 5, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.7013, Accuracy: 0.1786, Precision: 0.3000, Recall: 0.1286, F1: 0.1583
Epoch 5/70
Train Loss: 0.5497, Accuracy: 0.8044, Precision: 0.5558, Recall: 0.5302, F1: 0.5356
Validation Loss: 0.5464, Accuracy: 0.7983, Precision: 0.5903, Recall: 0.5592, F1: 0.5715
Testing Loss: 0.5698, Accuracy: 0.8271, Precision: 0.6179, Recall: 0.5828, F1: 0.5717
LM Predictions:  [5, 5, 5, 1, 1, 3, 3, 3, 5, 5, 5, 1, 2, 4, 5, 4, 5, 5, 5, 5, 2, 3, 3, 5, 1, 0, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3304, Accuracy: 0.3214, Precision: 0.5944, Recall: 0.2786, F1: 0.3463
Epoch 6/70
Train Loss: 0.4226, Accuracy: 0.8516, Precision: 0.7060, Recall: 0.6223, F1: 0.6297
Validation Loss: 0.5386, Accuracy: 0.8210, Precision: 0.6303, Recall: 0.5988, F1: 0.6066
Testing Loss: 0.5929, Accuracy: 0.8324, Precision: 0.6578, Recall: 0.5948, F1: 0.6115
LM Predictions:  [5, 5, 5, 5, 1, 3, 2, 3, 5, 5, 5, 5, 2, 4, 5, 4, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1401, Accuracy: 0.2143, Precision: 0.4861, Recall: 0.1702, F1: 0.2444
Epoch 7/70
Train Loss: 0.3459, Accuracy: 0.8796, Precision: 0.7387, Recall: 0.6780, F1: 0.6925
Validation Loss: 0.6720, Accuracy: 0.8040, Precision: 0.6316, Recall: 0.5799, F1: 0.5932
Testing Loss: 0.6751, Accuracy: 0.8165, Precision: 0.6995, Recall: 0.6251, F1: 0.6299
LM Predictions:  [5, 5, 5, 1, 1, 2, 2, 4, 2, 5, 5, 5, 2, 4, 5, 4, 5, 5, 5, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6299, Accuracy: 0.4286, Precision: 0.5357, Recall: 0.3405, F1: 0.3976
Epoch 8/70
Train Loss: 0.2806, Accuracy: 0.9031, Precision: 0.7999, Recall: 0.7602, F1: 0.7762
Validation Loss: 0.5203, Accuracy: 0.8267, Precision: 0.6483, Recall: 0.6249, F1: 0.6210
Testing Loss: 0.5947, Accuracy: 0.8537, Precision: 0.6749, Recall: 0.6260, F1: 0.6395
LM Predictions:  [5, 5, 2, 5, 1, 3, 3, 3, 2, 5, 5, 0, 2, 4, 5, 4, 5, 5, 5, 5, 5, 2, 1, 2, 5, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8494, Accuracy: 0.4286, Precision: 0.6944, Recall: 0.3321, F1: 0.4224
Epoch 9/70
Train Loss: 0.1983, Accuracy: 0.9332, Precision: 0.8597, Recall: 0.8219, F1: 0.8369
Validation Loss: 0.6322, Accuracy: 0.8267, Precision: 0.6733, Recall: 0.6781, F1: 0.6575
Testing Loss: 0.7565, Accuracy: 0.8191, Precision: 0.6483, Recall: 0.6724, F1: 0.6290
LM Predictions:  [2, 5, 2, 1, 1, 1, 3, 4, 2, 5, 5, 0, 2, 4, 5, 4, 5, 5, 1, 1, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4528, Accuracy: 0.6071, Precision: 0.7381, Recall: 0.4964, F1: 0.5381
Epoch 10/70
Train Loss: 0.1761, Accuracy: 0.9419, Precision: 0.8937, Recall: 0.8628, F1: 0.8763
Validation Loss: 0.5827, Accuracy: 0.8381, Precision: 0.6574, Recall: 0.6449, F1: 0.6447
Testing Loss: 0.6586, Accuracy: 0.8431, Precision: 0.7264, Recall: 0.6910, F1: 0.6914
LM Predictions:  [2, 0, 2, 1, 1, 3, 3, 4, 2, 5, 5, 0, 2, 4, 4, 4, 3, 3, 1, 4, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6547, Accuracy: 0.7857, Precision: 0.7333, Recall: 0.6536, F1: 0.6852
Epoch 11/70
Train Loss: 0.1063, Accuracy: 0.9643, Precision: 0.9245, Recall: 0.9213, F1: 0.9224
Validation Loss: 0.7091, Accuracy: 0.8153, Precision: 0.6298, Recall: 0.6390, F1: 0.6265
Testing Loss: 0.7345, Accuracy: 0.8324, Precision: 0.6121, Recall: 0.6232, F1: 0.6058
LM Predictions:  [2, 0, 2, 1, 1, 3, 3, 4, 2, 5, 4, 0, 2, 4, 4, 4, 3, 3, 1, 4, 4, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4732, Accuracy: 0.8571, Precision: 0.7429, Recall: 0.7012, F1: 0.7169
Epoch 12/70
Train Loss: 0.0750, Accuracy: 0.9762, Precision: 0.9516, Recall: 0.9342, F1: 0.9422
Validation Loss: 0.8440, Accuracy: 0.8040, Precision: 0.6493, Recall: 0.6053, F1: 0.6212
Testing Loss: 0.8458, Accuracy: 0.8245, Precision: 0.6299, Recall: 0.5912, F1: 0.6068
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 5, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2713, Accuracy: 0.9286, Precision: 0.7917, Recall: 0.7583, F1: 0.7731
Epoch 13/70
Train Loss: 0.0525, Accuracy: 0.9853, Precision: 0.9665, Recall: 0.9684, F1: 0.9674
Validation Loss: 0.6654, Accuracy: 0.8381, Precision: 0.6365, Recall: 0.6529, F1: 0.6428
Testing Loss: 0.7829, Accuracy: 0.8245, Precision: 0.6126, Recall: 0.5899, F1: 0.5866
LM Predictions:  [2, 0, 2, 1, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1956, Accuracy: 0.9286, Precision: 0.9333, Recall: 0.9314, F1: 0.9224
Epoch 14/70
Train Loss: 0.0363, Accuracy: 0.9902, Precision: 0.9833, Recall: 0.9750, F1: 0.9790
Validation Loss: 0.6973, Accuracy: 0.8665, Precision: 0.6822, Recall: 0.6495, F1: 0.6643
Testing Loss: 0.8627, Accuracy: 0.8431, Precision: 0.6261, Recall: 0.6199, F1: 0.6203
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0646, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 15/70
Train Loss: 0.0325, Accuracy: 0.9913, Precision: 0.9768, Recall: 0.9705, F1: 0.9736
Validation Loss: 0.7683, Accuracy: 0.8551, Precision: 0.6734, Recall: 0.6385, F1: 0.6482
Testing Loss: 0.9790, Accuracy: 0.8271, Precision: 0.6133, Recall: 0.6030, F1: 0.5983
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0393, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 16/70
Train Loss: 0.0249, Accuracy: 0.9937, Precision: 0.9913, Recall: 0.9819, F1: 0.9863
Validation Loss: 0.7694, Accuracy: 0.8466, Precision: 0.6728, Recall: 0.6273, F1: 0.6410
Testing Loss: 0.9426, Accuracy: 0.8404, Precision: 0.6444, Recall: 0.5924, F1: 0.6039
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0147, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 17/70
Train Loss: 0.0179, Accuracy: 0.9958, Precision: 0.9927, Recall: 0.9877, F1: 0.9902
Validation Loss: 0.8148, Accuracy: 0.8295, Precision: 0.6673, Recall: 0.6995, F1: 0.6686
Testing Loss: 0.9148, Accuracy: 0.8457, Precision: 0.6841, Recall: 0.7048, F1: 0.6854
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0192, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 18/70
Train Loss: 0.0213, Accuracy: 0.9941, Precision: 0.9924, Recall: 0.9894, F1: 0.9909
Validation Loss: 0.8739, Accuracy: 0.8466, Precision: 0.6561, Recall: 0.6364, F1: 0.6434
Testing Loss: 0.9754, Accuracy: 0.8457, Precision: 0.6347, Recall: 0.6096, F1: 0.6139
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0156, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 19/70
Train Loss: 0.0153, Accuracy: 0.9965, Precision: 0.9966, Recall: 0.9951, F1: 0.9958
Validation Loss: 0.9138, Accuracy: 0.8295, Precision: 0.6842, Recall: 0.6841, F1: 0.6680
Testing Loss: 1.0730, Accuracy: 0.8378, Precision: 0.6406, Recall: 0.6431, F1: 0.6343
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0070, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 20/70
Train Loss: 0.0234, Accuracy: 0.9923, Precision: 0.9872, Recall: 0.9841, F1: 0.9856
Validation Loss: 0.9035, Accuracy: 0.8295, Precision: 0.6403, Recall: 0.6347, F1: 0.6369
Testing Loss: 0.9783, Accuracy: 0.8457, Precision: 0.6640, Recall: 0.6668, F1: 0.6609
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0109, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 21/70
Train Loss: 0.0118, Accuracy: 0.9976, Precision: 0.9971, Recall: 0.9960, F1: 0.9966
Validation Loss: 0.9366, Accuracy: 0.8295, Precision: 0.7027, Recall: 0.5667, F1: 0.6017
Testing Loss: 1.1036, Accuracy: 0.8484, Precision: 0.6646, Recall: 0.6092, F1: 0.6275
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0032, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 22/70
Train Loss: 0.0126, Accuracy: 0.9958, Precision: 0.9896, Recall: 0.9941, F1: 0.9918
Validation Loss: 0.8448, Accuracy: 0.8381, Precision: 0.6653, Recall: 0.6134, F1: 0.6334
Testing Loss: 0.9509, Accuracy: 0.8511, Precision: 0.6821, Recall: 0.6492, F1: 0.6552
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0028, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 23/70
Train Loss: 0.0076, Accuracy: 0.9976, Precision: 0.9964, Recall: 0.9958, F1: 0.9961
Validation Loss: 0.9479, Accuracy: 0.8295, Precision: 0.6395, Recall: 0.6255, F1: 0.6309
Testing Loss: 0.9687, Accuracy: 0.8431, Precision: 0.6758, Recall: 0.6820, F1: 0.6756
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0059, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 24/70
Train Loss: 0.0190, Accuracy: 0.9948, Precision: 0.9899, Recall: 0.9888, F1: 0.9894
Validation Loss: 0.9595, Accuracy: 0.8153, Precision: 0.6387, Recall: 0.6998, F1: 0.6575
Testing Loss: 1.0201, Accuracy: 0.8378, Precision: 0.6341, Recall: 0.6587, F1: 0.6433
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0073, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 25/70
Train Loss: 0.0060, Accuracy: 0.9979, Precision: 0.9920, Recall: 0.9959, F1: 0.9939
Validation Loss: 1.0922, Accuracy: 0.8125, Precision: 0.6701, Recall: 0.5971, F1: 0.6208
Testing Loss: 1.1648, Accuracy: 0.8271, Precision: 0.6257, Recall: 0.6071, F1: 0.6140
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 26/70
Train Loss: 0.0057, Accuracy: 0.9986, Precision: 0.9968, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.9281, Accuracy: 0.8494, Precision: 0.6681, Recall: 0.6245, F1: 0.6416
Testing Loss: 1.1301, Accuracy: 0.8457, Precision: 0.7124, Recall: 0.6509, F1: 0.6652
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 27/70
Train Loss: 0.0028, Accuracy: 0.9997, Precision: 0.9998, Recall: 0.9997, F1: 0.9998
Validation Loss: 0.9876, Accuracy: 0.8324, Precision: 0.6526, Recall: 0.6256, F1: 0.6329
Testing Loss: 1.0658, Accuracy: 0.8537, Precision: 0.6825, Recall: 0.6612, F1: 0.6668
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 28/70
Train Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0050, Accuracy: 0.8551, Precision: 0.6775, Recall: 0.6421, F1: 0.6559
Testing Loss: 1.0944, Accuracy: 0.8484, Precision: 0.6751, Recall: 0.6567, F1: 0.6625
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 29/70
Train Loss: 0.0229, Accuracy: 0.9934, Precision: 0.9956, Recall: 0.9943, F1: 0.9949
Validation Loss: 0.9151, Accuracy: 0.8438, Precision: 0.6599, Recall: 0.6104, F1: 0.6308
Testing Loss: 1.1225, Accuracy: 0.8351, Precision: 0.6967, Recall: 0.6308, F1: 0.6553
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0009, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 30/70
Train Loss: 0.0066, Accuracy: 0.9986, Precision: 0.9990, Recall: 0.9960, F1: 0.9975
Validation Loss: 0.9460, Accuracy: 0.8466, Precision: 0.6834, Recall: 0.6209, F1: 0.6444
Testing Loss: 1.1086, Accuracy: 0.8378, Precision: 0.6710, Recall: 0.6127, F1: 0.6306
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 31/70
Train Loss: 0.0075, Accuracy: 0.9979, Precision: 0.9962, Recall: 0.9972, F1: 0.9967
Validation Loss: 1.0871, Accuracy: 0.8068, Precision: 0.6764, Recall: 0.5818, F1: 0.6000
Testing Loss: 1.2162, Accuracy: 0.8298, Precision: 0.6547, Recall: 0.6198, F1: 0.6173
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0008, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 32/70
Train Loss: 0.0221, Accuracy: 0.9916, Precision: 0.9814, Recall: 0.9818, F1: 0.9816
Validation Loss: 1.0264, Accuracy: 0.8182, Precision: 0.7285, Recall: 0.5713, F1: 0.6074
Testing Loss: 1.2831, Accuracy: 0.8245, Precision: 0.6575, Recall: 0.5784, F1: 0.5955
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0020, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 33/70
Train Loss: 0.0171, Accuracy: 0.9934, Precision: 0.9869, Recall: 0.9845, F1: 0.9857
Validation Loss: 0.9902, Accuracy: 0.8295, Precision: 0.6547, Recall: 0.5605, F1: 0.5915
Testing Loss: 1.2003, Accuracy: 0.8138, Precision: 0.6146, Recall: 0.5467, F1: 0.5684
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0052, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 34/70
Train Loss: 0.0185, Accuracy: 0.9923, Precision: 0.9910, Recall: 0.9865, F1: 0.9887
Validation Loss: 0.9916, Accuracy: 0.8324, Precision: 0.6326, Recall: 0.6324, F1: 0.6294
Testing Loss: 1.1297, Accuracy: 0.8378, Precision: 0.6590, Recall: 0.6546, F1: 0.6432
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0018, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 35/70
Train Loss: 0.0050, Accuracy: 0.9983, Precision: 0.9988, Recall: 0.9990, F1: 0.9989
Validation Loss: 0.9712, Accuracy: 0.8580, Precision: 0.6750, Recall: 0.6474, F1: 0.6592
Testing Loss: 1.0606, Accuracy: 0.8484, Precision: 0.6792, Recall: 0.6551, F1: 0.6630
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0011, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 36/70
Train Loss: 0.0016, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0387, Accuracy: 0.8494, Precision: 0.6881, Recall: 0.6165, F1: 0.6441
Testing Loss: 1.1340, Accuracy: 0.8431, Precision: 0.6667, Recall: 0.6299, F1: 0.6441
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 37/70
Train Loss: 0.0010, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0123, Accuracy: 0.8551, Precision: 0.6801, Recall: 0.6460, F1: 0.6599
Testing Loss: 1.1198, Accuracy: 0.8484, Precision: 0.6741, Recall: 0.6493, F1: 0.6540
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 38/70
Train Loss: 0.0101, Accuracy: 0.9955, Precision: 0.9933, Recall: 0.9922, F1: 0.9928
Validation Loss: 1.4447, Accuracy: 0.8097, Precision: 0.6835, Recall: 0.6038, F1: 0.6105
Testing Loss: 1.5919, Accuracy: 0.8138, Precision: 0.6088, Recall: 0.6068, F1: 0.5782
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0096, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 39/70
Train Loss: 0.0209, Accuracy: 0.9934, Precision: 0.9858, Recall: 0.9871, F1: 0.9864
Validation Loss: 1.0946, Accuracy: 0.8381, Precision: 0.7091, Recall: 0.5963, F1: 0.6316
Testing Loss: 1.1246, Accuracy: 0.8537, Precision: 0.6632, Recall: 0.6088, F1: 0.6263
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0004, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 40/70
Train Loss: 0.0022, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0004, Accuracy: 0.8438, Precision: 0.6645, Recall: 0.6044, F1: 0.6266
Testing Loss: 1.1384, Accuracy: 0.8457, Precision: 0.6371, Recall: 0.6154, F1: 0.6171
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 41/70
Train Loss: 0.0111, Accuracy: 0.9962, Precision: 0.9941, Recall: 0.9963, F1: 0.9952
Validation Loss: 1.1230, Accuracy: 0.8324, Precision: 0.6940, Recall: 0.6003, F1: 0.6339
Testing Loss: 1.3063, Accuracy: 0.8218, Precision: 0.6210, Recall: 0.5919, F1: 0.6014
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0009, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 42/70
Train Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 0.9853, Accuracy: 0.8523, Precision: 0.6922, Recall: 0.6242, F1: 0.6495
Testing Loss: 1.1956, Accuracy: 0.8404, Precision: 0.6952, Recall: 0.6423, F1: 0.6591
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 43/70
Train Loss: 0.0036, Accuracy: 0.9990, Precision: 0.9994, Recall: 0.9992, F1: 0.9993
Validation Loss: 1.0638, Accuracy: 0.8438, Precision: 0.6726, Recall: 0.6201, F1: 0.6402
Testing Loss: 1.1408, Accuracy: 0.8431, Precision: 0.6820, Recall: 0.6468, F1: 0.6598
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 44/70
Train Loss: 0.0007, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0267, Accuracy: 0.8466, Precision: 0.6576, Recall: 0.6190, F1: 0.6349
Testing Loss: 1.1767, Accuracy: 0.8670, Precision: 0.7152, Recall: 0.6867, F1: 0.6965
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 45/70
Train Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0974, Accuracy: 0.8523, Precision: 0.6926, Recall: 0.6227, F1: 0.6483
Testing Loss: 1.2579, Accuracy: 0.8484, Precision: 0.6568, Recall: 0.6256, F1: 0.6359
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 46/70
Train Loss: 0.0009, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0794, Accuracy: 0.8409, Precision: 0.6527, Recall: 0.6054, F1: 0.6241
Testing Loss: 1.2166, Accuracy: 0.8537, Precision: 0.6724, Recall: 0.6342, F1: 0.6477
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 47/70
Train Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0762, Accuracy: 0.8466, Precision: 0.6510, Recall: 0.6142, F1: 0.6297
Testing Loss: 1.2117, Accuracy: 0.8537, Precision: 0.6603, Recall: 0.6371, F1: 0.6451
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 48/70
Train Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0817, Accuracy: 0.8295, Precision: 0.6473, Recall: 0.6052, F1: 0.6224
Testing Loss: 1.2280, Accuracy: 0.8511, Precision: 0.6898, Recall: 0.6702, F1: 0.6747
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 49/70
Train Loss: 0.0202, Accuracy: 0.9934, Precision: 0.9925, Recall: 0.9940, F1: 0.9932
Validation Loss: 1.0377, Accuracy: 0.8040, Precision: 0.6115, Recall: 0.6505, F1: 0.6229
Testing Loss: 1.1082, Accuracy: 0.8245, Precision: 0.6090, Recall: 0.6265, F1: 0.6013
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0016, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0064, Accuracy: 0.9979, Precision: 0.9934, Recall: 0.9934, F1: 0.9934
Validation Loss: 1.0618, Accuracy: 0.8324, Precision: 0.6521, Recall: 0.6254, F1: 0.6325
Testing Loss: 1.2335, Accuracy: 0.8351, Precision: 0.6276, Recall: 0.6179, F1: 0.6101
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 51/70
Train Loss: 0.0047, Accuracy: 0.9993, Precision: 0.9984, Recall: 0.9984, F1: 0.9984
Validation Loss: 1.0316, Accuracy: 0.8409, Precision: 0.6975, Recall: 0.6254, F1: 0.6547
Testing Loss: 1.2173, Accuracy: 0.8457, Precision: 0.6421, Recall: 0.6166, F1: 0.6258
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 52/70
Train Loss: 0.0080, Accuracy: 0.9972, Precision: 0.9925, Recall: 0.9950, F1: 0.9937
Validation Loss: 1.0722, Accuracy: 0.8438, Precision: 0.6572, Recall: 0.6330, F1: 0.6420
Testing Loss: 1.1037, Accuracy: 0.8378, Precision: 0.6425, Recall: 0.6252, F1: 0.6315
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 53/70
Train Loss: 0.0058, Accuracy: 0.9983, Precision: 0.9992, Recall: 0.9990, F1: 0.9991
Validation Loss: 1.0139, Accuracy: 0.8239, Precision: 0.6636, Recall: 0.6222, F1: 0.6402
Testing Loss: 1.1964, Accuracy: 0.8378, Precision: 0.6376, Recall: 0.6354, F1: 0.6328
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0021, Accuracy: 0.9997, Precision: 0.9998, Recall: 0.9998, F1: 0.9998
Validation Loss: 1.1178, Accuracy: 0.8409, Precision: 0.6941, Recall: 0.6330, F1: 0.6573
Testing Loss: 1.3002, Accuracy: 0.8378, Precision: 0.6458, Recall: 0.6276, F1: 0.6311
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 55/70
Train Loss: 0.0008, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1482, Accuracy: 0.8466, Precision: 0.6927, Recall: 0.6404, F1: 0.6629
Testing Loss: 1.2768, Accuracy: 0.8351, Precision: 0.6343, Recall: 0.6177, F1: 0.6228
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0007, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1450, Accuracy: 0.8295, Precision: 0.6730, Recall: 0.6297, F1: 0.6452
Testing Loss: 1.3537, Accuracy: 0.8457, Precision: 0.6770, Recall: 0.6600, F1: 0.6599
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1324, Accuracy: 0.8352, Precision: 0.6721, Recall: 0.6202, F1: 0.6407
Testing Loss: 1.3341, Accuracy: 0.8404, Precision: 0.6399, Recall: 0.6338, F1: 0.6320
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0080, Accuracy: 0.9986, Precision: 0.9978, Recall: 0.9965, F1: 0.9971
Validation Loss: 1.6160, Accuracy: 0.7898, Precision: 0.7209, Recall: 0.5405, F1: 0.5587
Testing Loss: 1.5214, Accuracy: 0.8298, Precision: 0.6802, Recall: 0.5710, F1: 0.5899
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0051, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0138, Accuracy: 0.9965, Precision: 0.9923, Recall: 0.9892, F1: 0.9907
Validation Loss: 1.0320, Accuracy: 0.8409, Precision: 0.6981, Recall: 0.6468, F1: 0.6672
Testing Loss: 1.2380, Accuracy: 0.8537, Precision: 0.6614, Recall: 0.6223, F1: 0.6372
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0011, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0606, Accuracy: 0.8409, Precision: 0.6840, Recall: 0.6424, F1: 0.6572
Testing Loss: 1.2439, Accuracy: 0.8431, Precision: 0.6461, Recall: 0.6338, F1: 0.6350
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0006, Accuracy: 0.9997, Precision: 0.9986, Recall: 0.9997, F1: 0.9991
Validation Loss: 1.2284, Accuracy: 0.8324, Precision: 0.7067, Recall: 0.6076, F1: 0.6363
Testing Loss: 1.3619, Accuracy: 0.8404, Precision: 0.6624, Recall: 0.5800, F1: 0.6015
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.0007, Accuracy: 0.9997, Precision: 0.9997, Recall: 0.9986, F1: 0.9991
Validation Loss: 1.0976, Accuracy: 0.8324, Precision: 0.6625, Recall: 0.6189, F1: 0.6322
Testing Loss: 1.2765, Accuracy: 0.8431, Precision: 0.6472, Recall: 0.6219, F1: 0.6295
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1467, Accuracy: 0.8352, Precision: 0.6650, Recall: 0.6186, F1: 0.6336
Testing Loss: 1.3160, Accuracy: 0.8431, Precision: 0.6527, Recall: 0.6264, F1: 0.6335
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0027, Accuracy: 0.9990, Precision: 0.9992, Recall: 0.9994, F1: 0.9993
Validation Loss: 1.5450, Accuracy: 0.8239, Precision: 0.7035, Recall: 0.5782, F1: 0.6197
Testing Loss: 1.7573, Accuracy: 0.8165, Precision: 0.6559, Recall: 0.5762, F1: 0.6030
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0161, Accuracy: 0.9962, Precision: 0.9961, Recall: 0.9938, F1: 0.9949
Validation Loss: 1.1081, Accuracy: 0.8438, Precision: 0.6509, Recall: 0.6647, F1: 0.6538
Testing Loss: 1.2688, Accuracy: 0.8431, Precision: 0.6277, Recall: 0.6597, F1: 0.6386
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0035, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0011, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0866, Accuracy: 0.8494, Precision: 0.6796, Recall: 0.6502, F1: 0.6611
Testing Loss: 1.2327, Accuracy: 0.8404, Precision: 0.6369, Recall: 0.6202, F1: 0.6189
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0008, Accuracy: 0.9993, Precision: 0.9982, Recall: 0.9995, F1: 0.9989
Validation Loss: 1.2912, Accuracy: 0.8381, Precision: 0.7075, Recall: 0.5819, F1: 0.6108
Testing Loss: 1.5573, Accuracy: 0.8085, Precision: 0.6175, Recall: 0.5221, F1: 0.5376
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0012, Accuracy: 0.9997, Precision: 0.9997, Recall: 0.9986, F1: 0.9991
Validation Loss: 1.1866, Accuracy: 0.8381, Precision: 0.6630, Recall: 0.6296, F1: 0.6406
Testing Loss: 1.2464, Accuracy: 0.8617, Precision: 0.6529, Recall: 0.6515, F1: 0.6490
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1565, Accuracy: 0.8523, Precision: 0.6823, Recall: 0.6526, F1: 0.6652
Testing Loss: 1.2508, Accuracy: 0.8537, Precision: 0.6485, Recall: 0.6445, F1: 0.6442
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.0004, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.1877, Accuracy: 0.8494, Precision: 0.6741, Recall: 0.6350, F1: 0.6509
Testing Loss: 1.2748, Accuracy: 0.8431, Precision: 0.6495, Recall: 0.6182, F1: 0.6302
LM Predictions:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Label Memorization Analysis: 
LM Loss: 0.0001, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
---------------------------------------------------------------------------



