---------------------------------------------------------------------------
Results for seed:  28
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 5
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 3: 486
  Label 1: 115
  Label 5: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 3: 60
  Label 0: 3
  Label 5: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 5: 29
  Label 3: 58
28
Actual labels:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]
Label counts for Train:
  Label 4: 973
  Label 2: 1106
  Label 3: 491
  Label 1: 119
  Label 5: 116
  Label 0: 53
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.3987, Accuracy: 0.3642, Precision: 0.1823, Recall: 0.1658, F1: 0.1408
Validation Loss: 1.4124, Accuracy: 0.3835, Precision: 0.1270, Recall: 0.1783, F1: 0.1478
Testing Loss: 1.4309, Accuracy: 0.3856, Precision: 0.1282, Recall: 0.1790, F1: 0.1452
LM Predictions:  [2, 2, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 4, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0519, Accuracy: 0.3214, Precision: 0.1382, Recall: 0.2571, F1: 0.1723
Epoch 2/70
Train Loss: 1.3862, Accuracy: 0.3849, Precision: 0.2096, Recall: 0.1741, F1: 0.1462
Validation Loss: 1.4058, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4335, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0374, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 3/70
Train Loss: 1.3780, Accuracy: 0.3845, Precision: 0.1258, Recall: 0.1723, F1: 0.1420
Validation Loss: 1.3976, Accuracy: 0.3778, Precision: 0.1186, Recall: 0.1668, F1: 0.0941
Testing Loss: 1.4322, Accuracy: 0.3644, Precision: 0.1163, Recall: 0.1679, F1: 0.0915
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9890, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 4/70
Train Loss: 1.3801, Accuracy: 0.3810, Precision: 0.1234, Recall: 0.1703, F1: 0.1392
Validation Loss: 1.4019, Accuracy: 0.4034, Precision: 0.1466, Recall: 0.1805, F1: 0.1270
Testing Loss: 1.4301, Accuracy: 0.3989, Precision: 0.1685, Recall: 0.1843, F1: 0.1268
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0032, Accuracy: 0.2500, Precision: 0.0560, Recall: 0.2000, F1: 0.0875
Epoch 5/70
Train Loss: 1.3756, Accuracy: 0.3957, Precision: 0.1842, Recall: 0.1778, F1: 0.1475
Validation Loss: 1.4021, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4292, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0018, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 6/70
Train Loss: 1.3708, Accuracy: 0.4020, Precision: 0.1320, Recall: 0.1799, F1: 0.1477
Validation Loss: 1.4034, Accuracy: 0.3977, Precision: 0.1342, Recall: 0.1825, F1: 0.1488
Testing Loss: 1.4216, Accuracy: 0.3936, Precision: 0.1349, Recall: 0.1827, F1: 0.1483
LM Predictions:  [2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9610, Accuracy: 0.2857, Precision: 0.1100, Recall: 0.2286, F1: 0.1422
Epoch 7/70
Train Loss: 1.3698, Accuracy: 0.4017, Precision: 0.1316, Recall: 0.1804, F1: 0.1496
Validation Loss: 1.4023, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4328, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0529, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 8/70
Train Loss: 1.3703, Accuracy: 0.4097, Precision: 0.1991, Recall: 0.1842, F1: 0.1535
Validation Loss: 1.4115, Accuracy: 0.3949, Precision: 0.1327, Recall: 0.1858, F1: 0.1541
Testing Loss: 1.4334, Accuracy: 0.4441, Precision: 0.1492, Recall: 0.2070, F1: 0.1730
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0716, Accuracy: 0.2857, Precision: 0.1333, Recall: 0.2286, F1: 0.1571
Epoch 9/70
Train Loss: 1.3683, Accuracy: 0.4027, Precision: 0.1332, Recall: 0.1826, F1: 0.1535
Validation Loss: 1.3854, Accuracy: 0.3864, Precision: 0.1333, Recall: 0.1857, F1: 0.1472
Testing Loss: 1.4050, Accuracy: 0.4548, Precision: 0.1581, Recall: 0.2125, F1: 0.1749
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9776, Accuracy: 0.2857, Precision: 0.1322, Recall: 0.2286, F1: 0.1467
Epoch 10/70
Train Loss: 1.3650, Accuracy: 0.3950, Precision: 0.1298, Recall: 0.1771, F1: 0.1461
Validation Loss: 1.4153, Accuracy: 0.3807, Precision: 0.1193, Recall: 0.1686, F1: 0.1019
Testing Loss: 1.4388, Accuracy: 0.3777, Precision: 0.1866, Recall: 0.1742, F1: 0.1041
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1261, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 11/70
Train Loss: 1.3578, Accuracy: 0.4041, Precision: 0.1323, Recall: 0.1818, F1: 0.1512
Validation Loss: 1.3768, Accuracy: 0.4119, Precision: 0.2210, Recall: 0.1879, F1: 0.1481
Testing Loss: 1.3953, Accuracy: 0.4149, Precision: 0.3129, Recall: 0.1985, F1: 0.1622
LM Predictions:  [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9670, Accuracy: 0.2500, Precision: 0.0609, Recall: 0.2000, F1: 0.0933
Epoch 12/70
Train Loss: 1.3523, Accuracy: 0.4143, Precision: 0.1981, Recall: 0.1891, F1: 0.1620
Validation Loss: 1.3585, Accuracy: 0.4205, Precision: 0.2538, Recall: 0.1901, F1: 0.1412
Testing Loss: 1.3815, Accuracy: 0.4202, Precision: 0.3446, Recall: 0.1976, F1: 0.1502
LM Predictions:  [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9421, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.2000, F1: 0.0824
Epoch 13/70
Train Loss: 1.3405, Accuracy: 0.4381, Precision: 0.2258, Recall: 0.1996, F1: 0.1719
Validation Loss: 1.3724, Accuracy: 0.4460, Precision: 0.1624, Recall: 0.2142, F1: 0.1717
Testing Loss: 1.3728, Accuracy: 0.4441, Precision: 0.3211, Recall: 0.2093, F1: 0.1741
LM Predictions:  [4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 4, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9678, Accuracy: 0.2500, Precision: 0.1000, Recall: 0.2000, F1: 0.1274
Epoch 14/70
Train Loss: 1.3401, Accuracy: 0.4255, Precision: 0.2047, Recall: 0.1974, F1: 0.1753
Validation Loss: 1.3860, Accuracy: 0.4233, Precision: 0.1414, Recall: 0.1985, F1: 0.1649
Testing Loss: 1.4103, Accuracy: 0.4574, Precision: 0.1541, Recall: 0.2132, F1: 0.1783
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0679, Accuracy: 0.2857, Precision: 0.1156, Recall: 0.2286, F1: 0.1506
Epoch 15/70
Train Loss: 1.3423, Accuracy: 0.4314, Precision: 0.2057, Recall: 0.1978, F1: 0.1720
Validation Loss: 1.4054, Accuracy: 0.4602, Precision: 0.1532, Recall: 0.2129, F1: 0.1761
Testing Loss: 1.4022, Accuracy: 0.4867, Precision: 0.1637, Recall: 0.2264, F1: 0.1885
LM Predictions:  [2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1568, Accuracy: 0.2857, Precision: 0.0950, Recall: 0.2286, F1: 0.1304
Epoch 16/70
Train Loss: 1.3266, Accuracy: 0.4507, Precision: 0.2179, Recall: 0.2118, F1: 0.1925
Validation Loss: 1.3497, Accuracy: 0.4261, Precision: 0.1429, Recall: 0.2000, F1: 0.1662
Testing Loss: 1.3364, Accuracy: 0.4787, Precision: 0.3265, Recall: 0.2247, F1: 0.1912
LM Predictions:  [4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0818, Accuracy: 0.2500, Precision: 0.1044, Recall: 0.2000, F1: 0.1346
Epoch 17/70
Train Loss: 1.3050, Accuracy: 0.4734, Precision: 0.2231, Recall: 0.2244, F1: 0.2056
Validation Loss: 1.4452, Accuracy: 0.4062, Precision: 0.2213, Recall: 0.2007, F1: 0.1478
Testing Loss: 1.4577, Accuracy: 0.3830, Precision: 0.2484, Recall: 0.1947, F1: 0.1400
LM Predictions:  [2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2305, Accuracy: 0.2500, Precision: 0.0538, Recall: 0.2000, F1: 0.0848
Epoch 18/70
Train Loss: 1.2950, Accuracy: 0.4857, Precision: 0.2327, Recall: 0.2290, F1: 0.2083
Validation Loss: 1.3026, Accuracy: 0.4716, Precision: 0.2653, Recall: 0.2419, F1: 0.2210
Testing Loss: 1.3053, Accuracy: 0.5106, Precision: 0.2601, Recall: 0.2565, F1: 0.2380
LM Predictions:  [4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 3, 2, 2, 4, 3, 2, 4, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9937, Accuracy: 0.3214, Precision: 0.2079, Recall: 0.2686, F1: 0.2157
Epoch 19/70
Train Loss: 1.2833, Accuracy: 0.4843, Precision: 0.2233, Recall: 0.2323, F1: 0.2157
Validation Loss: 1.2948, Accuracy: 0.4659, Precision: 0.2332, Recall: 0.2279, F1: 0.2026
Testing Loss: 1.3142, Accuracy: 0.4654, Precision: 0.2327, Recall: 0.2271, F1: 0.2060
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 2, 4, 4, 4, 4, 3, 4, 4, 4, 2, 4, 2, 3, 4, 2, 4]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9828, Accuracy: 0.3571, Precision: 0.2298, Recall: 0.2971, F1: 0.2346
Epoch 20/70
Train Loss: 1.2617, Accuracy: 0.5014, Precision: 0.2290, Recall: 0.2417, F1: 0.2257
Validation Loss: 1.2979, Accuracy: 0.5000, Precision: 0.2545, Recall: 0.2701, F1: 0.2499
Testing Loss: 1.3152, Accuracy: 0.4734, Precision: 0.2388, Recall: 0.2560, F1: 0.2356
LM Predictions:  [3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 3, 2, 2, 4, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1267, Accuracy: 0.2500, Precision: 0.1071, Recall: 0.2343, F1: 0.1467
Epoch 21/70
Train Loss: 1.2305, Accuracy: 0.5227, Precision: 0.2520, Recall: 0.2527, F1: 0.2367
Validation Loss: 1.3478, Accuracy: 0.4034, Precision: 0.2492, Recall: 0.2587, F1: 0.2186
Testing Loss: 1.3590, Accuracy: 0.4362, Precision: 0.2758, Recall: 0.2785, F1: 0.2385
LM Predictions:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 4, 2, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2300, Accuracy: 0.2143, Precision: 0.1364, Recall: 0.2171, F1: 0.1320
Epoch 22/70
Train Loss: 1.1978, Accuracy: 0.5346, Precision: 0.2484, Recall: 0.2670, F1: 0.2537
Validation Loss: 1.2981, Accuracy: 0.5199, Precision: 0.2819, Recall: 0.2748, F1: 0.2557
Testing Loss: 1.3118, Accuracy: 0.5053, Precision: 0.2731, Recall: 0.2707, F1: 0.2504
LM Predictions:  [2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 4, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2075, Accuracy: 0.2500, Precision: 0.1033, Recall: 0.2229, F1: 0.1405
Epoch 23/70
Train Loss: 1.1554, Accuracy: 0.5668, Precision: 0.2704, Recall: 0.2839, F1: 0.2712
Validation Loss: 1.2469, Accuracy: 0.5483, Precision: 0.3012, Recall: 0.3094, F1: 0.2794
Testing Loss: 1.2314, Accuracy: 0.5346, Precision: 0.2955, Recall: 0.3041, F1: 0.2757
LM Predictions:  [2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 2, 4, 2, 2, 4, 2, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0930, Accuracy: 0.2857, Precision: 0.1214, Recall: 0.2629, F1: 0.1658
Epoch 24/70
Train Loss: 1.1397, Accuracy: 0.5731, Precision: 0.2735, Recall: 0.2836, F1: 0.2701
Validation Loss: 1.1722, Accuracy: 0.6023, Precision: 0.3033, Recall: 0.3236, F1: 0.3067
Testing Loss: 1.1731, Accuracy: 0.5984, Precision: 0.2871, Recall: 0.3145, F1: 0.2956
LM Predictions:  [2, 2, 2, 3, 2, 2, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4208, Accuracy: 0.2500, Precision: 0.0971, Recall: 0.2114, F1: 0.1257
Epoch 25/70
Train Loss: 1.0773, Accuracy: 0.6036, Precision: 0.2878, Recall: 0.3065, F1: 0.2935
Validation Loss: 1.1593, Accuracy: 0.6023, Precision: 0.2916, Recall: 0.3023, F1: 0.2837
Testing Loss: 1.2201, Accuracy: 0.5691, Precision: 0.2528, Recall: 0.2765, F1: 0.2514
LM Predictions:  [2, 2, 2, 4, 2, 2, 4, 3, 3, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2191, Accuracy: 0.2500, Precision: 0.1000, Recall: 0.2000, F1: 0.1222
Epoch 26/70
Train Loss: 1.0558, Accuracy: 0.6092, Precision: 0.2900, Recall: 0.3103, F1: 0.2970
Validation Loss: 1.3079, Accuracy: 0.5426, Precision: 0.3153, Recall: 0.3069, F1: 0.2779
Testing Loss: 1.2421, Accuracy: 0.5745, Precision: 0.3194, Recall: 0.3324, F1: 0.2971
LM Predictions:  [3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4138, Accuracy: 0.3571, Precision: 0.1436, Recall: 0.3429, F1: 0.2000
Epoch 27/70
Train Loss: 1.0249, Accuracy: 0.6242, Precision: 0.2976, Recall: 0.3175, F1: 0.3042
Validation Loss: 1.0695, Accuracy: 0.6307, Precision: 0.3143, Recall: 0.3538, F1: 0.3269
Testing Loss: 1.0760, Accuracy: 0.6410, Precision: 0.3144, Recall: 0.3642, F1: 0.3302
LM Predictions:  [3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 4, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4112, Accuracy: 0.2857, Precision: 0.1300, Recall: 0.2743, F1: 0.1703
Epoch 28/70
Train Loss: 1.0116, Accuracy: 0.6386, Precision: 0.3052, Recall: 0.3275, F1: 0.3137
Validation Loss: 1.0156, Accuracy: 0.6420, Precision: 0.3075, Recall: 0.3408, F1: 0.3223
Testing Loss: 1.0666, Accuracy: 0.6250, Precision: 0.2910, Recall: 0.3306, F1: 0.3091
LM Predictions:  [4, 2, 2, 3, 3, 4, 2, 3, 2, 3, 2, 3, 2, 2, 4, 2, 3, 3, 3, 3, 2, 2, 3, 2, 3, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1767, Accuracy: 0.2857, Precision: 0.1287, Recall: 0.2514, F1: 0.1700
Epoch 29/70
Train Loss: 0.9658, Accuracy: 0.6473, Precision: 0.3113, Recall: 0.3350, F1: 0.3209
Validation Loss: 1.0772, Accuracy: 0.6250, Precision: 0.2924, Recall: 0.3030, F1: 0.2745
Testing Loss: 1.0519, Accuracy: 0.6090, Precision: 0.2738, Recall: 0.2919, F1: 0.2611
LM Predictions:  [5, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 3, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2206, Accuracy: 0.2143, Precision: 0.0500, Recall: 0.1429, F1: 0.0741
Epoch 30/70
Train Loss: 0.9288, Accuracy: 0.6700, Precision: 0.3233, Recall: 0.3486, F1: 0.3339
Validation Loss: 0.9441, Accuracy: 0.6818, Precision: 0.3353, Recall: 0.3677, F1: 0.3483
Testing Loss: 0.9767, Accuracy: 0.6755, Precision: 0.4883, Recall: 0.3666, F1: 0.3489
LM Predictions:  [3, 2, 2, 3, 3, 2, 2, 3, 2, 3, 2, 4, 2, 2, 4, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3322, Accuracy: 0.2857, Precision: 0.1150, Recall: 0.2514, F1: 0.1571
Epoch 31/70
Train Loss: 0.9173, Accuracy: 0.6721, Precision: 0.4874, Recall: 0.3490, F1: 0.3351
Validation Loss: 1.0182, Accuracy: 0.6023, Precision: 0.3296, Recall: 0.3581, F1: 0.3301
Testing Loss: 0.9995, Accuracy: 0.6410, Precision: 0.4037, Recall: 0.3722, F1: 0.3413
LM Predictions:  [4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 4, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 4, 2, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2374, Accuracy: 0.2500, Precision: 0.1302, Recall: 0.2457, F1: 0.1553
Epoch 32/70
Train Loss: 0.8920, Accuracy: 0.6879, Precision: 0.4982, Recall: 0.3606, F1: 0.3464
Validation Loss: 0.9488, Accuracy: 0.6790, Precision: 0.3296, Recall: 0.3680, F1: 0.3464
Testing Loss: 0.9467, Accuracy: 0.6729, Precision: 0.3186, Recall: 0.3626, F1: 0.3375
LM Predictions:  [2, 2, 2, 3, 3, 2, 3, 3, 3, 3, 2, 4, 2, 4, 4, 2, 3, 3, 2, 3, 2, 2, 3, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3100, Accuracy: 0.3571, Precision: 0.1957, Recall: 0.3200, F1: 0.2306
Epoch 33/70
Train Loss: 0.8760, Accuracy: 0.6889, Precision: 0.3325, Recall: 0.3619, F1: 0.3456
Validation Loss: 0.9302, Accuracy: 0.6591, Precision: 0.3255, Recall: 0.3734, F1: 0.3412
Testing Loss: 0.9472, Accuracy: 0.6569, Precision: 0.4887, Recall: 0.3779, F1: 0.3482
LM Predictions:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0907, Accuracy: 0.3214, Precision: 0.2137, Recall: 0.3029, F1: 0.2194
Epoch 34/70
Train Loss: 0.8368, Accuracy: 0.7022, Precision: 0.3383, Recall: 0.3695, F1: 0.3524
Validation Loss: 0.9233, Accuracy: 0.6648, Precision: 0.3272, Recall: 0.3693, F1: 0.3424
Testing Loss: 0.8988, Accuracy: 0.6888, Precision: 0.4197, Recall: 0.3909, F1: 0.3645
LM Predictions:  [2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1240, Accuracy: 0.3929, Precision: 0.2400, Recall: 0.3600, F1: 0.2612
Epoch 35/70
Train Loss: 0.8195, Accuracy: 0.7089, Precision: 0.5096, Recall: 0.3775, F1: 0.3628
Validation Loss: 0.9542, Accuracy: 0.6648, Precision: 0.3470, Recall: 0.3747, F1: 0.3543
Testing Loss: 0.9299, Accuracy: 0.6755, Precision: 0.3867, Recall: 0.3891, F1: 0.3704
LM Predictions:  [2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1189, Accuracy: 0.3929, Precision: 0.2500, Recall: 0.3600, F1: 0.2726
Epoch 36/70
Train Loss: 0.8125, Accuracy: 0.7113, Precision: 0.3985, Recall: 0.3771, F1: 0.3607
Validation Loss: 0.8722, Accuracy: 0.6875, Precision: 0.3304, Recall: 0.3656, F1: 0.3454
Testing Loss: 0.8771, Accuracy: 0.7128, Precision: 0.5118, Recall: 0.3888, F1: 0.3712
LM Predictions:  [2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 2, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9520, Accuracy: 0.3929, Precision: 0.2256, Recall: 0.3600, F1: 0.2541
Epoch 37/70
Train Loss: 0.7862, Accuracy: 0.7239, Precision: 0.5511, Recall: 0.3913, F1: 0.3805
Validation Loss: 0.9581, Accuracy: 0.6420, Precision: 0.3145, Recall: 0.3618, F1: 0.3306
Testing Loss: 0.9481, Accuracy: 0.6995, Precision: 0.4656, Recall: 0.4116, F1: 0.3886
LM Predictions:  [4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0586, Accuracy: 0.3214, Precision: 0.2204, Recall: 0.3029, F1: 0.2291
Epoch 38/70
Train Loss: 0.7706, Accuracy: 0.7313, Precision: 0.4965, Recall: 0.3973, F1: 0.3831
Validation Loss: 0.9046, Accuracy: 0.6591, Precision: 0.3493, Recall: 0.3779, F1: 0.3571
Testing Loss: 0.8712, Accuracy: 0.6995, Precision: 0.4048, Recall: 0.4301, F1: 0.4135
LM Predictions:  [5, 3, 3, 5, 3, 3, 5, 3, 3, 3, 5, 5, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 4, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0810, Accuracy: 0.2857, Precision: 0.2556, Recall: 0.2190, F1: 0.2045
Epoch 39/70
Train Loss: 0.7401, Accuracy: 0.7334, Precision: 0.4079, Recall: 0.4012, F1: 0.3897
Validation Loss: 0.9764, Accuracy: 0.6392, Precision: 0.4924, Recall: 0.3568, F1: 0.3467
Testing Loss: 0.9174, Accuracy: 0.7048, Precision: 0.3988, Recall: 0.4035, F1: 0.3941
LM Predictions:  [2, 4, 2, 3, 3, 3, 5, 5, 3, 5, 2, 4, 2, 4, 4, 4, 3, 3, 3, 3, 3, 2, 3, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9115, Accuracy: 0.3929, Precision: 0.2167, Recall: 0.2905, F1: 0.2429
Epoch 40/70
Train Loss: 0.7304, Accuracy: 0.7446, Precision: 0.4474, Recall: 0.4127, F1: 0.4039
Validation Loss: 0.9213, Accuracy: 0.6875, Precision: 0.3310, Recall: 0.3722, F1: 0.3490
Testing Loss: 0.8767, Accuracy: 0.7074, Precision: 0.4250, Recall: 0.3995, F1: 0.3731
LM Predictions:  [2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0177, Accuracy: 0.3929, Precision: 0.2400, Recall: 0.3600, F1: 0.2612
Epoch 41/70
Train Loss: 0.7306, Accuracy: 0.7421, Precision: 0.5633, Recall: 0.4117, F1: 0.4041
Validation Loss: 0.9373, Accuracy: 0.6790, Precision: 0.3575, Recall: 0.3548, F1: 0.3472
Testing Loss: 0.8848, Accuracy: 0.7181, Precision: 0.4236, Recall: 0.3994, F1: 0.3983
LM Predictions:  [2, 3, 2, 2, 3, 2, 5, 5, 2, 3, 2, 5, 2, 2, 5, 2, 3, 3, 5, 3, 2, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2154, Accuracy: 0.3214, Precision: 0.1205, Recall: 0.2333, F1: 0.1570
Epoch 42/70
Train Loss: 0.7066, Accuracy: 0.7505, Precision: 0.4781, Recall: 0.4214, F1: 0.4144
Validation Loss: 0.8883, Accuracy: 0.6903, Precision: 0.3388, Recall: 0.3777, F1: 0.3540
Testing Loss: 0.8362, Accuracy: 0.7234, Precision: 0.4343, Recall: 0.4086, F1: 0.3819
LM Predictions:  [2, 3, 2, 2, 3, 3, 2, 3, 3, 3, 5, 4, 2, 2, 4, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0404, Accuracy: 0.3214, Precision: 0.1186, Recall: 0.2429, F1: 0.1588
Epoch 43/70
Train Loss: 0.6948, Accuracy: 0.7558, Precision: 0.5023, Recall: 0.4258, F1: 0.4195
Validation Loss: 0.9237, Accuracy: 0.6705, Precision: 0.3414, Recall: 0.3808, F1: 0.3506
Testing Loss: 0.8297, Accuracy: 0.7101, Precision: 0.3829, Recall: 0.4092, F1: 0.3769
LM Predictions:  [2, 3, 3, 2, 3, 3, 3, 3, 3, 3, 5, 4, 2, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 2, 3, 4, 2, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9281, Accuracy: 0.3214, Precision: 0.1920, Recall: 0.2524, F1: 0.1935
Epoch 44/70
Train Loss: 0.6780, Accuracy: 0.7586, Precision: 0.4845, Recall: 0.4268, F1: 0.4205
Validation Loss: 0.8563, Accuracy: 0.6903, Precision: 0.3817, Recall: 0.4083, F1: 0.3902
Testing Loss: 0.7849, Accuracy: 0.7287, Precision: 0.4219, Recall: 0.4341, F1: 0.4158
LM Predictions:  [2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 5, 5, 2, 4, 3, 3, 3, 3, 5, 3, 3, 2, 3, 2, 3, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9017, Accuracy: 0.4286, Precision: 0.3333, Recall: 0.3333, F1: 0.2500
Epoch 45/70
Train Loss: 0.6730, Accuracy: 0.7600, Precision: 0.5434, Recall: 0.4362, F1: 0.4346
Validation Loss: 0.8691, Accuracy: 0.6903, Precision: 0.3701, Recall: 0.3967, F1: 0.3812
Testing Loss: 0.8129, Accuracy: 0.7207, Precision: 0.4222, Recall: 0.4476, F1: 0.4316
LM Predictions:  [2, 5, 2, 2, 3, 3, 3, 3, 2, 5, 5, 5, 2, 4, 5, 3, 3, 3, 5, 3, 3, 2, 3, 2, 3, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0552, Accuracy: 0.4286, Precision: 0.3439, Recall: 0.3238, F1: 0.2623
Epoch 46/70
Train Loss: 0.6582, Accuracy: 0.7628, Precision: 0.4706, Recall: 0.4403, F1: 0.4365
Validation Loss: 1.0152, Accuracy: 0.6761, Precision: 0.3399, Recall: 0.3462, F1: 0.3341
Testing Loss: 0.9566, Accuracy: 0.7101, Precision: 0.4344, Recall: 0.3867, F1: 0.3820
LM Predictions:  [2, 3, 2, 2, 3, 3, 2, 2, 2, 3, 5, 2, 2, 2, 2, 2, 3, 3, 5, 3, 2, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2341, Accuracy: 0.3571, Precision: 0.1273, Recall: 0.2667, F1: 0.1703
Epoch 47/70
Train Loss: 0.6564, Accuracy: 0.7673, Precision: 0.5138, Recall: 0.4490, F1: 0.4499
Validation Loss: 1.0192, Accuracy: 0.6847, Precision: 0.3479, Recall: 0.3534, F1: 0.3424
Testing Loss: 0.9239, Accuracy: 0.6968, Precision: 0.4159, Recall: 0.3768, F1: 0.3751
LM Predictions:  [2, 3, 2, 2, 3, 3, 2, 2, 2, 3, 5, 2, 2, 4, 2, 2, 3, 3, 5, 3, 2, 2, 3, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0641, Accuracy: 0.3929, Precision: 0.2978, Recall: 0.2905, F1: 0.2158
Epoch 48/70
Train Loss: 0.6416, Accuracy: 0.7719, Precision: 0.4820, Recall: 0.4500, F1: 0.4448
Validation Loss: 1.0033, Accuracy: 0.6364, Precision: 0.5138, Recall: 0.3853, F1: 0.3702
Testing Loss: 0.8480, Accuracy: 0.7207, Precision: 0.4276, Recall: 0.4627, F1: 0.4392
LM Predictions:  [5, 3, 5, 2, 3, 3, 5, 3, 3, 5, 4, 5, 2, 4, 4, 3, 3, 3, 5, 3, 3, 2, 3, 2, 3, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9034, Accuracy: 0.3214, Precision: 0.2861, Recall: 0.2429, F1: 0.2366
Epoch 49/70
Train Loss: 0.6100, Accuracy: 0.7848, Precision: 0.5052, Recall: 0.4654, F1: 0.4650
Validation Loss: 0.9626, Accuracy: 0.6676, Precision: 0.3423, Recall: 0.3720, F1: 0.3536
Testing Loss: 0.8620, Accuracy: 0.7074, Precision: 0.4000, Recall: 0.4171, F1: 0.4055
LM Predictions:  [4, 3, 2, 2, 3, 3, 5, 3, 2, 5, 4, 5, 2, 4, 4, 5, 3, 3, 5, 3, 3, 2, 3, 2, 3, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7580, Accuracy: 0.3929, Precision: 0.2417, Recall: 0.2905, F1: 0.2556
Epoch 50/70
Train Loss: 0.6048, Accuracy: 0.7841, Precision: 0.5437, Recall: 0.4831, F1: 0.4861
Validation Loss: 0.9564, Accuracy: 0.6648, Precision: 0.4365, Recall: 0.3862, F1: 0.3773
Testing Loss: 0.8465, Accuracy: 0.7394, Precision: 0.4304, Recall: 0.4643, F1: 0.4422
LM Predictions:  [5, 3, 2, 2, 3, 3, 5, 5, 2, 5, 4, 5, 2, 4, 4, 5, 3, 5, 5, 3, 3, 2, 3, 2, 4, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9994, Accuracy: 0.3571, Precision: 0.2738, Recall: 0.2571, F1: 0.2590
Epoch 51/70
Train Loss: 0.6025, Accuracy: 0.7869, Precision: 0.5074, Recall: 0.4687, F1: 0.4652
Validation Loss: 1.1243, Accuracy: 0.6392, Precision: 0.4977, Recall: 0.3783, F1: 0.3764
Testing Loss: 0.9353, Accuracy: 0.7101, Precision: 0.4234, Recall: 0.4500, F1: 0.4321
LM Predictions:  [4, 3, 2, 2, 3, 3, 5, 3, 2, 5, 4, 5, 2, 4, 4, 4, 3, 3, 5, 3, 3, 2, 3, 2, 4, 4, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9267, Accuracy: 0.4286, Precision: 0.2520, Recall: 0.3143, F1: 0.2762
Epoch 52/70
Train Loss: 0.5852, Accuracy: 0.8048, Precision: 0.5319, Recall: 0.4933, F1: 0.4959
Validation Loss: 0.9080, Accuracy: 0.7045, Precision: 0.3769, Recall: 0.3996, F1: 0.3864
Testing Loss: 0.8083, Accuracy: 0.7394, Precision: 0.4392, Recall: 0.4641, F1: 0.4459
LM Predictions:  [2, 3, 2, 2, 3, 3, 5, 2, 2, 5, 5, 5, 2, 4, 5, 2, 3, 3, 5, 3, 3, 2, 3, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0770, Accuracy: 0.3929, Precision: 0.3264, Recall: 0.2905, F1: 0.2414
Epoch 53/70
Train Loss: 0.5791, Accuracy: 0.7957, Precision: 0.5186, Recall: 0.4780, F1: 0.4784
Validation Loss: 1.0160, Accuracy: 0.6818, Precision: 0.3571, Recall: 0.3835, F1: 0.3689
Testing Loss: 0.8891, Accuracy: 0.7314, Precision: 0.4194, Recall: 0.4334, F1: 0.4248
LM Predictions:  [2, 3, 2, 2, 3, 3, 5, 3, 2, 5, 5, 5, 2, 4, 4, 2, 3, 3, 5, 3, 5, 2, 3, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8826, Accuracy: 0.3929, Precision: 0.2519, Recall: 0.2905, F1: 0.2436
Epoch 54/70
Train Loss: 0.5682, Accuracy: 0.7988, Precision: 0.5326, Recall: 0.4927, F1: 0.4958
Validation Loss: 0.9281, Accuracy: 0.7045, Precision: 0.3735, Recall: 0.4001, F1: 0.3855
Testing Loss: 0.8104, Accuracy: 0.7420, Precision: 0.4338, Recall: 0.4600, F1: 0.4459
LM Predictions:  [2, 3, 2, 2, 3, 3, 3, 3, 2, 5, 5, 5, 2, 4, 4, 3, 3, 3, 5, 3, 3, 2, 3, 2, 3, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8406, Accuracy: 0.4286, Precision: 0.2685, Recall: 0.3238, F1: 0.2613
Epoch 55/70
Train Loss: 0.5477, Accuracy: 0.8100, Precision: 0.5386, Recall: 0.4990, F1: 0.5010
Validation Loss: 1.0812, Accuracy: 0.6932, Precision: 0.5299, Recall: 0.3873, F1: 0.3952
Testing Loss: 0.9477, Accuracy: 0.7181, Precision: 0.4981, Recall: 0.4157, F1: 0.4223
LM Predictions:  [2, 3, 2, 2, 3, 3, 2, 2, 2, 5, 4, 5, 2, 4, 4, 2, 3, 3, 5, 3, 2, 2, 3, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7028, Accuracy: 0.4286, Precision: 0.2659, Recall: 0.3143, F1: 0.2611
Epoch 56/70
Train Loss: 0.5540, Accuracy: 0.8149, Precision: 0.5580, Recall: 0.5140, F1: 0.5198
Validation Loss: 1.1102, Accuracy: 0.6591, Precision: 0.3895, Recall: 0.3928, F1: 0.3625
Testing Loss: 0.9168, Accuracy: 0.7101, Precision: 0.4461, Recall: 0.4399, F1: 0.4164
LM Predictions:  [2, 3, 5, 2, 3, 3, 3, 3, 3, 5, 5, 5, 2, 4, 3, 3, 3, 3, 5, 3, 3, 2, 3, 2, 3, 1, 2, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9899, Accuracy: 0.3571, Precision: 0.3333, Recall: 0.2857, F1: 0.2276
Epoch 57/70
Train Loss: 0.5333, Accuracy: 0.8198, Precision: 0.5786, Recall: 0.5222, F1: 0.5304
Validation Loss: 1.0544, Accuracy: 0.6761, Precision: 0.4299, Recall: 0.4273, F1: 0.4239
Testing Loss: 0.9056, Accuracy: 0.7367, Precision: 0.4753, Recall: 0.4908, F1: 0.4774
LM Predictions:  [2, 3, 2, 2, 3, 3, 3, 1, 2, 5, 5, 5, 2, 4, 1, 3, 3, 3, 5, 1, 5, 2, 3, 2, 3, 1, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8245, Accuracy: 0.4286, Precision: 0.3866, Recall: 0.3238, F1: 0.2925
Epoch 58/70
Train Loss: 0.5308, Accuracy: 0.8125, Precision: 0.5414, Recall: 0.5141, F1: 0.5152
Validation Loss: 1.0005, Accuracy: 0.6989, Precision: 0.4579, Recall: 0.4135, F1: 0.4219
Testing Loss: 0.8661, Accuracy: 0.7367, Precision: 0.4369, Recall: 0.4587, F1: 0.4455
LM Predictions:  [2, 3, 2, 5, 3, 3, 3, 2, 2, 5, 5, 5, 2, 4, 1, 2, 3, 3, 5, 5, 5, 2, 3, 2, 3, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9871, Accuracy: 0.4286, Precision: 0.3667, Recall: 0.3238, F1: 0.2815
Epoch 59/70
Train Loss: 0.5131, Accuracy: 0.8240, Precision: 0.5582, Recall: 0.5304, F1: 0.5333
Validation Loss: 1.1328, Accuracy: 0.6676, Precision: 0.4576, Recall: 0.4188, F1: 0.4005
Testing Loss: 0.9697, Accuracy: 0.7128, Precision: 0.4568, Recall: 0.4486, F1: 0.4304
LM Predictions:  [2, 3, 2, 5, 3, 3, 3, 3, 3, 5, 4, 5, 5, 4, 1, 3, 3, 3, 5, 3, 3, 3, 3, 2, 3, 1, 5, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9035, Accuracy: 0.3214, Precision: 0.3778, Recall: 0.2524, F1: 0.2407
Epoch 60/70
Train Loss: 0.4996, Accuracy: 0.8226, Precision: 0.5768, Recall: 0.5319, F1: 0.5420
Validation Loss: 1.1091, Accuracy: 0.6449, Precision: 0.4130, Recall: 0.4209, F1: 0.4096
Testing Loss: 0.9312, Accuracy: 0.7128, Precision: 0.4578, Recall: 0.4791, F1: 0.4611
LM Predictions:  [2, 1, 5, 5, 3, 3, 1, 1, 3, 5, 4, 5, 5, 1, 1, 1, 3, 3, 5, 1, 5, 5, 3, 2, 3, 1, 5, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8123, Accuracy: 0.2143, Precision: 0.3958, Recall: 0.1714, F1: 0.1927
Epoch 61/70
Train Loss: 0.5163, Accuracy: 0.8233, Precision: 0.5678, Recall: 0.5393, F1: 0.5454
Validation Loss: 1.0065, Accuracy: 0.6989, Precision: 0.4036, Recall: 0.4137, F1: 0.3930
Testing Loss: 0.8881, Accuracy: 0.7340, Precision: 0.4442, Recall: 0.4567, F1: 0.4363
LM Predictions:  [2, 3, 2, 5, 3, 3, 3, 3, 3, 5, 4, 5, 2, 3, 3, 3, 3, 3, 5, 3, 5, 2, 3, 2, 3, 5, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9704, Accuracy: 0.4286, Precision: 0.3690, Recall: 0.3333, F1: 0.2722
Epoch 62/70
Train Loss: 0.4891, Accuracy: 0.8251, Precision: 0.5818, Recall: 0.5453, F1: 0.5498
Validation Loss: 1.0059, Accuracy: 0.7131, Precision: 0.4788, Recall: 0.4265, F1: 0.4281
Testing Loss: 0.9036, Accuracy: 0.7420, Precision: 0.4206, Recall: 0.4346, F1: 0.4255
LM Predictions:  [2, 3, 2, 5, 3, 3, 3, 4, 2, 5, 4, 5, 2, 1, 4, 2, 3, 3, 5, 3, 5, 2, 3, 2, 2, 1, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5492, Accuracy: 0.4643, Precision: 0.3111, Recall: 0.3476, F1: 0.3065
Epoch 63/70
Train Loss: 0.4973, Accuracy: 0.8314, Precision: 0.5716, Recall: 0.5418, F1: 0.5459
Validation Loss: 0.9301, Accuracy: 0.7045, Precision: 0.5088, Recall: 0.4536, F1: 0.4482
Testing Loss: 0.8683, Accuracy: 0.7420, Precision: 0.4525, Recall: 0.4702, F1: 0.4551
LM Predictions:  [2, 3, 5, 5, 5, 3, 3, 1, 2, 5, 1, 5, 2, 3, 4, 3, 3, 3, 5, 1, 5, 2, 3, 2, 3, 1, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8017, Accuracy: 0.3571, Precision: 0.2169, Recall: 0.2762, F1: 0.2381
Epoch 64/70
Train Loss: 0.4720, Accuracy: 0.8362, Precision: 0.5973, Recall: 0.5621, F1: 0.5686
Validation Loss: 1.0769, Accuracy: 0.6875, Precision: 0.4505, Recall: 0.4409, F1: 0.4240
Testing Loss: 0.9449, Accuracy: 0.7340, Precision: 0.4748, Recall: 0.4906, F1: 0.4705
LM Predictions:  [4, 3, 5, 5, 3, 3, 5, 1, 3, 5, 4, 5, 2, 5, 3, 3, 3, 3, 5, 1, 5, 5, 3, 2, 3, 1, 5, 3]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9112, Accuracy: 0.2500, Precision: 0.3106, Recall: 0.2048, F1: 0.1944
Epoch 65/70
Train Loss: 0.4696, Accuracy: 0.8390, Precision: 0.5933, Recall: 0.5601, F1: 0.5670
Validation Loss: 1.0058, Accuracy: 0.6960, Precision: 0.4326, Recall: 0.4302, F1: 0.4277
Testing Loss: 0.8951, Accuracy: 0.7394, Precision: 0.4710, Recall: 0.4774, F1: 0.4728
LM Predictions:  [2, 3, 2, 5, 1, 3, 5, 4, 2, 5, 4, 5, 2, 1, 1, 4, 3, 3, 5, 1, 5, 2, 3, 2, 3, 1, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5156, Accuracy: 0.5000, Precision: 0.4500, Recall: 0.3798, F1: 0.3946
Epoch 66/70
Train Loss: 0.4656, Accuracy: 0.8446, Precision: 0.6010, Recall: 0.5772, F1: 0.5822
Validation Loss: 0.9753, Accuracy: 0.7216, Precision: 0.5714, Recall: 0.4200, F1: 0.4140
Testing Loss: 0.8436, Accuracy: 0.7447, Precision: 0.4733, Recall: 0.4377, F1: 0.4319
LM Predictions:  [2, 3, 2, 2, 3, 3, 3, 3, 2, 5, 4, 5, 2, 3, 3, 2, 3, 3, 5, 3, 2, 2, 3, 2, 3, 1, 2, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6665, Accuracy: 0.4643, Precision: 0.3422, Recall: 0.3571, F1: 0.2693
Epoch 67/70
Train Loss: 0.4306, Accuracy: 0.8464, Precision: 0.5838, Recall: 0.5593, F1: 0.5636
Validation Loss: 1.2373, Accuracy: 0.6420, Precision: 0.4213, Recall: 0.3932, F1: 0.3779
Testing Loss: 1.0786, Accuracy: 0.7181, Precision: 0.4943, Recall: 0.4934, F1: 0.4539
LM Predictions:  [2, 1, 5, 5, 5, 5, 5, 1, 2, 5, 4, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1976, Accuracy: 0.2857, Precision: 0.3333, Recall: 0.1905, F1: 0.2389
Epoch 68/70
Train Loss: 0.4457, Accuracy: 0.8485, Precision: 0.6019, Recall: 0.5799, F1: 0.5864
Validation Loss: 1.0510, Accuracy: 0.6875, Precision: 0.4309, Recall: 0.4359, F1: 0.4209
Testing Loss: 0.9095, Accuracy: 0.7473, Precision: 0.5569, Recall: 0.5175, F1: 0.5001
LM Predictions:  [2, 3, 2, 5, 5, 3, 5, 3, 2, 5, 4, 5, 2, 4, 5, 4, 3, 3, 5, 5, 5, 2, 3, 2, 3, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8783, Accuracy: 0.4643, Precision: 0.4048, Recall: 0.3381, F1: 0.3500
Epoch 69/70
Train Loss: 0.4324, Accuracy: 0.8485, Precision: 0.5985, Recall: 0.5917, F1: 0.5917
Validation Loss: 0.9408, Accuracy: 0.7074, Precision: 0.4951, Recall: 0.4240, F1: 0.4219
Testing Loss: 0.8355, Accuracy: 0.7367, Precision: 0.4269, Recall: 0.4469, F1: 0.4364
LM Predictions:  [2, 3, 2, 2, 5, 3, 3, 4, 2, 5, 4, 5, 2, 4, 5, 4, 3, 3, 5, 3, 5, 2, 3, 2, 3, 5, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5821, Accuracy: 0.5357, Precision: 0.3958, Recall: 0.3952, F1: 0.3793
Epoch 70/70
Train Loss: 0.4272, Accuracy: 0.8485, Precision: 0.6055, Recall: 0.5764, F1: 0.5817
Validation Loss: 0.9827, Accuracy: 0.7017, Precision: 0.4566, Recall: 0.4584, F1: 0.4561
Testing Loss: 0.9021, Accuracy: 0.7447, Precision: 0.4929, Recall: 0.5064, F1: 0.4978
LM Predictions:  [2, 1, 2, 5, 1, 3, 5, 1, 2, 5, 4, 5, 2, 1, 1, 4, 3, 3, 5, 1, 5, 2, 3, 2, 3, 1, 5, 2]
LM Labels:  [2, 0, 2, 4, 1, 3, 3, 4, 2, 1, 4, 0, 2, 4, 3, 4, 3, 3, 1, 4, 4, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6470, Accuracy: 0.4643, Precision: 0.4571, Recall: 0.3560, F1: 0.3710
Label Memorization Analysis: 
LM Loss: 1.6470, Accuracy: 0.4643, Precision: 0.4571, Recall: 0.3560, F1: 0.3710
---------------------------------------------------------------------------



