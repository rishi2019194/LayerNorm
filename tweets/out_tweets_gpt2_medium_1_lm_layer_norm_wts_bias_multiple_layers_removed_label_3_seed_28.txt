---------------------------------------------------------------------------
Results for seed:  28
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 3
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 5: 486
  Label 1: 115
  Label 3: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 5: 60
  Label 0: 3
  Label 3: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 3: 29
  Label 5: 58
28
Actual labels:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
Label counts for Train:
  Label 4: 971
  Label 2: 1106
  Label 5: 493
  Label 1: 119
  Label 3: 116
  Label 0: 53
For early layers:  [0, 1, 2, 3]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.4855, Accuracy: 0.3548, Precision: 0.1641, Recall: 0.1689, F1: 0.1566
Validation Loss: 1.4520, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4726, Accuracy: 0.3644, Precision: 0.2271, Recall: 0.1679, F1: 0.0912
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1823, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 2/70
Train Loss: 1.3929, Accuracy: 0.4017, Precision: 0.1549, Recall: 0.1825, F1: 0.1556
Validation Loss: 1.4574, Accuracy: 0.3239, Precision: 0.1034, Recall: 0.1603, F1: 0.1024
Testing Loss: 1.4612, Accuracy: 0.3484, Precision: 0.1206, Recall: 0.1636, F1: 0.1154
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1240, Accuracy: 0.2143, Precision: 0.1385, Recall: 0.2286, F1: 0.1090
Epoch 3/70
Train Loss: 1.3816, Accuracy: 0.3954, Precision: 0.1668, Recall: 0.1808, F1: 0.1565
Validation Loss: 1.4030, Accuracy: 0.3892, Precision: 0.1319, Recall: 0.1847, F1: 0.1514
Testing Loss: 1.4226, Accuracy: 0.3697, Precision: 0.1251, Recall: 0.1725, F1: 0.1436
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0349, Accuracy: 0.1786, Precision: 0.0800, Recall: 0.1771, F1: 0.1013
Epoch 4/70
Train Loss: 1.3724, Accuracy: 0.4115, Precision: 0.1807, Recall: 0.1883, F1: 0.1633
Validation Loss: 1.4359, Accuracy: 0.3892, Precision: 0.1393, Recall: 0.1732, F1: 0.1137
Testing Loss: 1.4541, Accuracy: 0.3856, Precision: 0.1498, Recall: 0.1780, F1: 0.1163
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2069, Accuracy: 0.2500, Precision: 0.0538, Recall: 0.2000, F1: 0.0848
Epoch 5/70
Train Loss: 1.3692, Accuracy: 0.4111, Precision: 0.1660, Recall: 0.1866, F1: 0.1586
Validation Loss: 1.3865, Accuracy: 0.3864, Precision: 0.1434, Recall: 0.1728, F1: 0.1211
Testing Loss: 1.4210, Accuracy: 0.3910, Precision: 0.1445, Recall: 0.1806, F1: 0.1258
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0376, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 6/70
Train Loss: 1.3633, Accuracy: 0.4164, Precision: 0.1973, Recall: 0.1909, F1: 0.1656
Validation Loss: 1.3814, Accuracy: 0.3920, Precision: 0.1473, Recall: 0.1753, F1: 0.1228
Testing Loss: 1.3986, Accuracy: 0.4122, Precision: 0.2803, Recall: 0.1938, F1: 0.1443
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0426, Accuracy: 0.2857, Precision: 0.1538, Recall: 0.2400, F1: 0.1420
Epoch 7/70
Train Loss: 1.3446, Accuracy: 0.4325, Precision: 0.1987, Recall: 0.1996, F1: 0.1762
Validation Loss: 1.3561, Accuracy: 0.4517, Precision: 0.1503, Recall: 0.2116, F1: 0.1757
Testing Loss: 1.3554, Accuracy: 0.4441, Precision: 0.3142, Recall: 0.2084, F1: 0.1774
LM Predictions:  [4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0838, Accuracy: 0.1429, Precision: 0.0583, Recall: 0.1371, F1: 0.0802
Epoch 8/70
Train Loss: 1.3246, Accuracy: 0.4479, Precision: 0.2022, Recall: 0.2065, F1: 0.1811
Validation Loss: 1.3782, Accuracy: 0.4176, Precision: 0.2027, Recall: 0.2063, F1: 0.1702
Testing Loss: 1.3678, Accuracy: 0.4601, Precision: 0.2347, Recall: 0.2250, F1: 0.2011
LM Predictions:  [4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1257, Accuracy: 0.2500, Precision: 0.2971, Recall: 0.2457, F1: 0.1711
Epoch 9/70
Train Loss: 1.3184, Accuracy: 0.4650, Precision: 0.2188, Recall: 0.2212, F1: 0.2035
Validation Loss: 1.3294, Accuracy: 0.4858, Precision: 0.2386, Recall: 0.2264, F1: 0.1951
Testing Loss: 1.3354, Accuracy: 0.4681, Precision: 0.2508, Recall: 0.2252, F1: 0.1975
LM Predictions:  [2, 2, 4, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0553, Accuracy: 0.2500, Precision: 0.0945, Recall: 0.2114, F1: 0.1228
Epoch 10/70
Train Loss: 1.2836, Accuracy: 0.4766, Precision: 0.2192, Recall: 0.2298, F1: 0.2145
Validation Loss: 1.2702, Accuracy: 0.5199, Precision: 0.2623, Recall: 0.2721, F1: 0.2556
Testing Loss: 1.2914, Accuracy: 0.5053, Precision: 0.2588, Recall: 0.2691, F1: 0.2480
LM Predictions:  [2, 4, 2, 5, 2, 2, 2, 5, 5, 2, 2, 5, 2, 4, 2, 2, 5, 2, 2, 2, 2, 4, 5, 2, 5, 5, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9885, Accuracy: 0.2143, Precision: 0.1000, Recall: 0.1714, F1: 0.1229
Epoch 11/70
Train Loss: 1.2290, Accuracy: 0.5255, Precision: 0.2453, Recall: 0.2567, F1: 0.2422
Validation Loss: 1.1992, Accuracy: 0.5256, Precision: 0.2505, Recall: 0.2772, F1: 0.2572
Testing Loss: 1.1693, Accuracy: 0.5505, Precision: 0.2581, Recall: 0.2863, F1: 0.2668
LM Predictions:  [5, 4, 2, 5, 5, 2, 5, 4, 5, 2, 2, 4, 2, 4, 4, 2, 5, 2, 2, 4, 2, 4, 5, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9321, Accuracy: 0.1786, Precision: 0.1031, Recall: 0.1543, F1: 0.1219
Epoch 12/70
Train Loss: 1.1546, Accuracy: 0.5654, Precision: 0.2634, Recall: 0.2823, F1: 0.2686
Validation Loss: 1.1559, Accuracy: 0.5653, Precision: 0.2793, Recall: 0.3236, F1: 0.2910
Testing Loss: 1.1093, Accuracy: 0.5532, Precision: 0.2683, Recall: 0.3055, F1: 0.2793
LM Predictions:  [5, 4, 2, 5, 5, 4, 5, 5, 5, 5, 2, 5, 2, 4, 4, 5, 5, 4, 5, 5, 5, 5, 5, 2, 5, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8589, Accuracy: 0.3929, Precision: 0.2682, Recall: 0.3486, F1: 0.2870
Epoch 13/70
Train Loss: 1.0614, Accuracy: 0.6176, Precision: 0.2897, Recall: 0.3129, F1: 0.2984
Validation Loss: 1.0614, Accuracy: 0.5909, Precision: 0.2941, Recall: 0.3377, F1: 0.3076
Testing Loss: 1.0323, Accuracy: 0.6356, Precision: 0.3134, Recall: 0.3633, F1: 0.3282
LM Predictions:  [5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 2, 5, 2, 4, 4, 5, 5, 2, 2, 5, 5, 5, 5, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8679, Accuracy: 0.3214, Precision: 0.1833, Recall: 0.2686, F1: 0.2104
Epoch 14/70
Train Loss: 1.0208, Accuracy: 0.6302, Precision: 0.3002, Recall: 0.3250, F1: 0.3107
Validation Loss: 1.0150, Accuracy: 0.6222, Precision: 0.3153, Recall: 0.3530, F1: 0.3246
Testing Loss: 0.9959, Accuracy: 0.6410, Precision: 0.3182, Recall: 0.3624, F1: 0.3301
LM Predictions:  [5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 2, 5, 2, 5, 4, 5, 5, 5, 2, 5, 5, 5, 5, 2, 2, 4, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0166, Accuracy: 0.3571, Precision: 0.2417, Recall: 0.2971, F1: 0.2331
Epoch 15/70
Train Loss: 0.9586, Accuracy: 0.6491, Precision: 0.3100, Recall: 0.3381, F1: 0.3225
Validation Loss: 1.0231, Accuracy: 0.5938, Precision: 0.2830, Recall: 0.3289, F1: 0.3001
Testing Loss: 0.9754, Accuracy: 0.6330, Precision: 0.3011, Recall: 0.3460, F1: 0.3180
LM Predictions:  [5, 5, 2, 5, 5, 4, 4, 5, 5, 2, 2, 4, 2, 4, 4, 5, 5, 5, 5, 5, 2, 2, 5, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7354, Accuracy: 0.3929, Precision: 0.2417, Recall: 0.3486, F1: 0.2832
Epoch 16/70
Train Loss: 0.9069, Accuracy: 0.6770, Precision: 0.3247, Recall: 0.3539, F1: 0.3379
Validation Loss: 1.0469, Accuracy: 0.6165, Precision: 0.2955, Recall: 0.3363, F1: 0.3106
Testing Loss: 1.0114, Accuracy: 0.6516, Precision: 0.3889, Recall: 0.3526, F1: 0.3333
LM Predictions:  [5, 4, 2, 5, 5, 4, 3, 5, 5, 5, 2, 5, 2, 4, 4, 5, 5, 5, 2, 5, 5, 2, 5, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8146, Accuracy: 0.3929, Precision: 0.2070, Recall: 0.2810, F1: 0.2341
Epoch 17/70
Train Loss: 0.8760, Accuracy: 0.6854, Precision: 0.3309, Recall: 0.3641, F1: 0.3460
Validation Loss: 0.9957, Accuracy: 0.6534, Precision: 0.3331, Recall: 0.3406, F1: 0.3276
Testing Loss: 0.9612, Accuracy: 0.6649, Precision: 0.4993, Recall: 0.3565, F1: 0.3440
LM Predictions:  [2, 5, 2, 5, 5, 2, 2, 5, 5, 2, 2, 2, 2, 2, 4, 2, 5, 5, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9071, Accuracy: 0.3571, Precision: 0.3333, Recall: 0.2971, F1: 0.2377
Epoch 18/70
Train Loss: 0.8309, Accuracy: 0.7026, Precision: 0.5673, Recall: 0.3764, F1: 0.3637
Validation Loss: 0.9028, Accuracy: 0.6705, Precision: 0.3167, Recall: 0.3515, F1: 0.3323
Testing Loss: 0.8670, Accuracy: 0.6915, Precision: 0.4929, Recall: 0.3836, F1: 0.3686
LM Predictions:  [5, 5, 2, 5, 5, 2, 2, 5, 5, 2, 2, 3, 2, 4, 4, 5, 5, 5, 2, 5, 2, 2, 5, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7230, Accuracy: 0.3571, Precision: 0.1803, Recall: 0.2476, F1: 0.1991
Epoch 19/70
Train Loss: 0.7985, Accuracy: 0.7131, Precision: 0.4061, Recall: 0.3828, F1: 0.3679
Validation Loss: 0.8826, Accuracy: 0.6619, Precision: 0.3584, Recall: 0.3797, F1: 0.3590
Testing Loss: 0.8412, Accuracy: 0.7021, Precision: 0.3847, Recall: 0.3984, F1: 0.3784
LM Predictions:  [5, 5, 2, 5, 5, 2, 1, 5, 5, 5, 5, 1, 2, 4, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7354, Accuracy: 0.4286, Precision: 0.2413, Recall: 0.2952, F1: 0.2516
Epoch 20/70
Train Loss: 0.7698, Accuracy: 0.7267, Precision: 0.4645, Recall: 0.3953, F1: 0.3807
Validation Loss: 0.9180, Accuracy: 0.6761, Precision: 0.3478, Recall: 0.3780, F1: 0.3550
Testing Loss: 0.8761, Accuracy: 0.7154, Precision: 0.5922, Recall: 0.4372, F1: 0.4264
LM Predictions:  [5, 5, 2, 5, 5, 2, 3, 5, 5, 5, 2, 3, 2, 5, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 3, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9429, Accuracy: 0.3929, Precision: 0.3244, Recall: 0.2714, F1: 0.2378
Epoch 21/70
Train Loss: 0.7500, Accuracy: 0.7278, Precision: 0.4574, Recall: 0.3979, F1: 0.3883
Validation Loss: 0.8526, Accuracy: 0.6733, Precision: 0.3603, Recall: 0.3884, F1: 0.3730
Testing Loss: 0.8063, Accuracy: 0.7287, Precision: 0.4233, Recall: 0.4431, F1: 0.4324
LM Predictions:  [3, 5, 2, 2, 5, 2, 3, 5, 5, 3, 2, 3, 2, 3, 4, 3, 5, 3, 3, 5, 5, 2, 5, 2, 2, 3, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7685, Accuracy: 0.3214, Precision: 0.3125, Recall: 0.2238, F1: 0.2203
Epoch 22/70
Train Loss: 0.7018, Accuracy: 0.7540, Precision: 0.4236, Recall: 0.4266, F1: 0.4155
Validation Loss: 0.9143, Accuracy: 0.6477, Precision: 0.3352, Recall: 0.3745, F1: 0.3407
Testing Loss: 0.8559, Accuracy: 0.6968, Precision: 0.4392, Recall: 0.4154, F1: 0.3888
LM Predictions:  [5, 5, 2, 5, 5, 5, 3, 5, 5, 5, 5, 3, 2, 4, 4, 5, 5, 5, 5, 5, 5, 2, 5, 2, 5, 4, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7401, Accuracy: 0.3929, Precision: 0.2444, Recall: 0.2714, F1: 0.2328
Epoch 23/70
Train Loss: 0.6896, Accuracy: 0.7565, Precision: 0.4658, Recall: 0.4282, F1: 0.4241
Validation Loss: 0.8719, Accuracy: 0.7074, Precision: 0.4288, Recall: 0.3863, F1: 0.3758
Testing Loss: 0.8346, Accuracy: 0.7128, Precision: 0.4055, Recall: 0.3991, F1: 0.3910
LM Predictions:  [5, 5, 2, 2, 5, 2, 3, 5, 5, 5, 2, 3, 2, 2, 4, 2, 5, 5, 3, 5, 5, 2, 5, 2, 5, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6819, Accuracy: 0.3214, Precision: 0.2778, Recall: 0.2238, F1: 0.1959
Epoch 24/70
Train Loss: 0.6669, Accuracy: 0.7663, Precision: 0.4861, Recall: 0.4442, F1: 0.4400
Validation Loss: 0.8868, Accuracy: 0.6960, Precision: 0.5593, Recall: 0.3988, F1: 0.3864
Testing Loss: 0.8548, Accuracy: 0.7287, Precision: 0.4213, Recall: 0.4264, F1: 0.4077
LM Predictions:  [5, 5, 2, 2, 5, 5, 3, 5, 5, 5, 5, 3, 2, 4, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 3, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4949, Accuracy: 0.3929, Precision: 0.2579, Recall: 0.2714, F1: 0.2424
Epoch 25/70
Train Loss: 0.6404, Accuracy: 0.7736, Precision: 0.4956, Recall: 0.4573, F1: 0.4529
Validation Loss: 0.9291, Accuracy: 0.6903, Precision: 0.4438, Recall: 0.4201, F1: 0.4173
Testing Loss: 0.9007, Accuracy: 0.7048, Precision: 0.4758, Recall: 0.4509, F1: 0.4461
LM Predictions:  [3, 1, 3, 2, 1, 2, 3, 5, 2, 3, 3, 3, 2, 2, 4, 2, 1, 3, 3, 5, 2, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8035, Accuracy: 0.3214, Precision: 0.4091, Recall: 0.2417, F1: 0.2624
Epoch 26/70
Train Loss: 0.6348, Accuracy: 0.7778, Precision: 0.5192, Recall: 0.4609, F1: 0.4631
Validation Loss: 0.8720, Accuracy: 0.6960, Precision: 0.4105, Recall: 0.4089, F1: 0.3804
Testing Loss: 0.8274, Accuracy: 0.7207, Precision: 0.4426, Recall: 0.4374, F1: 0.4102
LM Predictions:  [5, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 2, 5, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6063, Accuracy: 0.3929, Precision: 0.4020, Recall: 0.2714, F1: 0.2528
Epoch 27/70
Train Loss: 0.6010, Accuracy: 0.7869, Precision: 0.6417, Recall: 0.4851, F1: 0.4970
Validation Loss: 0.8508, Accuracy: 0.7131, Precision: 0.4666, Recall: 0.4344, F1: 0.4345
Testing Loss: 0.8426, Accuracy: 0.7394, Precision: 0.4559, Recall: 0.4645, F1: 0.4543
LM Predictions:  [5, 5, 2, 5, 1, 4, 3, 5, 5, 3, 5, 3, 2, 4, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5033, Accuracy: 0.5000, Precision: 0.5278, Recall: 0.3702, F1: 0.3942
Epoch 28/70
Train Loss: 0.5850, Accuracy: 0.7925, Precision: 0.5245, Recall: 0.4894, F1: 0.4930
Validation Loss: 0.8652, Accuracy: 0.6847, Precision: 0.4909, Recall: 0.4418, F1: 0.4264
Testing Loss: 0.8037, Accuracy: 0.7207, Precision: 0.4748, Recall: 0.4696, F1: 0.4535
LM Predictions:  [3, 3, 3, 2, 1, 4, 3, 5, 2, 3, 3, 3, 2, 1, 4, 5, 4, 4, 3, 3, 3, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5243, Accuracy: 0.4286, Precision: 0.4802, Recall: 0.3417, F1: 0.3894
Epoch 29/70
Train Loss: 0.5644, Accuracy: 0.7988, Precision: 0.7178, Recall: 0.5166, F1: 0.5325
Validation Loss: 0.9785, Accuracy: 0.7045, Precision: 0.5718, Recall: 0.4270, F1: 0.4198
Testing Loss: 0.9289, Accuracy: 0.7181, Precision: 0.4051, Recall: 0.4219, F1: 0.3983
LM Predictions:  [5, 5, 3, 5, 5, 5, 5, 5, 5, 3, 5, 3, 2, 5, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6140, Accuracy: 0.3929, Precision: 0.3981, Recall: 0.2714, F1: 0.2489
Epoch 30/70
Train Loss: 0.5688, Accuracy: 0.7971, Precision: 0.5588, Recall: 0.4974, F1: 0.5062
Validation Loss: 0.8648, Accuracy: 0.7216, Precision: 0.4708, Recall: 0.4459, F1: 0.4437
Testing Loss: 0.8555, Accuracy: 0.7314, Precision: 0.4710, Recall: 0.4702, F1: 0.4608
LM Predictions:  [5, 1, 2, 5, 1, 5, 1, 5, 2, 3, 5, 3, 2, 5, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 0, 0, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4208, Accuracy: 0.5714, Precision: 0.6453, Recall: 0.4274, F1: 0.4540
Epoch 31/70
Train Loss: 0.5074, Accuracy: 0.8202, Precision: 0.6661, Recall: 0.5440, F1: 0.5593
Validation Loss: 0.9054, Accuracy: 0.7273, Precision: 0.4598, Recall: 0.4574, F1: 0.4551
Testing Loss: 0.8860, Accuracy: 0.7234, Precision: 0.4661, Recall: 0.4965, F1: 0.4669
LM Predictions:  [3, 1, 3, 5, 1, 4, 1, 5, 5, 3, 5, 3, 2, 5, 4, 5, 1, 1, 3, 5, 5, 2, 5, 2, 5, 1, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3399, Accuracy: 0.5000, Precision: 0.4778, Recall: 0.3702, F1: 0.3870
Epoch 32/70
Train Loss: 0.5233, Accuracy: 0.8072, Precision: 0.5501, Recall: 0.5223, F1: 0.5293
Validation Loss: 1.0149, Accuracy: 0.6648, Precision: 0.4844, Recall: 0.4512, F1: 0.4391
Testing Loss: 0.9055, Accuracy: 0.7261, Precision: 0.4795, Recall: 0.4955, F1: 0.4786
LM Predictions:  [3, 1, 3, 5, 1, 4, 3, 5, 3, 3, 5, 3, 2, 4, 4, 5, 4, 4, 3, 5, 5, 5, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8187, Accuracy: 0.4643, Precision: 0.4833, Recall: 0.3655, F1: 0.3806
Epoch 33/70
Train Loss: 0.4771, Accuracy: 0.8376, Precision: 0.6781, Recall: 0.5815, F1: 0.6039
Validation Loss: 0.9452, Accuracy: 0.6932, Precision: 0.4636, Recall: 0.4533, F1: 0.4508
Testing Loss: 0.8586, Accuracy: 0.7128, Precision: 0.4610, Recall: 0.4691, F1: 0.4532
LM Predictions:  [3, 1, 3, 5, 1, 4, 1, 5, 5, 3, 5, 3, 2, 5, 4, 5, 1, 4, 3, 5, 5, 2, 5, 2, 5, 1, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3082, Accuracy: 0.5000, Precision: 0.4727, Recall: 0.3798, F1: 0.3917
Epoch 34/70
Train Loss: 0.4880, Accuracy: 0.8212, Precision: 0.6854, Recall: 0.5613, F1: 0.5817
Validation Loss: 1.0080, Accuracy: 0.6705, Precision: 0.4170, Recall: 0.4216, F1: 0.4154
Testing Loss: 0.9103, Accuracy: 0.7207, Precision: 0.4854, Recall: 0.5089, F1: 0.4824
LM Predictions:  [1, 3, 3, 2, 1, 4, 3, 5, 2, 3, 0, 3, 2, 1, 4, 5, 1, 4, 3, 5, 3, 2, 5, 2, 5, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3676, Accuracy: 0.4286, Precision: 0.4472, Recall: 0.3321, F1: 0.3782
Epoch 35/70
Train Loss: 0.4387, Accuracy: 0.8422, Precision: 0.7069, Recall: 0.6049, F1: 0.6245
Validation Loss: 1.3455, Accuracy: 0.6250, Precision: 0.4822, Recall: 0.4036, F1: 0.3734
Testing Loss: 1.1214, Accuracy: 0.7181, Precision: 0.5148, Recall: 0.4909, F1: 0.4638
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 0, 3, 3, 3, 4, 5, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4957, Accuracy: 0.2500, Precision: 0.6667, Recall: 0.2036, F1: 0.3101
Epoch 36/70
Train Loss: 0.4571, Accuracy: 0.8324, Precision: 0.6803, Recall: 0.5821, F1: 0.6002
Validation Loss: 0.9432, Accuracy: 0.6960, Precision: 0.4466, Recall: 0.4221, F1: 0.4275
Testing Loss: 0.8721, Accuracy: 0.7447, Precision: 0.5027, Recall: 0.4855, F1: 0.4897
LM Predictions:  [2, 1, 3, 5, 1, 4, 1, 5, 2, 3, 5, 3, 2, 5, 4, 5, 1, 4, 3, 5, 5, 2, 5, 2, 2, 1, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.9752, Accuracy: 0.6429, Precision: 0.6554, Recall: 0.4845, F1: 0.5160
Epoch 37/70
Train Loss: 0.4219, Accuracy: 0.8541, Precision: 0.7185, Recall: 0.6132, F1: 0.6387
Validation Loss: 1.1294, Accuracy: 0.6648, Precision: 0.4392, Recall: 0.4375, F1: 0.4296
Testing Loss: 1.0282, Accuracy: 0.7128, Precision: 0.4654, Recall: 0.4675, F1: 0.4553
LM Predictions:  [1, 1, 3, 5, 1, 4, 1, 5, 5, 3, 5, 3, 2, 5, 4, 5, 1, 4, 1, 3, 5, 2, 1, 2, 5, 3, 0, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1407, Accuracy: 0.5357, Precision: 0.6587, Recall: 0.4310, F1: 0.4662
Epoch 38/70
Train Loss: 0.4107, Accuracy: 0.8576, Precision: 0.7295, Recall: 0.6421, F1: 0.6606
Validation Loss: 1.0183, Accuracy: 0.7074, Precision: 0.4579, Recall: 0.4561, F1: 0.4552
Testing Loss: 0.9890, Accuracy: 0.7340, Precision: 0.4900, Recall: 0.5109, F1: 0.4885
LM Predictions:  [1, 1, 2, 5, 1, 4, 1, 5, 2, 3, 5, 3, 2, 5, 4, 5, 1, 4, 1, 5, 3, 2, 1, 2, 5, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.0297, Accuracy: 0.6429, Precision: 0.6905, Recall: 0.5024, F1: 0.5379
Epoch 39/70
Train Loss: 0.4076, Accuracy: 0.8523, Precision: 0.7119, Recall: 0.6273, F1: 0.6511
Validation Loss: 1.0032, Accuracy: 0.7330, Precision: 0.5181, Recall: 0.4613, F1: 0.4740
Testing Loss: 0.9408, Accuracy: 0.7553, Precision: 0.5064, Recall: 0.4870, F1: 0.4869
LM Predictions:  [2, 1, 2, 5, 1, 4, 0, 5, 2, 3, 5, 3, 2, 5, 4, 5, 1, 4, 3, 5, 5, 2, 5, 2, 5, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8591, Accuracy: 0.6786, Precision: 0.6019, Recall: 0.5083, F1: 0.5327
Epoch 40/70
Train Loss: 0.3814, Accuracy: 0.8586, Precision: 0.7438, Recall: 0.6415, F1: 0.6672
Validation Loss: 1.0771, Accuracy: 0.6903, Precision: 0.4611, Recall: 0.4391, F1: 0.4356
Testing Loss: 1.0213, Accuracy: 0.7340, Precision: 0.4953, Recall: 0.4863, F1: 0.4634
LM Predictions:  [2, 1, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5892, Accuracy: 0.8214, Precision: 0.6875, Recall: 0.6500, F1: 0.6648
Epoch 41/70
Train Loss: 0.3793, Accuracy: 0.8597, Precision: 0.7376, Recall: 0.6719, F1: 0.6943
Validation Loss: 1.0905, Accuracy: 0.7045, Precision: 0.5799, Recall: 0.4222, F1: 0.4269
Testing Loss: 1.0458, Accuracy: 0.7261, Precision: 0.4475, Recall: 0.4140, F1: 0.4063
LM Predictions:  [2, 1, 2, 5, 1, 4, 1, 5, 2, 3, 5, 0, 2, 5, 4, 5, 1, 4, 1, 5, 5, 2, 5, 2, 5, 1, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5700, Accuracy: 0.7500, Precision: 0.6852, Recall: 0.5833, F1: 0.5994
Epoch 42/70
Train Loss: 0.3374, Accuracy: 0.8775, Precision: 0.7807, Recall: 0.6981, F1: 0.7247
Validation Loss: 1.2449, Accuracy: 0.7045, Precision: 0.4922, Recall: 0.4007, F1: 0.4136
Testing Loss: 1.2105, Accuracy: 0.7207, Precision: 0.4968, Recall: 0.4107, F1: 0.4199
LM Predictions:  [2, 1, 2, 5, 1, 4, 4, 5, 2, 3, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 2, 2, 1, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.7351, Accuracy: 0.7143, Precision: 0.5227, Recall: 0.5595, F1: 0.5335
Epoch 43/70
Train Loss: 0.3298, Accuracy: 0.8835, Precision: 0.7755, Recall: 0.7111, F1: 0.7338
Validation Loss: 1.4342, Accuracy: 0.6705, Precision: 0.4904, Recall: 0.4303, F1: 0.4317
Testing Loss: 1.3013, Accuracy: 0.6915, Precision: 0.4616, Recall: 0.4500, F1: 0.4348
LM Predictions:  [2, 1, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 4, 1, 0, 0]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5807, Accuracy: 0.8214, Precision: 0.8000, Recall: 0.8014, F1: 0.7864
Epoch 44/70
Train Loss: 0.3126, Accuracy: 0.8803, Precision: 0.7439, Recall: 0.7024, F1: 0.7200
Validation Loss: 1.1497, Accuracy: 0.7074, Precision: 0.5277, Recall: 0.4688, F1: 0.4828
Testing Loss: 1.0866, Accuracy: 0.7447, Precision: 0.4730, Recall: 0.4654, F1: 0.4615
LM Predictions:  [2, 1, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3915, Accuracy: 0.8571, Precision: 0.7292, Recall: 0.6833, F1: 0.6972
Epoch 45/70
Train Loss: 0.2966, Accuracy: 0.8957, Precision: 0.7993, Recall: 0.7330, F1: 0.7559
Validation Loss: 1.1890, Accuracy: 0.6790, Precision: 0.5006, Recall: 0.5028, F1: 0.4721
Testing Loss: 1.1360, Accuracy: 0.7128, Precision: 0.5042, Recall: 0.5100, F1: 0.4855
LM Predictions:  [1, 1, 2, 5, 1, 4, 0, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 0]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5244, Accuracy: 0.7500, Precision: 0.6667, Recall: 0.6202, F1: 0.6318
Epoch 46/70
Train Loss: 0.2866, Accuracy: 0.8922, Precision: 0.7853, Recall: 0.7351, F1: 0.7559
Validation Loss: 1.2721, Accuracy: 0.7188, Precision: 0.5023, Recall: 0.4296, F1: 0.4438
Testing Loss: 1.2222, Accuracy: 0.7500, Precision: 0.5058, Recall: 0.4559, F1: 0.4646
LM Predictions:  [2, 0, 2, 5, 1, 4, 2, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4518, Accuracy: 0.8571, Precision: 0.7407, Recall: 0.6833, F1: 0.7040
Epoch 47/70
Train Loss: 0.2818, Accuracy: 0.8996, Precision: 0.8057, Recall: 0.7378, F1: 0.7631
Validation Loss: 1.0296, Accuracy: 0.7273, Precision: 0.4948, Recall: 0.4599, F1: 0.4703
Testing Loss: 1.0179, Accuracy: 0.7580, Precision: 0.5358, Recall: 0.5121, F1: 0.5185
LM Predictions:  [2, 3, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5507, Accuracy: 0.7857, Precision: 0.7014, Recall: 0.6167, F1: 0.6489
Epoch 48/70
Train Loss: 0.2627, Accuracy: 0.9076, Precision: 0.8248, Recall: 0.7741, F1: 0.7958
Validation Loss: 1.1767, Accuracy: 0.7244, Precision: 0.5113, Recall: 0.4886, F1: 0.4923
Testing Loss: 1.1841, Accuracy: 0.7234, Precision: 0.4499, Recall: 0.4559, F1: 0.4459
LM Predictions:  [3, 1, 2, 5, 1, 4, 0, 5, 2, 1, 5, 0, 3, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6006, Accuracy: 0.7857, Precision: 0.7042, Recall: 0.6440, F1: 0.6648
Epoch 49/70
Train Loss: 0.2229, Accuracy: 0.9199, Precision: 0.8432, Recall: 0.8051, F1: 0.8212
Validation Loss: 1.3169, Accuracy: 0.7017, Precision: 0.5112, Recall: 0.4719, F1: 0.4749
Testing Loss: 1.2475, Accuracy: 0.7340, Precision: 0.4860, Recall: 0.4675, F1: 0.4567
LM Predictions:  [4, 1, 2, 5, 1, 4, 0, 5, 2, 1, 5, 0, 3, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3590, Accuracy: 0.7857, Precision: 0.6708, Recall: 0.6440, F1: 0.6500
Epoch 50/70
Train Loss: 0.2401, Accuracy: 0.9181, Precision: 0.8437, Recall: 0.8318, F1: 0.8372
Validation Loss: 1.1882, Accuracy: 0.7074, Precision: 0.5304, Recall: 0.4420, F1: 0.4584
Testing Loss: 1.1359, Accuracy: 0.7500, Precision: 0.4713, Recall: 0.4493, F1: 0.4490
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3839, Accuracy: 0.8929, Precision: 0.7847, Recall: 0.7167, F1: 0.7330
Epoch 51/70
Train Loss: 0.2373, Accuracy: 0.9178, Precision: 0.8482, Recall: 0.8168, F1: 0.8313
Validation Loss: 1.0826, Accuracy: 0.6960, Precision: 0.5373, Recall: 0.5238, F1: 0.4898
Testing Loss: 1.0791, Accuracy: 0.7234, Precision: 0.4873, Recall: 0.4886, F1: 0.4777
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 3, 0, 3, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.5492, Accuracy: 0.7857, Precision: 0.7206, Recall: 0.6357, F1: 0.6734
Epoch 52/70
Train Loss: 0.2338, Accuracy: 0.9206, Precision: 0.8609, Recall: 0.8236, F1: 0.8396
Validation Loss: 1.3487, Accuracy: 0.7330, Precision: 0.5262, Recall: 0.4746, F1: 0.4826
Testing Loss: 1.2901, Accuracy: 0.7500, Precision: 0.4776, Recall: 0.4621, F1: 0.4572
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3267, Accuracy: 0.8571, Precision: 0.7236, Recall: 0.6833, F1: 0.6989
Epoch 53/70
Train Loss: 0.2170, Accuracy: 0.9220, Precision: 0.8443, Recall: 0.8215, F1: 0.8320
Validation Loss: 1.2146, Accuracy: 0.7102, Precision: 0.4686, Recall: 0.4541, F1: 0.4546
Testing Loss: 1.1571, Accuracy: 0.7314, Precision: 0.4750, Recall: 0.4572, F1: 0.4614
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3048, Accuracy: 0.8929, Precision: 0.7569, Recall: 0.7167, F1: 0.7323
Epoch 54/70
Train Loss: 0.1938, Accuracy: 0.9297, Precision: 0.8502, Recall: 0.8273, F1: 0.8372
Validation Loss: 1.3183, Accuracy: 0.7131, Precision: 0.4965, Recall: 0.4910, F1: 0.4915
Testing Loss: 1.2674, Accuracy: 0.7394, Precision: 0.4781, Recall: 0.4868, F1: 0.4802
LM Predictions:  [4, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2598, Accuracy: 0.9286, Precision: 0.9267, Recall: 0.9314, F1: 0.9220
Epoch 55/70
Train Loss: 0.1828, Accuracy: 0.9367, Precision: 0.8903, Recall: 0.8610, F1: 0.8744
Validation Loss: 1.3817, Accuracy: 0.7102, Precision: 0.5202, Recall: 0.4526, F1: 0.4607
Testing Loss: 1.2768, Accuracy: 0.7447, Precision: 0.4866, Recall: 0.4627, F1: 0.4644
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2881, Accuracy: 0.9286, Precision: 0.8125, Recall: 0.7500, F1: 0.7667
Epoch 56/70
Train Loss: 0.1828, Accuracy: 0.9360, Precision: 0.8788, Recall: 0.8586, F1: 0.8675
Validation Loss: 1.2667, Accuracy: 0.7188, Precision: 0.4953, Recall: 0.4804, F1: 0.4843
Testing Loss: 1.1993, Accuracy: 0.7420, Precision: 0.4673, Recall: 0.4695, F1: 0.4677
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 3, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2551, Accuracy: 0.8929, Precision: 0.8333, Recall: 0.7345, F1: 0.7782
Epoch 57/70
Train Loss: 0.1841, Accuracy: 0.9381, Precision: 0.8830, Recall: 0.8523, F1: 0.8661
Validation Loss: 1.4427, Accuracy: 0.6989, Precision: 0.5301, Recall: 0.4969, F1: 0.5020
Testing Loss: 1.2744, Accuracy: 0.7367, Precision: 0.4905, Recall: 0.4953, F1: 0.4892
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1416, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 58/70
Train Loss: 0.1798, Accuracy: 0.9346, Precision: 0.8872, Recall: 0.8593, F1: 0.8717
Validation Loss: 1.4406, Accuracy: 0.7244, Precision: 0.5064, Recall: 0.4765, F1: 0.4831
Testing Loss: 1.3880, Accuracy: 0.7473, Precision: 0.4832, Recall: 0.4667, F1: 0.4658
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0799, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9500, F1: 0.9581
Epoch 59/70
Train Loss: 0.1690, Accuracy: 0.9381, Precision: 0.8926, Recall: 0.8468, F1: 0.8669
Validation Loss: 1.3730, Accuracy: 0.7188, Precision: 0.4939, Recall: 0.4796, F1: 0.4731
Testing Loss: 1.2755, Accuracy: 0.7527, Precision: 0.4835, Recall: 0.4830, F1: 0.4797
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1135, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9500, F1: 0.9581
Epoch 60/70
Train Loss: 0.1628, Accuracy: 0.9391, Precision: 0.8914, Recall: 0.8671, F1: 0.8782
Validation Loss: 1.3623, Accuracy: 0.7415, Precision: 0.5670, Recall: 0.5294, F1: 0.5433
Testing Loss: 1.3199, Accuracy: 0.7234, Precision: 0.4391, Recall: 0.4173, F1: 0.4232
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0702, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9500, F1: 0.9581
Epoch 61/70
Train Loss: 0.1524, Accuracy: 0.9447, Precision: 0.8891, Recall: 0.8815, F1: 0.8851
Validation Loss: 1.5457, Accuracy: 0.7074, Precision: 0.5455, Recall: 0.4813, F1: 0.4654
Testing Loss: 1.3471, Accuracy: 0.7234, Precision: 0.4739, Recall: 0.4458, F1: 0.4411
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 1, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2997, Accuracy: 0.8929, Precision: 0.8125, Recall: 0.7250, F1: 0.7567
Epoch 62/70
Train Loss: 0.1589, Accuracy: 0.9430, Precision: 0.8846, Recall: 0.8717, F1: 0.8778
Validation Loss: 1.3648, Accuracy: 0.7358, Precision: 0.5528, Recall: 0.5549, F1: 0.5492
Testing Loss: 1.2991, Accuracy: 0.7394, Precision: 0.4632, Recall: 0.4518, F1: 0.4547
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0568, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.1333, Accuracy: 0.9566, Precision: 0.9130, Recall: 0.9098, F1: 0.9113
Validation Loss: 1.6441, Accuracy: 0.6875, Precision: 0.5659, Recall: 0.5140, F1: 0.4874
Testing Loss: 1.4482, Accuracy: 0.7314, Precision: 0.4851, Recall: 0.4703, F1: 0.4634
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3294, Accuracy: 0.8571, Precision: 0.7792, Recall: 0.6833, F1: 0.7148
Epoch 64/70
Train Loss: 0.1533, Accuracy: 0.9461, Precision: 0.8909, Recall: 0.8797, F1: 0.8849
Validation Loss: 1.3908, Accuracy: 0.7330, Precision: 0.5620, Recall: 0.4952, F1: 0.4903
Testing Loss: 1.3011, Accuracy: 0.7553, Precision: 0.4961, Recall: 0.4916, F1: 0.4860
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 5, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1645, Accuracy: 0.9286, Precision: 0.8125, Recall: 0.7583, F1: 0.7799
Epoch 65/70
Train Loss: 0.1305, Accuracy: 0.9542, Precision: 0.9360, Recall: 0.9117, F1: 0.9230
Validation Loss: 1.5744, Accuracy: 0.7273, Precision: 0.5369, Recall: 0.5639, F1: 0.5455
Testing Loss: 1.5049, Accuracy: 0.7420, Precision: 0.4763, Recall: 0.4841, F1: 0.4791
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0490, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8000, F1: 0.8148
Epoch 66/70
Train Loss: 0.1312, Accuracy: 0.9482, Precision: 0.8884, Recall: 0.8976, F1: 0.8928
Validation Loss: 1.4379, Accuracy: 0.7244, Precision: 0.5388, Recall: 0.5750, F1: 0.5511
Testing Loss: 1.3369, Accuracy: 0.7473, Precision: 0.4955, Recall: 0.5010, F1: 0.4967
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0948, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.1108, Accuracy: 0.9608, Precision: 0.9227, Recall: 0.9207, F1: 0.9217
Validation Loss: 1.6389, Accuracy: 0.7330, Precision: 0.5378, Recall: 0.5015, F1: 0.5079
Testing Loss: 1.5520, Accuracy: 0.7633, Precision: 0.4868, Recall: 0.4634, F1: 0.4639
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0658, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.1074, Accuracy: 0.9570, Precision: 0.9077, Recall: 0.8986, F1: 0.9030
Validation Loss: 1.4999, Accuracy: 0.7301, Precision: 0.5371, Recall: 0.5257, F1: 0.5294
Testing Loss: 1.4756, Accuracy: 0.7500, Precision: 0.4626, Recall: 0.4548, F1: 0.4555
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0444, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.1066, Accuracy: 0.9664, Precision: 0.9392, Recall: 0.9230, F1: 0.9307
Validation Loss: 1.7572, Accuracy: 0.7045, Precision: 0.5393, Recall: 0.5469, F1: 0.5176
Testing Loss: 1.6997, Accuracy: 0.7394, Precision: 0.5029, Recall: 0.4927, F1: 0.4695
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0086, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.1039, Accuracy: 0.9661, Precision: 0.9292, Recall: 0.9239, F1: 0.9265
Validation Loss: 1.5949, Accuracy: 0.7017, Precision: 0.5168, Recall: 0.5208, F1: 0.5153
Testing Loss: 1.4296, Accuracy: 0.7367, Precision: 0.4538, Recall: 0.4527, F1: 0.4526
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0222, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For middle layers:  [4, 5, 6, 7]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.5347, Accuracy: 0.3502, Precision: 0.1516, Recall: 0.1670, F1: 0.1545
Validation Loss: 1.4251, Accuracy: 0.3750, Precision: 0.1044, Recall: 0.1656, F1: 0.0935
Testing Loss: 1.4712, Accuracy: 0.3617, Precision: 0.1435, Recall: 0.1667, F1: 0.0907
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0760, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 2/70
Train Loss: 1.4024, Accuracy: 0.3877, Precision: 0.1647, Recall: 0.1779, F1: 0.1558
Validation Loss: 1.4085, Accuracy: 0.3864, Precision: 0.2302, Recall: 0.1709, F1: 0.1003
Testing Loss: 1.4410, Accuracy: 0.3723, Precision: 0.3525, Recall: 0.1749, F1: 0.1073
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9637, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 3/70
Train Loss: 1.3848, Accuracy: 0.3940, Precision: 0.1671, Recall: 0.1807, F1: 0.1577
Validation Loss: 1.3625, Accuracy: 0.3892, Precision: 0.2304, Recall: 0.1724, F1: 0.1032
Testing Loss: 1.3993, Accuracy: 0.3803, Precision: 0.2281, Recall: 0.1754, F1: 0.1064
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0764, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 4/70
Train Loss: 1.2618, Accuracy: 0.5161, Precision: 0.2468, Recall: 0.2443, F1: 0.2244
Validation Loss: 0.9976, Accuracy: 0.6392, Precision: 0.3152, Recall: 0.3096, F1: 0.2807
Testing Loss: 1.0268, Accuracy: 0.6676, Precision: 0.3216, Recall: 0.3225, F1: 0.2954
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8896, Accuracy: 0.2857, Precision: 0.1227, Recall: 0.2286, F1: 0.1275
Epoch 5/70
Train Loss: 0.9593, Accuracy: 0.6631, Precision: 0.3236, Recall: 0.3260, F1: 0.3135
Validation Loss: 0.8118, Accuracy: 0.7301, Precision: 0.3535, Recall: 0.4066, F1: 0.3743
Testing Loss: 0.7838, Accuracy: 0.7580, Precision: 0.3597, Recall: 0.4187, F1: 0.3850
LM Predictions:  [5, 5, 2, 2, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 2, 5, 5, 5, 5, 2, 4, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0776, Accuracy: 0.2857, Precision: 0.1222, Recall: 0.2286, F1: 0.1550
Epoch 6/70
Train Loss: 0.7159, Accuracy: 0.7523, Precision: 0.5686, Recall: 0.4107, F1: 0.3955
Validation Loss: 0.7978, Accuracy: 0.7500, Precision: 0.5247, Recall: 0.4036, F1: 0.3894
Testing Loss: 0.7445, Accuracy: 0.7633, Precision: 0.3618, Recall: 0.4129, F1: 0.3853
LM Predictions:  [5, 3, 2, 2, 5, 2, 5, 5, 5, 5, 5, 2, 2, 2, 4, 5, 5, 5, 2, 5, 2, 5, 5, 2, 4, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8959, Accuracy: 0.2857, Precision: 0.1778, Recall: 0.2000, F1: 0.1670
Epoch 7/70
Train Loss: 0.5963, Accuracy: 0.7981, Precision: 0.5286, Recall: 0.4642, F1: 0.4600
Validation Loss: 0.6844, Accuracy: 0.7699, Precision: 0.4563, Recall: 0.4531, F1: 0.4385
Testing Loss: 0.6365, Accuracy: 0.7926, Precision: 0.5106, Recall: 0.4758, F1: 0.4683
LM Predictions:  [3, 3, 2, 2, 5, 2, 3, 5, 5, 3, 3, 5, 2, 2, 4, 5, 5, 3, 3, 3, 5, 5, 5, 2, 4, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9637, Accuracy: 0.2500, Precision: 0.2167, Recall: 0.1762, F1: 0.1834
Epoch 8/70
Train Loss: 0.5264, Accuracy: 0.8195, Precision: 0.5651, Recall: 0.5259, F1: 0.5340
Validation Loss: 0.5461, Accuracy: 0.8352, Precision: 0.6340, Recall: 0.6137, F1: 0.6203
Testing Loss: 0.5590, Accuracy: 0.8324, Precision: 0.6116, Recall: 0.6145, F1: 0.5988
LM Predictions:  [3, 3, 3, 2, 1, 2, 3, 5, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.5769, Accuracy: 0.1429, Precision: 0.2361, Recall: 0.1310, F1: 0.1626
Epoch 9/70
Train Loss: 0.4666, Accuracy: 0.8464, Precision: 0.6127, Recall: 0.5967, F1: 0.6009
Validation Loss: 0.5619, Accuracy: 0.8381, Precision: 0.6749, Recall: 0.5987, F1: 0.6230
Testing Loss: 0.5670, Accuracy: 0.8191, Precision: 0.5858, Recall: 0.5669, F1: 0.5691
LM Predictions:  [3, 3, 3, 2, 1, 2, 3, 5, 5, 3, 3, 3, 3, 2, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.5345, Accuracy: 0.1786, Precision: 0.4028, Recall: 0.1643, F1: 0.2181
Epoch 10/70
Train Loss: 0.4136, Accuracy: 0.8611, Precision: 0.8052, Recall: 0.6302, F1: 0.6368
Validation Loss: 0.5787, Accuracy: 0.8352, Precision: 0.6488, Recall: 0.6015, F1: 0.6187
Testing Loss: 0.6030, Accuracy: 0.8138, Precision: 0.5752, Recall: 0.5735, F1: 0.5611
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 3, 2, 3, 5, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.5556, Accuracy: 0.1429, Precision: 0.1944, Recall: 0.1310, F1: 0.1558
Epoch 11/70
Train Loss: 0.3622, Accuracy: 0.8772, Precision: 0.8156, Recall: 0.6650, F1: 0.6609
Validation Loss: 0.5555, Accuracy: 0.8438, Precision: 0.6723, Recall: 0.6311, F1: 0.6484
Testing Loss: 0.5366, Accuracy: 0.8484, Precision: 0.6428, Recall: 0.6322, F1: 0.6344
LM Predictions:  [3, 3, 3, 2, 1, 2, 3, 5, 3, 3, 3, 3, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3591, Accuracy: 0.1786, Precision: 0.4833, Recall: 0.1464, F1: 0.2083
Epoch 12/70
Train Loss: 0.3297, Accuracy: 0.8880, Precision: 0.7489, Recall: 0.6914, F1: 0.6865
Validation Loss: 0.5594, Accuracy: 0.8438, Precision: 0.6948, Recall: 0.6857, F1: 0.6794
Testing Loss: 0.5909, Accuracy: 0.8404, Precision: 0.6535, Recall: 0.6637, F1: 0.6571
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 3, 0, 3, 5, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.8717, Accuracy: 0.1071, Precision: 0.1944, Recall: 0.0893, F1: 0.1222
Epoch 13/70
Train Loss: 0.2804, Accuracy: 0.9059, Precision: 0.7644, Recall: 0.7205, F1: 0.7215
Validation Loss: 0.5427, Accuracy: 0.8381, Precision: 0.6970, Recall: 0.7109, F1: 0.6978
Testing Loss: 0.5712, Accuracy: 0.8431, Precision: 0.6251, Recall: 0.6347, F1: 0.6253
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 2, 0, 4, 5, 3, 3, 3, 3, 3, 3, 5, 3, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3186, Accuracy: 0.2143, Precision: 0.4833, Recall: 0.1881, F1: 0.2593
Epoch 14/70
Train Loss: 0.2523, Accuracy: 0.9171, Precision: 0.8095, Recall: 0.7631, F1: 0.7737
Validation Loss: 0.6257, Accuracy: 0.8409, Precision: 0.6920, Recall: 0.6906, F1: 0.6783
Testing Loss: 0.6768, Accuracy: 0.8298, Precision: 0.6013, Recall: 0.6301, F1: 0.5996
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 2, 0, 4, 3, 3, 3, 3, 1, 3, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4405, Accuracy: 0.2500, Precision: 0.4583, Recall: 0.2119, F1: 0.2668
Epoch 15/70
Train Loss: 0.2113, Accuracy: 0.9314, Precision: 0.8608, Recall: 0.8119, F1: 0.8228
Validation Loss: 0.6857, Accuracy: 0.8494, Precision: 0.6796, Recall: 0.6339, F1: 0.6500
Testing Loss: 0.6921, Accuracy: 0.8378, Precision: 0.6284, Recall: 0.6124, F1: 0.6135
LM Predictions:  [3, 3, 3, 2, 1, 2, 3, 5, 5, 3, 3, 5, 2, 2, 4, 5, 3, 3, 3, 3, 3, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1464, Accuracy: 0.2857, Precision: 0.4444, Recall: 0.2357, F1: 0.2883
Epoch 16/70
Train Loss: 0.1870, Accuracy: 0.9391, Precision: 0.8572, Recall: 0.8250, F1: 0.8345
Validation Loss: 0.7569, Accuracy: 0.8267, Precision: 0.6886, Recall: 0.6917, F1: 0.6837
Testing Loss: 0.6294, Accuracy: 0.8324, Precision: 0.6037, Recall: 0.6326, F1: 0.6125
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 3, 3, 3, 0, 4, 5, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1207, Accuracy: 0.2143, Precision: 0.5833, Recall: 0.1798, F1: 0.2665
Epoch 17/70
Train Loss: 0.1646, Accuracy: 0.9458, Precision: 0.8723, Recall: 0.8461, F1: 0.8553
Validation Loss: 0.5859, Accuracy: 0.8636, Precision: 0.7367, Recall: 0.7177, F1: 0.7249
Testing Loss: 0.5996, Accuracy: 0.8431, Precision: 0.6311, Recall: 0.6383, F1: 0.6321
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 5, 3, 3, 3, 2, 0, 4, 5, 3, 3, 3, 1, 5, 3, 5, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9618, Accuracy: 0.3214, Precision: 0.5167, Recall: 0.2512, F1: 0.3341
Epoch 18/70
Train Loss: 0.1388, Accuracy: 0.9507, Precision: 0.8792, Recall: 0.8609, F1: 0.8669
Validation Loss: 0.9395, Accuracy: 0.8409, Precision: 0.7023, Recall: 0.6811, F1: 0.6857
Testing Loss: 0.8468, Accuracy: 0.8404, Precision: 0.6185, Recall: 0.6240, F1: 0.6107
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 0, 3, 3, 0, 2, 0, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1833, Accuracy: 0.3214, Precision: 0.6667, Recall: 0.2786, F1: 0.3738
Epoch 19/70
Train Loss: 0.1114, Accuracy: 0.9619, Precision: 0.9072, Recall: 0.9043, F1: 0.9046
Validation Loss: 0.7249, Accuracy: 0.8551, Precision: 0.7467, Recall: 0.7031, F1: 0.7205
Testing Loss: 0.7317, Accuracy: 0.8351, Precision: 0.6121, Recall: 0.6145, F1: 0.6108
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 5, 3, 3, 5, 2, 0, 4, 5, 3, 3, 3, 5, 5, 2, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5259, Accuracy: 0.3929, Precision: 0.5278, Recall: 0.2988, F1: 0.3746
Epoch 20/70
Train Loss: 0.1107, Accuracy: 0.9626, Precision: 0.9193, Recall: 0.9098, F1: 0.9136
Validation Loss: 0.7806, Accuracy: 0.8352, Precision: 0.7122, Recall: 0.7136, F1: 0.7073
Testing Loss: 0.7039, Accuracy: 0.8431, Precision: 0.6970, Recall: 0.6785, F1: 0.6708
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 3, 3, 3, 3, 4, 5, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9142, Accuracy: 0.2500, Precision: 0.5833, Recall: 0.2036, F1: 0.2989
Epoch 21/70
Train Loss: 0.1030, Accuracy: 0.9685, Precision: 0.9173, Recall: 0.9167, F1: 0.9159
Validation Loss: 0.7712, Accuracy: 0.8466, Precision: 0.6668, Recall: 0.7063, F1: 0.6783
Testing Loss: 0.7645, Accuracy: 0.8564, Precision: 0.7269, Recall: 0.6854, F1: 0.6881
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 3, 0, 2, 5, 4, 5, 3, 3, 3, 5, 5, 2, 5, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7074, Accuracy: 0.5000, Precision: 0.8056, Recall: 0.3976, F1: 0.5113
Epoch 22/70
Train Loss: 0.0780, Accuracy: 0.9762, Precision: 0.9469, Recall: 0.9369, F1: 0.9405
Validation Loss: 1.0190, Accuracy: 0.8267, Precision: 0.6705, Recall: 0.6939, F1: 0.6621
Testing Loss: 0.9938, Accuracy: 0.8457, Precision: 0.7162, Recall: 0.7895, F1: 0.7230
LM Predictions:  [2, 3, 2, 3, 1, 4, 3, 5, 0, 3, 3, 0, 2, 0, 4, 5, 3, 3, 1, 5, 0, 2, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1885, Accuracy: 0.5357, Precision: 0.6667, Recall: 0.4393, F1: 0.5111
Epoch 23/70
Train Loss: 0.0656, Accuracy: 0.9769, Precision: 0.9430, Recall: 0.9327, F1: 0.9370
Validation Loss: 1.0000, Accuracy: 0.8438, Precision: 0.6878, Recall: 0.6742, F1: 0.6693
Testing Loss: 0.9702, Accuracy: 0.8404, Precision: 0.6272, Recall: 0.6395, F1: 0.6235
LM Predictions:  [3, 3, 2, 5, 1, 4, 3, 5, 2, 3, 3, 0, 2, 5, 4, 5, 3, 3, 1, 5, 5, 2, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8960, Accuracy: 0.6429, Precision: 0.7917, Recall: 0.5107, F1: 0.5835
Epoch 24/70
Train Loss: 0.0706, Accuracy: 0.9734, Precision: 0.9363, Recall: 0.9357, F1: 0.9356
Validation Loss: 0.9187, Accuracy: 0.8381, Precision: 0.7069, Recall: 0.6730, F1: 0.6790
Testing Loss: 0.8362, Accuracy: 0.8404, Precision: 0.6334, Recall: 0.6293, F1: 0.6301
LM Predictions:  [3, 3, 2, 5, 1, 4, 4, 5, 2, 3, 5, 5, 2, 5, 4, 5, 4, 3, 1, 5, 5, 2, 1, 2, 1, 3, 5, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.7122, Accuracy: 0.7143, Precision: 0.5880, Recall: 0.5679, F1: 0.5728
Epoch 25/70
Train Loss: 0.0590, Accuracy: 0.9794, Precision: 0.9465, Recall: 0.9303, F1: 0.9376
Validation Loss: 1.1061, Accuracy: 0.8210, Precision: 0.6859, Recall: 0.5927, F1: 0.6267
Testing Loss: 1.0276, Accuracy: 0.8431, Precision: 0.7726, Recall: 0.6643, F1: 0.6992
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 3, 3, 1, 5, 5, 2, 5, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6071, Accuracy: 0.7857, Precision: 0.7679, Recall: 0.6345, F1: 0.6885
Epoch 26/70
Train Loss: 0.0473, Accuracy: 0.9853, Precision: 0.9603, Recall: 0.9579, F1: 0.9588
Validation Loss: 0.9566, Accuracy: 0.8210, Precision: 0.6279, Recall: 0.6186, F1: 0.6087
Testing Loss: 0.9850, Accuracy: 0.8431, Precision: 0.7020, Recall: 0.6924, F1: 0.6619
LM Predictions:  [2, 3, 2, 3, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 3, 1, 5, 5, 2, 1, 2, 1, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6331, Accuracy: 0.7500, Precision: 0.7361, Recall: 0.6107, F1: 0.6620
Epoch 27/70
Train Loss: 0.0454, Accuracy: 0.9843, Precision: 0.9641, Recall: 0.9588, F1: 0.9612
Validation Loss: 1.2700, Accuracy: 0.8210, Precision: 0.7022, Recall: 0.6683, F1: 0.6724
Testing Loss: 1.1145, Accuracy: 0.8404, Precision: 0.7049, Recall: 0.6587, F1: 0.6567
LM Predictions:  [2, 0, 2, 1, 1, 4, 4, 5, 2, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3650, Accuracy: 0.8929, Precision: 0.8933, Recall: 0.9029, F1: 0.8867
Epoch 28/70
Train Loss: 0.0382, Accuracy: 0.9902, Precision: 0.9723, Recall: 0.9720, F1: 0.9721
Validation Loss: 0.8606, Accuracy: 0.8466, Precision: 0.7161, Recall: 0.6597, F1: 0.6752
Testing Loss: 0.9103, Accuracy: 0.8457, Precision: 0.6283, Recall: 0.6318, F1: 0.6225
LM Predictions:  [2, 0, 2, 0, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 3, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3845, Accuracy: 0.8214, Precision: 0.7361, Recall: 0.6774, F1: 0.6999
Epoch 29/70
Train Loss: 0.0357, Accuracy: 0.9892, Precision: 0.9683, Recall: 0.9697, F1: 0.9689
Validation Loss: 0.9079, Accuracy: 0.8409, Precision: 0.7056, Recall: 0.7034, F1: 0.6990
Testing Loss: 0.9925, Accuracy: 0.8431, Precision: 0.6262, Recall: 0.6560, F1: 0.6269
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2243, Accuracy: 0.9286, Precision: 0.9200, Recall: 0.9314, F1: 0.9224
Epoch 30/70
Train Loss: 0.0239, Accuracy: 0.9923, Precision: 0.9836, Recall: 0.9733, F1: 0.9782
Validation Loss: 1.0425, Accuracy: 0.8352, Precision: 0.6849, Recall: 0.5872, F1: 0.6153
Testing Loss: 1.0770, Accuracy: 0.8378, Precision: 0.6406, Recall: 0.6112, F1: 0.6207
LM Predictions:  [2, 0, 2, 0, 1, 4, 4, 5, 2, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1795, Accuracy: 0.8929, Precision: 0.8933, Recall: 0.9029, F1: 0.8899
Epoch 31/70
Train Loss: 0.0248, Accuracy: 0.9920, Precision: 0.9733, Recall: 0.9822, F1: 0.9776
Validation Loss: 1.3037, Accuracy: 0.8466, Precision: 0.7560, Recall: 0.6782, F1: 0.6988
Testing Loss: 1.3084, Accuracy: 0.8537, Precision: 0.7194, Recall: 0.6554, F1: 0.6795
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0891, Accuracy: 0.9286, Precision: 0.8056, Recall: 0.7857, F1: 0.7925
Epoch 32/70
Train Loss: 0.0268, Accuracy: 0.9916, Precision: 0.9850, Recall: 0.9821, F1: 0.9835
Validation Loss: 1.0452, Accuracy: 0.8381, Precision: 0.7051, Recall: 0.7074, F1: 0.6974
Testing Loss: 1.0829, Accuracy: 0.8404, Precision: 0.6368, Recall: 0.6391, F1: 0.6316
LM Predictions:  [2, 0, 2, 0, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1587, Accuracy: 0.8929, Precision: 0.7857, Recall: 0.7440, F1: 0.7540
Epoch 33/70
Train Loss: 0.0269, Accuracy: 0.9906, Precision: 0.9728, Recall: 0.9738, F1: 0.9733
Validation Loss: 1.0408, Accuracy: 0.8381, Precision: 0.7036, Recall: 0.6847, F1: 0.6835
Testing Loss: 1.0637, Accuracy: 0.8404, Precision: 0.6438, Recall: 0.6285, F1: 0.6292
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0835, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 34/70
Train Loss: 0.0256, Accuracy: 0.9927, Precision: 0.9836, Recall: 0.9877, F1: 0.9856
Validation Loss: 0.9034, Accuracy: 0.8494, Precision: 0.6891, Recall: 0.6584, F1: 0.6726
Testing Loss: 1.0768, Accuracy: 0.8404, Precision: 0.6107, Recall: 0.6190, F1: 0.6132
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0111, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 35/70
Train Loss: 0.0333, Accuracy: 0.9885, Precision: 0.9670, Recall: 0.9603, F1: 0.9635
Validation Loss: 0.9004, Accuracy: 0.8580, Precision: 0.7465, Recall: 0.7098, F1: 0.7236
Testing Loss: 0.9446, Accuracy: 0.8511, Precision: 0.6623, Recall: 0.6215, F1: 0.6329
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1855, Accuracy: 0.9286, Precision: 0.7917, Recall: 0.7583, F1: 0.7731
Epoch 36/70
Train Loss: 0.0240, Accuracy: 0.9927, Precision: 0.9816, Recall: 0.9821, F1: 0.9818
Validation Loss: 0.9302, Accuracy: 0.8409, Precision: 0.6962, Recall: 0.7623, F1: 0.7137
Testing Loss: 1.0323, Accuracy: 0.8324, Precision: 0.6060, Recall: 0.6178, F1: 0.5971
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0507, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 37/70
Train Loss: 0.0233, Accuracy: 0.9941, Precision: 0.9871, Recall: 0.9858, F1: 0.9864
Validation Loss: 0.8675, Accuracy: 0.8722, Precision: 0.7488, Recall: 0.7811, F1: 0.7477
Testing Loss: 1.0070, Accuracy: 0.8351, Precision: 0.6629, Recall: 0.6386, F1: 0.6469
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0543, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 38/70
Train Loss: 0.0130, Accuracy: 0.9955, Precision: 0.9817, Recall: 0.9815, F1: 0.9816
Validation Loss: 1.1648, Accuracy: 0.8295, Precision: 0.6994, Recall: 0.7128, F1: 0.7044
Testing Loss: 1.1583, Accuracy: 0.8324, Precision: 0.6457, Recall: 0.6510, F1: 0.6433
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 3, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0376, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 39/70
Train Loss: 0.0096, Accuracy: 0.9965, Precision: 0.9873, Recall: 0.9898, F1: 0.9885
Validation Loss: 1.2491, Accuracy: 0.8438, Precision: 0.7172, Recall: 0.7568, F1: 0.7192
Testing Loss: 1.2860, Accuracy: 0.8404, Precision: 0.7217, Recall: 0.6660, F1: 0.6872
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 3, 5, 5, 2, 0, 2, 3, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3124, Accuracy: 0.8929, Precision: 0.8333, Recall: 0.7083, F1: 0.7333
Epoch 40/70
Train Loss: 0.0197, Accuracy: 0.9930, Precision: 0.9851, Recall: 0.9787, F1: 0.9818
Validation Loss: 1.1631, Accuracy: 0.8438, Precision: 0.6935, Recall: 0.6441, F1: 0.6628
Testing Loss: 1.2281, Accuracy: 0.8404, Precision: 0.8046, Recall: 0.6460, F1: 0.6638
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0335, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 41/70
Train Loss: 0.0197, Accuracy: 0.9930, Precision: 0.9842, Recall: 0.9842, F1: 0.9842
Validation Loss: 1.0231, Accuracy: 0.8494, Precision: 0.7136, Recall: 0.7781, F1: 0.7200
Testing Loss: 0.9929, Accuracy: 0.8590, Precision: 0.6847, Recall: 0.6943, F1: 0.6886
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0497, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 42/70
Train Loss: 0.0106, Accuracy: 0.9965, Precision: 0.9952, Recall: 0.9927, F1: 0.9940
Validation Loss: 1.1930, Accuracy: 0.8352, Precision: 0.7154, Recall: 0.7565, F1: 0.7282
Testing Loss: 1.0797, Accuracy: 0.8537, Precision: 0.7099, Recall: 0.6743, F1: 0.6701
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0352, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 43/70
Train Loss: 0.0170, Accuracy: 0.9948, Precision: 0.9895, Recall: 0.9864, F1: 0.9880
Validation Loss: 1.2781, Accuracy: 0.8295, Precision: 0.7170, Recall: 0.6730, F1: 0.6773
Testing Loss: 1.2315, Accuracy: 0.8351, Precision: 0.6900, Recall: 0.6356, F1: 0.6479
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0415, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 44/70
Train Loss: 0.0323, Accuracy: 0.9874, Precision: 0.9730, Recall: 0.9719, F1: 0.9724
Validation Loss: 1.0966, Accuracy: 0.8523, Precision: 0.7379, Recall: 0.8103, F1: 0.7279
Testing Loss: 1.1175, Accuracy: 0.8324, Precision: 0.6813, Recall: 0.6598, F1: 0.6496
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0588, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 45/70
Train Loss: 0.0181, Accuracy: 0.9951, Precision: 0.9955, Recall: 0.9872, F1: 0.9912
Validation Loss: 1.0308, Accuracy: 0.8523, Precision: 0.7188, Recall: 0.6991, F1: 0.7042
Testing Loss: 1.1242, Accuracy: 0.8378, Precision: 0.6424, Recall: 0.6055, F1: 0.6175
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0590, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 46/70
Train Loss: 0.0076, Accuracy: 0.9972, Precision: 0.9929, Recall: 0.9971, F1: 0.9950
Validation Loss: 1.1507, Accuracy: 0.8523, Precision: 0.7068, Recall: 0.7763, F1: 0.7163
Testing Loss: 1.1978, Accuracy: 0.8351, Precision: 0.6587, Recall: 0.6534, F1: 0.6491
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0155, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 47/70
Train Loss: 0.0092, Accuracy: 0.9976, Precision: 0.9948, Recall: 0.9958, F1: 0.9953
Validation Loss: 0.9081, Accuracy: 0.8551, Precision: 0.7642, Recall: 0.7944, F1: 0.7484
Testing Loss: 1.0640, Accuracy: 0.8351, Precision: 0.6705, Recall: 0.6573, F1: 0.6517
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0040, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 48/70
Train Loss: 0.0079, Accuracy: 0.9972, Precision: 0.9968, Recall: 0.9927, F1: 0.9947
Validation Loss: 1.0399, Accuracy: 0.8580, Precision: 0.7342, Recall: 0.6803, F1: 0.6899
Testing Loss: 1.1831, Accuracy: 0.8457, Precision: 0.7133, Recall: 0.6635, F1: 0.6746
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0029, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 49/70
Train Loss: 0.0087, Accuracy: 0.9976, Precision: 0.9953, Recall: 0.9911, F1: 0.9932
Validation Loss: 1.1570, Accuracy: 0.8494, Precision: 0.6680, Recall: 0.6752, F1: 0.6707
Testing Loss: 1.2106, Accuracy: 0.8484, Precision: 0.6835, Recall: 0.6645, F1: 0.6713
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0163, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0135, Accuracy: 0.9958, Precision: 0.9882, Recall: 0.9906, F1: 0.9893
Validation Loss: 1.1211, Accuracy: 0.8523, Precision: 0.6929, Recall: 0.7297, F1: 0.7058
Testing Loss: 1.1677, Accuracy: 0.8351, Precision: 0.7084, Recall: 0.6554, F1: 0.6665
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 3, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3264, Accuracy: 0.8929, Precision: 0.8333, Recall: 0.7262, F1: 0.7650
Epoch 51/70
Train Loss: 0.0071, Accuracy: 0.9965, Precision: 0.9889, Recall: 0.9930, F1: 0.9909
Validation Loss: 1.3452, Accuracy: 0.8324, Precision: 0.7473, Recall: 0.7070, F1: 0.6890
Testing Loss: 1.3014, Accuracy: 0.8404, Precision: 0.7099, Recall: 0.6168, F1: 0.6462
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0020, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 52/70
Train Loss: 0.0146, Accuracy: 0.9955, Precision: 0.9912, Recall: 0.9872, F1: 0.9892
Validation Loss: 1.0544, Accuracy: 0.8438, Precision: 0.7036, Recall: 0.7741, F1: 0.7174
Testing Loss: 1.1396, Accuracy: 0.8404, Precision: 0.6638, Recall: 0.6730, F1: 0.6656
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0140, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 53/70
Train Loss: 0.0078, Accuracy: 0.9976, Precision: 0.9960, Recall: 0.9935, F1: 0.9948
Validation Loss: 1.1674, Accuracy: 0.8438, Precision: 0.7063, Recall: 0.7569, F1: 0.7142
Testing Loss: 1.2814, Accuracy: 0.8351, Precision: 0.6540, Recall: 0.6484, F1: 0.6459
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0077, Accuracy: 0.9972, Precision: 0.9909, Recall: 0.9913, F1: 0.9911
Validation Loss: 1.0076, Accuracy: 0.8580, Precision: 0.7036, Recall: 0.7337, F1: 0.7154
Testing Loss: 1.1482, Accuracy: 0.8537, Precision: 0.7003, Recall: 0.6837, F1: 0.6856
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0056, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 55/70
Train Loss: 0.0070, Accuracy: 0.9993, Precision: 0.9995, Recall: 0.9997, F1: 0.9996
Validation Loss: 1.1442, Accuracy: 0.8523, Precision: 0.7452, Recall: 0.7490, F1: 0.7304
Testing Loss: 1.1729, Accuracy: 0.8457, Precision: 0.6929, Recall: 0.6562, F1: 0.6708
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0015, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0049, Accuracy: 0.9979, Precision: 0.9924, Recall: 0.9885, F1: 0.9904
Validation Loss: 1.1016, Accuracy: 0.8580, Precision: 0.7092, Recall: 0.7074, F1: 0.7042
Testing Loss: 1.2484, Accuracy: 0.8537, Precision: 0.6881, Recall: 0.6603, F1: 0.6701
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0004, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0023, Accuracy: 0.9993, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.2072, Accuracy: 0.8523, Precision: 0.7316, Recall: 0.7474, F1: 0.7325
Testing Loss: 1.2676, Accuracy: 0.8324, Precision: 0.6516, Recall: 0.6218, F1: 0.6298
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0142, Accuracy: 0.9962, Precision: 0.9908, Recall: 0.9922, F1: 0.9915
Validation Loss: 1.0674, Accuracy: 0.8551, Precision: 0.7478, Recall: 0.7031, F1: 0.7146
Testing Loss: 1.1511, Accuracy: 0.8564, Precision: 0.7041, Recall: 0.6509, F1: 0.6696
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0022, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0031, Accuracy: 0.9993, Precision: 0.9997, Recall: 0.9997, F1: 0.9997
Validation Loss: 1.3276, Accuracy: 0.8381, Precision: 0.6665, Recall: 0.6473, F1: 0.6536
Testing Loss: 1.3025, Accuracy: 0.8590, Precision: 0.7150, Recall: 0.6718, F1: 0.6869
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0004, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0113, Accuracy: 0.9972, Precision: 0.9971, Recall: 0.9971, F1: 0.9971
Validation Loss: 1.1612, Accuracy: 0.8438, Precision: 0.6883, Recall: 0.7229, F1: 0.6995
Testing Loss: 1.1224, Accuracy: 0.8378, Precision: 0.6609, Recall: 0.6727, F1: 0.6612
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0021, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0127, Accuracy: 0.9955, Precision: 0.9895, Recall: 0.9933, F1: 0.9913
Validation Loss: 1.0051, Accuracy: 0.8693, Precision: 0.6955, Recall: 0.6749, F1: 0.6817
Testing Loss: 1.1368, Accuracy: 0.8431, Precision: 0.6460, Recall: 0.6305, F1: 0.6371
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0029, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.0043, Accuracy: 0.9986, Precision: 0.9990, Recall: 0.9962, F1: 0.9976
Validation Loss: 1.1546, Accuracy: 0.8580, Precision: 0.7622, Recall: 0.6950, F1: 0.7180
Testing Loss: 1.2791, Accuracy: 0.8511, Precision: 0.7472, Recall: 0.6774, F1: 0.6994
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.0286, Accuracy: 0.9934, Precision: 0.9798, Recall: 0.9748, F1: 0.9773
Validation Loss: 0.9062, Accuracy: 0.8523, Precision: 0.7115, Recall: 0.7838, F1: 0.7288
Testing Loss: 0.9066, Accuracy: 0.8484, Precision: 0.7015, Recall: 0.6877, F1: 0.6929
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0112, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0070, Accuracy: 0.9983, Precision: 0.9967, Recall: 0.9960, F1: 0.9963
Validation Loss: 0.9633, Accuracy: 0.8636, Precision: 0.7199, Recall: 0.7080, F1: 0.7075
Testing Loss: 1.0884, Accuracy: 0.8404, Precision: 0.6704, Recall: 0.6476, F1: 0.6535
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0032, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0041, Accuracy: 0.9986, Precision: 0.9952, Recall: 0.9968, F1: 0.9960
Validation Loss: 0.9840, Accuracy: 0.8665, Precision: 0.7569, Recall: 0.7951, F1: 0.7683
Testing Loss: 1.0533, Accuracy: 0.8457, Precision: 0.6993, Recall: 0.6893, F1: 0.6893
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0034, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0189, Accuracy: 0.9951, Precision: 0.9900, Recall: 0.9871, F1: 0.9886
Validation Loss: 0.9302, Accuracy: 0.8551, Precision: 0.7362, Recall: 0.7854, F1: 0.7472
Testing Loss: 1.0306, Accuracy: 0.8484, Precision: 0.6842, Recall: 0.6673, F1: 0.6728
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0008, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Validation Loss: 1.0292, Accuracy: 0.8551, Precision: 0.7311, Recall: 0.7839, F1: 0.7433
Testing Loss: 1.1430, Accuracy: 0.8511, Precision: 0.6942, Recall: 0.6731, F1: 0.6801
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0086, Accuracy: 0.9983, Precision: 0.9989, Recall: 0.9959, F1: 0.9974
Validation Loss: 1.0305, Accuracy: 0.8608, Precision: 0.7334, Recall: 0.7849, F1: 0.7439
Testing Loss: 1.0936, Accuracy: 0.8511, Precision: 0.7010, Recall: 0.6918, F1: 0.6942
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0008, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0012, Accuracy: 0.9993, Precision: 0.9997, Recall: 0.9997, F1: 0.9997
Validation Loss: 1.1118, Accuracy: 0.8466, Precision: 0.6931, Recall: 0.7307, F1: 0.7052
Testing Loss: 1.1716, Accuracy: 0.8378, Precision: 0.6587, Recall: 0.6608, F1: 0.6574
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.0253, Accuracy: 0.9937, Precision: 0.9851, Recall: 0.9851, F1: 0.9851
Validation Loss: 0.9203, Accuracy: 0.8409, Precision: 0.6847, Recall: 0.7203, F1: 0.6922
Testing Loss: 0.9663, Accuracy: 0.8271, Precision: 0.6473, Recall: 0.6349, F1: 0.6349
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0028, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For later layers:  [8, 9, 10, 11]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.4775, Accuracy: 0.3593, Precision: 0.1799, Recall: 0.1683, F1: 0.1508
Validation Loss: 1.3915, Accuracy: 0.4062, Precision: 0.1295, Recall: 0.1855, F1: 0.1485
Testing Loss: 1.4139, Accuracy: 0.4043, Precision: 0.1329, Recall: 0.1876, F1: 0.1512
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9860, Accuracy: 0.3929, Precision: 0.1810, Recall: 0.3600, F1: 0.2333
Epoch 2/70
Train Loss: 1.3873, Accuracy: 0.3744, Precision: 0.1467, Recall: 0.1688, F1: 0.1410
Validation Loss: 1.4055, Accuracy: 0.3381, Precision: 0.1670, Recall: 0.1692, F1: 0.0886
Testing Loss: 1.4181, Accuracy: 0.3537, Precision: 0.0591, Recall: 0.1667, F1: 0.0873
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0049, Accuracy: 0.1786, Precision: 0.0357, Recall: 0.2000, F1: 0.0606
Epoch 3/70
Train Loss: 1.3809, Accuracy: 0.3859, Precision: 0.1262, Recall: 0.1738, F1: 0.1445
Validation Loss: 1.3977, Accuracy: 0.3864, Precision: 0.1357, Recall: 0.1709, F1: 0.1008
Testing Loss: 1.4145, Accuracy: 0.3723, Precision: 0.1653, Recall: 0.1717, F1: 0.1011
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9524, Accuracy: 0.2857, Precision: 0.2519, Recall: 0.2400, F1: 0.1490
Epoch 4/70
Train Loss: 1.3794, Accuracy: 0.3891, Precision: 0.1833, Recall: 0.1758, F1: 0.1475
Validation Loss: 1.3949, Accuracy: 0.3608, Precision: 0.1343, Recall: 0.1770, F1: 0.1248
Testing Loss: 1.4203, Accuracy: 0.3936, Precision: 0.1564, Recall: 0.1847, F1: 0.1374
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 4, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9580, Accuracy: 0.2143, Precision: 0.0788, Recall: 0.2286, F1: 0.1048
Epoch 5/70
Train Loss: 1.3718, Accuracy: 0.3975, Precision: 0.2145, Recall: 0.1801, F1: 0.1513
Validation Loss: 1.3983, Accuracy: 0.3807, Precision: 0.2298, Recall: 0.1681, F1: 0.0944
Testing Loss: 1.4564, Accuracy: 0.3670, Precision: 0.2273, Recall: 0.1692, F1: 0.0938
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0918, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 6/70
Train Loss: 1.3583, Accuracy: 0.4150, Precision: 0.1998, Recall: 0.1889, F1: 0.1619
Validation Loss: 1.4018, Accuracy: 0.4148, Precision: 0.1582, Recall: 0.2016, F1: 0.1522
Testing Loss: 1.4239, Accuracy: 0.4362, Precision: 0.1720, Recall: 0.2045, F1: 0.1582
LM Predictions:  [2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1262, Accuracy: 0.2143, Precision: 0.1067, Recall: 0.2286, F1: 0.1067
Epoch 7/70
Train Loss: 1.2941, Accuracy: 0.4762, Precision: 0.2375, Recall: 0.2262, F1: 0.2089
Validation Loss: 1.0576, Accuracy: 0.6023, Precision: 0.2689, Recall: 0.2976, F1: 0.2704
Testing Loss: 1.0726, Accuracy: 0.6223, Precision: 0.3072, Recall: 0.3149, F1: 0.2948
LM Predictions:  [2, 2, 2, 4, 5, 5, 4, 2, 2, 2, 5, 2, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1495, Accuracy: 0.3214, Precision: 0.1777, Recall: 0.2800, F1: 0.2030
Epoch 8/70
Train Loss: 0.9571, Accuracy: 0.6589, Precision: 0.3190, Recall: 0.3404, F1: 0.3271
Validation Loss: 1.0873, Accuracy: 0.6761, Precision: 0.3074, Recall: 0.3400, F1: 0.3167
Testing Loss: 0.9781, Accuracy: 0.7261, Precision: 0.3378, Recall: 0.3759, F1: 0.3529
LM Predictions:  [2, 2, 2, 2, 5, 2, 5, 2, 5, 5, 5, 2, 2, 2, 4, 4, 5, 2, 2, 5, 2, 5, 2, 2, 4, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4776, Accuracy: 0.2500, Precision: 0.1600, Recall: 0.2114, F1: 0.1698
Epoch 9/70
Train Loss: 0.7784, Accuracy: 0.7246, Precision: 0.3497, Recall: 0.3893, F1: 0.3672
Validation Loss: 0.9118, Accuracy: 0.7159, Precision: 0.3468, Recall: 0.3606, F1: 0.3409
Testing Loss: 0.8472, Accuracy: 0.7420, Precision: 0.3614, Recall: 0.3899, F1: 0.3709
LM Predictions:  [2, 2, 5, 2, 1, 2, 2, 2, 5, 5, 5, 2, 2, 2, 4, 4, 5, 2, 2, 2, 2, 5, 5, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8969, Accuracy: 0.2500, Precision: 0.3730, Recall: 0.2329, F1: 0.2297
Epoch 10/70
Train Loss: 0.6928, Accuracy: 0.7537, Precision: 0.5538, Recall: 0.4161, F1: 0.4017
Validation Loss: 0.8674, Accuracy: 0.7273, Precision: 0.5514, Recall: 0.4102, F1: 0.4141
Testing Loss: 0.7407, Accuracy: 0.7713, Precision: 0.5263, Recall: 0.4441, F1: 0.4406
LM Predictions:  [3, 3, 5, 2, 1, 2, 4, 5, 5, 5, 5, 4, 2, 4, 4, 4, 5, 2, 4, 3, 5, 3, 5, 2, 4, 5, 1, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9682, Accuracy: 0.2857, Precision: 0.2476, Recall: 0.2274, F1: 0.2255
Epoch 11/70
Train Loss: 0.6214, Accuracy: 0.7848, Precision: 0.5145, Recall: 0.4463, F1: 0.4348
Validation Loss: 0.8748, Accuracy: 0.7585, Precision: 0.5295, Recall: 0.4130, F1: 0.3970
Testing Loss: 0.8015, Accuracy: 0.7872, Precision: 0.6264, Recall: 0.4609, F1: 0.4600
LM Predictions:  [3, 3, 2, 2, 5, 2, 5, 5, 5, 5, 5, 5, 2, 2, 4, 2, 5, 2, 5, 5, 3, 3, 5, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2378, Accuracy: 0.2857, Precision: 0.2689, Recall: 0.2000, F1: 0.1823
Epoch 12/70
Train Loss: 0.5903, Accuracy: 0.7995, Precision: 0.5077, Recall: 0.4740, F1: 0.4738
Validation Loss: 0.6510, Accuracy: 0.8011, Precision: 0.6389, Recall: 0.5198, F1: 0.5480
Testing Loss: 0.6139, Accuracy: 0.7979, Precision: 0.5752, Recall: 0.5278, F1: 0.5214
LM Predictions:  [3, 3, 3, 2, 1, 5, 3, 5, 5, 3, 3, 3, 2, 2, 4, 2, 5, 2, 3, 3, 3, 3, 1, 2, 1, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0537, Accuracy: 0.2500, Precision: 0.3736, Recall: 0.2119, F1: 0.2452
Epoch 13/70
Train Loss: 0.5187, Accuracy: 0.8223, Precision: 0.5757, Recall: 0.5377, F1: 0.5477
Validation Loss: 0.6270, Accuracy: 0.8068, Precision: 0.6070, Recall: 0.5354, F1: 0.5339
Testing Loss: 0.5845, Accuracy: 0.8138, Precision: 0.5636, Recall: 0.5360, F1: 0.5428
LM Predictions:  [3, 3, 3, 2, 3, 5, 3, 5, 3, 3, 3, 3, 2, 4, 4, 2, 3, 2, 3, 3, 3, 3, 1, 2, 3, 5, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.8388, Accuracy: 0.1786, Precision: 0.2222, Recall: 0.1286, F1: 0.1579
Epoch 14/70
Train Loss: 0.4966, Accuracy: 0.8300, Precision: 0.5979, Recall: 0.5728, F1: 0.5811
Validation Loss: 0.5605, Accuracy: 0.7841, Precision: 0.5979, Recall: 0.5395, F1: 0.5510
Testing Loss: 0.5495, Accuracy: 0.8165, Precision: 0.5927, Recall: 0.5390, F1: 0.5469
LM Predictions:  [3, 3, 3, 2, 1, 5, 5, 5, 3, 3, 3, 3, 2, 4, 4, 5, 3, 3, 3, 3, 3, 5, 1, 3, 5, 5, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3289, Accuracy: 0.1786, Precision: 0.2917, Recall: 0.1464, F1: 0.1847
Epoch 15/70
Train Loss: 0.4678, Accuracy: 0.8453, Precision: 0.6092, Recall: 0.5899, F1: 0.5966
Validation Loss: 0.5850, Accuracy: 0.8267, Precision: 0.6384, Recall: 0.5855, F1: 0.5920
Testing Loss: 0.5498, Accuracy: 0.8298, Precision: 0.5890, Recall: 0.5672, F1: 0.5748
LM Predictions:  [3, 3, 3, 2, 1, 5, 3, 5, 3, 3, 3, 3, 2, 2, 4, 3, 3, 2, 3, 3, 3, 5, 1, 3, 3, 5, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.8145, Accuracy: 0.1786, Precision: 0.3583, Recall: 0.1464, F1: 0.1970
Epoch 16/70
Train Loss: 0.4282, Accuracy: 0.8572, Precision: 0.6191, Recall: 0.6086, F1: 0.6118
Validation Loss: 0.5208, Accuracy: 0.8153, Precision: 0.5979, Recall: 0.6297, F1: 0.6119
Testing Loss: 0.5433, Accuracy: 0.8218, Precision: 0.5868, Recall: 0.5985, F1: 0.5830
LM Predictions:  [3, 3, 3, 3, 1, 5, 5, 5, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 5, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.8166, Accuracy: 0.1071, Precision: 0.2833, Recall: 0.0988, F1: 0.1389
Epoch 17/70
Train Loss: 0.4023, Accuracy: 0.8698, Precision: 0.6593, Recall: 0.6527, F1: 0.6543
Validation Loss: 0.5555, Accuracy: 0.8210, Precision: 0.6200, Recall: 0.6386, F1: 0.6148
Testing Loss: 0.5377, Accuracy: 0.8165, Precision: 0.5637, Recall: 0.5863, F1: 0.5741
LM Predictions:  [3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.8027, Accuracy: 0.1071, Precision: 0.4167, Recall: 0.0810, F1: 0.1343
Epoch 18/70
Train Loss: 0.3614, Accuracy: 0.8719, Precision: 0.7024, Recall: 0.6484, F1: 0.6510
Validation Loss: 0.5243, Accuracy: 0.8295, Precision: 0.6544, Recall: 0.6147, F1: 0.6300
Testing Loss: 0.5834, Accuracy: 0.8271, Precision: 0.5962, Recall: 0.6141, F1: 0.5981
LM Predictions:  [3, 3, 3, 1, 1, 5, 5, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 5, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0661, Accuracy: 0.1786, Precision: 0.4306, Recall: 0.1464, F1: 0.2076
Epoch 19/70
Train Loss: 0.3344, Accuracy: 0.8849, Precision: 0.7327, Recall: 0.6704, F1: 0.6770
Validation Loss: 0.5930, Accuracy: 0.8295, Precision: 0.6869, Recall: 0.6529, F1: 0.6589
Testing Loss: 0.6123, Accuracy: 0.8191, Precision: 0.5950, Recall: 0.5763, F1: 0.5840
LM Predictions:  [3, 3, 3, 3, 3, 2, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2706, Accuracy: 0.1786, Precision: 0.4333, Recall: 0.1286, F1: 0.1806
Epoch 20/70
Train Loss: 0.3167, Accuracy: 0.8922, Precision: 0.7647, Recall: 0.7076, F1: 0.7183
Validation Loss: 0.6042, Accuracy: 0.8409, Precision: 0.6750, Recall: 0.6049, F1: 0.6209
Testing Loss: 0.6150, Accuracy: 0.8484, Precision: 0.6525, Recall: 0.6215, F1: 0.6325
LM Predictions:  [3, 3, 3, 3, 1, 5, 5, 5, 5, 3, 3, 3, 2, 5, 4, 5, 3, 2, 3, 3, 3, 3, 5, 2, 3, 5, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.5248, Accuracy: 0.2500, Precision: 0.5069, Recall: 0.1940, F1: 0.2556
Epoch 21/70
Train Loss: 0.2821, Accuracy: 0.9020, Precision: 0.7891, Recall: 0.7300, F1: 0.7457
Validation Loss: 0.5836, Accuracy: 0.8324, Precision: 0.6418, Recall: 0.6372, F1: 0.6380
Testing Loss: 0.6141, Accuracy: 0.8351, Precision: 0.6102, Recall: 0.6466, F1: 0.6207
LM Predictions:  [3, 3, 3, 1, 1, 3, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 1, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3764, Accuracy: 0.2143, Precision: 0.5278, Recall: 0.1881, F1: 0.2472
Epoch 22/70
Train Loss: 0.2646, Accuracy: 0.9115, Precision: 0.8086, Recall: 0.7538, F1: 0.7674
Validation Loss: 0.7717, Accuracy: 0.8267, Precision: 0.7042, Recall: 0.6633, F1: 0.6662
Testing Loss: 0.7088, Accuracy: 0.8271, Precision: 0.6407, Recall: 0.6205, F1: 0.6219
LM Predictions:  [3, 3, 3, 2, 1, 4, 4, 5, 3, 3, 3, 3, 2, 0, 4, 5, 3, 2, 3, 3, 2, 5, 1, 2, 3, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7086, Accuracy: 0.3214, Precision: 0.4048, Recall: 0.2607, F1: 0.3126
Epoch 23/70
Train Loss: 0.2515, Accuracy: 0.9136, Precision: 0.7984, Recall: 0.7621, F1: 0.7710
Validation Loss: 0.6417, Accuracy: 0.8409, Precision: 0.6907, Recall: 0.6237, F1: 0.6492
Testing Loss: 0.6330, Accuracy: 0.8298, Precision: 0.6299, Recall: 0.6021, F1: 0.6092
LM Predictions:  [3, 3, 3, 3, 1, 2, 4, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 3, 2, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3655, Accuracy: 0.2500, Precision: 0.5000, Recall: 0.2036, F1: 0.2694
Epoch 24/70
Train Loss: 0.2143, Accuracy: 0.9311, Precision: 0.8339, Recall: 0.8013, F1: 0.8101
Validation Loss: 0.6381, Accuracy: 0.8438, Precision: 0.7001, Recall: 0.6482, F1: 0.6713
Testing Loss: 0.6448, Accuracy: 0.8564, Precision: 0.6745, Recall: 0.6632, F1: 0.6657
LM Predictions:  [3, 3, 2, 2, 1, 4, 4, 5, 3, 3, 3, 3, 2, 2, 4, 5, 3, 2, 3, 3, 2, 3, 1, 2, 3, 3, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7913, Accuracy: 0.3571, Precision: 0.4907, Recall: 0.2845, F1: 0.3380
Epoch 25/70
Train Loss: 0.2171, Accuracy: 0.9283, Precision: 0.8424, Recall: 0.8074, F1: 0.8204
Validation Loss: 0.5403, Accuracy: 0.8239, Precision: 0.6252, Recall: 0.6196, F1: 0.6215
Testing Loss: 0.5596, Accuracy: 0.8431, Precision: 0.6648, Recall: 0.6693, F1: 0.6643
LM Predictions:  [3, 3, 3, 1, 1, 3, 3, 5, 3, 3, 3, 3, 2, 5, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8511, Accuracy: 0.2857, Precision: 0.6806, Recall: 0.2274, F1: 0.3237
Epoch 26/70
Train Loss: 0.1806, Accuracy: 0.9409, Precision: 0.8695, Recall: 0.8471, F1: 0.8531
Validation Loss: 0.8078, Accuracy: 0.8239, Precision: 0.6859, Recall: 0.7186, F1: 0.6717
Testing Loss: 0.7630, Accuracy: 0.8271, Precision: 0.6579, Recall: 0.6455, F1: 0.6397
LM Predictions:  [3, 3, 3, 1, 1, 4, 4, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.7635, Accuracy: 0.2500, Precision: 0.5000, Recall: 0.2131, F1: 0.2810
Epoch 27/70
Train Loss: 0.1705, Accuracy: 0.9423, Precision: 0.8711, Recall: 0.8472, F1: 0.8558
Validation Loss: 0.6772, Accuracy: 0.8295, Precision: 0.6879, Recall: 0.6958, F1: 0.6763
Testing Loss: 0.6137, Accuracy: 0.8271, Precision: 0.6279, Recall: 0.6481, F1: 0.6328
LM Predictions:  [3, 3, 2, 1, 1, 4, 4, 5, 3, 3, 3, 3, 2, 0, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6921, Accuracy: 0.3571, Precision: 0.6056, Recall: 0.2940, F1: 0.3730
Epoch 28/70
Train Loss: 0.1540, Accuracy: 0.9482, Precision: 0.8824, Recall: 0.8636, F1: 0.8704
Validation Loss: 0.8697, Accuracy: 0.8466, Precision: 0.7177, Recall: 0.6938, F1: 0.6943
Testing Loss: 0.7232, Accuracy: 0.8457, Precision: 0.7204, Recall: 0.6598, F1: 0.6733
LM Predictions:  [3, 3, 2, 1, 1, 4, 4, 5, 3, 3, 3, 3, 2, 5, 4, 5, 3, 4, 3, 5, 3, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4081, Accuracy: 0.5357, Precision: 0.7500, Recall: 0.4405, F1: 0.5295
Epoch 29/70
Train Loss: 0.1335, Accuracy: 0.9528, Precision: 0.8896, Recall: 0.8906, F1: 0.8886
Validation Loss: 0.6565, Accuracy: 0.8580, Precision: 0.7109, Recall: 0.7214, F1: 0.7050
Testing Loss: 0.6270, Accuracy: 0.8324, Precision: 0.6627, Recall: 0.6812, F1: 0.6601
LM Predictions:  [3, 3, 2, 1, 1, 4, 2, 5, 3, 3, 3, 3, 2, 5, 4, 3, 3, 2, 3, 5, 2, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4341, Accuracy: 0.4286, Precision: 0.6786, Recall: 0.3500, F1: 0.4294
Epoch 30/70
Train Loss: 0.1393, Accuracy: 0.9521, Precision: 0.8837, Recall: 0.8670, F1: 0.8732
Validation Loss: 0.6016, Accuracy: 0.8494, Precision: 0.6884, Recall: 0.6608, F1: 0.6721
Testing Loss: 0.5706, Accuracy: 0.8378, Precision: 0.6777, Recall: 0.6611, F1: 0.6641
LM Predictions:  [3, 3, 3, 5, 1, 4, 4, 5, 3, 3, 3, 3, 2, 5, 4, 5, 3, 2, 3, 5, 3, 3, 5, 2, 3, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3674, Accuracy: 0.4643, Precision: 0.7639, Recall: 0.3655, F1: 0.4663
Epoch 31/70
Train Loss: 0.1078, Accuracy: 0.9615, Precision: 0.9122, Recall: 0.9036, F1: 0.9056
Validation Loss: 0.8562, Accuracy: 0.8466, Precision: 0.7330, Recall: 0.7412, F1: 0.7081
Testing Loss: 0.7408, Accuracy: 0.8404, Precision: 0.6733, Recall: 0.6672, F1: 0.6674
LM Predictions:  [2, 3, 2, 2, 1, 4, 4, 5, 3, 3, 3, 0, 2, 5, 4, 5, 3, 2, 1, 5, 2, 2, 1, 2, 1, 0, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.0708, Accuracy: 0.6429, Precision: 0.7250, Recall: 0.5298, F1: 0.5841
Epoch 32/70
Train Loss: 0.0976, Accuracy: 0.9668, Precision: 0.9144, Recall: 0.9062, F1: 0.9095
Validation Loss: 0.8802, Accuracy: 0.8352, Precision: 0.7255, Recall: 0.8045, F1: 0.7128
Testing Loss: 0.7277, Accuracy: 0.8511, Precision: 0.6867, Recall: 0.7037, F1: 0.6901
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 3, 3, 3, 0, 2, 3, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6527, Accuracy: 0.3571, Precision: 0.7083, Recall: 0.3036, F1: 0.4084
Epoch 33/70
Train Loss: 0.0820, Accuracy: 0.9706, Precision: 0.9263, Recall: 0.9281, F1: 0.9268
Validation Loss: 0.8829, Accuracy: 0.8438, Precision: 0.7077, Recall: 0.6335, F1: 0.6597
Testing Loss: 0.8424, Accuracy: 0.8431, Precision: 0.6957, Recall: 0.6917, F1: 0.6929
LM Predictions:  [3, 3, 2, 5, 1, 4, 5, 5, 3, 3, 3, 0, 2, 5, 4, 5, 5, 2, 1, 5, 3, 3, 5, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3120, Accuracy: 0.5714, Precision: 0.7375, Recall: 0.4726, F1: 0.5556
Epoch 34/70
Train Loss: 0.0854, Accuracy: 0.9703, Precision: 0.9319, Recall: 0.9262, F1: 0.9280
Validation Loss: 0.8445, Accuracy: 0.8636, Precision: 0.7847, Recall: 0.7345, F1: 0.7281
Testing Loss: 0.8894, Accuracy: 0.8324, Precision: 0.6634, Recall: 0.6094, F1: 0.6289
LM Predictions:  [3, 3, 2, 2, 1, 4, 4, 5, 3, 3, 0, 0, 2, 5, 4, 5, 3, 4, 1, 5, 2, 2, 5, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8010, Accuracy: 0.6429, Precision: 0.6968, Recall: 0.5393, F1: 0.6045
Epoch 35/70
Train Loss: 0.0840, Accuracy: 0.9731, Precision: 0.9351, Recall: 0.9282, F1: 0.9307
Validation Loss: 0.7443, Accuracy: 0.8381, Precision: 0.6871, Recall: 0.7608, F1: 0.6924
Testing Loss: 0.8229, Accuracy: 0.8271, Precision: 0.6460, Recall: 0.7192, F1: 0.6641
LM Predictions:  [3, 3, 2, 1, 1, 4, 4, 5, 3, 3, 5, 0, 2, 5, 4, 5, 3, 4, 1, 5, 3, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8899, Accuracy: 0.6429, Precision: 0.7667, Recall: 0.5393, F1: 0.6146
Epoch 36/70
Train Loss: 0.0674, Accuracy: 0.9773, Precision: 0.9368, Recall: 0.9315, F1: 0.9335
Validation Loss: 0.8138, Accuracy: 0.8381, Precision: 0.7156, Recall: 0.7358, F1: 0.6971
Testing Loss: 0.7785, Accuracy: 0.8590, Precision: 0.7024, Recall: 0.6898, F1: 0.6940
LM Predictions:  [3, 3, 2, 1, 1, 4, 4, 5, 3, 3, 4, 0, 2, 5, 4, 5, 3, 4, 1, 5, 2, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8120, Accuracy: 0.6071, Precision: 0.7000, Recall: 0.5155, F1: 0.5720
Epoch 37/70
Train Loss: 0.0738, Accuracy: 0.9755, Precision: 0.9434, Recall: 0.9421, F1: 0.9424
Validation Loss: 0.7502, Accuracy: 0.8324, Precision: 0.6882, Recall: 0.6704, F1: 0.6743
Testing Loss: 0.7562, Accuracy: 0.8351, Precision: 0.7019, Recall: 0.6423, F1: 0.6566
LM Predictions:  [3, 3, 2, 2, 1, 4, 4, 5, 3, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 3, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8838, Accuracy: 0.6786, Precision: 0.7583, Recall: 0.5726, F1: 0.6369
Epoch 38/70
Train Loss: 0.0612, Accuracy: 0.9811, Precision: 0.9556, Recall: 0.9474, F1: 0.9510
Validation Loss: 0.9728, Accuracy: 0.8381, Precision: 0.7014, Recall: 0.7565, F1: 0.6962
Testing Loss: 0.9488, Accuracy: 0.8431, Precision: 0.6673, Recall: 0.6861, F1: 0.6710
LM Predictions:  [3, 3, 2, 0, 1, 4, 4, 5, 3, 3, 5, 0, 2, 5, 4, 5, 4, 4, 3, 5, 3, 2, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8696, Accuracy: 0.6786, Precision: 0.7222, Recall: 0.5548, F1: 0.6230
Epoch 39/70
Train Loss: 0.0578, Accuracy: 0.9825, Precision: 0.9446, Recall: 0.9394, F1: 0.9413
Validation Loss: 0.9387, Accuracy: 0.8324, Precision: 0.7081, Recall: 0.6941, F1: 0.6675
Testing Loss: 0.9685, Accuracy: 0.8324, Precision: 0.6603, Recall: 0.6218, F1: 0.6292
LM Predictions:  [3, 3, 2, 5, 1, 4, 4, 5, 0, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4256, Accuracy: 0.8214, Precision: 0.7333, Recall: 0.6952, F1: 0.7075
Epoch 40/70
Train Loss: 0.0525, Accuracy: 0.9818, Precision: 0.9534, Recall: 0.9489, F1: 0.9511
Validation Loss: 0.8334, Accuracy: 0.8636, Precision: 0.7544, Recall: 0.8105, F1: 0.7473
Testing Loss: 0.9293, Accuracy: 0.8404, Precision: 0.6699, Recall: 0.6851, F1: 0.6728
LM Predictions:  [2, 3, 2, 0, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4127, Accuracy: 0.8214, Precision: 0.7250, Recall: 0.6774, F1: 0.6972
Epoch 41/70
Train Loss: 0.0401, Accuracy: 0.9878, Precision: 0.9640, Recall: 0.9671, F1: 0.9653
Validation Loss: 1.2674, Accuracy: 0.8352, Precision: 0.7192, Recall: 0.7304, F1: 0.7036
Testing Loss: 1.1559, Accuracy: 0.8378, Precision: 0.6813, Recall: 0.6483, F1: 0.6586
LM Predictions:  [3, 3, 2, 5, 1, 4, 4, 5, 3, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 2, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3812, Accuracy: 0.7857, Precision: 0.7639, Recall: 0.6536, F1: 0.6987
Epoch 42/70
Train Loss: 0.0715, Accuracy: 0.9762, Precision: 0.9378, Recall: 0.9341, F1: 0.9355
Validation Loss: 0.8861, Accuracy: 0.8438, Precision: 0.7572, Recall: 0.6526, F1: 0.6788
Testing Loss: 0.9938, Accuracy: 0.8378, Precision: 0.6410, Recall: 0.5997, F1: 0.6128
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 5, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3119, Accuracy: 0.9286, Precision: 0.8125, Recall: 0.7583, F1: 0.7799
Epoch 43/70
Train Loss: 0.0427, Accuracy: 0.9860, Precision: 0.9642, Recall: 0.9517, F1: 0.9573
Validation Loss: 0.9057, Accuracy: 0.8466, Precision: 0.7155, Recall: 0.7182, F1: 0.7053
Testing Loss: 1.1671, Accuracy: 0.8085, Precision: 0.5996, Recall: 0.6131, F1: 0.5952
LM Predictions:  [2, 0, 2, 1, 1, 4, 4, 5, 2, 1, 3, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2910, Accuracy: 0.8929, Precision: 0.7778, Recall: 0.7524, F1: 0.7537
Epoch 44/70
Train Loss: 0.0254, Accuracy: 0.9930, Precision: 0.9814, Recall: 0.9821, F1: 0.9817
Validation Loss: 1.1764, Accuracy: 0.8466, Precision: 0.7489, Recall: 0.6520, F1: 0.6713
Testing Loss: 1.2292, Accuracy: 0.8484, Precision: 0.7128, Recall: 0.6139, F1: 0.6473
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 2, 2, 5, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2611, Accuracy: 0.8929, Precision: 0.7887, Recall: 0.7345, F1: 0.7561
Epoch 45/70
Train Loss: 0.0395, Accuracy: 0.9871, Precision: 0.9712, Recall: 0.9633, F1: 0.9671
Validation Loss: 1.0150, Accuracy: 0.8494, Precision: 0.7242, Recall: 0.7595, F1: 0.7207
Testing Loss: 1.0387, Accuracy: 0.8537, Precision: 0.7226, Recall: 0.6996, F1: 0.7099
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1616, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 46/70
Train Loss: 0.0217, Accuracy: 0.9923, Precision: 0.9814, Recall: 0.9856, F1: 0.9835
Validation Loss: 1.2661, Accuracy: 0.8438, Precision: 0.7248, Recall: 0.6125, F1: 0.6486
Testing Loss: 1.3632, Accuracy: 0.8457, Precision: 0.7372, Recall: 0.6353, F1: 0.6679
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1884, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 47/70
Train Loss: 0.0319, Accuracy: 0.9906, Precision: 0.9765, Recall: 0.9770, F1: 0.9767
Validation Loss: 0.9220, Accuracy: 0.8352, Precision: 0.7270, Recall: 0.6939, F1: 0.7032
Testing Loss: 0.9983, Accuracy: 0.8271, Precision: 0.6625, Recall: 0.6288, F1: 0.6426
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0926, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 48/70
Train Loss: 0.0278, Accuracy: 0.9916, Precision: 0.9829, Recall: 0.9780, F1: 0.9804
Validation Loss: 0.9708, Accuracy: 0.8636, Precision: 0.7149, Recall: 0.7691, F1: 0.7185
Testing Loss: 1.0341, Accuracy: 0.8404, Precision: 0.6695, Recall: 0.6910, F1: 0.6767
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1504, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 49/70
Train Loss: 0.0259, Accuracy: 0.9909, Precision: 0.9762, Recall: 0.9766, F1: 0.9763
Validation Loss: 0.8905, Accuracy: 0.8494, Precision: 0.7174, Recall: 0.7991, F1: 0.7231
Testing Loss: 0.9262, Accuracy: 0.8351, Precision: 0.6697, Recall: 0.6663, F1: 0.6646
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0432, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0228, Accuracy: 0.9899, Precision: 0.9749, Recall: 0.9737, F1: 0.9742
Validation Loss: 1.1202, Accuracy: 0.8239, Precision: 0.6959, Recall: 0.7989, F1: 0.7080
Testing Loss: 1.2829, Accuracy: 0.8271, Precision: 0.6326, Recall: 0.6460, F1: 0.6349
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0267, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 51/70
Train Loss: 0.0153, Accuracy: 0.9958, Precision: 0.9934, Recall: 0.9926, F1: 0.9930
Validation Loss: 1.1213, Accuracy: 0.8438, Precision: 0.7244, Recall: 0.7446, F1: 0.7168
Testing Loss: 1.2437, Accuracy: 0.8324, Precision: 0.6303, Recall: 0.6112, F1: 0.6128
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0191, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 52/70
Train Loss: 0.0217, Accuracy: 0.9937, Precision: 0.9812, Recall: 0.9796, F1: 0.9804
Validation Loss: 1.0476, Accuracy: 0.8665, Precision: 0.7947, Recall: 0.7400, F1: 0.7495
Testing Loss: 1.1882, Accuracy: 0.8351, Precision: 0.6471, Recall: 0.6026, F1: 0.6191
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0167, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 53/70
Train Loss: 0.0163, Accuracy: 0.9948, Precision: 0.9882, Recall: 0.9846, F1: 0.9864
Validation Loss: 1.3263, Accuracy: 0.8523, Precision: 0.6922, Recall: 0.6120, F1: 0.6426
Testing Loss: 1.4955, Accuracy: 0.8324, Precision: 0.6512, Recall: 0.6025, F1: 0.6196
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0051, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0376, Accuracy: 0.9902, Precision: 0.9790, Recall: 0.9712, F1: 0.9748
Validation Loss: 1.0169, Accuracy: 0.8352, Precision: 0.7525, Recall: 0.7382, F1: 0.7212
Testing Loss: 1.1078, Accuracy: 0.8431, Precision: 0.6946, Recall: 0.6353, F1: 0.6557
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0611, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 55/70
Train Loss: 0.0279, Accuracy: 0.9906, Precision: 0.9792, Recall: 0.9777, F1: 0.9783
Validation Loss: 1.0338, Accuracy: 0.8665, Precision: 0.7649, Recall: 0.6756, F1: 0.6969
Testing Loss: 1.2436, Accuracy: 0.8218, Precision: 0.6730, Recall: 0.6016, F1: 0.6228
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0093, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0247, Accuracy: 0.9927, Precision: 0.9825, Recall: 0.9851, F1: 0.9838
Validation Loss: 1.2194, Accuracy: 0.8324, Precision: 0.6680, Recall: 0.6167, F1: 0.6329
Testing Loss: 1.3246, Accuracy: 0.8218, Precision: 0.6288, Recall: 0.5882, F1: 0.5929
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0071, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0188, Accuracy: 0.9948, Precision: 0.9904, Recall: 0.9904, F1: 0.9904
Validation Loss: 0.9502, Accuracy: 0.8466, Precision: 0.7046, Recall: 0.7181, F1: 0.7059
Testing Loss: 1.1707, Accuracy: 0.8351, Precision: 0.6562, Recall: 0.6509, F1: 0.6500
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0084, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0122, Accuracy: 0.9965, Precision: 0.9953, Recall: 0.9953, F1: 0.9953
Validation Loss: 1.1556, Accuracy: 0.8636, Precision: 0.7348, Recall: 0.7147, F1: 0.7201
Testing Loss: 1.3724, Accuracy: 0.8298, Precision: 0.6359, Recall: 0.6275, F1: 0.6313
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0510, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0169, Accuracy: 0.9944, Precision: 0.9921, Recall: 0.9897, F1: 0.9909
Validation Loss: 0.9536, Accuracy: 0.8551, Precision: 0.7328, Recall: 0.7948, F1: 0.7474
Testing Loss: 1.1495, Accuracy: 0.8324, Precision: 0.6753, Recall: 0.6431, F1: 0.6557
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0017, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0087, Accuracy: 0.9979, Precision: 0.9962, Recall: 0.9985, F1: 0.9974
Validation Loss: 1.2241, Accuracy: 0.8494, Precision: 0.7413, Recall: 0.6734, F1: 0.6872
Testing Loss: 1.4187, Accuracy: 0.8378, Precision: 0.6839, Recall: 0.6082, F1: 0.6326
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0053, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0184, Accuracy: 0.9937, Precision: 0.9858, Recall: 0.9864, F1: 0.9860
Validation Loss: 1.3560, Accuracy: 0.8210, Precision: 0.6911, Recall: 0.7528, F1: 0.6970
Testing Loss: 1.4764, Accuracy: 0.8138, Precision: 0.6196, Recall: 0.6407, F1: 0.6164
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0157, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.0181, Accuracy: 0.9937, Precision: 0.9838, Recall: 0.9842, F1: 0.9840
Validation Loss: 1.0383, Accuracy: 0.8438, Precision: 0.6656, Recall: 0.6616, F1: 0.6620
Testing Loss: 1.3075, Accuracy: 0.8404, Precision: 0.6823, Recall: 0.6943, F1: 0.6860
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0061, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.0128, Accuracy: 0.9958, Precision: 0.9949, Recall: 0.9880, F1: 0.9914
Validation Loss: 1.1280, Accuracy: 0.8352, Precision: 0.6797, Recall: 0.6483, F1: 0.6446
Testing Loss: 1.3750, Accuracy: 0.8324, Precision: 0.6651, Recall: 0.6296, F1: 0.6413
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0045, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0134, Accuracy: 0.9944, Precision: 0.9921, Recall: 0.9921, F1: 0.9921
Validation Loss: 1.0021, Accuracy: 0.8352, Precision: 0.6589, Recall: 0.6460, F1: 0.6520
Testing Loss: 1.2919, Accuracy: 0.8298, Precision: 0.6657, Recall: 0.6419, F1: 0.6462
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0052, Accuracy: 0.9983, Precision: 0.9974, Recall: 0.9976, F1: 0.9975
Validation Loss: 1.1184, Accuracy: 0.8523, Precision: 0.7185, Recall: 0.7079, F1: 0.7084
Testing Loss: 1.4701, Accuracy: 0.8404, Precision: 0.6725, Recall: 0.6526, F1: 0.6593
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0123, Accuracy: 0.9958, Precision: 0.9868, Recall: 0.9851, F1: 0.9859
Validation Loss: 1.3118, Accuracy: 0.8295, Precision: 0.6858, Recall: 0.5996, F1: 0.6201
Testing Loss: 1.6684, Accuracy: 0.8005, Precision: 0.5914, Recall: 0.5517, F1: 0.5433
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0036, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0154, Accuracy: 0.9951, Precision: 0.9868, Recall: 0.9868, F1: 0.9868
Validation Loss: 0.9984, Accuracy: 0.8239, Precision: 0.6450, Recall: 0.6140, F1: 0.6206
Testing Loss: 1.2328, Accuracy: 0.8271, Precision: 0.6133, Recall: 0.6125, F1: 0.6091
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0039, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0220, Accuracy: 0.9937, Precision: 0.9815, Recall: 0.9763, F1: 0.9788
Validation Loss: 0.9053, Accuracy: 0.8267, Precision: 0.6745, Recall: 0.6972, F1: 0.6759
Testing Loss: 1.1316, Accuracy: 0.8378, Precision: 0.6560, Recall: 0.6566, F1: 0.6537
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0029, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0021, Accuracy: 0.9997, Precision: 0.9998, Recall: 0.9986, F1: 0.9992
Validation Loss: 1.1526, Accuracy: 0.8381, Precision: 0.6915, Recall: 0.6129, F1: 0.6436
Testing Loss: 1.3577, Accuracy: 0.8457, Precision: 0.7216, Recall: 0.6586, F1: 0.6830
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0014, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.0162, Accuracy: 0.9958, Precision: 0.9913, Recall: 0.9899, F1: 0.9906
Validation Loss: 1.0583, Accuracy: 0.8466, Precision: 0.6910, Recall: 0.6224, F1: 0.6458
Testing Loss: 1.2480, Accuracy: 0.8271, Precision: 0.6813, Recall: 0.6299, F1: 0.6437
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0022, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
---------------------------------------------------------------------------