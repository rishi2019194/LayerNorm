---------------------------------------------------------------------------
Results for seed:  28
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 3
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 5: 486
  Label 1: 115
  Label 3: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 5: 60
  Label 0: 3
  Label 3: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 3: 29
  Label 5: 58
28
Actual labels:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
Label counts for Train:
  Label 4: 971
  Label 2: 1106
  Label 5: 493
  Label 1: 119
  Label 3: 116
  Label 0: 53
For early layers:  [0, 1, 2, 3]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.4820, Accuracy: 0.3709, Precision: 0.1825, Recall: 0.1751, F1: 0.1579
Validation Loss: 1.4093, Accuracy: 0.3778, Precision: 0.1293, Recall: 0.1797, F1: 0.1468
Testing Loss: 1.4493, Accuracy: 0.3830, Precision: 0.1307, Recall: 0.1790, F1: 0.1463
LM Predictions:  [2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1788, Accuracy: 0.2857, Precision: 0.1333, Recall: 0.2629, F1: 0.1698
Epoch 2/70
Train Loss: 1.3982, Accuracy: 0.3968, Precision: 0.1490, Recall: 0.1799, F1: 0.1520
Validation Loss: 1.4224, Accuracy: 0.3977, Precision: 0.1405, Recall: 0.1907, F1: 0.1529
Testing Loss: 1.4340, Accuracy: 0.4335, Precision: 0.1583, Recall: 0.2027, F1: 0.1659
LM Predictions:  [4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2387, Accuracy: 0.2143, Precision: 0.0933, Recall: 0.2057, F1: 0.1228
Epoch 3/70
Train Loss: 1.3685, Accuracy: 0.4055, Precision: 0.1866, Recall: 0.1846, F1: 0.1574
Validation Loss: 1.3869, Accuracy: 0.4233, Precision: 0.1404, Recall: 0.1973, F1: 0.1639
Testing Loss: 1.4090, Accuracy: 0.4229, Precision: 0.1406, Recall: 0.1967, F1: 0.1633
LM Predictions:  [2, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1016, Accuracy: 0.2143, Precision: 0.0857, Recall: 0.1943, F1: 0.1183
Epoch 4/70
Train Loss: 1.3505, Accuracy: 0.4318, Precision: 0.2117, Recall: 0.1975, F1: 0.1711
Validation Loss: 1.3520, Accuracy: 0.4347, Precision: 0.1473, Recall: 0.2060, F1: 0.1693
Testing Loss: 1.3761, Accuracy: 0.4628, Precision: 0.1579, Recall: 0.2159, F1: 0.1800
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0420, Accuracy: 0.2143, Precision: 0.0875, Recall: 0.2057, F1: 0.1203
Epoch 5/70
Train Loss: 1.3290, Accuracy: 0.4640, Precision: 0.2353, Recall: 0.2153, F1: 0.1908
Validation Loss: 1.3602, Accuracy: 0.4631, Precision: 0.1629, Recall: 0.2118, F1: 0.1721
Testing Loss: 1.3890, Accuracy: 0.4468, Precision: 0.1634, Recall: 0.2071, F1: 0.1647
LM Predictions:  [2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1996, Accuracy: 0.2857, Precision: 0.1009, Recall: 0.2400, F1: 0.1333
Epoch 6/70
Train Loss: 1.3113, Accuracy: 0.4608, Precision: 0.2248, Recall: 0.2171, F1: 0.1974
Validation Loss: 1.3079, Accuracy: 0.4943, Precision: 0.2367, Recall: 0.2520, F1: 0.2372
Testing Loss: 1.3396, Accuracy: 0.5053, Precision: 0.2442, Recall: 0.2610, F1: 0.2436
LM Predictions:  [2, 2, 5, 5, 5, 2, 4, 5, 2, 4, 2, 4, 2, 5, 4, 5, 5, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9379, Accuracy: 0.4286, Precision: 0.2610, Recall: 0.3657, F1: 0.2961
Epoch 7/70
Train Loss: 1.2902, Accuracy: 0.4930, Precision: 0.2327, Recall: 0.2364, F1: 0.2197
Validation Loss: 1.3633, Accuracy: 0.4716, Precision: 0.1577, Recall: 0.2217, F1: 0.1842
Testing Loss: 1.3122, Accuracy: 0.5000, Precision: 0.3330, Recall: 0.2344, F1: 0.1990
LM Predictions:  [2, 2, 4, 4, 4, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1876, Accuracy: 0.2857, Precision: 0.1128, Recall: 0.2629, F1: 0.1576
Epoch 8/70
Train Loss: 1.2441, Accuracy: 0.5056, Precision: 0.2426, Recall: 0.2462, F1: 0.2323
Validation Loss: 1.2331, Accuracy: 0.5341, Precision: 0.2552, Recall: 0.2815, F1: 0.2661
Testing Loss: 1.1798, Accuracy: 0.5638, Precision: 0.2601, Recall: 0.2937, F1: 0.2747
LM Predictions:  [2, 2, 4, 5, 5, 5, 4, 5, 5, 4, 2, 4, 2, 4, 4, 5, 5, 5, 2, 2, 2, 2, 5, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9296, Accuracy: 0.3214, Precision: 0.1911, Recall: 0.2800, F1: 0.2263
Epoch 9/70
Train Loss: 1.1968, Accuracy: 0.5462, Precision: 0.2599, Recall: 0.2732, F1: 0.2604
Validation Loss: 1.1939, Accuracy: 0.5341, Precision: 0.2534, Recall: 0.2901, F1: 0.2692
Testing Loss: 1.1709, Accuracy: 0.5745, Precision: 0.2672, Recall: 0.3071, F1: 0.2847
LM Predictions:  [2, 4, 2, 5, 5, 4, 4, 5, 5, 2, 2, 4, 2, 4, 4, 5, 5, 5, 5, 5, 2, 2, 5, 2, 4, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8651, Accuracy: 0.4286, Precision: 0.2578, Recall: 0.3771, F1: 0.3048
Epoch 10/70
Train Loss: 1.1235, Accuracy: 0.5843, Precision: 0.4473, Recall: 0.2992, F1: 0.2882
Validation Loss: 1.1593, Accuracy: 0.5511, Precision: 0.2770, Recall: 0.2786, F1: 0.2652
Testing Loss: 1.1218, Accuracy: 0.5878, Precision: 0.2908, Recall: 0.2980, F1: 0.2817
LM Predictions:  [2, 2, 2, 5, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 4, 2, 5, 5, 2, 2, 2, 2, 5, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9573, Accuracy: 0.3571, Precision: 0.2367, Recall: 0.2971, F1: 0.2224
Epoch 11/70
Train Loss: 1.0842, Accuracy: 0.6004, Precision: 0.3318, Recall: 0.3098, F1: 0.2989
Validation Loss: 1.0987, Accuracy: 0.5881, Precision: 0.4508, Recall: 0.3278, F1: 0.3181
Testing Loss: 1.0525, Accuracy: 0.6090, Precision: 0.4461, Recall: 0.3245, F1: 0.3083
LM Predictions:  [2, 4, 2, 5, 5, 4, 4, 5, 5, 2, 2, 5, 2, 4, 4, 5, 5, 5, 2, 5, 2, 2, 5, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8338, Accuracy: 0.4643, Precision: 0.2800, Recall: 0.4057, F1: 0.3295
Epoch 12/70
Train Loss: 1.0248, Accuracy: 0.6085, Precision: 0.3908, Recall: 0.3184, F1: 0.3087
Validation Loss: 1.1812, Accuracy: 0.5710, Precision: 0.3164, Recall: 0.2921, F1: 0.2809
Testing Loss: 1.1053, Accuracy: 0.6144, Precision: 0.4909, Recall: 0.3307, F1: 0.3278
LM Predictions:  [2, 2, 2, 5, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 4, 3, 5, 3, 2, 5, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9978, Accuracy: 0.3929, Precision: 0.2447, Recall: 0.2714, F1: 0.2207
Epoch 13/70
Train Loss: 0.9618, Accuracy: 0.6505, Precision: 0.4221, Recall: 0.3402, F1: 0.3281
Validation Loss: 1.0492, Accuracy: 0.6420, Precision: 0.3244, Recall: 0.3523, F1: 0.3307
Testing Loss: 1.0204, Accuracy: 0.6303, Precision: 0.3092, Recall: 0.3541, F1: 0.3237
LM Predictions:  [5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 5, 5, 5, 5, 5, 2, 2, 5, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0863, Accuracy: 0.3571, Precision: 0.2200, Recall: 0.2971, F1: 0.2404
Epoch 14/70
Train Loss: 0.9265, Accuracy: 0.6599, Precision: 0.3616, Recall: 0.3492, F1: 0.3372
Validation Loss: 0.9912, Accuracy: 0.6080, Precision: 0.3110, Recall: 0.3369, F1: 0.3196
Testing Loss: 0.9664, Accuracy: 0.6489, Precision: 0.3574, Recall: 0.3587, F1: 0.3477
LM Predictions:  [2, 5, 2, 5, 5, 4, 3, 5, 5, 5, 3, 3, 2, 4, 4, 5, 5, 3, 3, 5, 2, 2, 5, 2, 2, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7904, Accuracy: 0.3929, Precision: 0.2375, Recall: 0.2810, F1: 0.2562
Epoch 15/70
Train Loss: 0.8979, Accuracy: 0.6704, Precision: 0.3632, Recall: 0.3584, F1: 0.3480
Validation Loss: 0.9117, Accuracy: 0.6676, Precision: 0.3275, Recall: 0.3655, F1: 0.3435
Testing Loss: 0.9574, Accuracy: 0.6622, Precision: 0.3678, Recall: 0.3572, F1: 0.3401
LM Predictions:  [2, 5, 5, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 4, 4, 2, 5, 5, 3, 5, 5, 2, 5, 2, 2, 4, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0081, Accuracy: 0.3571, Precision: 0.1779, Recall: 0.2476, F1: 0.1972
Epoch 16/70
Train Loss: 0.8431, Accuracy: 0.6938, Precision: 0.4620, Recall: 0.3765, F1: 0.3678
Validation Loss: 0.9796, Accuracy: 0.6108, Precision: 0.2975, Recall: 0.3252, F1: 0.3025
Testing Loss: 0.9864, Accuracy: 0.6516, Precision: 0.3043, Recall: 0.3399, F1: 0.3180
LM Predictions:  [2, 5, 3, 2, 5, 4, 4, 5, 5, 5, 2, 4, 2, 4, 4, 2, 5, 5, 5, 5, 2, 2, 5, 2, 5, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8242, Accuracy: 0.3214, Precision: 0.1758, Recall: 0.2429, F1: 0.2037
Epoch 17/70
Train Loss: 0.7863, Accuracy: 0.7194, Precision: 0.4221, Recall: 0.4066, F1: 0.4034
Validation Loss: 0.9169, Accuracy: 0.6676, Precision: 0.3578, Recall: 0.3779, F1: 0.3609
Testing Loss: 0.8851, Accuracy: 0.6888, Precision: 0.3885, Recall: 0.3978, F1: 0.3840
LM Predictions:  [2, 5, 3, 2, 5, 2, 3, 5, 2, 3, 2, 3, 2, 4, 4, 5, 5, 3, 3, 5, 2, 2, 5, 2, 5, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9467, Accuracy: 0.3214, Precision: 0.2167, Recall: 0.2238, F1: 0.2045
Epoch 18/70
Train Loss: 0.7704, Accuracy: 0.7337, Precision: 0.4390, Recall: 0.4223, F1: 0.4187
Validation Loss: 0.9205, Accuracy: 0.6477, Precision: 0.3681, Recall: 0.3847, F1: 0.3569
Testing Loss: 0.8787, Accuracy: 0.7048, Precision: 0.4210, Recall: 0.4360, F1: 0.4077
LM Predictions:  [5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 3, 5, 2, 5, 4, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 1, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9770, Accuracy: 0.3214, Precision: 0.3380, Recall: 0.2238, F1: 0.2131
Epoch 19/70
Train Loss: 0.7721, Accuracy: 0.7169, Precision: 0.6403, Recall: 0.4134, F1: 0.4181
Validation Loss: 0.9579, Accuracy: 0.6222, Precision: 0.4604, Recall: 0.3737, F1: 0.3660
Testing Loss: 0.9133, Accuracy: 0.6702, Precision: 0.4147, Recall: 0.3938, F1: 0.3882
LM Predictions:  [5, 5, 3, 5, 5, 5, 4, 5, 5, 3, 3, 4, 2, 1, 4, 5, 4, 3, 3, 5, 5, 3, 5, 2, 5, 4, 3, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7585, Accuracy: 0.3571, Precision: 0.3194, Recall: 0.2667, F1: 0.2527
Epoch 20/70
Train Loss: 0.7294, Accuracy: 0.7323, Precision: 0.4658, Recall: 0.4249, F1: 0.4233
Validation Loss: 0.9155, Accuracy: 0.6335, Precision: 0.3937, Recall: 0.3609, F1: 0.3374
Testing Loss: 0.8915, Accuracy: 0.6915, Precision: 0.4011, Recall: 0.3937, F1: 0.3717
LM Predictions:  [5, 5, 4, 5, 5, 5, 4, 5, 5, 3, 5, 3, 2, 4, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 4, 2, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7895, Accuracy: 0.3929, Precision: 0.2520, Recall: 0.2810, F1: 0.2468
Epoch 21/70
Train Loss: 0.6846, Accuracy: 0.7530, Precision: 0.5017, Recall: 0.4409, F1: 0.4401
Validation Loss: 0.9337, Accuracy: 0.6534, Precision: 0.4504, Recall: 0.4175, F1: 0.4028
Testing Loss: 0.8359, Accuracy: 0.7128, Precision: 0.4181, Recall: 0.4540, F1: 0.4314
LM Predictions:  [2, 5, 3, 2, 5, 5, 3, 5, 3, 3, 3, 3, 2, 4, 4, 5, 5, 3, 3, 5, 5, 3, 5, 2, 1, 4, 3, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8166, Accuracy: 0.3214, Precision: 0.4074, Recall: 0.2417, F1: 0.2779
Epoch 22/70
Train Loss: 0.6959, Accuracy: 0.7498, Precision: 0.5161, Recall: 0.4525, F1: 0.4562
Validation Loss: 0.8656, Accuracy: 0.6733, Precision: 0.4929, Recall: 0.4282, F1: 0.4162
Testing Loss: 0.8038, Accuracy: 0.7207, Precision: 0.4360, Recall: 0.4608, F1: 0.4397
LM Predictions:  [5, 5, 3, 2, 5, 5, 3, 5, 5, 3, 5, 3, 2, 5, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8069, Accuracy: 0.3571, Precision: 0.3583, Recall: 0.2476, F1: 0.2374
Epoch 23/70
Train Loss: 0.6501, Accuracy: 0.7656, Precision: 0.5134, Recall: 0.4702, F1: 0.4751
Validation Loss: 0.9380, Accuracy: 0.6676, Precision: 0.4047, Recall: 0.3742, F1: 0.3541
Testing Loss: 0.8790, Accuracy: 0.7154, Precision: 0.4249, Recall: 0.4059, F1: 0.3912
LM Predictions:  [2, 5, 3, 2, 5, 4, 3, 5, 2, 3, 5, 3, 2, 4, 4, 5, 4, 5, 3, 5, 5, 2, 5, 2, 2, 4, 3, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4964, Accuracy: 0.4643, Precision: 0.2950, Recall: 0.3381, F1: 0.3141
Epoch 24/70
Train Loss: 0.6516, Accuracy: 0.7691, Precision: 0.4889, Recall: 0.4681, F1: 0.4666
Validation Loss: 0.8818, Accuracy: 0.6818, Precision: 0.4558, Recall: 0.4100, F1: 0.4001
Testing Loss: 0.7864, Accuracy: 0.7261, Precision: 0.4251, Recall: 0.4398, F1: 0.4313
LM Predictions:  [2, 5, 3, 2, 5, 3, 3, 5, 2, 3, 3, 3, 2, 3, 4, 5, 5, 3, 3, 5, 3, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8604, Accuracy: 0.3571, Precision: 0.3631, Recall: 0.2476, F1: 0.2603
Epoch 25/70
Train Loss: 0.6278, Accuracy: 0.7740, Precision: 0.5776, Recall: 0.4730, F1: 0.4759
Validation Loss: 0.9161, Accuracy: 0.6676, Precision: 0.3982, Recall: 0.3964, F1: 0.3884
Testing Loss: 0.8181, Accuracy: 0.7261, Precision: 0.4358, Recall: 0.4334, F1: 0.4304
LM Predictions:  [2, 1, 3, 2, 5, 5, 3, 5, 5, 3, 5, 3, 2, 5, 4, 5, 4, 3, 3, 5, 5, 2, 5, 2, 1, 1, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6074, Accuracy: 0.5000, Precision: 0.4611, Recall: 0.3702, F1: 0.3887
Epoch 26/70
Train Loss: 0.6015, Accuracy: 0.7852, Precision: 0.5394, Recall: 0.4993, F1: 0.5026
Validation Loss: 0.9824, Accuracy: 0.6591, Precision: 0.4853, Recall: 0.4238, F1: 0.4095
Testing Loss: 0.8052, Accuracy: 0.7314, Precision: 0.4341, Recall: 0.4605, F1: 0.4424
LM Predictions:  [5, 5, 3, 2, 5, 5, 3, 5, 2, 3, 3, 3, 3, 5, 4, 5, 5, 3, 3, 5, 5, 3, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8597, Accuracy: 0.2857, Precision: 0.3419, Recall: 0.2000, F1: 0.2056
Epoch 27/70
Train Loss: 0.5836, Accuracy: 0.7932, Precision: 0.5846, Recall: 0.5038, F1: 0.5163
Validation Loss: 0.9523, Accuracy: 0.6733, Precision: 0.4287, Recall: 0.4363, F1: 0.4233
Testing Loss: 0.8742, Accuracy: 0.7234, Precision: 0.4432, Recall: 0.4486, F1: 0.4419
LM Predictions:  [2, 1, 3, 2, 5, 4, 3, 5, 5, 3, 5, 3, 2, 3, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8044, Accuracy: 0.4286, Precision: 0.3783, Recall: 0.3048, F1: 0.3185
Epoch 28/70
Train Loss: 0.5992, Accuracy: 0.7817, Precision: 0.6419, Recall: 0.5064, F1: 0.5175
Validation Loss: 0.9101, Accuracy: 0.6847, Precision: 0.4448, Recall: 0.4266, F1: 0.4229
Testing Loss: 0.8521, Accuracy: 0.7261, Precision: 0.4698, Recall: 0.4648, F1: 0.4647
LM Predictions:  [2, 1, 3, 2, 5, 2, 3, 5, 2, 3, 5, 3, 2, 3, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9553, Accuracy: 0.4286, Precision: 0.3819, Recall: 0.2952, F1: 0.2917
Epoch 29/70
Train Loss: 0.5634, Accuracy: 0.7939, Precision: 0.6190, Recall: 0.5286, F1: 0.5422
Validation Loss: 0.9541, Accuracy: 0.6705, Precision: 0.4215, Recall: 0.4217, F1: 0.4117
Testing Loss: 0.8690, Accuracy: 0.7128, Precision: 0.4448, Recall: 0.4599, F1: 0.4481
LM Predictions:  [2, 1, 3, 5, 5, 3, 3, 5, 2, 3, 5, 3, 2, 3, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0481, Accuracy: 0.4643, Precision: 0.4333, Recall: 0.3190, F1: 0.3270
Epoch 30/70
Train Loss: 0.5341, Accuracy: 0.8027, Precision: 0.6228, Recall: 0.5341, F1: 0.5474
Validation Loss: 0.9396, Accuracy: 0.6875, Precision: 0.4316, Recall: 0.4417, F1: 0.4321
Testing Loss: 0.8465, Accuracy: 0.7287, Precision: 0.4514, Recall: 0.4715, F1: 0.4576
LM Predictions:  [2, 1, 3, 0, 5, 3, 3, 5, 3, 3, 5, 3, 2, 3, 4, 5, 5, 3, 3, 5, 5, 2, 5, 2, 5, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8687, Accuracy: 0.3929, Precision: 0.4259, Recall: 0.2714, F1: 0.2986
Epoch 31/70
Train Loss: 0.5502, Accuracy: 0.8023, Precision: 0.6530, Recall: 0.5417, F1: 0.5625
Validation Loss: 0.9758, Accuracy: 0.6591, Precision: 0.4413, Recall: 0.4252, F1: 0.4065
Testing Loss: 0.8733, Accuracy: 0.7207, Precision: 0.4795, Recall: 0.4897, F1: 0.4602
LM Predictions:  [5, 1, 3, 5, 5, 1, 3, 5, 1, 3, 5, 3, 2, 1, 4, 5, 1, 3, 3, 5, 5, 2, 5, 2, 1, 1, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6787, Accuracy: 0.3929, Precision: 0.4571, Recall: 0.2893, F1: 0.3035
Epoch 32/70
Train Loss: 0.5426, Accuracy: 0.7999, Precision: 0.6615, Recall: 0.5605, F1: 0.5821
Validation Loss: 0.9732, Accuracy: 0.6903, Precision: 0.4411, Recall: 0.4483, F1: 0.4439
Testing Loss: 0.8360, Accuracy: 0.7261, Precision: 0.4744, Recall: 0.4896, F1: 0.4768
LM Predictions:  [2, 1, 3, 5, 5, 2, 3, 5, 2, 3, 5, 3, 2, 1, 4, 5, 1, 3, 3, 5, 5, 2, 5, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5427, Accuracy: 0.5000, Precision: 0.4762, Recall: 0.3607, F1: 0.3734
Epoch 33/70
Train Loss: 0.4908, Accuracy: 0.8338, Precision: 0.6957, Recall: 0.5890, F1: 0.6081
Validation Loss: 0.9645, Accuracy: 0.6619, Precision: 0.4347, Recall: 0.4497, F1: 0.4369
Testing Loss: 0.8593, Accuracy: 0.7287, Precision: 0.4777, Recall: 0.5028, F1: 0.4791
LM Predictions:  [5, 1, 3, 5, 5, 1, 3, 5, 3, 3, 5, 3, 3, 1, 4, 5, 1, 3, 3, 5, 3, 2, 5, 2, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0309, Accuracy: 0.3214, Precision: 0.4593, Recall: 0.2417, F1: 0.2708
Epoch 34/70
Train Loss: 0.4660, Accuracy: 0.8352, Precision: 0.7052, Recall: 0.5999, F1: 0.6230
Validation Loss: 0.9559, Accuracy: 0.6818, Precision: 0.4429, Recall: 0.4494, F1: 0.4431
Testing Loss: 0.8665, Accuracy: 0.7181, Precision: 0.4750, Recall: 0.4942, F1: 0.4736
LM Predictions:  [2, 1, 3, 5, 1, 1, 3, 5, 3, 3, 5, 3, 2, 1, 4, 5, 1, 3, 3, 5, 5, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4186, Accuracy: 0.4643, Precision: 0.5476, Recall: 0.3548, F1: 0.3912
Epoch 35/70
Train Loss: 0.4562, Accuracy: 0.8369, Precision: 0.6864, Recall: 0.5965, F1: 0.6172
Validation Loss: 0.9760, Accuracy: 0.6960, Precision: 0.4977, Recall: 0.4570, F1: 0.4630
Testing Loss: 0.8590, Accuracy: 0.7234, Precision: 0.4595, Recall: 0.4552, F1: 0.4503
LM Predictions:  [2, 1, 3, 5, 5, 1, 3, 5, 2, 3, 5, 3, 2, 4, 4, 5, 4, 5, 3, 5, 5, 2, 5, 2, 5, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.2016, Accuracy: 0.5357, Precision: 0.5444, Recall: 0.3857, F1: 0.4104
Epoch 36/70
Train Loss: 0.4421, Accuracy: 0.8397, Precision: 0.6967, Recall: 0.6096, F1: 0.6338
Validation Loss: 1.0119, Accuracy: 0.6818, Precision: 0.5091, Recall: 0.4570, F1: 0.4411
Testing Loss: 0.9306, Accuracy: 0.7261, Precision: 0.4947, Recall: 0.5053, F1: 0.4682
LM Predictions:  [5, 1, 1, 5, 1, 1, 3, 5, 2, 3, 5, 3, 2, 1, 4, 5, 1, 5, 3, 5, 5, 2, 5, 2, 1, 1, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.5345, Accuracy: 0.5000, Precision: 0.4861, Recall: 0.3786, F1: 0.3750
Epoch 37/70
Train Loss: 0.4274, Accuracy: 0.8457, Precision: 0.7398, Recall: 0.6632, F1: 0.6902
Validation Loss: 0.9793, Accuracy: 0.7188, Precision: 0.4751, Recall: 0.4752, F1: 0.4718
Testing Loss: 0.8687, Accuracy: 0.7420, Precision: 0.4809, Recall: 0.4892, F1: 0.4826
LM Predictions:  [2, 1, 3, 5, 5, 4, 3, 5, 2, 3, 5, 3, 2, 3, 4, 5, 1, 3, 3, 5, 3, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4801, Accuracy: 0.4643, Precision: 0.4286, Recall: 0.3286, F1: 0.3571
Epoch 38/70
Train Loss: 0.3913, Accuracy: 0.8572, Precision: 0.7558, Recall: 0.6654, F1: 0.6924
Validation Loss: 1.1698, Accuracy: 0.6705, Precision: 0.4344, Recall: 0.4395, F1: 0.4303
Testing Loss: 1.0069, Accuracy: 0.7314, Precision: 0.4936, Recall: 0.5151, F1: 0.4875
LM Predictions:  [5, 1, 2, 5, 5, 1, 3, 5, 2, 1, 5, 3, 2, 1, 4, 5, 1, 5, 1, 5, 3, 3, 1, 2, 1, 1, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4672, Accuracy: 0.5000, Precision: 0.4931, Recall: 0.3964, F1: 0.3825
Epoch 39/70
Train Loss: 0.3981, Accuracy: 0.8548, Precision: 0.7025, Recall: 0.6467, F1: 0.6645
Validation Loss: 1.0466, Accuracy: 0.6903, Precision: 0.4663, Recall: 0.4533, F1: 0.4484
Testing Loss: 0.8740, Accuracy: 0.7447, Precision: 0.4788, Recall: 0.4872, F1: 0.4824
LM Predictions:  [2, 3, 3, 5, 1, 2, 3, 5, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 3, 5, 3, 2, 5, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1329, Accuracy: 0.5357, Precision: 0.6012, Recall: 0.3940, F1: 0.4381
Epoch 40/70
Train Loss: 0.3976, Accuracy: 0.8625, Precision: 0.7724, Recall: 0.6720, F1: 0.6999
Validation Loss: 1.0199, Accuracy: 0.6903, Precision: 0.4534, Recall: 0.4614, F1: 0.4557
Testing Loss: 0.8555, Accuracy: 0.7394, Precision: 0.4881, Recall: 0.5196, F1: 0.4981
LM Predictions:  [2, 1, 3, 5, 1, 4, 3, 5, 3, 3, 5, 3, 2, 4, 4, 5, 4, 3, 3, 5, 5, 2, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1710, Accuracy: 0.5714, Precision: 0.5417, Recall: 0.4452, F1: 0.4872
Epoch 41/70
Train Loss: 0.3720, Accuracy: 0.8670, Precision: 0.7332, Recall: 0.6791, F1: 0.6956
Validation Loss: 1.1520, Accuracy: 0.6847, Precision: 0.4277, Recall: 0.4383, F1: 0.4283
Testing Loss: 0.9563, Accuracy: 0.7420, Precision: 0.5007, Recall: 0.5152, F1: 0.5044
LM Predictions:  [2, 1, 3, 5, 1, 4, 3, 5, 3, 3, 5, 3, 2, 1, 4, 5, 4, 3, 1, 5, 5, 2, 5, 2, 5, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1070, Accuracy: 0.5714, Precision: 0.5417, Recall: 0.4452, F1: 0.4806
Epoch 42/70
Train Loss: 0.3601, Accuracy: 0.8639, Precision: 0.7710, Recall: 0.6971, F1: 0.7231
Validation Loss: 1.3303, Accuracy: 0.6989, Precision: 0.5471, Recall: 0.4371, F1: 0.4350
Testing Loss: 1.1239, Accuracy: 0.7527, Precision: 0.4501, Recall: 0.4851, F1: 0.4659
LM Predictions:  [2, 1, 3, 5, 5, 4, 3, 5, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 3, 5, 3, 2, 5, 2, 5, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1848, Accuracy: 0.5714, Precision: 0.6111, Recall: 0.4190, F1: 0.4594
Epoch 43/70
Train Loss: 0.3552, Accuracy: 0.8709, Precision: 0.7579, Recall: 0.6881, F1: 0.7136
Validation Loss: 1.3165, Accuracy: 0.6818, Precision: 0.4481, Recall: 0.4382, F1: 0.4269
Testing Loss: 1.2073, Accuracy: 0.7154, Precision: 0.4814, Recall: 0.4564, F1: 0.4498
LM Predictions:  [2, 1, 2, 5, 1, 4, 3, 5, 2, 3, 5, 0, 2, 2, 4, 5, 4, 3, 3, 5, 3, 2, 1, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.9419, Accuracy: 0.6786, Precision: 0.6852, Recall: 0.5274, F1: 0.5823
Epoch 44/70
Train Loss: 0.3325, Accuracy: 0.8810, Precision: 0.7661, Recall: 0.7220, F1: 0.7398
Validation Loss: 1.1697, Accuracy: 0.6790, Precision: 0.4238, Recall: 0.4150, F1: 0.4142
Testing Loss: 1.0935, Accuracy: 0.7128, Precision: 0.4776, Recall: 0.4830, F1: 0.4641
LM Predictions:  [2, 1, 2, 5, 1, 4, 3, 5, 2, 1, 5, 0, 3, 1, 4, 5, 4, 3, 1, 5, 3, 2, 1, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.7024, Accuracy: 0.7143, Precision: 0.7262, Recall: 0.5869, F1: 0.6317
Epoch 45/70
Train Loss: 0.2932, Accuracy: 0.8961, Precision: 0.8025, Recall: 0.7578, F1: 0.7771
Validation Loss: 1.2311, Accuracy: 0.7045, Precision: 0.4654, Recall: 0.4720, F1: 0.4679
Testing Loss: 1.1218, Accuracy: 0.7261, Precision: 0.4751, Recall: 0.4830, F1: 0.4787
LM Predictions:  [2, 1, 2, 5, 1, 4, 3, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 5, 1, 5, 3, 2, 3, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6288, Accuracy: 0.7857, Precision: 0.7470, Recall: 0.6345, F1: 0.6734
Epoch 46/70
Train Loss: 0.2981, Accuracy: 0.8835, Precision: 0.7819, Recall: 0.7414, F1: 0.7582
Validation Loss: 1.2663, Accuracy: 0.7273, Precision: 0.5408, Recall: 0.4652, F1: 0.4843
Testing Loss: 1.1228, Accuracy: 0.7473, Precision: 0.5076, Recall: 0.4436, F1: 0.4567
LM Predictions:  [2, 1, 2, 5, 5, 4, 4, 5, 2, 3, 5, 0, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4884, Accuracy: 0.8214, Precision: 0.6892, Recall: 0.6512, F1: 0.6591
Epoch 47/70
Train Loss: 0.2961, Accuracy: 0.8926, Precision: 0.8118, Recall: 0.7742, F1: 0.7901
Validation Loss: 1.2172, Accuracy: 0.7017, Precision: 0.4524, Recall: 0.4552, F1: 0.4501
Testing Loss: 1.1110, Accuracy: 0.7181, Precision: 0.4988, Recall: 0.5104, F1: 0.4988
LM Predictions:  [5, 1, 3, 5, 1, 4, 3, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 3, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4739, Accuracy: 0.8214, Precision: 0.7792, Recall: 0.6857, F1: 0.7157
Epoch 48/70
Train Loss: 0.2740, Accuracy: 0.9013, Precision: 0.8179, Recall: 0.7603, F1: 0.7837
Validation Loss: 1.2379, Accuracy: 0.7017, Precision: 0.4648, Recall: 0.4532, F1: 0.4565
Testing Loss: 1.1553, Accuracy: 0.7181, Precision: 0.4974, Recall: 0.4911, F1: 0.4895
LM Predictions:  [5, 1, 2, 5, 1, 4, 3, 5, 2, 1, 5, 0, 2, 1, 4, 5, 4, 4, 1, 5, 3, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4498, Accuracy: 0.7857, Precision: 0.7341, Recall: 0.6619, F1: 0.6764
Epoch 49/70
Train Loss: 0.2507, Accuracy: 0.9122, Precision: 0.8285, Recall: 0.7964, F1: 0.8104
Validation Loss: 1.1290, Accuracy: 0.7244, Precision: 0.4891, Recall: 0.4897, F1: 0.4892
Testing Loss: 1.1188, Accuracy: 0.7394, Precision: 0.4797, Recall: 0.4764, F1: 0.4772
LM Predictions:  [2, 1, 2, 5, 1, 4, 3, 5, 2, 3, 5, 3, 2, 2, 4, 5, 4, 4, 1, 5, 3, 2, 1, 2, 2, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.0209, Accuracy: 0.6429, Precision: 0.5463, Recall: 0.5024, F1: 0.5162
Epoch 50/70
Train Loss: 0.2614, Accuracy: 0.9013, Precision: 0.8204, Recall: 0.7717, F1: 0.7919
Validation Loss: 1.2463, Accuracy: 0.6761, Precision: 0.4509, Recall: 0.4547, F1: 0.4502
Testing Loss: 1.0635, Accuracy: 0.7447, Precision: 0.4878, Recall: 0.4930, F1: 0.4871
LM Predictions:  [2, 1, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 1, 4, 5, 4, 4, 1, 5, 3, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4611, Accuracy: 0.8214, Precision: 0.7500, Recall: 0.6774, F1: 0.6972
Epoch 51/70
Train Loss: 0.2551, Accuracy: 0.9101, Precision: 0.8257, Recall: 0.8048, F1: 0.8140
Validation Loss: 1.3719, Accuracy: 0.7273, Precision: 0.5507, Recall: 0.4557, F1: 0.4647
Testing Loss: 1.3114, Accuracy: 0.7420, Precision: 0.4806, Recall: 0.4473, F1: 0.4486
LM Predictions:  [2, 0, 2, 5, 5, 4, 0, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 5, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2397, Accuracy: 0.8929, Precision: 0.9156, Recall: 0.8700, F1: 0.8842
Epoch 52/70
Train Loss: 0.2254, Accuracy: 0.9181, Precision: 0.8595, Recall: 0.8373, F1: 0.8475
Validation Loss: 1.5204, Accuracy: 0.7159, Precision: 0.5406, Recall: 0.4616, F1: 0.4741
Testing Loss: 1.4201, Accuracy: 0.7207, Precision: 0.4842, Recall: 0.4463, F1: 0.4513
LM Predictions:  [5, 0, 2, 5, 5, 4, 0, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 5, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2970, Accuracy: 0.8571, Precision: 0.9000, Recall: 0.8414, F1: 0.8585
Epoch 53/70
Train Loss: 0.2177, Accuracy: 0.9241, Precision: 0.8622, Recall: 0.8414, F1: 0.8507
Validation Loss: 1.3634, Accuracy: 0.6960, Precision: 0.4556, Recall: 0.4439, F1: 0.4367
Testing Loss: 1.2430, Accuracy: 0.7287, Precision: 0.5008, Recall: 0.4806, F1: 0.4746
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2232, Accuracy: 0.9643, Precision: 0.9600, Recall: 0.9600, F1: 0.9556
Epoch 54/70
Train Loss: 0.2284, Accuracy: 0.9146, Precision: 0.8696, Recall: 0.8332, F1: 0.8495
Validation Loss: 1.4996, Accuracy: 0.7017, Precision: 0.4797, Recall: 0.4531, F1: 0.4568
Testing Loss: 1.2977, Accuracy: 0.7420, Precision: 0.4962, Recall: 0.4681, F1: 0.4724
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 3, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3155, Accuracy: 0.8571, Precision: 0.7792, Recall: 0.6833, F1: 0.7148
Epoch 55/70
Train Loss: 0.2058, Accuracy: 0.9265, Precision: 0.8643, Recall: 0.8333, F1: 0.8474
Validation Loss: 1.3563, Accuracy: 0.7216, Precision: 0.5340, Recall: 0.4834, F1: 0.4832
Testing Loss: 1.2352, Accuracy: 0.7447, Precision: 0.4887, Recall: 0.4679, F1: 0.4663
LM Predictions:  [2, 3, 2, 5, 5, 4, 4, 5, 2, 3, 5, 0, 2, 3, 4, 5, 4, 4, 1, 5, 5, 2, 3, 2, 3, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3641, Accuracy: 0.7857, Precision: 0.8095, Recall: 0.6179, F1: 0.6679
Epoch 56/70
Train Loss: 0.2041, Accuracy: 0.9265, Precision: 0.8680, Recall: 0.8446, F1: 0.8554
Validation Loss: 1.3471, Accuracy: 0.7017, Precision: 0.4818, Recall: 0.4570, F1: 0.4651
Testing Loss: 1.2561, Accuracy: 0.7394, Precision: 0.4879, Recall: 0.4744, F1: 0.4753
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1414, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 57/70
Train Loss: 0.1892, Accuracy: 0.9381, Precision: 0.8722, Recall: 0.8626, F1: 0.8673
Validation Loss: 1.3714, Accuracy: 0.7273, Precision: 0.5025, Recall: 0.4777, F1: 0.4786
Testing Loss: 1.2854, Accuracy: 0.7420, Precision: 0.4383, Recall: 0.4605, F1: 0.4480
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 3, 5, 4, 5, 4, 4, 1, 5, 5, 2, 3, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2418, Accuracy: 0.8571, Precision: 0.8333, Recall: 0.7012, F1: 0.7550
Epoch 58/70
Train Loss: 0.1832, Accuracy: 0.9367, Precision: 0.8805, Recall: 0.8667, F1: 0.8728
Validation Loss: 1.4751, Accuracy: 0.7159, Precision: 0.5594, Recall: 0.4647, F1: 0.4810
Testing Loss: 1.3731, Accuracy: 0.7527, Precision: 0.4759, Recall: 0.4464, F1: 0.4421
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0585, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.1711, Accuracy: 0.9381, Precision: 0.8834, Recall: 0.8673, F1: 0.8745
Validation Loss: 1.4664, Accuracy: 0.6960, Precision: 0.4816, Recall: 0.4332, F1: 0.4449
Testing Loss: 1.3269, Accuracy: 0.7207, Precision: 0.4848, Recall: 0.4619, F1: 0.4641
LM Predictions:  [2, 0, 2, 5, 1, 4, 0, 5, 2, 3, 5, 0, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2426, Accuracy: 0.8929, Precision: 0.7847, Recall: 0.7345, F1: 0.7519
Epoch 60/70
Train Loss: 0.1567, Accuracy: 0.9451, Precision: 0.9018, Recall: 0.8877, F1: 0.8945
Validation Loss: 1.4453, Accuracy: 0.7244, Precision: 0.5202, Recall: 0.4833, F1: 0.4917
Testing Loss: 1.3350, Accuracy: 0.7447, Precision: 0.4745, Recall: 0.4698, F1: 0.4652
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 3, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1254, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8000, F1: 0.8148
Epoch 61/70
Train Loss: 0.1604, Accuracy: 0.9398, Precision: 0.8750, Recall: 0.8571, F1: 0.8656
Validation Loss: 1.5761, Accuracy: 0.7301, Precision: 0.5608, Recall: 0.4969, F1: 0.5076
Testing Loss: 1.5030, Accuracy: 0.7553, Precision: 0.5123, Recall: 0.4662, F1: 0.4643
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0253, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.1728, Accuracy: 0.9363, Precision: 0.8731, Recall: 0.8725, F1: 0.8727
Validation Loss: 1.3836, Accuracy: 0.7500, Precision: 0.5524, Recall: 0.4997, F1: 0.5126
Testing Loss: 1.4154, Accuracy: 0.7420, Precision: 0.4875, Recall: 0.4559, F1: 0.4598
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0725, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 63/70
Train Loss: 0.1551, Accuracy: 0.9447, Precision: 0.9052, Recall: 0.8934, F1: 0.8989
Validation Loss: 1.4527, Accuracy: 0.7500, Precision: 0.5728, Recall: 0.4923, F1: 0.5127
Testing Loss: 1.4529, Accuracy: 0.7207, Precision: 0.4751, Recall: 0.4178, F1: 0.4253
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0481, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9714, F1: 0.9713
Epoch 64/70
Train Loss: 0.1300, Accuracy: 0.9549, Precision: 0.9171, Recall: 0.9138, F1: 0.9154
Validation Loss: 1.3943, Accuracy: 0.7358, Precision: 0.5116, Recall: 0.5082, F1: 0.5088
Testing Loss: 1.4350, Accuracy: 0.7527, Precision: 0.4881, Recall: 0.4695, F1: 0.4739
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 3, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0788, Accuracy: 0.9286, Precision: 0.8125, Recall: 0.7762, F1: 0.7909
Epoch 65/70
Train Loss: 0.1465, Accuracy: 0.9503, Precision: 0.9142, Recall: 0.8962, F1: 0.9044
Validation Loss: 1.5196, Accuracy: 0.7216, Precision: 0.4975, Recall: 0.5024, F1: 0.4983
Testing Loss: 1.4246, Accuracy: 0.7394, Precision: 0.4694, Recall: 0.4646, F1: 0.4654
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0701, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.1323, Accuracy: 0.9542, Precision: 0.9283, Recall: 0.9107, F1: 0.9190
Validation Loss: 1.7144, Accuracy: 0.7188, Precision: 0.5072, Recall: 0.4712, F1: 0.4748
Testing Loss: 1.6873, Accuracy: 0.7287, Precision: 0.5013, Recall: 0.4477, F1: 0.4522
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0076, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.1146, Accuracy: 0.9584, Precision: 0.9309, Recall: 0.9217, F1: 0.9261
Validation Loss: 1.5262, Accuracy: 0.7386, Precision: 0.5391, Recall: 0.4881, F1: 0.5066
Testing Loss: 1.5642, Accuracy: 0.7287, Precision: 0.4692, Recall: 0.4378, F1: 0.4471
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0595, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9714, F1: 0.9713
Epoch 68/70
Train Loss: 0.1148, Accuracy: 0.9629, Precision: 0.9256, Recall: 0.9212, F1: 0.9233
Validation Loss: 1.4267, Accuracy: 0.7443, Precision: 0.5955, Recall: 0.5118, F1: 0.5216
Testing Loss: 1.4242, Accuracy: 0.7420, Precision: 0.4576, Recall: 0.4498, F1: 0.4475
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 2, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 2, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1160, Accuracy: 0.9286, Precision: 0.9556, Recall: 0.9214, F1: 0.9310
Epoch 69/70
Train Loss: 0.1102, Accuracy: 0.9626, Precision: 0.9332, Recall: 0.9205, F1: 0.9266
Validation Loss: 1.6757, Accuracy: 0.7244, Precision: 0.4857, Recall: 0.4841, F1: 0.4847
Testing Loss: 1.6701, Accuracy: 0.7287, Precision: 0.4536, Recall: 0.4428, F1: 0.4465
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0357, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.1182, Accuracy: 0.9573, Precision: 0.9251, Recall: 0.9148, F1: 0.9197
Validation Loss: 1.4924, Accuracy: 0.7102, Precision: 0.4796, Recall: 0.4936, F1: 0.4827
Testing Loss: 1.5584, Accuracy: 0.7261, Precision: 0.4605, Recall: 0.4638, F1: 0.4576
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0266, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For middle layers:  [4, 5, 6, 7]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.5598, Accuracy: 0.3726, Precision: 0.2050, Recall: 0.1774, F1: 0.1612
Validation Loss: 1.4203, Accuracy: 0.3835, Precision: 0.1278, Recall: 0.1801, F1: 0.1495
Testing Loss: 1.4407, Accuracy: 0.3564, Precision: 0.1187, Recall: 0.1660, F1: 0.1384
LM Predictions:  [2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9940, Accuracy: 0.2500, Precision: 0.0857, Recall: 0.2114, F1: 0.1190
Epoch 2/70
Train Loss: 1.4049, Accuracy: 0.3793, Precision: 0.1258, Recall: 0.1723, F1: 0.1451
Validation Loss: 1.3966, Accuracy: 0.3920, Precision: 0.1340, Recall: 0.1758, F1: 0.1267
Testing Loss: 1.4223, Accuracy: 0.3936, Precision: 0.1402, Recall: 0.1820, F1: 0.1300
LM Predictions:  [2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0042, Accuracy: 0.2857, Precision: 0.1227, Recall: 0.2400, F1: 0.1375
Epoch 3/70
Train Loss: 1.3871, Accuracy: 0.3898, Precision: 0.1292, Recall: 0.1762, F1: 0.1477
Validation Loss: 1.4041, Accuracy: 0.4545, Precision: 0.1523, Recall: 0.2108, F1: 0.1749
Testing Loss: 1.4357, Accuracy: 0.4043, Precision: 0.1357, Recall: 0.1879, F1: 0.1553
LM Predictions:  [2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1146, Accuracy: 0.3571, Precision: 0.1404, Recall: 0.3200, F1: 0.1934
Epoch 4/70
Train Loss: 1.3753, Accuracy: 0.3989, Precision: 0.1666, Recall: 0.1811, F1: 0.1536
Validation Loss: 1.3802, Accuracy: 0.4062, Precision: 0.1542, Recall: 0.1821, F1: 0.1307
Testing Loss: 1.4037, Accuracy: 0.4096, Precision: 0.1631, Recall: 0.1894, F1: 0.1369
LM Predictions:  [2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9689, Accuracy: 0.2500, Precision: 0.1000, Recall: 0.2114, F1: 0.1219
Epoch 5/70
Train Loss: 1.3620, Accuracy: 0.4153, Precision: 0.1915, Recall: 0.1895, F1: 0.1627
Validation Loss: 1.3801, Accuracy: 0.3722, Precision: 0.2255, Recall: 0.1881, F1: 0.1327
Testing Loss: 1.3901, Accuracy: 0.4016, Precision: 0.2697, Recall: 0.1985, F1: 0.1531
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0110, Accuracy: 0.1786, Precision: 0.0370, Recall: 0.2000, F1: 0.0625
Epoch 6/70
Train Loss: 1.3233, Accuracy: 0.4528, Precision: 0.2141, Recall: 0.2114, F1: 0.1901
Validation Loss: 1.2496, Accuracy: 0.6023, Precision: 0.2999, Recall: 0.2894, F1: 0.2655
Testing Loss: 1.2750, Accuracy: 0.5824, Precision: 0.3103, Recall: 0.2888, F1: 0.2721
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0280, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 7/70
Train Loss: 1.1540, Accuracy: 0.5682, Precision: 0.2785, Recall: 0.2740, F1: 0.2582
Validation Loss: 0.9373, Accuracy: 0.6847, Precision: 0.3395, Recall: 0.3617, F1: 0.3461
Testing Loss: 0.9825, Accuracy: 0.6755, Precision: 0.3329, Recall: 0.3670, F1: 0.3441
LM Predictions:  [2, 2, 2, 2, 2, 5, 5, 2, 5, 2, 2, 2, 2, 2, 2, 5, 5, 2, 2, 5, 5, 5, 5, 2, 4, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3244, Accuracy: 0.2857, Precision: 0.1188, Recall: 0.2286, F1: 0.1539
Epoch 8/70
Train Loss: 0.9113, Accuracy: 0.6837, Precision: 0.3326, Recall: 0.3474, F1: 0.3351
Validation Loss: 0.7347, Accuracy: 0.7216, Precision: 0.3442, Recall: 0.3795, F1: 0.3594
Testing Loss: 0.7158, Accuracy: 0.7553, Precision: 0.3626, Recall: 0.4107, F1: 0.3835
LM Predictions:  [2, 5, 2, 2, 5, 5, 5, 2, 5, 5, 5, 2, 2, 2, 2, 5, 5, 5, 2, 5, 2, 5, 5, 2, 4, 2, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0305, Accuracy: 0.2500, Precision: 0.1044, Recall: 0.2000, F1: 0.1371
Epoch 9/70
Train Loss: 0.7128, Accuracy: 0.7519, Precision: 0.5448, Recall: 0.4127, F1: 0.3977
Validation Loss: 0.6772, Accuracy: 0.7642, Precision: 0.6035, Recall: 0.4466, F1: 0.4367
Testing Loss: 0.6388, Accuracy: 0.7846, Precision: 0.5086, Recall: 0.4573, F1: 0.4387
LM Predictions:  [3, 3, 3, 5, 5, 5, 3, 5, 5, 5, 3, 5, 2, 2, 4, 5, 5, 5, 3, 5, 2, 5, 5, 2, 4, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9724, Accuracy: 0.2500, Precision: 0.1944, Recall: 0.1762, F1: 0.1638
Epoch 10/70
Train Loss: 0.6083, Accuracy: 0.7943, Precision: 0.5752, Recall: 0.4704, F1: 0.4704
Validation Loss: 0.5733, Accuracy: 0.7983, Precision: 0.4658, Recall: 0.5025, F1: 0.4825
Testing Loss: 0.5571, Accuracy: 0.8085, Precision: 0.4955, Recall: 0.5119, F1: 0.5004
LM Predictions:  [3, 3, 3, 2, 5, 5, 3, 5, 5, 3, 3, 3, 2, 2, 4, 5, 5, 3, 3, 3, 5, 5, 5, 2, 5, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1503, Accuracy: 0.2143, Precision: 0.2955, Recall: 0.1524, F1: 0.1717
Epoch 11/70
Train Loss: 0.5341, Accuracy: 0.8212, Precision: 0.5781, Recall: 0.5323, F1: 0.5384
Validation Loss: 0.5516, Accuracy: 0.8011, Precision: 0.5675, Recall: 0.5995, F1: 0.5756
Testing Loss: 0.5281, Accuracy: 0.8085, Precision: 0.5641, Recall: 0.5849, F1: 0.5699
LM Predictions:  [3, 3, 3, 2, 1, 5, 3, 5, 3, 3, 3, 3, 2, 2, 4, 3, 3, 3, 3, 1, 3, 3, 5, 3, 1, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3074, Accuracy: 0.1786, Precision: 0.3889, Recall: 0.1643, F1: 0.2175
Epoch 12/70
Train Loss: 0.4689, Accuracy: 0.8418, Precision: 0.6215, Recall: 0.5934, F1: 0.6001
Validation Loss: 0.5546, Accuracy: 0.8125, Precision: 0.6650, Recall: 0.5740, F1: 0.5947
Testing Loss: 0.5628, Accuracy: 0.8324, Precision: 0.6464, Recall: 0.5997, F1: 0.6042
LM Predictions:  [3, 3, 3, 5, 5, 5, 3, 5, 5, 3, 3, 3, 2, 2, 4, 5, 3, 3, 3, 5, 5, 5, 5, 2, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3394, Accuracy: 0.3214, Precision: 0.5202, Recall: 0.2417, F1: 0.2815
Epoch 13/70
Train Loss: 0.4186, Accuracy: 0.8618, Precision: 0.6828, Recall: 0.6322, F1: 0.6384
Validation Loss: 0.5662, Accuracy: 0.8381, Precision: 0.6548, Recall: 0.6247, F1: 0.6379
Testing Loss: 0.5318, Accuracy: 0.8351, Precision: 0.6140, Recall: 0.6363, F1: 0.6085
LM Predictions:  [3, 3, 3, 1, 1, 2, 3, 5, 3, 3, 3, 3, 3, 2, 4, 3, 3, 3, 3, 1, 2, 3, 1, 3, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1734, Accuracy: 0.1786, Precision: 0.4417, Recall: 0.1643, F1: 0.2016
Epoch 14/70
Train Loss: 0.3824, Accuracy: 0.8716, Precision: 0.7624, Recall: 0.6760, F1: 0.6909
Validation Loss: 0.5325, Accuracy: 0.8295, Precision: 0.6550, Recall: 0.6026, F1: 0.6178
Testing Loss: 0.4960, Accuracy: 0.8431, Precision: 0.6496, Recall: 0.6363, F1: 0.6329
LM Predictions:  [3, 3, 3, 5, 1, 2, 3, 5, 3, 3, 3, 5, 3, 2, 4, 5, 3, 3, 3, 3, 2, 5, 5, 2, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4141, Accuracy: 0.2500, Precision: 0.4464, Recall: 0.2119, F1: 0.2684
Epoch 15/70
Train Loss: 0.3282, Accuracy: 0.8849, Precision: 0.7413, Recall: 0.6854, F1: 0.6954
Validation Loss: 0.5170, Accuracy: 0.8324, Precision: 0.6676, Recall: 0.6158, F1: 0.6328
Testing Loss: 0.5341, Accuracy: 0.8404, Precision: 0.6191, Recall: 0.6301, F1: 0.6122
LM Predictions:  [3, 3, 3, 1, 1, 2, 3, 5, 3, 3, 3, 3, 3, 2, 4, 5, 3, 3, 3, 1, 2, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1595, Accuracy: 0.2500, Precision: 0.4667, Recall: 0.2119, F1: 0.2593
Epoch 16/70
Train Loss: 0.2966, Accuracy: 0.9048, Precision: 0.8009, Recall: 0.7386, F1: 0.7549
Validation Loss: 0.4947, Accuracy: 0.8494, Precision: 0.7131, Recall: 0.7237, F1: 0.7103
Testing Loss: 0.4595, Accuracy: 0.8617, Precision: 0.6451, Recall: 0.6621, F1: 0.6530
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4301, Accuracy: 0.1786, Precision: 0.5278, Recall: 0.1464, F1: 0.2194
Epoch 17/70
Train Loss: 0.2679, Accuracy: 0.9097, Precision: 0.8149, Recall: 0.7733, F1: 0.7859
Validation Loss: 0.5785, Accuracy: 0.8153, Precision: 0.6678, Recall: 0.6110, F1: 0.6265
Testing Loss: 0.5967, Accuracy: 0.8351, Precision: 0.6321, Recall: 0.6010, F1: 0.5971
LM Predictions:  [3, 3, 3, 1, 1, 4, 5, 5, 5, 3, 3, 5, 2, 5, 4, 5, 1, 3, 3, 5, 5, 5, 1, 2, 1, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.7874, Accuracy: 0.3929, Precision: 0.4833, Recall: 0.3167, F1: 0.3414
Epoch 18/70
Train Loss: 0.2304, Accuracy: 0.9195, Precision: 0.8174, Recall: 0.7864, F1: 0.7955
Validation Loss: 0.5558, Accuracy: 0.8466, Precision: 0.6967, Recall: 0.6872, F1: 0.6801
Testing Loss: 0.5277, Accuracy: 0.8590, Precision: 0.6601, Recall: 0.6444, F1: 0.6492
LM Predictions:  [3, 3, 3, 1, 1, 2, 3, 5, 3, 3, 3, 3, 2, 2, 4, 2, 3, 3, 3, 3, 2, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8112, Accuracy: 0.2143, Precision: 0.4603, Recall: 0.1702, F1: 0.2163
Epoch 19/70
Train Loss: 0.1933, Accuracy: 0.9367, Precision: 0.8360, Recall: 0.8097, F1: 0.8176
Validation Loss: 0.6583, Accuracy: 0.8438, Precision: 0.7069, Recall: 0.7539, F1: 0.7022
Testing Loss: 0.6416, Accuracy: 0.8404, Precision: 0.6189, Recall: 0.6157, F1: 0.6099
LM Predictions:  [3, 3, 3, 1, 1, 2, 0, 5, 3, 3, 3, 3, 2, 0, 4, 5, 3, 0, 3, 3, 2, 3, 1, 2, 1, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6840, Accuracy: 0.2857, Precision: 0.5167, Recall: 0.2357, F1: 0.2963
Epoch 20/70
Train Loss: 0.1768, Accuracy: 0.9412, Precision: 0.8560, Recall: 0.8350, F1: 0.8427
Validation Loss: 0.6458, Accuracy: 0.8551, Precision: 0.7598, Recall: 0.7017, F1: 0.7157
Testing Loss: 0.6272, Accuracy: 0.8670, Precision: 0.6878, Recall: 0.6543, F1: 0.6685
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 2, 2, 4, 5, 3, 3, 3, 3, 5, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3031, Accuracy: 0.2857, Precision: 0.5167, Recall: 0.2179, F1: 0.2944
Epoch 21/70
Train Loss: 0.1573, Accuracy: 0.9468, Precision: 0.8884, Recall: 0.8606, F1: 0.8717
Validation Loss: 0.6620, Accuracy: 0.8466, Precision: 0.6955, Recall: 0.7148, F1: 0.6973
Testing Loss: 0.6053, Accuracy: 0.8697, Precision: 0.7466, Recall: 0.7223, F1: 0.7167
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 2, 2, 4, 5, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9659, Accuracy: 0.2500, Precision: 0.5167, Recall: 0.1940, F1: 0.2685
Epoch 22/70
Train Loss: 0.1241, Accuracy: 0.9584, Precision: 0.8897, Recall: 0.8769, F1: 0.8804
Validation Loss: 0.8012, Accuracy: 0.8153, Precision: 0.6811, Recall: 0.7390, F1: 0.6826
Testing Loss: 0.7027, Accuracy: 0.8511, Precision: 0.6430, Recall: 0.6622, F1: 0.6447
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 5, 3, 3, 0, 2, 5, 4, 5, 1, 4, 3, 3, 5, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.2693, Accuracy: 0.5357, Precision: 0.7167, Recall: 0.4500, F1: 0.5378
Epoch 23/70
Train Loss: 0.1120, Accuracy: 0.9591, Precision: 0.9031, Recall: 0.9000, F1: 0.9005
Validation Loss: 0.7456, Accuracy: 0.8438, Precision: 0.7067, Recall: 0.7544, F1: 0.7096
Testing Loss: 0.7708, Accuracy: 0.8511, Precision: 0.7143, Recall: 0.7197, F1: 0.7042
LM Predictions:  [3, 3, 3, 1, 1, 4, 4, 5, 2, 3, 3, 0, 2, 3, 4, 5, 1, 4, 3, 3, 5, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1272, Accuracy: 0.5357, Precision: 0.7333, Recall: 0.4500, F1: 0.5387
Epoch 24/70
Train Loss: 0.0949, Accuracy: 0.9692, Precision: 0.9207, Recall: 0.9202, F1: 0.9201
Validation Loss: 0.7836, Accuracy: 0.8693, Precision: 0.7408, Recall: 0.7883, F1: 0.7496
Testing Loss: 0.8297, Accuracy: 0.8511, Precision: 0.7432, Recall: 0.7098, F1: 0.7099
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 3, 4, 3, 4, 4, 1, 3, 5, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.2541, Accuracy: 0.5714, Precision: 0.7917, Recall: 0.5012, F1: 0.5822
Epoch 25/70
Train Loss: 0.0837, Accuracy: 0.9664, Precision: 0.9203, Recall: 0.9205, F1: 0.9201
Validation Loss: 0.7607, Accuracy: 0.8580, Precision: 0.7368, Recall: 0.7852, F1: 0.7471
Testing Loss: 0.7351, Accuracy: 0.8378, Precision: 0.6746, Recall: 0.6817, F1: 0.6608
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 3, 3, 3, 0, 2, 5, 4, 5, 3, 4, 1, 3, 5, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.9937, Accuracy: 0.5714, Precision: 0.7917, Recall: 0.4917, F1: 0.5896
Epoch 26/70
Train Loss: 0.0656, Accuracy: 0.9787, Precision: 0.9401, Recall: 0.9409, F1: 0.9402
Validation Loss: 0.8424, Accuracy: 0.8438, Precision: 0.6671, Recall: 0.6583, F1: 0.6624
Testing Loss: 0.8148, Accuracy: 0.8484, Precision: 0.7009, Recall: 0.6824, F1: 0.6855
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 3, 4, 1, 5, 5, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.9240, Accuracy: 0.6429, Precision: 0.7917, Recall: 0.5393, F1: 0.6285
Epoch 27/70
Train Loss: 0.0689, Accuracy: 0.9745, Precision: 0.9332, Recall: 0.9367, F1: 0.9347
Validation Loss: 0.9456, Accuracy: 0.8580, Precision: 0.7512, Recall: 0.6941, F1: 0.7151
Testing Loss: 0.8870, Accuracy: 0.8484, Precision: 0.6547, Recall: 0.6260, F1: 0.6353
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6374, Accuracy: 0.7500, Precision: 0.7917, Recall: 0.6298, F1: 0.6944
Epoch 28/70
Train Loss: 0.0700, Accuracy: 0.9762, Precision: 0.9508, Recall: 0.9458, F1: 0.9481
Validation Loss: 0.7997, Accuracy: 0.8580, Precision: 0.7470, Recall: 0.7783, F1: 0.7512
Testing Loss: 0.8418, Accuracy: 0.8457, Precision: 0.6425, Recall: 0.6723, F1: 0.6500
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 4, 4, 1, 3, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.7588, Accuracy: 0.7500, Precision: 0.8333, Recall: 0.6393, F1: 0.7178
Epoch 29/70
Train Loss: 0.0455, Accuracy: 0.9867, Precision: 0.9693, Recall: 0.9667, F1: 0.9679
Validation Loss: 0.9012, Accuracy: 0.8693, Precision: 0.7404, Recall: 0.7779, F1: 0.7459
Testing Loss: 0.9574, Accuracy: 0.8378, Precision: 0.7004, Recall: 0.7008, F1: 0.6755
LM Predictions:  [3, 0, 2, 1, 1, 4, 4, 5, 2, 1, 1, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4364, Accuracy: 0.8571, Precision: 0.7619, Recall: 0.7286, F1: 0.7288
Epoch 30/70
Train Loss: 0.0366, Accuracy: 0.9874, Precision: 0.9673, Recall: 0.9706, F1: 0.9689
Validation Loss: 0.9962, Accuracy: 0.8636, Precision: 0.7408, Recall: 0.7115, F1: 0.7224
Testing Loss: 1.0479, Accuracy: 0.8511, Precision: 0.6337, Recall: 0.6465, F1: 0.6328
LM Predictions:  [3, 3, 2, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4679, Accuracy: 0.8214, Precision: 0.8333, Recall: 0.6869, F1: 0.7504
Epoch 31/70
Train Loss: 0.0387, Accuracy: 0.9850, Precision: 0.9632, Recall: 0.9664, F1: 0.9646
Validation Loss: 0.8588, Accuracy: 0.8580, Precision: 0.7401, Recall: 0.7600, F1: 0.7477
Testing Loss: 0.8960, Accuracy: 0.8378, Precision: 0.6444, Recall: 0.6272, F1: 0.6311
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 3, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2384, Accuracy: 0.9286, Precision: 0.8333, Recall: 0.7679, F1: 0.7967
Epoch 32/70
Train Loss: 0.0275, Accuracy: 0.9902, Precision: 0.9751, Recall: 0.9823, F1: 0.9787
Validation Loss: 1.2517, Accuracy: 0.8267, Precision: 0.7547, Recall: 0.6739, F1: 0.7010
Testing Loss: 1.2479, Accuracy: 0.8165, Precision: 0.6077, Recall: 0.5965, F1: 0.5777
LM Predictions:  [2, 4, 2, 4, 1, 4, 4, 5, 2, 1, 1, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2758, Accuracy: 0.8929, Precision: 0.9029, Recall: 0.9029, F1: 0.8889
Epoch 33/70
Train Loss: 0.0296, Accuracy: 0.9881, Precision: 0.9681, Recall: 0.9688, F1: 0.9684
Validation Loss: 1.1996, Accuracy: 0.8580, Precision: 0.7109, Recall: 0.7049, F1: 0.7007
Testing Loss: 1.1419, Accuracy: 0.8537, Precision: 0.7247, Recall: 0.6964, F1: 0.6998
LM Predictions:  [3, 3, 2, 3, 1, 4, 4, 5, 2, 3, 3, 0, 2, 3, 4, 3, 4, 4, 1, 5, 5, 2, 0, 2, 3, 3, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8251, Accuracy: 0.6786, Precision: 0.8333, Recall: 0.5643, F1: 0.6566
Epoch 34/70
Train Loss: 0.0412, Accuracy: 0.9871, Precision: 0.9711, Recall: 0.9720, F1: 0.9714
Validation Loss: 0.9225, Accuracy: 0.8494, Precision: 0.7387, Recall: 0.8191, F1: 0.7418
Testing Loss: 0.8305, Accuracy: 0.8484, Precision: 0.6738, Recall: 0.6281, F1: 0.6428
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1846, Accuracy: 0.9643, Precision: 0.9600, Recall: 0.9600, F1: 0.9556
Epoch 35/70
Train Loss: 0.0272, Accuracy: 0.9923, Precision: 0.9782, Recall: 0.9756, F1: 0.9769
Validation Loss: 0.9072, Accuracy: 0.8608, Precision: 0.7191, Recall: 0.7746, F1: 0.7300
Testing Loss: 0.8617, Accuracy: 0.8378, Precision: 0.6435, Recall: 0.6550, F1: 0.6409
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1306, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8095, F1: 0.8205
Epoch 36/70
Train Loss: 0.0291, Accuracy: 0.9923, Precision: 0.9843, Recall: 0.9798, F1: 0.9820
Validation Loss: 1.1077, Accuracy: 0.8438, Precision: 0.7085, Recall: 0.7734, F1: 0.7246
Testing Loss: 0.9625, Accuracy: 0.8324, Precision: 0.6182, Recall: 0.6235, F1: 0.6080
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0847, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 37/70
Train Loss: 0.0281, Accuracy: 0.9902, Precision: 0.9765, Recall: 0.9712, F1: 0.9738
Validation Loss: 1.0393, Accuracy: 0.8466, Precision: 0.7173, Recall: 0.7661, F1: 0.7279
Testing Loss: 1.0786, Accuracy: 0.8404, Precision: 0.6373, Recall: 0.6301, F1: 0.6126
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0437, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 38/70
Train Loss: 0.0163, Accuracy: 0.9958, Precision: 0.9906, Recall: 0.9882, F1: 0.9894
Validation Loss: 1.0973, Accuracy: 0.8551, Precision: 0.7203, Recall: 0.7693, F1: 0.7289
Testing Loss: 1.0721, Accuracy: 0.8431, Precision: 0.6383, Recall: 0.6502, F1: 0.6332
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0527, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8095, F1: 0.8205
Epoch 39/70
Train Loss: 0.0172, Accuracy: 0.9948, Precision: 0.9857, Recall: 0.9799, F1: 0.9827
Validation Loss: 1.2311, Accuracy: 0.8523, Precision: 0.7238, Recall: 0.7789, F1: 0.7309
Testing Loss: 1.0703, Accuracy: 0.8404, Precision: 0.6417, Recall: 0.6518, F1: 0.6423
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0706, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 40/70
Train Loss: 0.0234, Accuracy: 0.9941, Precision: 0.9863, Recall: 0.9797, F1: 0.9829
Validation Loss: 1.0000, Accuracy: 0.8466, Precision: 0.7114, Recall: 0.7629, F1: 0.7177
Testing Loss: 0.9969, Accuracy: 0.8298, Precision: 0.6661, Recall: 0.6616, F1: 0.6434
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0236, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 41/70
Train Loss: 0.0194, Accuracy: 0.9937, Precision: 0.9806, Recall: 0.9826, F1: 0.9816
Validation Loss: 1.0950, Accuracy: 0.8381, Precision: 0.7029, Recall: 0.7010, F1: 0.6954
Testing Loss: 1.0091, Accuracy: 0.8271, Precision: 0.6107, Recall: 0.6198, F1: 0.6110
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0144, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 42/70
Train Loss: 0.0109, Accuracy: 0.9969, Precision: 0.9903, Recall: 0.9868, F1: 0.9885
Validation Loss: 1.1456, Accuracy: 0.8466, Precision: 0.7253, Recall: 0.7519, F1: 0.7147
Testing Loss: 1.1240, Accuracy: 0.8271, Precision: 0.6188, Recall: 0.6104, F1: 0.6093
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0121, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 43/70
Train Loss: 0.0142, Accuracy: 0.9958, Precision: 0.9896, Recall: 0.9908, F1: 0.9902
Validation Loss: 0.9771, Accuracy: 0.8665, Precision: 0.7601, Recall: 0.7684, F1: 0.7408
Testing Loss: 1.0812, Accuracy: 0.8404, Precision: 0.7005, Recall: 0.6656, F1: 0.6766
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0079, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 44/70
Train Loss: 0.0129, Accuracy: 0.9962, Precision: 0.9952, Recall: 0.9883, F1: 0.9917
Validation Loss: 1.1326, Accuracy: 0.8352, Precision: 0.7344, Recall: 0.7386, F1: 0.6735
Testing Loss: 1.3260, Accuracy: 0.8271, Precision: 0.6697, Recall: 0.6279, F1: 0.6282
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0084, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 45/70
Train Loss: 0.0225, Accuracy: 0.9930, Precision: 0.9744, Recall: 0.9770, F1: 0.9757
Validation Loss: 0.9906, Accuracy: 0.8636, Precision: 0.7696, Recall: 0.8160, F1: 0.7583
Testing Loss: 1.0479, Accuracy: 0.8245, Precision: 0.6609, Recall: 0.6123, F1: 0.6221
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0179, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 46/70
Train Loss: 0.0095, Accuracy: 0.9972, Precision: 0.9957, Recall: 0.9910, F1: 0.9933
Validation Loss: 1.0561, Accuracy: 0.8693, Precision: 0.7487, Recall: 0.8279, F1: 0.7588
Testing Loss: 1.2056, Accuracy: 0.8271, Precision: 0.6660, Recall: 0.6393, F1: 0.6395
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0120, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 47/70
Train Loss: 0.0114, Accuracy: 0.9965, Precision: 0.9885, Recall: 0.9930, F1: 0.9907
Validation Loss: 0.9914, Accuracy: 0.8608, Precision: 0.7298, Recall: 0.7186, F1: 0.7209
Testing Loss: 1.1215, Accuracy: 0.8484, Precision: 0.6599, Recall: 0.6514, F1: 0.6525
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0093, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 48/70
Train Loss: 0.0070, Accuracy: 0.9979, Precision: 0.9985, Recall: 0.9957, F1: 0.9971
Validation Loss: 1.0236, Accuracy: 0.8580, Precision: 0.7178, Recall: 0.7110, F1: 0.7073
Testing Loss: 1.2704, Accuracy: 0.8324, Precision: 0.6854, Recall: 0.6430, F1: 0.6570
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0078, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 49/70
Train Loss: 0.0164, Accuracy: 0.9927, Precision: 0.9927, Recall: 0.9850, F1: 0.9888
Validation Loss: 1.1099, Accuracy: 0.8523, Precision: 0.6931, Recall: 0.7277, F1: 0.7011
Testing Loss: 1.2609, Accuracy: 0.8351, Precision: 0.6466, Recall: 0.6652, F1: 0.6503
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0055, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0224, Accuracy: 0.9955, Precision: 0.9953, Recall: 0.9914, F1: 0.9933
Validation Loss: 0.8222, Accuracy: 0.8608, Precision: 0.7279, Recall: 0.7635, F1: 0.7316
Testing Loss: 1.1117, Accuracy: 0.8191, Precision: 0.6295, Recall: 0.6176, F1: 0.6101
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0060, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 51/70
Train Loss: 0.0208, Accuracy: 0.9934, Precision: 0.9871, Recall: 0.9895, F1: 0.9883
Validation Loss: 1.0439, Accuracy: 0.8381, Precision: 0.6718, Recall: 0.6321, F1: 0.6437
Testing Loss: 1.0887, Accuracy: 0.8404, Precision: 0.6330, Recall: 0.6156, F1: 0.6207
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0196, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 52/70
Train Loss: 0.0222, Accuracy: 0.9930, Precision: 0.9869, Recall: 0.9826, F1: 0.9848
Validation Loss: 0.9243, Accuracy: 0.8438, Precision: 0.6873, Recall: 0.7254, F1: 0.7009
Testing Loss: 1.0266, Accuracy: 0.8378, Precision: 0.6339, Recall: 0.6296, F1: 0.6300
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0075, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 53/70
Train Loss: 0.0154, Accuracy: 0.9948, Precision: 0.9859, Recall: 0.9863, F1: 0.9861
Validation Loss: 1.0963, Accuracy: 0.8210, Precision: 0.6605, Recall: 0.7701, F1: 0.6799
Testing Loss: 1.0398, Accuracy: 0.8404, Precision: 0.6489, Recall: 0.6878, F1: 0.6633
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0417, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0091, Accuracy: 0.9962, Precision: 0.9922, Recall: 0.9922, F1: 0.9922
Validation Loss: 1.0290, Accuracy: 0.8466, Precision: 0.7066, Recall: 0.7306, F1: 0.7074
Testing Loss: 1.0738, Accuracy: 0.8378, Precision: 0.6388, Recall: 0.6342, F1: 0.6335
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0024, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 55/70
Train Loss: 0.0089, Accuracy: 0.9976, Precision: 0.9931, Recall: 0.9973, F1: 0.9952
Validation Loss: 1.0187, Accuracy: 0.8580, Precision: 0.6958, Recall: 0.7166, F1: 0.6975
Testing Loss: 1.1669, Accuracy: 0.8245, Precision: 0.6115, Recall: 0.6116, F1: 0.6021
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0028, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0079, Accuracy: 0.9976, Precision: 0.9901, Recall: 0.9932, F1: 0.9916
Validation Loss: 0.9722, Accuracy: 0.8580, Precision: 0.6717, Recall: 0.6553, F1: 0.6627
Testing Loss: 1.1941, Accuracy: 0.8378, Precision: 0.6281, Recall: 0.6329, F1: 0.6241
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0174, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0168, Accuracy: 0.9951, Precision: 0.9915, Recall: 0.9887, F1: 0.9901
Validation Loss: 1.0897, Accuracy: 0.8494, Precision: 0.7347, Recall: 0.6945, F1: 0.7066
Testing Loss: 1.2294, Accuracy: 0.8271, Precision: 0.6293, Recall: 0.5951, F1: 0.6079
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0045, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0033, Accuracy: 0.9993, Precision: 0.9972, Recall: 0.9995, F1: 0.9983
Validation Loss: 1.1308, Accuracy: 0.8608, Precision: 0.7053, Recall: 0.7367, F1: 0.7141
Testing Loss: 1.2044, Accuracy: 0.8404, Precision: 0.6406, Recall: 0.6416, F1: 0.6346
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0022, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0035, Accuracy: 0.9990, Precision: 0.9981, Recall: 0.9994, F1: 0.9987
Validation Loss: 1.2808, Accuracy: 0.8494, Precision: 0.6838, Recall: 0.6640, F1: 0.6726
Testing Loss: 1.4319, Accuracy: 0.8404, Precision: 0.6541, Recall: 0.6404, F1: 0.6397
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0010, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0189, Accuracy: 0.9958, Precision: 0.9835, Recall: 0.9826, F1: 0.9831
Validation Loss: 1.0683, Accuracy: 0.8608, Precision: 0.7283, Recall: 0.7212, F1: 0.7200
Testing Loss: 1.1655, Accuracy: 0.8324, Precision: 0.6184, Recall: 0.6211, F1: 0.6125
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0112, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0089, Accuracy: 0.9969, Precision: 0.9925, Recall: 0.9926, F1: 0.9925
Validation Loss: 1.0826, Accuracy: 0.8608, Precision: 0.7243, Recall: 0.7776, F1: 0.7378
Testing Loss: 1.2039, Accuracy: 0.8298, Precision: 0.6452, Recall: 0.6574, F1: 0.6374
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0039, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.0033, Accuracy: 0.9990, Precision: 0.9969, Recall: 0.9981, F1: 0.9975
Validation Loss: 1.3033, Accuracy: 0.8381, Precision: 0.6747, Recall: 0.6977, F1: 0.6759
Testing Loss: 1.4094, Accuracy: 0.8085, Precision: 0.6560, Recall: 0.6364, F1: 0.6306
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0217, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.0073, Accuracy: 0.9976, Precision: 0.9935, Recall: 0.9935, F1: 0.9935
Validation Loss: 1.2044, Accuracy: 0.8665, Precision: 0.7169, Recall: 0.7299, F1: 0.7198
Testing Loss: 1.3009, Accuracy: 0.8378, Precision: 0.6600, Recall: 0.6611, F1: 0.6512
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0034, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0115, Accuracy: 0.9976, Precision: 0.9944, Recall: 0.9927, F1: 0.9936
Validation Loss: 1.4288, Accuracy: 0.8040, Precision: 0.6547, Recall: 0.6892, F1: 0.6556
Testing Loss: 1.2932, Accuracy: 0.8112, Precision: 0.6121, Recall: 0.6228, F1: 0.6067
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0045, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0142, Accuracy: 0.9948, Precision: 0.9898, Recall: 0.9927, F1: 0.9913
Validation Loss: 0.9548, Accuracy: 0.8608, Precision: 0.7239, Recall: 0.7365, F1: 0.7289
Testing Loss: 1.0906, Accuracy: 0.8351, Precision: 0.6306, Recall: 0.6301, F1: 0.6264
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0020, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0016, Accuracy: 0.9997, Precision: 0.9998, Recall: 0.9998, F1: 0.9998
Validation Loss: 1.1088, Accuracy: 0.8580, Precision: 0.7364, Recall: 0.7817, F1: 0.7519
Testing Loss: 1.1836, Accuracy: 0.8378, Precision: 0.6344, Recall: 0.6494, F1: 0.6381
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0013, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0041, Accuracy: 0.9993, Precision: 0.9995, Recall: 0.9967, F1: 0.9981
Validation Loss: 1.3866, Accuracy: 0.8324, Precision: 0.7261, Recall: 0.6501, F1: 0.6694
Testing Loss: 1.4828, Accuracy: 0.8191, Precision: 0.6541, Recall: 0.6086, F1: 0.6119
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0049, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0050, Accuracy: 0.9990, Precision: 0.9994, Recall: 0.9992, F1: 0.9993
Validation Loss: 1.1664, Accuracy: 0.8466, Precision: 0.6988, Recall: 0.7399, F1: 0.7126
Testing Loss: 1.1796, Accuracy: 0.8378, Precision: 0.6479, Recall: 0.6476, F1: 0.6378
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0010, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0025, Accuracy: 0.9993, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.1708, Accuracy: 0.8381, Precision: 0.6585, Recall: 0.6676, F1: 0.6613
Testing Loss: 1.2182, Accuracy: 0.8457, Precision: 0.6740, Recall: 0.6693, F1: 0.6613
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0010, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.0140, Accuracy: 0.9948, Precision: 0.9883, Recall: 0.9855, F1: 0.9869
Validation Loss: 1.2652, Accuracy: 0.8352, Precision: 0.7015, Recall: 0.5793, F1: 0.5985
Testing Loss: 1.3969, Accuracy: 0.8191, Precision: 0.6273, Recall: 0.5980, F1: 0.5866
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0015, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For later layers:  [8, 9, 10, 11]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.4998, Accuracy: 0.3786, Precision: 0.1597, Recall: 0.1749, F1: 0.1516
Validation Loss: 1.4067, Accuracy: 0.3580, Precision: 0.1178, Recall: 0.1661, F1: 0.1375
Testing Loss: 1.4372, Accuracy: 0.3777, Precision: 0.1261, Recall: 0.1757, F1: 0.1462
LM Predictions:  [2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0546, Accuracy: 0.1071, Precision: 0.0316, Recall: 0.0857, F1: 0.0462
Epoch 2/70
Train Loss: 1.3908, Accuracy: 0.3786, Precision: 0.1665, Recall: 0.1723, F1: 0.1476
Validation Loss: 1.3967, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4247, Accuracy: 0.3644, Precision: 0.2271, Recall: 0.1679, F1: 0.0912
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0409, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 3/70
Train Loss: 1.3894, Accuracy: 0.3835, Precision: 0.1790, Recall: 0.1733, F1: 0.1462
Validation Loss: 1.4041, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4404, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2786, Accuracy: 0.2500, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 4/70
Train Loss: 1.3786, Accuracy: 0.3915, Precision: 0.1718, Recall: 0.1757, F1: 0.1456
Validation Loss: 1.3693, Accuracy: 0.4318, Precision: 0.1440, Recall: 0.2035, F1: 0.1685
Testing Loss: 1.3928, Accuracy: 0.4601, Precision: 0.1533, Recall: 0.2143, F1: 0.1787
LM Predictions:  [2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 2, 4, 4, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0845, Accuracy: 0.1786, Precision: 0.0652, Recall: 0.1543, F1: 0.0917
Epoch 5/70
Train Loss: 1.3655, Accuracy: 0.4038, Precision: 0.2687, Recall: 0.1856, F1: 0.1624
Validation Loss: 1.3570, Accuracy: 0.4403, Precision: 0.3166, Recall: 0.2053, F1: 0.1676
Testing Loss: 1.3877, Accuracy: 0.4548, Precision: 0.3062, Recall: 0.2236, F1: 0.1934
LM Predictions:  [2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0297, Accuracy: 0.2500, Precision: 0.0636, Recall: 0.2000, F1: 0.0966
Epoch 6/70
Train Loss: 1.3434, Accuracy: 0.4353, Precision: 0.2470, Recall: 0.2033, F1: 0.1846
Validation Loss: 1.3187, Accuracy: 0.4574, Precision: 0.2730, Recall: 0.2194, F1: 0.1964
Testing Loss: 1.3554, Accuracy: 0.4814, Precision: 0.2961, Recall: 0.2411, F1: 0.2188
LM Predictions:  [2, 2, 2, 4, 5, 2, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 5, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9922, Accuracy: 0.2857, Precision: 0.1100, Recall: 0.2400, F1: 0.1437
Epoch 7/70
Train Loss: 1.2676, Accuracy: 0.4976, Precision: 0.2551, Recall: 0.2400, F1: 0.2262
Validation Loss: 1.0811, Accuracy: 0.5881, Precision: 0.2942, Recall: 0.2985, F1: 0.2829
Testing Loss: 1.1138, Accuracy: 0.6144, Precision: 0.3089, Recall: 0.3090, F1: 0.2926
LM Predictions:  [2, 2, 2, 4, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 5, 2, 2, 5, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9652, Accuracy: 0.2857, Precision: 0.1333, Recall: 0.2400, F1: 0.1500
Epoch 8/70
Train Loss: 1.0343, Accuracy: 0.6340, Precision: 0.3239, Recall: 0.3101, F1: 0.2985
Validation Loss: 0.9526, Accuracy: 0.7045, Precision: 0.3349, Recall: 0.3849, F1: 0.3574
Testing Loss: 0.9092, Accuracy: 0.7234, Precision: 0.3473, Recall: 0.4076, F1: 0.3731
LM Predictions:  [2, 5, 2, 2, 5, 5, 2, 5, 5, 5, 2, 2, 2, 4, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 2, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1854, Accuracy: 0.2500, Precision: 0.1045, Recall: 0.2000, F1: 0.1362
Epoch 9/70
Train Loss: 0.8243, Accuracy: 0.7190, Precision: 0.5171, Recall: 0.3775, F1: 0.3637
Validation Loss: 0.8860, Accuracy: 0.7102, Precision: 0.3369, Recall: 0.3841, F1: 0.3586
Testing Loss: 0.7589, Accuracy: 0.7606, Precision: 0.5259, Recall: 0.4194, F1: 0.3951
LM Predictions:  [3, 5, 5, 2, 5, 2, 5, 5, 5, 5, 5, 2, 2, 4, 4, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0560, Accuracy: 0.2857, Precision: 0.1939, Recall: 0.2000, F1: 0.1673
Epoch 10/70
Train Loss: 0.6864, Accuracy: 0.7705, Precision: 0.6246, Recall: 0.4380, F1: 0.4278
Validation Loss: 0.7871, Accuracy: 0.7585, Precision: 0.4382, Recall: 0.4457, F1: 0.4374
Testing Loss: 0.7087, Accuracy: 0.7926, Precision: 0.5271, Recall: 0.4765, F1: 0.4793
LM Predictions:  [3, 3, 3, 2, 5, 2, 2, 5, 5, 3, 3, 3, 2, 4, 4, 5, 5, 2, 3, 5, 5, 5, 5, 2, 5, 5, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9367, Accuracy: 0.2500, Precision: 0.1944, Recall: 0.1762, F1: 0.1691
Epoch 11/70
Train Loss: 0.6440, Accuracy: 0.7817, Precision: 0.5049, Recall: 0.4521, F1: 0.4445
Validation Loss: 0.7712, Accuracy: 0.7528, Precision: 0.4639, Recall: 0.4607, F1: 0.4556
Testing Loss: 0.6500, Accuracy: 0.7979, Precision: 0.5131, Recall: 0.4819, F1: 0.4846
LM Predictions:  [3, 3, 3, 2, 5, 2, 1, 5, 5, 3, 3, 3, 2, 2, 4, 5, 5, 3, 2, 5, 5, 5, 5, 2, 4, 5, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.9623, Accuracy: 0.2857, Precision: 0.2214, Recall: 0.2000, F1: 0.1975
Epoch 12/70
Train Loss: 0.5690, Accuracy: 0.8058, Precision: 0.5445, Recall: 0.5033, F1: 0.4967
Validation Loss: 0.6870, Accuracy: 0.7869, Precision: 0.4645, Recall: 0.5071, F1: 0.4844
Testing Loss: 0.6238, Accuracy: 0.8085, Precision: 0.5713, Recall: 0.5086, F1: 0.5185
LM Predictions:  [3, 3, 3, 2, 5, 2, 3, 5, 5, 3, 3, 3, 2, 4, 4, 5, 3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2637, Accuracy: 0.2143, Precision: 0.2500, Recall: 0.1524, F1: 0.1865
Epoch 13/70
Train Loss: 0.5356, Accuracy: 0.8174, Precision: 0.5484, Recall: 0.5254, F1: 0.5223
Validation Loss: 0.6059, Accuracy: 0.8068, Precision: 0.5943, Recall: 0.5562, F1: 0.5495
Testing Loss: 0.5749, Accuracy: 0.7926, Precision: 0.5158, Recall: 0.5015, F1: 0.4991
LM Predictions:  [3, 3, 3, 2, 1, 2, 3, 5, 5, 3, 3, 3, 2, 4, 3, 5, 3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.2595, Accuracy: 0.1786, Precision: 0.3167, Recall: 0.1369, F1: 0.1828
Epoch 14/70
Train Loss: 0.4620, Accuracy: 0.8411, Precision: 0.5837, Recall: 0.5739, F1: 0.5742
Validation Loss: 0.6817, Accuracy: 0.7812, Precision: 0.6431, Recall: 0.5697, F1: 0.5595
Testing Loss: 0.6154, Accuracy: 0.8085, Precision: 0.5607, Recall: 0.5444, F1: 0.5433
LM Predictions:  [3, 3, 3, 3, 1, 5, 3, 5, 3, 3, 3, 3, 2, 5, 4, 5, 3, 3, 3, 3, 3, 5, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3589, Accuracy: 0.2857, Precision: 0.5167, Recall: 0.2179, F1: 0.2944
Epoch 15/70
Train Loss: 0.4434, Accuracy: 0.8530, Precision: 0.6172, Recall: 0.5992, F1: 0.6012
Validation Loss: 0.6108, Accuracy: 0.8267, Precision: 0.6645, Recall: 0.5724, F1: 0.6008
Testing Loss: 0.5930, Accuracy: 0.8112, Precision: 0.6119, Recall: 0.5671, F1: 0.5784
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 2, 2, 4, 5, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1852, Accuracy: 0.2857, Precision: 0.4611, Recall: 0.2357, F1: 0.2889
Epoch 16/70
Train Loss: 0.4071, Accuracy: 0.8663, Precision: 0.7068, Recall: 0.6230, F1: 0.6295
Validation Loss: 0.6149, Accuracy: 0.8068, Precision: 0.6068, Recall: 0.6117, F1: 0.6063
Testing Loss: 0.6049, Accuracy: 0.8378, Precision: 0.6121, Recall: 0.6293, F1: 0.6108
LM Predictions:  [3, 3, 3, 3, 1, 1, 3, 5, 3, 3, 3, 3, 2, 1, 4, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.6542, Accuracy: 0.1429, Precision: 0.5417, Recall: 0.1226, F1: 0.1806
Epoch 17/70
Train Loss: 0.3870, Accuracy: 0.8681, Precision: 0.6710, Recall: 0.6408, F1: 0.6419
Validation Loss: 0.5752, Accuracy: 0.8153, Precision: 0.6116, Recall: 0.5824, F1: 0.5684
Testing Loss: 0.5557, Accuracy: 0.8324, Precision: 0.6008, Recall: 0.5873, F1: 0.5906
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.7173, Accuracy: 0.1786, Precision: 0.5278, Recall: 0.1464, F1: 0.2194
Epoch 18/70
Train Loss: 0.3350, Accuracy: 0.8894, Precision: 0.7632, Recall: 0.6828, F1: 0.6942
Validation Loss: 0.6276, Accuracy: 0.8352, Precision: 0.6656, Recall: 0.6045, F1: 0.6287
Testing Loss: 0.6734, Accuracy: 0.8271, Precision: 0.6299, Recall: 0.5913, F1: 0.6014
LM Predictions:  [3, 2, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 2, 2, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 2, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4973, Accuracy: 0.2143, Precision: 0.4881, Recall: 0.1702, F1: 0.2242
Epoch 19/70
Train Loss: 0.3032, Accuracy: 0.8996, Precision: 0.7275, Recall: 0.7074, F1: 0.7086
Validation Loss: 0.5237, Accuracy: 0.8295, Precision: 0.6558, Recall: 0.6858, F1: 0.6653
Testing Loss: 0.5474, Accuracy: 0.8245, Precision: 0.5960, Recall: 0.6219, F1: 0.6012
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 3, 0, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 3]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3095, Accuracy: 0.1429, Precision: 0.5000, Recall: 0.1226, F1: 0.1898
Epoch 20/70
Train Loss: 0.2686, Accuracy: 0.9041, Precision: 0.7340, Recall: 0.7137, F1: 0.7164
Validation Loss: 0.6086, Accuracy: 0.8267, Precision: 0.6900, Recall: 0.7161, F1: 0.6863
Testing Loss: 0.6085, Accuracy: 0.8457, Precision: 0.6284, Recall: 0.6227, F1: 0.6251
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 3, 3, 3, 3, 3, 0, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.4154, Accuracy: 0.1786, Precision: 0.5278, Recall: 0.1464, F1: 0.2194
Epoch 21/70
Train Loss: 0.2494, Accuracy: 0.9153, Precision: 0.8093, Recall: 0.7530, F1: 0.7675
Validation Loss: 0.6249, Accuracy: 0.8409, Precision: 0.7150, Recall: 0.7015, F1: 0.7011
Testing Loss: 0.6387, Accuracy: 0.8218, Precision: 0.6021, Recall: 0.6177, F1: 0.5902
LM Predictions:  [3, 0, 3, 3, 1, 4, 3, 5, 5, 3, 3, 3, 3, 3, 4, 5, 3, 3, 3, 1, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0987, Accuracy: 0.2857, Precision: 0.6667, Recall: 0.2369, F1: 0.3392
Epoch 22/70
Train Loss: 0.2297, Accuracy: 0.9237, Precision: 0.8284, Recall: 0.7915, F1: 0.8038
Validation Loss: 0.6051, Accuracy: 0.8466, Precision: 0.7081, Recall: 0.6996, F1: 0.6986
Testing Loss: 0.6241, Accuracy: 0.8431, Precision: 0.6315, Recall: 0.6358, F1: 0.6313
LM Predictions:  [3, 3, 3, 3, 1, 2, 3, 5, 5, 3, 3, 3, 2, 3, 4, 5, 3, 3, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.1178, Accuracy: 0.2500, Precision: 0.4861, Recall: 0.1940, F1: 0.2687
Epoch 23/70
Train Loss: 0.1965, Accuracy: 0.9360, Precision: 0.8384, Recall: 0.8268, F1: 0.8296
Validation Loss: 0.5366, Accuracy: 0.8352, Precision: 0.7938, Recall: 0.7009, F1: 0.7131
Testing Loss: 0.6223, Accuracy: 0.8431, Precision: 0.6119, Recall: 0.6428, F1: 0.6143
LM Predictions:  [3, 3, 3, 1, 1, 4, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 5, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0063, Accuracy: 0.2857, Precision: 0.5556, Recall: 0.2274, F1: 0.3169
Epoch 24/70
Train Loss: 0.1874, Accuracy: 0.9356, Precision: 0.8411, Recall: 0.8126, F1: 0.8216
Validation Loss: 0.5299, Accuracy: 0.8494, Precision: 0.6865, Recall: 0.7674, F1: 0.7091
Testing Loss: 0.5756, Accuracy: 0.8351, Precision: 0.6155, Recall: 0.6375, F1: 0.6254
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 3, 3, 3, 3, 3, 1, 2, 3, 5, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.0162, Accuracy: 0.2500, Precision: 0.5000, Recall: 0.2036, F1: 0.2878
Epoch 25/70
Train Loss: 0.1698, Accuracy: 0.9440, Precision: 0.8596, Recall: 0.8376, F1: 0.8451
Validation Loss: 0.6090, Accuracy: 0.8494, Precision: 0.7159, Recall: 0.8147, F1: 0.7229
Testing Loss: 0.6039, Accuracy: 0.8351, Precision: 0.6233, Recall: 0.6383, F1: 0.6259
LM Predictions:  [3, 3, 3, 3, 1, 4, 3, 5, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 3, 3, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 2.3088, Accuracy: 0.2500, Precision: 0.5417, Recall: 0.2036, F1: 0.2834
Epoch 26/70
Train Loss: 0.1473, Accuracy: 0.9514, Precision: 0.8768, Recall: 0.8603, F1: 0.8665
Validation Loss: 0.7084, Accuracy: 0.8381, Precision: 0.6963, Recall: 0.8005, F1: 0.7089
Testing Loss: 0.6982, Accuracy: 0.8484, Precision: 0.6387, Recall: 0.6604, F1: 0.6446
LM Predictions:  [3, 0, 3, 3, 1, 4, 3, 5, 3, 3, 3, 3, 2, 3, 4, 5, 3, 2, 3, 1, 3, 3, 1, 2, 3, 3, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.6453, Accuracy: 0.3214, Precision: 0.6556, Recall: 0.2607, F1: 0.3558
Epoch 27/70
Train Loss: 0.1365, Accuracy: 0.9556, Precision: 0.8927, Recall: 0.8772, F1: 0.8824
Validation Loss: 0.7300, Accuracy: 0.8352, Precision: 0.6895, Recall: 0.7239, F1: 0.6731
Testing Loss: 0.7004, Accuracy: 0.8431, Precision: 0.6775, Recall: 0.6685, F1: 0.6595
LM Predictions:  [3, 0, 3, 2, 1, 4, 4, 5, 3, 3, 3, 0, 2, 3, 4, 3, 3, 2, 3, 1, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.4710, Accuracy: 0.3571, Precision: 0.6556, Recall: 0.3036, F1: 0.3929
Epoch 28/70
Train Loss: 0.1183, Accuracy: 0.9598, Precision: 0.8791, Recall: 0.8852, F1: 0.8812
Validation Loss: 0.8499, Accuracy: 0.8494, Precision: 0.7203, Recall: 0.7054, F1: 0.7072
Testing Loss: 0.7881, Accuracy: 0.8537, Precision: 0.6602, Recall: 0.6485, F1: 0.6520
LM Predictions:  [3, 3, 3, 2, 1, 4, 2, 5, 2, 3, 3, 0, 3, 3, 4, 5, 3, 4, 3, 5, 3, 3, 1, 2, 3, 3, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.8501, Accuracy: 0.3929, Precision: 0.6833, Recall: 0.3179, F1: 0.4194
Epoch 29/70
Train Loss: 0.1031, Accuracy: 0.9647, Precision: 0.8995, Recall: 0.8892, F1: 0.8926
Validation Loss: 0.7914, Accuracy: 0.8324, Precision: 0.7013, Recall: 0.6698, F1: 0.6807
Testing Loss: 0.7550, Accuracy: 0.8484, Precision: 0.6326, Recall: 0.6367, F1: 0.6293
LM Predictions:  [3, 3, 3, 2, 1, 4, 5, 5, 2, 3, 3, 0, 2, 5, 4, 5, 3, 4, 3, 5, 3, 3, 1, 2, 1, 3, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1312, Accuracy: 0.5000, Precision: 0.6889, Recall: 0.4071, F1: 0.4895
Epoch 30/70
Train Loss: 0.1009, Accuracy: 0.9650, Precision: 0.8992, Recall: 0.8936, F1: 0.8961
Validation Loss: 1.0168, Accuracy: 0.8267, Precision: 0.6868, Recall: 0.7318, F1: 0.6894
Testing Loss: 0.7809, Accuracy: 0.8431, Precision: 0.6601, Recall: 0.6686, F1: 0.6579
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 3, 3, 3, 0, 3, 3, 4, 5, 3, 4, 3, 5, 3, 3, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.3933, Accuracy: 0.4643, Precision: 0.7778, Recall: 0.4024, F1: 0.5127
Epoch 31/70
Train Loss: 0.0958, Accuracy: 0.9710, Precision: 0.9296, Recall: 0.9298, F1: 0.9289
Validation Loss: 1.0970, Accuracy: 0.8239, Precision: 0.7052, Recall: 0.7117, F1: 0.6639
Testing Loss: 1.0146, Accuracy: 0.8298, Precision: 0.7088, Recall: 0.6563, F1: 0.6655
LM Predictions:  [3, 3, 3, 2, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 3, 2, 3, 5, 2, 2, 1, 2, 3, 0, 2, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.2444, Accuracy: 0.5357, Precision: 0.6759, Recall: 0.4226, F1: 0.5012
Epoch 32/70
Train Loss: 0.0804, Accuracy: 0.9720, Precision: 0.9199, Recall: 0.9321, F1: 0.9255
Validation Loss: 1.2945, Accuracy: 0.8153, Precision: 0.7074, Recall: 0.7144, F1: 0.6926
Testing Loss: 1.0619, Accuracy: 0.8378, Precision: 0.7186, Recall: 0.6721, F1: 0.6788
LM Predictions:  [3, 3, 3, 5, 1, 4, 4, 5, 3, 3, 3, 0, 3, 5, 4, 3, 3, 4, 3, 5, 2, 2, 1, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 1.1214, Accuracy: 0.5357, Precision: 0.7361, Recall: 0.4500, F1: 0.5507
Epoch 33/70
Train Loss: 0.0726, Accuracy: 0.9766, Precision: 0.9395, Recall: 0.9425, F1: 0.9406
Validation Loss: 0.9193, Accuracy: 0.8438, Precision: 0.7120, Recall: 0.7470, F1: 0.7115
Testing Loss: 0.8597, Accuracy: 0.8112, Precision: 0.5871, Recall: 0.6033, F1: 0.5828
LM Predictions:  [3, 0, 3, 1, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 3, 2, 1, 5, 5, 2, 1, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6405, Accuracy: 0.7143, Precision: 0.7056, Recall: 0.5964, F1: 0.6365
Epoch 34/70
Train Loss: 0.0511, Accuracy: 0.9839, Precision: 0.9599, Recall: 0.9648, F1: 0.9623
Validation Loss: 1.0050, Accuracy: 0.8352, Precision: 0.6878, Recall: 0.7635, F1: 0.7065
Testing Loss: 1.0057, Accuracy: 0.8351, Precision: 0.6890, Recall: 0.6598, F1: 0.6525
LM Predictions:  [3, 3, 3, 5, 1, 4, 4, 5, 2, 3, 0, 0, 3, 5, 4, 5, 5, 2, 3, 5, 5, 2, 0, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.8338, Accuracy: 0.6429, Precision: 0.7345, Recall: 0.5214, F1: 0.6012
Epoch 35/70
Train Loss: 0.0674, Accuracy: 0.9773, Precision: 0.9408, Recall: 0.9374, F1: 0.9388
Validation Loss: 0.8420, Accuracy: 0.8466, Precision: 0.6967, Recall: 0.7455, F1: 0.7034
Testing Loss: 0.7382, Accuracy: 0.8431, Precision: 0.6292, Recall: 0.6575, F1: 0.6400
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 2, 0, 2, 3, 4, 5, 3, 2, 3, 5, 5, 2, 0, 2, 1, 0, 3, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.9613, Accuracy: 0.6071, Precision: 0.7857, Recall: 0.4976, F1: 0.6014
Epoch 36/70
Train Loss: 0.0596, Accuracy: 0.9815, Precision: 0.9541, Recall: 0.9532, F1: 0.9536
Validation Loss: 0.8510, Accuracy: 0.8551, Precision: 0.7579, Recall: 0.7603, F1: 0.7538
Testing Loss: 0.7546, Accuracy: 0.8537, Precision: 0.6360, Recall: 0.6436, F1: 0.6389
LM Predictions:  [3, 3, 3, 3, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 3, 4, 3, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.6957, Accuracy: 0.7143, Precision: 0.8000, Recall: 0.5881, F1: 0.6704
Epoch 37/70
Train Loss: 0.0379, Accuracy: 0.9874, Precision: 0.9704, Recall: 0.9685, F1: 0.9692
Validation Loss: 0.9378, Accuracy: 0.8494, Precision: 0.7199, Recall: 0.8012, F1: 0.7199
Testing Loss: 0.9039, Accuracy: 0.8351, Precision: 0.6352, Recall: 0.6165, F1: 0.6208
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 3, 4, 3, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4018, Accuracy: 0.8571, Precision: 0.8056, Recall: 0.6929, F1: 0.7313
Epoch 38/70
Train Loss: 0.0542, Accuracy: 0.9832, Precision: 0.9637, Recall: 0.9590, F1: 0.9610
Validation Loss: 0.9213, Accuracy: 0.8636, Precision: 0.7494, Recall: 0.7562, F1: 0.7296
Testing Loss: 0.9416, Accuracy: 0.8351, Precision: 0.6879, Recall: 0.6475, F1: 0.6563
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 5, 2, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.3817, Accuracy: 0.8571, Precision: 0.7609, Recall: 0.7012, F1: 0.7178
Epoch 39/70
Train Loss: 0.0367, Accuracy: 0.9871, Precision: 0.9643, Recall: 0.9683, F1: 0.9663
Validation Loss: 1.1257, Accuracy: 0.8352, Precision: 0.7333, Recall: 0.7960, F1: 0.7101
Testing Loss: 0.9729, Accuracy: 0.8245, Precision: 0.6811, Recall: 0.6695, F1: 0.6431
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.2656, Accuracy: 0.9286, Precision: 0.8056, Recall: 0.7679, F1: 0.7816
Epoch 40/70
Train Loss: 0.0438, Accuracy: 0.9871, Precision: 0.9716, Recall: 0.9693, F1: 0.9705
Validation Loss: 0.9742, Accuracy: 0.8409, Precision: 0.6946, Recall: 0.7415, F1: 0.7017
Testing Loss: 0.9124, Accuracy: 0.8431, Precision: 0.6755, Recall: 0.6705, F1: 0.6687
LM Predictions:  [3, 0, 2, 5, 1, 4, 4, 5, 2, 3, 3, 0, 2, 5, 4, 5, 3, 4, 3, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4008, Accuracy: 0.8214, Precision: 0.8333, Recall: 0.6690, F1: 0.7336
Epoch 41/70
Train Loss: 0.0408, Accuracy: 0.9874, Precision: 0.9740, Recall: 0.9709, F1: 0.9722
Validation Loss: 0.8716, Accuracy: 0.8580, Precision: 0.7236, Recall: 0.7565, F1: 0.7312
Testing Loss: 0.9306, Accuracy: 0.8298, Precision: 0.6977, Recall: 0.6628, F1: 0.6481
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1806, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 42/70
Train Loss: 0.0440, Accuracy: 0.9881, Precision: 0.9665, Recall: 0.9581, F1: 0.9620
Validation Loss: 0.7748, Accuracy: 0.8381, Precision: 0.7274, Recall: 0.7251, F1: 0.7019
Testing Loss: 0.8223, Accuracy: 0.8298, Precision: 0.6761, Recall: 0.6152, F1: 0.6251
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 3, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1577, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 43/70
Train Loss: 0.0241, Accuracy: 0.9934, Precision: 0.9816, Recall: 0.9837, F1: 0.9826
Validation Loss: 0.9912, Accuracy: 0.8239, Precision: 0.6891, Recall: 0.7292, F1: 0.6857
Testing Loss: 1.0857, Accuracy: 0.8191, Precision: 0.5990, Recall: 0.6034, F1: 0.5961
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1359, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8000, F1: 0.8148
Epoch 44/70
Train Loss: 0.0340, Accuracy: 0.9878, Precision: 0.9710, Recall: 0.9745, F1: 0.9727
Validation Loss: 0.8190, Accuracy: 0.8352, Precision: 0.6872, Recall: 0.7438, F1: 0.6980
Testing Loss: 0.9297, Accuracy: 0.8165, Precision: 0.6141, Recall: 0.6181, F1: 0.6115
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1200, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 45/70
Train Loss: 0.0222, Accuracy: 0.9916, Precision: 0.9831, Recall: 0.9806, F1: 0.9818
Validation Loss: 0.9920, Accuracy: 0.8551, Precision: 0.7408, Recall: 0.7709, F1: 0.7523
Testing Loss: 1.1559, Accuracy: 0.8378, Precision: 0.6546, Recall: 0.6657, F1: 0.6511
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0847, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 46/70
Train Loss: 0.0268, Accuracy: 0.9909, Precision: 0.9776, Recall: 0.9703, F1: 0.9737
Validation Loss: 1.0741, Accuracy: 0.8409, Precision: 0.7208, Recall: 0.7814, F1: 0.6920
Testing Loss: 1.1219, Accuracy: 0.8191, Precision: 0.6625, Recall: 0.6351, F1: 0.6186
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0562, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 47/70
Train Loss: 0.0210, Accuracy: 0.9934, Precision: 0.9818, Recall: 0.9816, F1: 0.9817
Validation Loss: 0.8951, Accuracy: 0.8438, Precision: 0.7089, Recall: 0.7610, F1: 0.7202
Testing Loss: 0.9705, Accuracy: 0.8191, Precision: 0.6040, Recall: 0.6301, F1: 0.5937
LM Predictions:  [2, 3, 2, 5, 1, 4, 4, 5, 2, 1, 3, 0, 2, 5, 4, 3, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.4576, Accuracy: 0.8929, Precision: 0.8333, Recall: 0.7524, F1: 0.7870
Epoch 48/70
Train Loss: 0.0247, Accuracy: 0.9923, Precision: 0.9784, Recall: 0.9755, F1: 0.9769
Validation Loss: 1.0328, Accuracy: 0.8494, Precision: 0.7302, Recall: 0.7777, F1: 0.7456
Testing Loss: 1.2033, Accuracy: 0.8245, Precision: 0.6285, Recall: 0.6636, F1: 0.6369
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 3, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1288, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8095, F1: 0.8205
Epoch 49/70
Train Loss: 0.0171, Accuracy: 0.9958, Precision: 0.9899, Recall: 0.9844, F1: 0.9871
Validation Loss: 1.0129, Accuracy: 0.8523, Precision: 0.7256, Recall: 0.7958, F1: 0.7285
Testing Loss: 1.1948, Accuracy: 0.8191, Precision: 0.6412, Recall: 0.6151, F1: 0.6138
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0382, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0107, Accuracy: 0.9972, Precision: 0.9959, Recall: 0.9899, F1: 0.9928
Validation Loss: 1.0566, Accuracy: 0.8466, Precision: 0.7144, Recall: 0.7884, F1: 0.6984
Testing Loss: 1.4935, Accuracy: 0.8165, Precision: 0.6499, Recall: 0.6433, F1: 0.6123
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 0, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0717, Accuracy: 0.9643, Precision: 0.9667, Recall: 0.9714, F1: 0.9664
Epoch 51/70
Train Loss: 0.0214, Accuracy: 0.9941, Precision: 0.9835, Recall: 0.9850, F1: 0.9842
Validation Loss: 0.9758, Accuracy: 0.8466, Precision: 0.6987, Recall: 0.7417, F1: 0.7043
Testing Loss: 1.2201, Accuracy: 0.8245, Precision: 0.6264, Recall: 0.6332, F1: 0.6217
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0630, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 52/70
Train Loss: 0.0142, Accuracy: 0.9944, Precision: 0.9868, Recall: 0.9898, F1: 0.9883
Validation Loss: 1.3007, Accuracy: 0.8381, Precision: 0.7604, Recall: 0.6706, F1: 0.7038
Testing Loss: 1.4093, Accuracy: 0.8032, Precision: 0.6435, Recall: 0.5917, F1: 0.6011
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 2, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0940, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9714, F1: 0.9713
Epoch 53/70
Train Loss: 0.0087, Accuracy: 0.9972, Precision: 0.9970, Recall: 0.9901, F1: 0.9934
Validation Loss: 1.2815, Accuracy: 0.8580, Precision: 0.7635, Recall: 0.7462, F1: 0.7440
Testing Loss: 1.4640, Accuracy: 0.8271, Precision: 0.6111, Recall: 0.5767, F1: 0.5811
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0157, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0133, Accuracy: 0.9976, Precision: 0.9901, Recall: 0.9941, F1: 0.9921
Validation Loss: 1.1660, Accuracy: 0.8551, Precision: 0.6740, Recall: 0.6460, F1: 0.6583
Testing Loss: 1.4178, Accuracy: 0.8271, Precision: 0.6156, Recall: 0.6132, F1: 0.6054
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 2, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1622, Accuracy: 0.9643, Precision: 0.9750, Recall: 0.9600, F1: 0.9644
Epoch 55/70
Train Loss: 0.0261, Accuracy: 0.9920, Precision: 0.9833, Recall: 0.9683, F1: 0.9755
Validation Loss: 1.1775, Accuracy: 0.8466, Precision: 0.7383, Recall: 0.7387, F1: 0.7161
Testing Loss: 1.2742, Accuracy: 0.8191, Precision: 0.6509, Recall: 0.6044, F1: 0.5932
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0204, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0111, Accuracy: 0.9972, Precision: 0.9931, Recall: 0.9950, F1: 0.9941
Validation Loss: 1.3592, Accuracy: 0.8381, Precision: 0.7041, Recall: 0.7087, F1: 0.6887
Testing Loss: 1.4431, Accuracy: 0.8298, Precision: 0.6273, Recall: 0.5791, F1: 0.5926
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0019, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0084, Accuracy: 0.9965, Precision: 0.9910, Recall: 0.9861, F1: 0.9885
Validation Loss: 1.3809, Accuracy: 0.8381, Precision: 0.6870, Recall: 0.7468, F1: 0.6974
Testing Loss: 1.3839, Accuracy: 0.8245, Precision: 0.6344, Recall: 0.6427, F1: 0.6266
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0032, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0128, Accuracy: 0.9976, Precision: 0.9960, Recall: 0.9947, F1: 0.9953
Validation Loss: 1.2770, Accuracy: 0.8523, Precision: 0.7208, Recall: 0.7457, F1: 0.7187
Testing Loss: 1.4436, Accuracy: 0.8298, Precision: 0.6136, Recall: 0.6050, F1: 0.6027
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0016, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0225, Accuracy: 0.9937, Precision: 0.9859, Recall: 0.9888, F1: 0.9873
Validation Loss: 1.0173, Accuracy: 0.8381, Precision: 0.6887, Recall: 0.7574, F1: 0.7033
Testing Loss: 1.0624, Accuracy: 0.8191, Precision: 0.6801, Recall: 0.6327, F1: 0.6377
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0059, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0132, Accuracy: 0.9976, Precision: 0.9914, Recall: 0.9941, F1: 0.9928
Validation Loss: 1.2820, Accuracy: 0.8438, Precision: 0.7209, Recall: 0.6950, F1: 0.6985
Testing Loss: 1.3812, Accuracy: 0.8271, Precision: 0.6519, Recall: 0.6209, F1: 0.6281
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0227, Accuracy: 0.9948, Precision: 0.9913, Recall: 0.9915, F1: 0.9914
Validation Loss: 1.2198, Accuracy: 0.8125, Precision: 0.6763, Recall: 0.7290, F1: 0.6662
Testing Loss: 1.0525, Accuracy: 0.8112, Precision: 0.6457, Recall: 0.6676, F1: 0.6246
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 0, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1109, Accuracy: 0.9643, Precision: 0.9667, Recall: 0.9714, F1: 0.9664
Epoch 62/70
Train Loss: 0.0223, Accuracy: 0.9934, Precision: 0.9822, Recall: 0.9851, F1: 0.9836
Validation Loss: 1.0159, Accuracy: 0.8267, Precision: 0.6850, Recall: 0.7298, F1: 0.6871
Testing Loss: 0.8983, Accuracy: 0.8324, Precision: 0.6435, Recall: 0.6141, F1: 0.6266
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0211, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 63/70
Train Loss: 0.0080, Accuracy: 0.9979, Precision: 0.9985, Recall: 0.9957, F1: 0.9971
Validation Loss: 1.1264, Accuracy: 0.8267, Precision: 0.6866, Recall: 0.6899, F1: 0.6851
Testing Loss: 1.0712, Accuracy: 0.8378, Precision: 0.6243, Recall: 0.6227, F1: 0.6198
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0034, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0130, Accuracy: 0.9976, Precision: 0.9958, Recall: 0.9943, F1: 0.9950
Validation Loss: 1.0141, Accuracy: 0.8352, Precision: 0.7341, Recall: 0.6697, F1: 0.6922
Testing Loss: 0.9707, Accuracy: 0.8431, Precision: 0.6616, Recall: 0.6100, F1: 0.6279
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0216, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0083, Accuracy: 0.9979, Precision: 0.9924, Recall: 0.9962, F1: 0.9943
Validation Loss: 1.2414, Accuracy: 0.8295, Precision: 0.7246, Recall: 0.6754, F1: 0.6906
Testing Loss: 1.3238, Accuracy: 0.8271, Precision: 0.6157, Recall: 0.5969, F1: 0.5897
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0030, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 66/70
Train Loss: 0.0059, Accuracy: 0.9983, Precision: 0.9974, Recall: 0.9936, F1: 0.9955
Validation Loss: 1.2441, Accuracy: 0.8580, Precision: 0.7344, Recall: 0.7609, F1: 0.7362
Testing Loss: 1.3493, Accuracy: 0.8298, Precision: 0.6200, Recall: 0.6050, F1: 0.6104
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0002, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0056, Accuracy: 0.9979, Precision: 0.9926, Recall: 0.9897, F1: 0.9912
Validation Loss: 1.4757, Accuracy: 0.8295, Precision: 0.6945, Recall: 0.7656, F1: 0.7164
Testing Loss: 1.3749, Accuracy: 0.8165, Precision: 0.5953, Recall: 0.6021, F1: 0.5934
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0006, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0074, Accuracy: 0.9979, Precision: 0.9971, Recall: 0.9919, F1: 0.9945
Validation Loss: 1.5251, Accuracy: 0.8324, Precision: 0.6859, Recall: 0.7351, F1: 0.6948
Testing Loss: 1.4851, Accuracy: 0.8245, Precision: 0.5857, Recall: 0.5977, F1: 0.5891
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 3, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.1013, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8095, F1: 0.8205
Epoch 69/70
Train Loss: 0.0220, Accuracy: 0.9934, Precision: 0.9851, Recall: 0.9847, F1: 0.9849
Validation Loss: 1.1285, Accuracy: 0.7926, Precision: 0.6889, Recall: 0.6518, F1: 0.6621
Testing Loss: 1.1835, Accuracy: 0.7952, Precision: 0.5898, Recall: 0.5736, F1: 0.5630
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 4, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0974, Accuracy: 0.9643, Precision: 0.9667, Recall: 0.9714, F1: 0.9664
Epoch 70/70
Train Loss: 0.0130, Accuracy: 0.9965, Precision: 0.9906, Recall: 0.9896, F1: 0.9901
Validation Loss: 1.0051, Accuracy: 0.8182, Precision: 0.6971, Recall: 0.7845, F1: 0.7029
Testing Loss: 1.1007, Accuracy: 0.8138, Precision: 0.6111, Recall: 0.6016, F1: 0.6014
LM Predictions:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Labels:  [2, 0, 2, 5, 1, 4, 4, 5, 2, 1, 5, 0, 2, 5, 4, 5, 4, 4, 1, 5, 5, 2, 0, 2, 1, 0, 0, 2]
LM Loss: 0.0096, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
---------------------------------------------------------------------------



