---------------------------------------------------------------------------
Results for seed:  89
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:1
Noise: 1% with label 3
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 5: 486
  Label 1: 115
  Label 3: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 5: 60
  Label 0: 3
  Label 3: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 3: 29
  Label 5: 58
28
Actual labels:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
Label counts for Train:
  Label 4: 974
  Label 2: 1105
  Label 5: 490
  Label 1: 117
  Label 0: 56
  Label 3: 116
For early layers:  [0, 1, 2, 3, 4, 5, 6, 7]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.5630, Accuracy: 0.3684, Precision: 0.1482, Recall: 0.1691, F1: 0.1472
Validation Loss: 1.4433, Accuracy: 0.4119, Precision: 0.1417, Recall: 0.1867, F1: 0.1452
Testing Loss: 1.4792, Accuracy: 0.3803, Precision: 0.1282, Recall: 0.1760, F1: 0.1335
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1949, Accuracy: 0.1786, Precision: 0.0370, Recall: 0.1667, F1: 0.0606
Epoch 2/70
Train Loss: 1.4319, Accuracy: 0.3747, Precision: 0.1542, Recall: 0.1706, F1: 0.1453
Validation Loss: 1.4340, Accuracy: 0.3551, Precision: 0.1553, Recall: 0.1763, F1: 0.1070
Testing Loss: 1.4823, Accuracy: 0.3697, Precision: 0.1707, Recall: 0.1739, F1: 0.1091
LM Predictions:  [4, 4, 2, 4, 4, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2470, Accuracy: 0.2857, Precision: 0.1009, Recall: 0.2083, F1: 0.1267
Epoch 3/70
Train Loss: 1.4021, Accuracy: 0.3838, Precision: 0.1365, Recall: 0.1739, F1: 0.1468
Validation Loss: 1.4160, Accuracy: 0.4062, Precision: 0.1473, Recall: 0.1968, F1: 0.1509
Testing Loss: 1.4462, Accuracy: 0.3856, Precision: 0.1329, Recall: 0.1806, F1: 0.1417
LM Predictions:  [4, 4, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1815, Accuracy: 0.2143, Precision: 0.0756, Recall: 0.1583, F1: 0.1019
Epoch 4/70
Train Loss: 1.3949, Accuracy: 0.4052, Precision: 0.1899, Recall: 0.1844, F1: 0.1565
Validation Loss: 1.4303, Accuracy: 0.3807, Precision: 0.1741, Recall: 0.1683, F1: 0.0968
Testing Loss: 1.4547, Accuracy: 0.3670, Precision: 0.2273, Recall: 0.1692, F1: 0.0938
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2795, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 5/70
Train Loss: 1.3870, Accuracy: 0.4038, Precision: 0.2034, Recall: 0.1850, F1: 0.1606
Validation Loss: 1.3909, Accuracy: 0.4205, Precision: 0.1409, Recall: 0.1971, F1: 0.1642
Testing Loss: 1.4079, Accuracy: 0.4229, Precision: 0.1411, Recall: 0.1968, F1: 0.1638
LM Predictions:  [4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1783, Accuracy: 0.2500, Precision: 0.0971, Recall: 0.2167, F1: 0.1271
Epoch 6/70
Train Loss: 1.3763, Accuracy: 0.4118, Precision: 0.1370, Recall: 0.1868, F1: 0.1574
Validation Loss: 1.3883, Accuracy: 0.4062, Precision: 0.1606, Recall: 0.1819, F1: 0.1294
Testing Loss: 1.4059, Accuracy: 0.4069, Precision: 0.1675, Recall: 0.1881, F1: 0.1363
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0626, Accuracy: 0.2143, Precision: 0.0444, Recall: 0.2000, F1: 0.0727
Epoch 7/70
Train Loss: 1.3677, Accuracy: 0.4034, Precision: 0.1732, Recall: 0.1836, F1: 0.1563
Validation Loss: 1.3828, Accuracy: 0.4347, Precision: 0.1526, Recall: 0.2078, F1: 0.1684
Testing Loss: 1.3988, Accuracy: 0.4495, Precision: 0.2553, Recall: 0.2148, F1: 0.1880
LM Predictions:  [4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1811, Accuracy: 0.2143, Precision: 0.0844, Recall: 0.1667, F1: 0.1115
Epoch 8/70
Train Loss: 1.3672, Accuracy: 0.4164, Precision: 0.1892, Recall: 0.1903, F1: 0.1636
Validation Loss: 1.3814, Accuracy: 0.4091, Precision: 0.1687, Recall: 0.1972, F1: 0.1633
Testing Loss: 1.3926, Accuracy: 0.4335, Precision: 0.2305, Recall: 0.2091, F1: 0.1847
LM Predictions:  [4, 4, 2, 4, 2, 4, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1438, Accuracy: 0.2500, Precision: 0.0952, Recall: 0.1917, F1: 0.1271
Epoch 9/70
Train Loss: 1.3467, Accuracy: 0.4356, Precision: 0.2165, Recall: 0.2001, F1: 0.1739
Validation Loss: 1.4978, Accuracy: 0.3949, Precision: 0.3012, Recall: 0.1822, F1: 0.1222
Testing Loss: 1.5238, Accuracy: 0.3777, Precision: 0.3044, Recall: 0.1823, F1: 0.1193
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3814, Accuracy: 0.2143, Precision: 0.0462, Recall: 0.2000, F1: 0.0750
Epoch 10/70
Train Loss: 1.3470, Accuracy: 0.4318, Precision: 0.1919, Recall: 0.2002, F1: 0.1777
Validation Loss: 1.5195, Accuracy: 0.3892, Precision: 0.2304, Recall: 0.1724, F1: 0.1032
Testing Loss: 1.5537, Accuracy: 0.3644, Precision: 0.2271, Recall: 0.1679, F1: 0.0912
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4011, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 11/70
Train Loss: 1.3372, Accuracy: 0.4433, Precision: 0.2244, Recall: 0.2042, F1: 0.1775
Validation Loss: 1.4518, Accuracy: 0.4233, Precision: 0.1854, Recall: 0.1901, F1: 0.1401
Testing Loss: 1.4267, Accuracy: 0.4202, Precision: 0.1809, Recall: 0.1943, F1: 0.1424
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0931, Accuracy: 0.2143, Precision: 0.1385, Recall: 0.1917, F1: 0.1025
Epoch 12/70
Train Loss: 1.3173, Accuracy: 0.4538, Precision: 0.2083, Recall: 0.2110, F1: 0.1877
Validation Loss: 1.3635, Accuracy: 0.4886, Precision: 0.1717, Recall: 0.2256, F1: 0.1881
Testing Loss: 1.3562, Accuracy: 0.4761, Precision: 0.3350, Recall: 0.2243, F1: 0.1907
LM Predictions:  [4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2528, Accuracy: 0.2500, Precision: 0.1150, Recall: 0.2083, F1: 0.1365
Epoch 13/70
Train Loss: 1.2789, Accuracy: 0.4878, Precision: 0.2347, Recall: 0.2323, F1: 0.2143
Validation Loss: 1.3148, Accuracy: 0.5000, Precision: 0.2283, Recall: 0.2458, F1: 0.2228
Testing Loss: 1.2732, Accuracy: 0.5452, Precision: 0.2735, Recall: 0.2755, F1: 0.2590
LM Predictions:  [4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 5, 4, 4, 4, 2, 4, 2, 4, 2, 2, 5, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2863, Accuracy: 0.2143, Precision: 0.0929, Recall: 0.1750, F1: 0.1212
Epoch 14/70
Train Loss: 1.2521, Accuracy: 0.5080, Precision: 0.2396, Recall: 0.2465, F1: 0.2313
Validation Loss: 1.3227, Accuracy: 0.5085, Precision: 0.2249, Recall: 0.2468, F1: 0.2199
Testing Loss: 1.3212, Accuracy: 0.5346, Precision: 0.2814, Recall: 0.2655, F1: 0.2476
LM Predictions:  [4, 2, 2, 4, 2, 4, 2, 2, 5, 4, 4, 4, 2, 2, 2, 5, 4, 4, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2541, Accuracy: 0.1786, Precision: 0.0786, Recall: 0.1417, F1: 0.1000
Epoch 15/70
Train Loss: 1.2213, Accuracy: 0.5301, Precision: 0.2473, Recall: 0.2588, F1: 0.2437
Validation Loss: 1.2870, Accuracy: 0.5170, Precision: 0.2354, Recall: 0.2640, F1: 0.2434
Testing Loss: 1.2931, Accuracy: 0.5718, Precision: 0.2860, Recall: 0.2895, F1: 0.2725
LM Predictions:  [4, 2, 2, 5, 2, 4, 2, 2, 5, 4, 4, 4, 4, 2, 2, 5, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1603, Accuracy: 0.2500, Precision: 0.1628, Recall: 0.2250, F1: 0.1803
Epoch 16/70
Train Loss: 1.1958, Accuracy: 0.5483, Precision: 0.2614, Recall: 0.2710, F1: 0.2573
Validation Loss: 1.2917, Accuracy: 0.5114, Precision: 0.2613, Recall: 0.2921, F1: 0.2675
Testing Loss: 1.2541, Accuracy: 0.5372, Precision: 0.2648, Recall: 0.3060, F1: 0.2770
LM Predictions:  [5, 2, 5, 5, 2, 5, 5, 2, 5, 4, 4, 5, 2, 5, 2, 5, 4, 4, 4, 2, 5, 2, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3261, Accuracy: 0.2500, Precision: 0.1673, Recall: 0.2667, F1: 0.1815
Epoch 17/70
Train Loss: 1.1613, Accuracy: 0.5619, Precision: 0.2682, Recall: 0.2833, F1: 0.2707
Validation Loss: 1.2785, Accuracy: 0.5142, Precision: 0.2519, Recall: 0.2809, F1: 0.2546
Testing Loss: 1.2686, Accuracy: 0.5399, Precision: 0.2670, Recall: 0.2850, F1: 0.2636
LM Predictions:  [4, 2, 4, 5, 2, 5, 5, 2, 4, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 2, 4, 2, 4, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2905, Accuracy: 0.2857, Precision: 0.1714, Recall: 0.2667, F1: 0.2070
Epoch 18/70
Train Loss: 1.1139, Accuracy: 0.5861, Precision: 0.2781, Recall: 0.2952, F1: 0.2821
Validation Loss: 1.2705, Accuracy: 0.5653, Precision: 0.2985, Recall: 0.3130, F1: 0.2908
Testing Loss: 1.1958, Accuracy: 0.5718, Precision: 0.2960, Recall: 0.3232, F1: 0.2956
LM Predictions:  [5, 2, 2, 5, 2, 5, 5, 2, 5, 4, 5, 5, 2, 2, 2, 5, 5, 4, 4, 2, 5, 2, 5, 2, 2, 5, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5518, Accuracy: 0.2143, Precision: 0.1333, Recall: 0.2250, F1: 0.1500
Epoch 19/70
Train Loss: 1.0885, Accuracy: 0.6092, Precision: 0.2950, Recall: 0.3087, F1: 0.2963
Validation Loss: 1.1853, Accuracy: 0.5852, Precision: 0.2920, Recall: 0.3133, F1: 0.2968
Testing Loss: 1.1317, Accuracy: 0.6064, Precision: 0.2910, Recall: 0.3232, F1: 0.3030
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 2, 5, 4, 4, 5, 2, 2, 2, 5, 5, 4, 4, 2, 5, 2, 5, 2, 2, 5, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4852, Accuracy: 0.2143, Precision: 0.1262, Recall: 0.2250, F1: 0.1511
Epoch 20/70
Train Loss: 1.0183, Accuracy: 0.6347, Precision: 0.3005, Recall: 0.3238, F1: 0.3094
Validation Loss: 1.1676, Accuracy: 0.6051, Precision: 0.2737, Recall: 0.2949, F1: 0.2654
Testing Loss: 1.2693, Accuracy: 0.6250, Precision: 0.3158, Recall: 0.3093, F1: 0.2867
LM Predictions:  [4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 5, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4706, Accuracy: 0.2857, Precision: 0.1227, Recall: 0.2333, F1: 0.1569
Epoch 21/70
Train Loss: 0.9921, Accuracy: 0.6501, Precision: 0.3125, Recall: 0.3366, F1: 0.3223
Validation Loss: 1.1443, Accuracy: 0.6023, Precision: 0.2946, Recall: 0.3382, F1: 0.3099
Testing Loss: 1.1569, Accuracy: 0.6489, Precision: 0.3080, Recall: 0.3565, F1: 0.3274
LM Predictions:  [5, 2, 2, 5, 2, 5, 5, 5, 5, 4, 5, 5, 2, 2, 2, 5, 4, 4, 4, 5, 5, 4, 5, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4323, Accuracy: 0.2500, Precision: 0.1786, Recall: 0.2417, F1: 0.1873
Epoch 22/70
Train Loss: 0.9709, Accuracy: 0.6571, Precision: 0.3166, Recall: 0.3410, F1: 0.3267
Validation Loss: 1.1194, Accuracy: 0.5909, Precision: 0.3250, Recall: 0.3511, F1: 0.3154
Testing Loss: 1.0803, Accuracy: 0.6011, Precision: 0.3193, Recall: 0.3537, F1: 0.3166
LM Predictions:  [5, 2, 5, 5, 2, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4962, Accuracy: 0.1786, Precision: 0.1686, Recall: 0.2083, F1: 0.1244
Epoch 23/70
Train Loss: 0.9470, Accuracy: 0.6547, Precision: 0.4802, Recall: 0.3420, F1: 0.3283
Validation Loss: 0.9785, Accuracy: 0.6335, Precision: 0.2929, Recall: 0.3301, F1: 0.3093
Testing Loss: 1.0561, Accuracy: 0.6489, Precision: 0.3044, Recall: 0.3450, F1: 0.3226
LM Predictions:  [4, 2, 2, 4, 2, 5, 5, 2, 4, 4, 5, 5, 2, 2, 2, 5, 5, 4, 4, 2, 4, 2, 5, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3411, Accuracy: 0.2143, Precision: 0.1268, Recall: 0.2000, F1: 0.1514
Epoch 24/70
Train Loss: 0.9089, Accuracy: 0.6781, Precision: 0.4918, Recall: 0.3554, F1: 0.3428
Validation Loss: 0.9611, Accuracy: 0.6420, Precision: 0.3135, Recall: 0.3610, F1: 0.3317
Testing Loss: 0.9758, Accuracy: 0.6649, Precision: 0.3843, Recall: 0.3746, F1: 0.3553
LM Predictions:  [5, 2, 3, 5, 2, 5, 5, 5, 5, 4, 5, 5, 2, 2, 2, 5, 5, 4, 4, 5, 5, 4, 5, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2189, Accuracy: 0.1786, Precision: 0.1127, Recall: 0.1528, F1: 0.1120
Epoch 25/70
Train Loss: 0.8832, Accuracy: 0.6802, Precision: 0.4749, Recall: 0.3655, F1: 0.3567
Validation Loss: 1.0797, Accuracy: 0.6222, Precision: 0.3149, Recall: 0.3607, F1: 0.3225
Testing Loss: 1.0855, Accuracy: 0.6356, Precision: 0.3141, Recall: 0.3587, F1: 0.3246
LM Predictions:  [5, 2, 2, 5, 2, 5, 5, 5, 5, 4, 5, 5, 5, 4, 2, 5, 5, 4, 4, 5, 5, 4, 5, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2445, Accuracy: 0.2500, Precision: 0.1917, Recall: 0.2417, F1: 0.1924
Epoch 26/70
Train Loss: 0.8572, Accuracy: 0.6945, Precision: 0.4025, Recall: 0.3709, F1: 0.3596
Validation Loss: 0.8856, Accuracy: 0.6761, Precision: 0.4999, Recall: 0.3883, F1: 0.3652
Testing Loss: 0.9414, Accuracy: 0.6676, Precision: 0.4849, Recall: 0.3790, F1: 0.3598
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 5, 5, 4, 5, 5, 2, 2, 2, 5, 5, 4, 4, 5, 3, 2, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1282, Accuracy: 0.2143, Precision: 0.1246, Recall: 0.2014, F1: 0.1275
Epoch 27/70
Train Loss: 0.8384, Accuracy: 0.7054, Precision: 0.4672, Recall: 0.3780, F1: 0.3657
Validation Loss: 0.9513, Accuracy: 0.6676, Precision: 0.3472, Recall: 0.3856, F1: 0.3523
Testing Loss: 0.9318, Accuracy: 0.6676, Precision: 0.4604, Recall: 0.3981, F1: 0.3759
LM Predictions:  [5, 2, 2, 5, 2, 5, 5, 5, 5, 2, 5, 5, 2, 2, 2, 5, 5, 5, 4, 5, 5, 2, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3774, Accuracy: 0.2143, Precision: 0.2312, Recall: 0.2014, F1: 0.1287
Epoch 28/70
Train Loss: 0.8380, Accuracy: 0.7008, Precision: 0.4313, Recall: 0.3821, F1: 0.3750
Validation Loss: 0.9369, Accuracy: 0.6591, Precision: 0.3296, Recall: 0.3559, F1: 0.3363
Testing Loss: 0.9121, Accuracy: 0.6755, Precision: 0.4985, Recall: 0.3731, F1: 0.3552
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 3, 2, 2, 5, 5, 2, 2, 2, 5, 2, 2, 4, 5, 5, 2, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3702, Accuracy: 0.2143, Precision: 0.2359, Recall: 0.2014, F1: 0.1370
Epoch 29/70
Train Loss: 0.7946, Accuracy: 0.7211, Precision: 0.5196, Recall: 0.4022, F1: 0.3983
Validation Loss: 0.8586, Accuracy: 0.6761, Precision: 0.4219, Recall: 0.4092, F1: 0.3996
Testing Loss: 0.8814, Accuracy: 0.6835, Precision: 0.3998, Recall: 0.3996, F1: 0.3914
LM Predictions:  [3, 2, 2, 5, 2, 5, 5, 3, 5, 1, 5, 5, 3, 2, 2, 5, 5, 4, 4, 5, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0046, Accuracy: 0.2500, Precision: 0.2004, Recall: 0.2222, F1: 0.1744
Epoch 30/70
Train Loss: 0.7662, Accuracy: 0.7271, Precision: 0.5085, Recall: 0.4076, F1: 0.4056
Validation Loss: 0.8802, Accuracy: 0.6932, Precision: 0.3306, Recall: 0.3553, F1: 0.3373
Testing Loss: 0.9135, Accuracy: 0.6809, Precision: 0.4922, Recall: 0.3621, F1: 0.3537
LM Predictions:  [2, 2, 2, 4, 2, 5, 5, 3, 2, 4, 2, 5, 2, 2, 2, 5, 2, 4, 4, 2, 4, 2, 5, 2, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0335, Accuracy: 0.1786, Precision: 0.0944, Recall: 0.1458, F1: 0.1066
Epoch 31/70
Train Loss: 0.7722, Accuracy: 0.7215, Precision: 0.4906, Recall: 0.4032, F1: 0.3982
Validation Loss: 0.9034, Accuracy: 0.6733, Precision: 0.3972, Recall: 0.3848, F1: 0.3815
Testing Loss: 0.8705, Accuracy: 0.6862, Precision: 0.4009, Recall: 0.3821, F1: 0.3739
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 3, 5, 3, 2, 5, 2, 2, 2, 5, 3, 5, 4, 3, 2, 2, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2829, Accuracy: 0.2857, Precision: 0.2722, Recall: 0.2569, F1: 0.1825
Epoch 32/70
Train Loss: 0.7410, Accuracy: 0.7341, Precision: 0.5183, Recall: 0.4215, F1: 0.4234
Validation Loss: 0.8512, Accuracy: 0.7074, Precision: 0.4727, Recall: 0.3964, F1: 0.3971
Testing Loss: 0.8356, Accuracy: 0.7154, Precision: 0.4126, Recall: 0.4041, F1: 0.4014
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 3, 2, 4, 2, 3, 2, 2, 2, 5, 3, 4, 4, 3, 2, 4, 2, 2, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1185, Accuracy: 0.2857, Precision: 0.1762, Recall: 0.2222, F1: 0.1759
Epoch 33/70
Train Loss: 0.7056, Accuracy: 0.7470, Precision: 0.5459, Recall: 0.4364, F1: 0.4405
Validation Loss: 0.9996, Accuracy: 0.6477, Precision: 0.3850, Recall: 0.4199, F1: 0.3858
Testing Loss: 0.8969, Accuracy: 0.6941, Precision: 0.4227, Recall: 0.4641, F1: 0.4307
LM Predictions:  [3, 5, 3, 5, 3, 5, 5, 3, 3, 3, 5, 3, 3, 3, 5, 5, 3, 5, 4, 3, 3, 3, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4853, Accuracy: 0.1429, Precision: 0.2803, Recall: 0.1319, F1: 0.1231
Epoch 34/70
Train Loss: 0.7133, Accuracy: 0.7383, Precision: 0.4861, Recall: 0.4359, F1: 0.4360
Validation Loss: 0.8527, Accuracy: 0.6875, Precision: 0.4495, Recall: 0.4017, F1: 0.3933
Testing Loss: 0.8395, Accuracy: 0.7154, Precision: 0.4681, Recall: 0.4370, F1: 0.4287
LM Predictions:  [2, 5, 2, 5, 4, 5, 5, 3, 5, 4, 5, 3, 2, 4, 5, 5, 5, 5, 4, 5, 2, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0282, Accuracy: 0.3214, Precision: 0.2405, Recall: 0.2500, F1: 0.2229
Epoch 35/70
Train Loss: 0.6925, Accuracy: 0.7488, Precision: 0.5089, Recall: 0.4543, F1: 0.4638
Validation Loss: 0.8893, Accuracy: 0.6875, Precision: 0.5404, Recall: 0.3946, F1: 0.3900
Testing Loss: 0.8349, Accuracy: 0.7261, Precision: 0.4179, Recall: 0.4258, F1: 0.4143
LM Predictions:  [3, 2, 2, 5, 2, 3, 5, 3, 5, 3, 2, 3, 2, 2, 5, 5, 5, 5, 4, 5, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1276, Accuracy: 0.2500, Precision: 0.2595, Recall: 0.2083, F1: 0.1825
Epoch 36/70
Train Loss: 0.6704, Accuracy: 0.7565, Precision: 0.5003, Recall: 0.4599, F1: 0.4630
Validation Loss: 0.8800, Accuracy: 0.6733, Precision: 0.4596, Recall: 0.4336, F1: 0.4163
Testing Loss: 0.8429, Accuracy: 0.7207, Precision: 0.4688, Recall: 0.4695, F1: 0.4650
LM Predictions:  [3, 5, 2, 3, 3, 3, 5, 3, 3, 3, 5, 3, 3, 4, 2, 5, 3, 4, 4, 3, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1504, Accuracy: 0.2143, Precision: 0.2599, Recall: 0.1597, F1: 0.1877
Epoch 37/70
Train Loss: 0.6434, Accuracy: 0.7649, Precision: 0.5383, Recall: 0.4633, F1: 0.4670
Validation Loss: 0.9754, Accuracy: 0.6477, Precision: 0.3816, Recall: 0.3999, F1: 0.3826
Testing Loss: 0.9787, Accuracy: 0.6888, Precision: 0.4471, Recall: 0.4250, F1: 0.4106
LM Predictions:  [4, 5, 2, 4, 4, 1, 5, 3, 1, 4, 1, 3, 1, 4, 5, 5, 1, 4, 4, 1, 4, 4, 4, 4, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9888, Accuracy: 0.3571, Precision: 0.3258, Recall: 0.3681, F1: 0.2877
Epoch 38/70
Train Loss: 0.6435, Accuracy: 0.7768, Precision: 0.5387, Recall: 0.4934, F1: 0.5003
Validation Loss: 0.8121, Accuracy: 0.7102, Precision: 0.4770, Recall: 0.4053, F1: 0.4028
Testing Loss: 0.8335, Accuracy: 0.7314, Precision: 0.4681, Recall: 0.4678, F1: 0.4647
LM Predictions:  [3, 5, 2, 5, 2, 1, 5, 3, 5, 1, 2, 3, 2, 4, 2, 5, 5, 4, 4, 3, 2, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9216, Accuracy: 0.3571, Precision: 0.3287, Recall: 0.3403, F1: 0.3132
Epoch 39/70
Train Loss: 0.6188, Accuracy: 0.7785, Precision: 0.5306, Recall: 0.4902, F1: 0.4949
Validation Loss: 0.9540, Accuracy: 0.7017, Precision: 0.4008, Recall: 0.3957, F1: 0.3773
Testing Loss: 0.9132, Accuracy: 0.7287, Precision: 0.4325, Recall: 0.4341, F1: 0.4168
LM Predictions:  [3, 5, 2, 5, 2, 5, 5, 5, 5, 4, 5, 3, 2, 2, 5, 5, 5, 5, 4, 5, 2, 2, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9993, Accuracy: 0.2143, Precision: 0.1681, Recall: 0.1875, F1: 0.1398
Epoch 40/70
Train Loss: 0.6002, Accuracy: 0.7848, Precision: 0.5299, Recall: 0.4845, F1: 0.4860
Validation Loss: 1.0268, Accuracy: 0.7074, Precision: 0.5308, Recall: 0.3946, F1: 0.3941
Testing Loss: 1.0113, Accuracy: 0.7314, Precision: 0.4217, Recall: 0.4138, F1: 0.4096
LM Predictions:  [3, 2, 2, 4, 4, 4, 5, 3, 5, 4, 2, 3, 2, 4, 5, 5, 4, 4, 4, 3, 2, 4, 5, 2, 2, 5, 4, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1271, Accuracy: 0.3214, Precision: 0.1786, Recall: 0.2153, F1: 0.1952
Epoch 41/70
Train Loss: 0.6098, Accuracy: 0.7894, Precision: 0.5623, Recall: 0.5103, F1: 0.5174
Validation Loss: 0.9466, Accuracy: 0.6477, Precision: 0.4211, Recall: 0.4077, F1: 0.3895
Testing Loss: 0.9025, Accuracy: 0.7101, Precision: 0.4618, Recall: 0.4441, F1: 0.4288
LM Predictions:  [3, 5, 5, 5, 3, 5, 5, 5, 5, 1, 5, 3, 1, 4, 5, 5, 5, 5, 4, 5, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1641, Accuracy: 0.2500, Precision: 0.4375, Recall: 0.2569, F1: 0.2552
Epoch 42/70
Train Loss: 0.5936, Accuracy: 0.7939, Precision: 0.5536, Recall: 0.5020, F1: 0.5097
Validation Loss: 0.9484, Accuracy: 0.7074, Precision: 0.5525, Recall: 0.4281, F1: 0.4127
Testing Loss: 0.8841, Accuracy: 0.7287, Precision: 0.4719, Recall: 0.4440, F1: 0.4237
LM Predictions:  [5, 5, 2, 5, 4, 5, 5, 5, 5, 5, 5, 3, 2, 2, 5, 5, 5, 5, 4, 5, 2, 4, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0360, Accuracy: 0.3214, Precision: 0.2778, Recall: 0.2708, F1: 0.2197
Epoch 43/70
Train Loss: 0.5600, Accuracy: 0.8006, Precision: 0.5486, Recall: 0.5245, F1: 0.5285
Validation Loss: 1.0044, Accuracy: 0.7045, Precision: 0.5587, Recall: 0.4234, F1: 0.4163
Testing Loss: 0.9093, Accuracy: 0.7314, Precision: 0.4373, Recall: 0.4364, F1: 0.4243
LM Predictions:  [3, 5, 2, 5, 4, 4, 5, 3, 5, 4, 2, 3, 3, 4, 5, 5, 4, 5, 4, 3, 2, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.7549, Accuracy: 0.3929, Precision: 0.2857, Recall: 0.2986, F1: 0.2799
Epoch 44/70
Train Loss: 0.5401, Accuracy: 0.8072, Precision: 0.5797, Recall: 0.5464, F1: 0.5549
Validation Loss: 0.9252, Accuracy: 0.7188, Precision: 0.4888, Recall: 0.4584, F1: 0.4469
Testing Loss: 0.8622, Accuracy: 0.7500, Precision: 0.4824, Recall: 0.4803, F1: 0.4720
LM Predictions:  [3, 1, 2, 3, 4, 3, 5, 3, 3, 4, 2, 3, 3, 4, 2, 5, 4, 4, 4, 3, 2, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.7857, Accuracy: 0.3571, Precision: 0.2857, Recall: 0.2569, F1: 0.2694
Epoch 45/70
Train Loss: 0.5232, Accuracy: 0.8149, Precision: 0.5653, Recall: 0.5433, F1: 0.5467
Validation Loss: 0.9847, Accuracy: 0.6847, Precision: 0.5812, Recall: 0.4465, F1: 0.4377
Testing Loss: 0.8930, Accuracy: 0.7314, Precision: 0.4465, Recall: 0.4659, F1: 0.4443
LM Predictions:  [3, 5, 2, 5, 4, 5, 5, 3, 3, 5, 5, 3, 3, 4, 5, 5, 5, 5, 4, 5, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8628, Accuracy: 0.3214, Precision: 0.3690, Recall: 0.2639, F1: 0.2500
Epoch 46/70
Train Loss: 0.5243, Accuracy: 0.8202, Precision: 0.5858, Recall: 0.5574, F1: 0.5643
Validation Loss: 0.8579, Accuracy: 0.7131, Precision: 0.4649, Recall: 0.4664, F1: 0.4446
Testing Loss: 0.8072, Accuracy: 0.7420, Precision: 0.5059, Recall: 0.5023, F1: 0.4869
LM Predictions:  [3, 2, 2, 3, 4, 3, 5, 3, 3, 3, 2, 3, 3, 3, 5, 5, 3, 5, 4, 3, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9219, Accuracy: 0.2500, Precision: 0.3155, Recall: 0.1875, F1: 0.2212
Epoch 47/70
Train Loss: 0.5143, Accuracy: 0.8181, Precision: 0.5744, Recall: 0.5602, F1: 0.5621
Validation Loss: 0.8517, Accuracy: 0.7358, Precision: 0.5284, Recall: 0.4734, F1: 0.4569
Testing Loss: 0.7991, Accuracy: 0.7447, Precision: 0.4398, Recall: 0.4710, F1: 0.4501
LM Predictions:  [3, 2, 2, 3, 4, 3, 5, 3, 3, 3, 2, 3, 3, 3, 5, 5, 3, 5, 4, 3, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9187, Accuracy: 0.2500, Precision: 0.3155, Recall: 0.1875, F1: 0.2212
Epoch 48/70
Train Loss: 0.5080, Accuracy: 0.8202, Precision: 0.5919, Recall: 0.5566, F1: 0.5641
Validation Loss: 0.9077, Accuracy: 0.7159, Precision: 0.4562, Recall: 0.4672, F1: 0.4565
Testing Loss: 0.8391, Accuracy: 0.7420, Precision: 0.4790, Recall: 0.4888, F1: 0.4830
LM Predictions:  [3, 1, 2, 3, 4, 3, 5, 3, 3, 1, 2, 3, 3, 4, 5, 5, 3, 5, 4, 3, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6053, Accuracy: 0.2857, Precision: 0.3571, Recall: 0.2083, F1: 0.2525
Epoch 49/70
Train Loss: 0.4664, Accuracy: 0.8338, Precision: 0.7815, Recall: 0.5994, F1: 0.6110
Validation Loss: 0.9686, Accuracy: 0.7131, Precision: 0.4505, Recall: 0.4617, F1: 0.4549
Testing Loss: 0.9042, Accuracy: 0.7447, Precision: 0.4883, Recall: 0.4933, F1: 0.4904
LM Predictions:  [4, 1, 2, 3, 4, 3, 5, 3, 3, 1, 1, 3, 3, 4, 5, 5, 4, 0, 4, 3, 2, 4, 5, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.3745, Accuracy: 0.3929, Precision: 0.5333, Recall: 0.2708, F1: 0.3280
Epoch 50/70
Train Loss: 0.4687, Accuracy: 0.8261, Precision: 0.6581, Recall: 0.5852, F1: 0.5974
Validation Loss: 0.8835, Accuracy: 0.7330, Precision: 0.5024, Recall: 0.4648, F1: 0.4765
Testing Loss: 0.8716, Accuracy: 0.7287, Precision: 0.4803, Recall: 0.4350, F1: 0.4371
LM Predictions:  [4, 1, 2, 5, 4, 1, 5, 2, 3, 1, 2, 3, 2, 4, 5, 5, 4, 5, 4, 1, 2, 4, 2, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2076, Accuracy: 0.5357, Precision: 0.3988, Recall: 0.4583, F1: 0.4129
Epoch 51/70
Train Loss: 0.4380, Accuracy: 0.8488, Precision: 0.7203, Recall: 0.6094, F1: 0.6222
Validation Loss: 0.9274, Accuracy: 0.7159, Precision: 0.4697, Recall: 0.4776, F1: 0.4616
Testing Loss: 0.8273, Accuracy: 0.7580, Precision: 0.5360, Recall: 0.5002, F1: 0.4970
LM Predictions:  [3, 2, 2, 3, 4, 3, 5, 3, 3, 4, 2, 3, 3, 4, 2, 5, 3, 5, 4, 3, 2, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8421, Accuracy: 0.3571, Precision: 0.2940, Recall: 0.2639, F1: 0.2724
Epoch 52/70
Train Loss: 0.4240, Accuracy: 0.8534, Precision: 0.6741, Recall: 0.6206, F1: 0.6270
Validation Loss: 0.9083, Accuracy: 0.7188, Precision: 0.4703, Recall: 0.4929, F1: 0.4680
Testing Loss: 0.8181, Accuracy: 0.7447, Precision: 0.5013, Recall: 0.4975, F1: 0.4935
LM Predictions:  [3, 1, 2, 3, 4, 3, 5, 3, 3, 3, 2, 3, 3, 4, 0, 5, 3, 0, 4, 3, 2, 4, 5, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4800, Accuracy: 0.3929, Precision: 0.5417, Recall: 0.2778, F1: 0.3528
Epoch 53/70
Train Loss: 0.4257, Accuracy: 0.8422, Precision: 0.7373, Recall: 0.6286, F1: 0.6507
Validation Loss: 0.9659, Accuracy: 0.7216, Precision: 0.5215, Recall: 0.4689, F1: 0.4747
Testing Loss: 0.9145, Accuracy: 0.7473, Precision: 0.4727, Recall: 0.4610, F1: 0.4501
LM Predictions:  [4, 1, 2, 5, 4, 3, 5, 3, 5, 5, 5, 5, 1, 4, 5, 5, 4, 5, 4, 3, 2, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.1203, Accuracy: 0.5000, Precision: 0.4722, Recall: 0.4583, F1: 0.4206
Epoch 54/70
Train Loss: 0.4162, Accuracy: 0.8492, Precision: 0.7414, Recall: 0.6374, F1: 0.6580
Validation Loss: 0.8968, Accuracy: 0.7188, Precision: 0.4681, Recall: 0.4990, F1: 0.4759
Testing Loss: 0.8430, Accuracy: 0.7420, Precision: 0.4908, Recall: 0.5208, F1: 0.5026
LM Predictions:  [3, 1, 2, 3, 4, 3, 1, 3, 3, 3, 2, 3, 3, 4, 3, 1, 3, 5, 4, 3, 2, 4, 5, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9586, Accuracy: 0.3214, Precision: 0.3889, Recall: 0.2361, F1: 0.2921
Epoch 55/70
Train Loss: 0.4051, Accuracy: 0.8548, Precision: 0.6990, Recall: 0.6374, F1: 0.6462
Validation Loss: 0.8929, Accuracy: 0.7273, Precision: 0.4962, Recall: 0.4849, F1: 0.4858
Testing Loss: 0.8347, Accuracy: 0.7527, Precision: 0.5062, Recall: 0.4954, F1: 0.4896
LM Predictions:  [3, 1, 2, 5, 4, 3, 5, 3, 0, 5, 2, 5, 1, 4, 5, 5, 3, 5, 4, 3, 2, 4, 5, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2263, Accuracy: 0.5000, Precision: 0.6574, Recall: 0.4653, F1: 0.4674
Epoch 56/70
Train Loss: 0.3808, Accuracy: 0.8639, Precision: 0.7422, Recall: 0.6646, F1: 0.6806
Validation Loss: 1.0845, Accuracy: 0.7301, Precision: 0.5418, Recall: 0.4841, F1: 0.4894
Testing Loss: 0.9809, Accuracy: 0.7394, Precision: 0.4826, Recall: 0.4507, F1: 0.4518
LM Predictions:  [4, 5, 2, 2, 4, 3, 5, 3, 3, 5, 2, 5, 3, 4, 3, 5, 4, 5, 4, 3, 2, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.1395, Accuracy: 0.5000, Precision: 0.3770, Recall: 0.3889, F1: 0.3727
Epoch 57/70
Train Loss: 0.3686, Accuracy: 0.8670, Precision: 0.7558, Recall: 0.6712, F1: 0.6913
Validation Loss: 1.2123, Accuracy: 0.6875, Precision: 0.4648, Recall: 0.4751, F1: 0.4636
Testing Loss: 0.9709, Accuracy: 0.7287, Precision: 0.4819, Recall: 0.4787, F1: 0.4759
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 3, 0, 5, 2, 5, 3, 4, 3, 3, 4, 0, 4, 3, 3, 4, 5, 3, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.0875, Accuracy: 0.6429, Precision: 0.7167, Recall: 0.5417, F1: 0.5891
Epoch 58/70
Train Loss: 0.3667, Accuracy: 0.8691, Precision: 0.7351, Recall: 0.6672, F1: 0.6861
Validation Loss: 1.0397, Accuracy: 0.7131, Precision: 0.4750, Recall: 0.4685, F1: 0.4712
Testing Loss: 0.8998, Accuracy: 0.7447, Precision: 0.4937, Recall: 0.4695, F1: 0.4713
LM Predictions:  [3, 1, 2, 5, 4, 1, 0, 3, 0, 1, 2, 5, 1, 4, 0, 1, 3, 0, 4, 3, 2, 4, 5, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.8531, Accuracy: 0.6786, Precision: 0.6917, Recall: 0.6111, F1: 0.6100
Epoch 59/70
Train Loss: 0.3466, Accuracy: 0.8817, Precision: 0.7955, Recall: 0.7007, F1: 0.7234
Validation Loss: 1.2171, Accuracy: 0.7159, Precision: 0.5861, Recall: 0.5029, F1: 0.4909
Testing Loss: 0.9898, Accuracy: 0.7473, Precision: 0.4404, Recall: 0.4795, F1: 0.4564
LM Predictions:  [4, 5, 2, 5, 4, 3, 0, 3, 3, 3, 2, 5, 3, 4, 0, 3, 3, 0, 4, 3, 3, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.9956, Accuracy: 0.5357, Precision: 0.6250, Recall: 0.4028, F1: 0.4774
Epoch 60/70
Train Loss: 0.3260, Accuracy: 0.8800, Precision: 0.7661, Recall: 0.6989, F1: 0.7195
Validation Loss: 1.3836, Accuracy: 0.6989, Precision: 0.4990, Recall: 0.4455, F1: 0.4541
Testing Loss: 1.2301, Accuracy: 0.7048, Precision: 0.4486, Recall: 0.4134, F1: 0.4168
LM Predictions:  [4, 5, 2, 5, 4, 4, 5, 5, 3, 4, 2, 5, 1, 4, 5, 1, 4, 0, 4, 3, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.7847, Accuracy: 0.6429, Precision: 0.6177, Recall: 0.5347, F1: 0.5297
Epoch 61/70
Train Loss: 0.3202, Accuracy: 0.8852, Precision: 0.7719, Recall: 0.7055, F1: 0.7250
Validation Loss: 1.2781, Accuracy: 0.7017, Precision: 0.4879, Recall: 0.4737, F1: 0.4748
Testing Loss: 1.1101, Accuracy: 0.7234, Precision: 0.4832, Recall: 0.4823, F1: 0.4718
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 3, 0, 1, 2, 5, 1, 4, 0, 1, 3, 0, 4, 3, 2, 4, 5, 0, 2, 3, 1, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.8041, Accuracy: 0.6786, Precision: 0.6667, Recall: 0.5903, F1: 0.5830
Epoch 62/70
Train Loss: 0.3168, Accuracy: 0.8891, Precision: 0.7961, Recall: 0.7318, F1: 0.7517
Validation Loss: 1.0047, Accuracy: 0.7358, Precision: 0.4955, Recall: 0.4887, F1: 0.4915
Testing Loss: 0.9130, Accuracy: 0.7287, Precision: 0.4923, Recall: 0.4830, F1: 0.4818
LM Predictions:  [4, 1, 2, 5, 4, 1, 5, 3, 3, 1, 2, 5, 1, 4, 5, 1, 3, 0, 4, 3, 2, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.9626, Accuracy: 0.5714, Precision: 0.6667, Recall: 0.5556, F1: 0.5231
Epoch 63/70
Train Loss: 0.2777, Accuracy: 0.8950, Precision: 0.7563, Recall: 0.7274, F1: 0.7384
Validation Loss: 1.2043, Accuracy: 0.7472, Precision: 0.5680, Recall: 0.5082, F1: 0.5281
Testing Loss: 1.0907, Accuracy: 0.7314, Precision: 0.5083, Recall: 0.4604, F1: 0.4684
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 3, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5205, Accuracy: 0.8571, Precision: 0.7778, Recall: 0.7431, F1: 0.7499
Epoch 64/70
Train Loss: 0.2818, Accuracy: 0.8961, Precision: 0.8167, Recall: 0.7511, F1: 0.7726
Validation Loss: 1.2958, Accuracy: 0.7045, Precision: 0.4823, Recall: 0.4860, F1: 0.4752
Testing Loss: 1.1017, Accuracy: 0.7394, Precision: 0.4938, Recall: 0.4950, F1: 0.4891
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 3, 3, 5, 2, 5, 3, 4, 0, 0, 4, 0, 4, 0, 3, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.7124, Accuracy: 0.7857, Precision: 0.7500, Recall: 0.6319, F1: 0.6817
Epoch 65/70
Train Loss: 0.2686, Accuracy: 0.9055, Precision: 0.8173, Recall: 0.7664, F1: 0.7848
Validation Loss: 1.1843, Accuracy: 0.7330, Precision: 0.5151, Recall: 0.4806, F1: 0.4834
Testing Loss: 1.0543, Accuracy: 0.7500, Precision: 0.5220, Recall: 0.4679, F1: 0.4715
LM Predictions:  [4, 5, 2, 5, 4, 1, 0, 3, 0, 5, 2, 5, 3, 4, 0, 0, 3, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5271, Accuracy: 0.8214, Precision: 0.8000, Recall: 0.6597, F1: 0.7092
Epoch 66/70
Train Loss: 0.2522, Accuracy: 0.9055, Precision: 0.8065, Recall: 0.7566, F1: 0.7736
Validation Loss: 1.1773, Accuracy: 0.7244, Precision: 0.4777, Recall: 0.4696, F1: 0.4713
Testing Loss: 1.0437, Accuracy: 0.7340, Precision: 0.4881, Recall: 0.4621, F1: 0.4704
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 2, 3, 1, 2, 5, 1, 4, 0, 3, 3, 0, 4, 3, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.6650, Accuracy: 0.7500, Precision: 0.7500, Recall: 0.6667, F1: 0.6746
Epoch 67/70
Train Loss: 0.2547, Accuracy: 0.9069, Precision: 0.8191, Recall: 0.7813, F1: 0.7959
Validation Loss: 1.2363, Accuracy: 0.7273, Precision: 0.5126, Recall: 0.4660, F1: 0.4734
Testing Loss: 1.0866, Accuracy: 0.7207, Precision: 0.5034, Recall: 0.4469, F1: 0.4594
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 3, 3, 4, 2, 5, 1, 4, 3, 3, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5483, Accuracy: 0.7857, Precision: 0.8148, Recall: 0.6806, F1: 0.7290
Epoch 68/70
Train Loss: 0.2421, Accuracy: 0.9111, Precision: 0.8537, Recall: 0.7880, F1: 0.8088
Validation Loss: 1.2558, Accuracy: 0.7330, Precision: 0.4931, Recall: 0.4835, F1: 0.4865
Testing Loss: 1.0709, Accuracy: 0.7261, Precision: 0.5339, Recall: 0.5002, F1: 0.5075
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 5, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.3652, Accuracy: 0.8929, Precision: 0.7444, Recall: 0.7639, F1: 0.7441
Epoch 69/70
Train Loss: 0.2358, Accuracy: 0.9195, Precision: 0.8435, Recall: 0.8029, F1: 0.8210
Validation Loss: 1.3229, Accuracy: 0.7045, Precision: 0.4979, Recall: 0.4831, F1: 0.4835
Testing Loss: 1.0901, Accuracy: 0.7447, Precision: 0.5101, Recall: 0.4932, F1: 0.4930
LM Predictions:  [4, 1, 2, 5, 4, 1, 0, 5, 0, 5, 2, 5, 1, 4, 3, 0, 4, 0, 4, 0, 3, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.3513, Accuracy: 0.8214, Precision: 0.7444, Recall: 0.7153, F1: 0.7132
Epoch 70/70
Train Loss: 0.2450, Accuracy: 0.9125, Precision: 0.8467, Recall: 0.8132, F1: 0.8262
Validation Loss: 1.2035, Accuracy: 0.7074, Precision: 0.4756, Recall: 0.4448, F1: 0.4538
Testing Loss: 1.0878, Accuracy: 0.7340, Precision: 0.4739, Recall: 0.4437, F1: 0.4512
LM Predictions:  [4, 5, 2, 5, 4, 1, 0, 2, 0, 1, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 3, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.2699, Accuracy: 0.8571, Precision: 0.7361, Recall: 0.7222, F1: 0.7210
For middle layers:  [8, 9, 10, 11, 12, 13, 14, 15]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.6309, Accuracy: 0.3565, Precision: 0.1669, Recall: 0.1694, F1: 0.1554
Validation Loss: 1.4093, Accuracy: 0.3920, Precision: 0.1284, Recall: 0.1805, F1: 0.1477
Testing Loss: 1.4418, Accuracy: 0.3537, Precision: 0.1179, Recall: 0.1643, F1: 0.1348
LM Predictions:  [4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0668, Accuracy: 0.2500, Precision: 0.1088, Recall: 0.2083, F1: 0.1346
Epoch 2/70
Train Loss: 1.4247, Accuracy: 0.3635, Precision: 0.1201, Recall: 0.1652, F1: 0.1389
Validation Loss: 1.4174, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4478, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0822, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 3/70
Train Loss: 1.3939, Accuracy: 0.3747, Precision: 0.1233, Recall: 0.1686, F1: 0.1401
Validation Loss: 1.3992, Accuracy: 0.3835, Precision: 0.1634, Recall: 0.1697, F1: 0.0999
Testing Loss: 1.4219, Accuracy: 0.3856, Precision: 0.1841, Recall: 0.1780, F1: 0.1146
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1606, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 4/70
Train Loss: 1.3930, Accuracy: 0.3712, Precision: 0.1218, Recall: 0.1673, F1: 0.1394
Validation Loss: 1.4122, Accuracy: 0.3807, Precision: 0.2298, Recall: 0.1681, F1: 0.0944
Testing Loss: 1.4426, Accuracy: 0.3697, Precision: 0.2274, Recall: 0.1704, F1: 0.0964
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0990, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 5/70
Train Loss: 1.3858, Accuracy: 0.3880, Precision: 0.1277, Recall: 0.1738, F1: 0.1431
Validation Loss: 1.4162, Accuracy: 0.3324, Precision: 0.0556, Recall: 0.1667, F1: 0.0833
Testing Loss: 1.4261, Accuracy: 0.3537, Precision: 0.0590, Recall: 0.1667, F1: 0.0871
LM Predictions:  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2093, Accuracy: 0.2857, Precision: 0.0571, Recall: 0.2000, F1: 0.0889
Epoch 6/70
Train Loss: 1.3821, Accuracy: 0.3901, Precision: 0.1292, Recall: 0.1762, F1: 0.1475
Validation Loss: 1.4038, Accuracy: 0.4062, Precision: 0.1376, Recall: 0.1944, F1: 0.1560
Testing Loss: 1.4225, Accuracy: 0.4016, Precision: 0.1394, Recall: 0.1881, F1: 0.1479
LM Predictions:  [4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0541, Accuracy: 0.2857, Precision: 0.1083, Recall: 0.2167, F1: 0.1444
Epoch 7/70
Train Loss: 1.3904, Accuracy: 0.3894, Precision: 0.1283, Recall: 0.1761, F1: 0.1475
Validation Loss: 1.4450, Accuracy: 0.3324, Precision: 0.0554, Recall: 0.1667, F1: 0.0832
Testing Loss: 1.4708, Accuracy: 0.3537, Precision: 0.0590, Recall: 0.1667, F1: 0.0871
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2536, Accuracy: 0.2500, Precision: 0.0519, Recall: 0.1750, F1: 0.0800
Epoch 8/70
Train Loss: 1.3824, Accuracy: 0.3978, Precision: 0.1321, Recall: 0.1800, F1: 0.1510
Validation Loss: 1.3792, Accuracy: 0.4119, Precision: 0.1399, Recall: 0.1985, F1: 0.1555
Testing Loss: 1.4083, Accuracy: 0.4122, Precision: 0.1389, Recall: 0.1928, F1: 0.1556
LM Predictions:  [4, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1455, Accuracy: 0.2500, Precision: 0.1015, Recall: 0.2000, F1: 0.1333
Epoch 9/70
Train Loss: 1.3575, Accuracy: 0.4265, Precision: 0.1436, Recall: 0.1929, F1: 0.1623
Validation Loss: 1.3403, Accuracy: 0.5739, Precision: 0.2208, Recall: 0.2665, F1: 0.2296
Testing Loss: 1.3689, Accuracy: 0.5452, Precision: 0.2146, Recall: 0.2533, F1: 0.2152
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1783, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 10/70
Train Loss: 1.3302, Accuracy: 0.4675, Precision: 0.1593, Recall: 0.2126, F1: 0.1802
Validation Loss: 1.2728, Accuracy: 0.5284, Precision: 0.1748, Recall: 0.2519, F1: 0.2047
Testing Loss: 1.2874, Accuracy: 0.5186, Precision: 0.1713, Recall: 0.2422, F1: 0.2000
LM Predictions:  [4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1358, Accuracy: 0.2500, Precision: 0.1048, Recall: 0.2167, F1: 0.1274
Epoch 11/70
Train Loss: 1.2078, Accuracy: 0.5521, Precision: 0.3599, Recall: 0.2516, F1: 0.2157
Validation Loss: 1.1895, Accuracy: 0.5199, Precision: 0.1717, Recall: 0.2485, F1: 0.2004
Testing Loss: 1.1685, Accuracy: 0.5452, Precision: 0.1798, Recall: 0.2547, F1: 0.2092
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 4, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1512, Accuracy: 0.1429, Precision: 0.0700, Recall: 0.1167, F1: 0.0808
Epoch 12/70
Train Loss: 1.0998, Accuracy: 0.6001, Precision: 0.2159, Recall: 0.2735, F1: 0.2360
Validation Loss: 1.0669, Accuracy: 0.6023, Precision: 0.2021, Recall: 0.2849, F1: 0.2364
Testing Loss: 1.0586, Accuracy: 0.6090, Precision: 0.2065, Recall: 0.2841, F1: 0.2388
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0560, Accuracy: 0.2500, Precision: 0.1417, Recall: 0.2167, F1: 0.1333
Epoch 13/70
Train Loss: 0.9957, Accuracy: 0.6417, Precision: 0.3243, Recall: 0.2950, F1: 0.2605
Validation Loss: 0.9271, Accuracy: 0.6619, Precision: 0.2337, Recall: 0.3112, F1: 0.2645
Testing Loss: 0.9257, Accuracy: 0.6676, Precision: 0.2368, Recall: 0.3110, F1: 0.2649
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2337, Accuracy: 0.2500, Precision: 0.2444, Recall: 0.2250, F1: 0.1172
Epoch 14/70
Train Loss: 0.9050, Accuracy: 0.6802, Precision: 0.3480, Recall: 0.3260, F1: 0.3088
Validation Loss: 0.7824, Accuracy: 0.7188, Precision: 0.3385, Recall: 0.3754, F1: 0.3546
Testing Loss: 0.7938, Accuracy: 0.7500, Precision: 0.3623, Recall: 0.4017, F1: 0.3783
LM Predictions:  [5, 5, 5, 5, 2, 5, 2, 2, 5, 5, 2, 5, 2, 4, 2, 2, 5, 5, 2, 2, 2, 2, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2722, Accuracy: 0.2857, Precision: 0.3033, Recall: 0.3083, F1: 0.1950
Epoch 15/70
Train Loss: 0.7500, Accuracy: 0.7302, Precision: 0.5853, Recall: 0.3960, F1: 0.3910
Validation Loss: 0.7308, Accuracy: 0.7301, Precision: 0.5316, Recall: 0.4252, F1: 0.3927
Testing Loss: 0.7177, Accuracy: 0.7580, Precision: 0.3739, Recall: 0.4335, F1: 0.3911
LM Predictions:  [5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2916, Accuracy: 0.2857, Precision: 0.3364, Recall: 0.3167, F1: 0.2215
Epoch 16/70
Train Loss: 0.6803, Accuracy: 0.7638, Precision: 0.5084, Recall: 0.4286, F1: 0.4195
Validation Loss: 0.6959, Accuracy: 0.7585, Precision: 0.5794, Recall: 0.4422, F1: 0.4483
Testing Loss: 0.6605, Accuracy: 0.7952, Precision: 0.6336, Recall: 0.4893, F1: 0.4973
LM Predictions:  [5, 5, 5, 5, 3, 5, 5, 2, 5, 5, 1, 5, 2, 4, 5, 5, 5, 5, 4, 5, 5, 1, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1809, Accuracy: 0.2500, Precision: 0.2611, Recall: 0.2222, F1: 0.1727
Epoch 17/70
Train Loss: 0.6289, Accuracy: 0.7838, Precision: 0.5837, Recall: 0.4778, F1: 0.4864
Validation Loss: 0.6342, Accuracy: 0.7983, Precision: 0.6572, Recall: 0.5481, F1: 0.5514
Testing Loss: 0.6130, Accuracy: 0.7926, Precision: 0.5638, Recall: 0.5020, F1: 0.4968
LM Predictions:  [3, 5, 3, 5, 3, 3, 5, 5, 5, 5, 3, 5, 4, 4, 2, 5, 3, 5, 4, 5, 2, 1, 3, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0767, Accuracy: 0.2857, Precision: 0.2500, Recall: 0.2639, F1: 0.2106
Epoch 18/70
Train Loss: 0.5429, Accuracy: 0.8156, Precision: 0.5783, Recall: 0.5361, F1: 0.5475
Validation Loss: 0.6440, Accuracy: 0.7841, Precision: 0.6340, Recall: 0.5093, F1: 0.5436
Testing Loss: 0.6375, Accuracy: 0.7872, Precision: 0.6142, Recall: 0.5179, F1: 0.5439
LM Predictions:  [3, 5, 2, 3, 3, 3, 2, 2, 3, 1, 3, 5, 3, 4, 2, 5, 3, 3, 4, 2, 2, 1, 3, 3, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1488, Accuracy: 0.2500, Precision: 0.3056, Recall: 0.1944, F1: 0.2095
Epoch 19/70
Train Loss: 0.4873, Accuracy: 0.8422, Precision: 0.7759, Recall: 0.5878, F1: 0.5991
Validation Loss: 0.5943, Accuracy: 0.8040, Precision: 0.6607, Recall: 0.5897, F1: 0.5979
Testing Loss: 0.5807, Accuracy: 0.8191, Precision: 0.6085, Recall: 0.5800, F1: 0.5825
LM Predictions:  [3, 5, 5, 5, 3, 3, 5, 5, 5, 1, 3, 5, 3, 4, 5, 5, 3, 3, 4, 5, 5, 1, 3, 3, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.7898, Accuracy: 0.1786, Precision: 0.3636, Recall: 0.1528, F1: 0.1587
Epoch 20/70
Train Loss: 0.4560, Accuracy: 0.8443, Precision: 0.6135, Recall: 0.6029, F1: 0.6059
Validation Loss: 0.5651, Accuracy: 0.8153, Precision: 0.5922, Recall: 0.5910, F1: 0.5682
Testing Loss: 0.5328, Accuracy: 0.8351, Precision: 0.6181, Recall: 0.6293, F1: 0.6206
LM Predictions:  [3, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 4, 5, 3, 3, 3, 4, 3, 3, 1, 3, 3, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.8296, Accuracy: 0.1071, Precision: 0.3333, Recall: 0.0694, F1: 0.1143
Epoch 21/70
Train Loss: 0.4317, Accuracy: 0.8527, Precision: 0.6168, Recall: 0.6180, F1: 0.6165
Validation Loss: 0.5151, Accuracy: 0.8352, Precision: 0.6334, Recall: 0.6278, F1: 0.6257
Testing Loss: 0.5474, Accuracy: 0.8138, Precision: 0.5935, Recall: 0.5951, F1: 0.5886
LM Predictions:  [3, 5, 3, 3, 3, 3, 5, 2, 5, 1, 3, 5, 3, 4, 5, 5, 3, 3, 4, 5, 3, 1, 3, 3, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5292, Accuracy: 0.1786, Precision: 0.3571, Recall: 0.1389, F1: 0.1803
Epoch 22/70
Train Loss: 0.3834, Accuracy: 0.8747, Precision: 0.8179, Recall: 0.6654, F1: 0.6699
Validation Loss: 0.5133, Accuracy: 0.8352, Precision: 0.6526, Recall: 0.6234, F1: 0.6337
Testing Loss: 0.5723, Accuracy: 0.8218, Precision: 0.6003, Recall: 0.5865, F1: 0.5859
LM Predictions:  [3, 5, 3, 5, 3, 3, 5, 2, 5, 1, 3, 5, 3, 4, 5, 5, 3, 3, 4, 5, 5, 1, 3, 3, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2990, Accuracy: 0.2143, Precision: 0.3148, Recall: 0.1806, F1: 0.1920
Epoch 23/70
Train Loss: 0.3399, Accuracy: 0.8779, Precision: 0.7056, Recall: 0.6632, F1: 0.6637
Validation Loss: 0.6173, Accuracy: 0.8239, Precision: 0.6878, Recall: 0.5892, F1: 0.6181
Testing Loss: 0.6321, Accuracy: 0.8245, Precision: 0.6416, Recall: 0.5766, F1: 0.5969
LM Predictions:  [3, 5, 3, 3, 3, 3, 5, 2, 5, 3, 3, 5, 3, 4, 2, 0, 3, 3, 4, 5, 3, 3, 3, 3, 2, 2, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3045, Accuracy: 0.2143, Precision: 0.4333, Recall: 0.1597, F1: 0.2013
Epoch 24/70
Train Loss: 0.3152, Accuracy: 0.8884, Precision: 0.7537, Recall: 0.6842, F1: 0.6915
Validation Loss: 0.5554, Accuracy: 0.8352, Precision: 0.6431, Recall: 0.6181, F1: 0.6251
Testing Loss: 0.5784, Accuracy: 0.8378, Precision: 0.6258, Recall: 0.5989, F1: 0.6042
LM Predictions:  [3, 5, 3, 3, 3, 3, 5, 2, 5, 3, 3, 5, 3, 4, 5, 5, 3, 3, 4, 5, 3, 1, 3, 3, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2104, Accuracy: 0.1786, Precision: 0.2986, Recall: 0.1389, F1: 0.1685
Epoch 25/70
Train Loss: 0.2852, Accuracy: 0.9090, Precision: 0.8044, Recall: 0.7334, F1: 0.7447
Validation Loss: 0.5961, Accuracy: 0.8239, Precision: 0.6620, Recall: 0.6558, F1: 0.6502
Testing Loss: 0.6102, Accuracy: 0.8298, Precision: 0.6930, Recall: 0.6444, F1: 0.6485
LM Predictions:  [3, 5, 3, 3, 3, 3, 5, 3, 5, 3, 3, 5, 3, 4, 5, 0, 3, 3, 4, 5, 3, 1, 3, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3391, Accuracy: 0.2143, Precision: 0.5417, Recall: 0.1736, F1: 0.2069
Epoch 26/70
Train Loss: 0.2789, Accuracy: 0.9101, Precision: 0.7925, Recall: 0.7496, F1: 0.7586
Validation Loss: 0.6030, Accuracy: 0.8182, Precision: 0.6483, Recall: 0.6228, F1: 0.6283
Testing Loss: 0.5694, Accuracy: 0.8191, Precision: 0.5897, Recall: 0.5944, F1: 0.5844
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 5, 3, 4, 5, 3, 3, 3, 4, 3, 3, 1, 3, 2, 2, 5, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1998, Accuracy: 0.1429, Precision: 0.2833, Recall: 0.1111, F1: 0.1454
Epoch 27/70
Train Loss: 0.2428, Accuracy: 0.9195, Precision: 0.8113, Recall: 0.7642, F1: 0.7721
Validation Loss: 0.7360, Accuracy: 0.8210, Precision: 0.6890, Recall: 0.7545, F1: 0.6867
Testing Loss: 0.7402, Accuracy: 0.8218, Precision: 0.6195, Recall: 0.6448, F1: 0.6183
LM Predictions:  [3, 1, 3, 3, 3, 3, 5, 2, 3, 1, 3, 5, 1, 4, 5, 0, 3, 3, 4, 0, 3, 1, 3, 3, 2, 3, 0, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9369, Accuracy: 0.2857, Precision: 0.5417, Recall: 0.2639, F1: 0.3138
Epoch 28/70
Train Loss: 0.2223, Accuracy: 0.9279, Precision: 0.8333, Recall: 0.7943, F1: 0.8053
Validation Loss: 0.6674, Accuracy: 0.8381, Precision: 0.6934, Recall: 0.6220, F1: 0.6498
Testing Loss: 0.6803, Accuracy: 0.8138, Precision: 0.5884, Recall: 0.5874, F1: 0.5812
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 0, 3, 3, 5, 3, 4, 5, 0, 3, 3, 4, 0, 3, 1, 3, 2, 2, 2, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8289, Accuracy: 0.2857, Precision: 0.4556, Recall: 0.2014, F1: 0.2658
Epoch 29/70
Train Loss: 0.2048, Accuracy: 0.9279, Precision: 0.8254, Recall: 0.7775, F1: 0.7896
Validation Loss: 0.6711, Accuracy: 0.8295, Precision: 0.6860, Recall: 0.7113, F1: 0.6880
Testing Loss: 0.7360, Accuracy: 0.8138, Precision: 0.5932, Recall: 0.6169, F1: 0.5852
LM Predictions:  [3, 1, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5, 1, 4, 0, 0, 3, 3, 4, 0, 3, 1, 3, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8786, Accuracy: 0.3571, Precision: 0.6667, Recall: 0.3264, F1: 0.4028
Epoch 30/70
Train Loss: 0.1675, Accuracy: 0.9419, Precision: 0.8479, Recall: 0.8492, F1: 0.8476
Validation Loss: 0.5984, Accuracy: 0.8438, Precision: 0.6633, Recall: 0.6605, F1: 0.6612
Testing Loss: 0.6623, Accuracy: 0.8245, Precision: 0.6497, Recall: 0.6456, F1: 0.6319
LM Predictions:  [3, 3, 3, 3, 3, 3, 0, 2, 5, 3, 3, 5, 1, 4, 5, 0, 3, 3, 4, 0, 3, 1, 3, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6336, Accuracy: 0.3571, Precision: 0.6500, Recall: 0.3264, F1: 0.3983
Epoch 31/70
Train Loss: 0.1599, Accuracy: 0.9458, Precision: 0.8746, Recall: 0.8409, F1: 0.8505
Validation Loss: 0.8818, Accuracy: 0.8381, Precision: 0.7408, Recall: 0.7276, F1: 0.6944
Testing Loss: 0.8559, Accuracy: 0.8218, Precision: 0.6353, Recall: 0.5911, F1: 0.6099
LM Predictions:  [3, 3, 2, 3, 3, 3, 0, 2, 0, 3, 3, 5, 4, 4, 0, 0, 3, 3, 4, 0, 2, 4, 3, 2, 2, 2, 0, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5675, Accuracy: 0.4643, Precision: 0.5417, Recall: 0.3194, F1: 0.3802
Epoch 32/70
Train Loss: 0.1272, Accuracy: 0.9549, Precision: 0.8887, Recall: 0.8733, F1: 0.8795
Validation Loss: 0.7730, Accuracy: 0.8438, Precision: 0.7269, Recall: 0.7561, F1: 0.7131
Testing Loss: 0.8694, Accuracy: 0.8324, Precision: 0.6170, Recall: 0.6264, F1: 0.6181
LM Predictions:  [3, 3, 2, 3, 3, 3, 0, 2, 0, 3, 3, 5, 1, 4, 0, 0, 3, 3, 4, 0, 3, 1, 3, 3, 2, 2, 0, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4422, Accuracy: 0.4286, Precision: 0.6806, Recall: 0.3542, F1: 0.4357
Epoch 33/70
Train Loss: 0.1169, Accuracy: 0.9566, Precision: 0.8883, Recall: 0.8853, F1: 0.8854
Validation Loss: 0.7856, Accuracy: 0.8267, Precision: 0.6752, Recall: 0.6369, F1: 0.6439
Testing Loss: 0.8519, Accuracy: 0.8245, Precision: 0.6161, Recall: 0.5969, F1: 0.5987
LM Predictions:  [3, 4, 3, 5, 3, 3, 5, 2, 5, 3, 3, 5, 1, 4, 5, 0, 3, 3, 4, 3, 5, 4, 3, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2516, Accuracy: 0.3929, Precision: 0.7292, Recall: 0.3681, F1: 0.4259
Epoch 34/70
Train Loss: 0.1076, Accuracy: 0.9657, Precision: 0.9240, Recall: 0.9005, F1: 0.9106
Validation Loss: 0.7375, Accuracy: 0.8352, Precision: 0.7025, Recall: 0.7561, F1: 0.7049
Testing Loss: 0.7821, Accuracy: 0.8298, Precision: 0.6434, Recall: 0.6481, F1: 0.6343
LM Predictions:  [3, 4, 2, 5, 3, 3, 0, 2, 0, 3, 3, 5, 1, 4, 5, 0, 4, 3, 4, 0, 3, 4, 3, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.9802, Accuracy: 0.5714, Precision: 0.7917, Recall: 0.4792, F1: 0.5865
Epoch 35/70
Train Loss: 0.0806, Accuracy: 0.9738, Precision: 0.9354, Recall: 0.9275, F1: 0.9311
Validation Loss: 1.0133, Accuracy: 0.8494, Precision: 0.7266, Recall: 0.7049, F1: 0.6982
Testing Loss: 0.9595, Accuracy: 0.8484, Precision: 0.6497, Recall: 0.6433, F1: 0.6461
LM Predictions:  [3, 3, 2, 3, 3, 3, 0, 2, 0, 3, 3, 5, 4, 4, 0, 0, 3, 3, 4, 3, 2, 4, 3, 3, 2, 2, 0, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2890, Accuracy: 0.4286, Precision: 0.5583, Recall: 0.2986, F1: 0.3738
Epoch 36/70
Train Loss: 0.0837, Accuracy: 0.9699, Precision: 0.9247, Recall: 0.9167, F1: 0.9199
Validation Loss: 0.9838, Accuracy: 0.8438, Precision: 0.7409, Recall: 0.7151, F1: 0.7081
Testing Loss: 0.9050, Accuracy: 0.8324, Precision: 0.6546, Recall: 0.6398, F1: 0.6453
LM Predictions:  [3, 3, 2, 5, 3, 3, 0, 2, 0, 3, 3, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 3, 2, 2, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.6810, Accuracy: 0.6786, Precision: 0.8056, Recall: 0.5556, F1: 0.6468
Epoch 37/70
Train Loss: 0.0679, Accuracy: 0.9769, Precision: 0.9439, Recall: 0.9340, F1: 0.9380
Validation Loss: 0.9657, Accuracy: 0.8608, Precision: 0.7631, Recall: 0.7829, F1: 0.7454
Testing Loss: 1.0504, Accuracy: 0.8484, Precision: 0.6383, Recall: 0.6440, F1: 0.6389
LM Predictions:  [3, 4, 2, 5, 3, 3, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 3, 0, 4, 0, 2, 4, 2, 0, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5914, Accuracy: 0.7857, Precision: 0.8000, Recall: 0.6458, F1: 0.6926
Epoch 38/70
Train Loss: 0.0711, Accuracy: 0.9738, Precision: 0.9319, Recall: 0.9367, F1: 0.9342
Validation Loss: 0.9890, Accuracy: 0.8494, Precision: 0.7208, Recall: 0.6611, F1: 0.6860
Testing Loss: 1.0688, Accuracy: 0.8511, Precision: 0.6580, Recall: 0.6350, F1: 0.6420
LM Predictions:  [3, 4, 2, 5, 3, 1, 0, 2, 5, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.6144, Accuracy: 0.8214, Precision: 0.7778, Recall: 0.7292, F1: 0.7377
Epoch 39/70
Train Loss: 0.0719, Accuracy: 0.9787, Precision: 0.9571, Recall: 0.9469, F1: 0.9517
Validation Loss: 1.0024, Accuracy: 0.8580, Precision: 0.6932, Recall: 0.6852, F1: 0.6881
Testing Loss: 1.1377, Accuracy: 0.8404, Precision: 0.6300, Recall: 0.6417, F1: 0.6331
LM Predictions:  [3, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5399, Accuracy: 0.8571, Precision: 0.8000, Recall: 0.7500, F1: 0.7652
Epoch 40/70
Train Loss: 0.0604, Accuracy: 0.9776, Precision: 0.9464, Recall: 0.9410, F1: 0.9436
Validation Loss: 1.0581, Accuracy: 0.8352, Precision: 0.7227, Recall: 0.6725, F1: 0.6837
Testing Loss: 1.1166, Accuracy: 0.8404, Precision: 0.6409, Recall: 0.6318, F1: 0.6307
LM Predictions:  [4, 4, 2, 5, 3, 3, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 3, 2, 4, 2, 0, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.3980, Accuracy: 0.8214, Precision: 0.8333, Recall: 0.6667, F1: 0.7302
Epoch 41/70
Train Loss: 0.0456, Accuracy: 0.9864, Precision: 0.9596, Recall: 0.9625, F1: 0.9610
Validation Loss: 1.0961, Accuracy: 0.8324, Precision: 0.6527, Recall: 0.6631, F1: 0.6554
Testing Loss: 1.0902, Accuracy: 0.8404, Precision: 0.7766, Recall: 0.6678, F1: 0.6651
LM Predictions:  [3, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 5, 0, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.4545, Accuracy: 0.8214, Precision: 0.7778, Recall: 0.7222, F1: 0.7353
Epoch 42/70
Train Loss: 0.0437, Accuracy: 0.9857, Precision: 0.9641, Recall: 0.9625, F1: 0.9632
Validation Loss: 1.0484, Accuracy: 0.8438, Precision: 0.6803, Recall: 0.7270, F1: 0.6873
Testing Loss: 1.1677, Accuracy: 0.8351, Precision: 0.6656, Recall: 0.6960, F1: 0.6689
LM Predictions:  [3, 4, 2, 5, 3, 1, 0, 2, 3, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 3, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5994, Accuracy: 0.7500, Precision: 0.8333, Recall: 0.6667, F1: 0.7326
Epoch 43/70
Train Loss: 0.0350, Accuracy: 0.9888, Precision: 0.9679, Recall: 0.9694, F1: 0.9684
Validation Loss: 1.0928, Accuracy: 0.8551, Precision: 0.7342, Recall: 0.7140, F1: 0.7163
Testing Loss: 1.1521, Accuracy: 0.8537, Precision: 0.7292, Recall: 0.6760, F1: 0.6839
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1508, Accuracy: 0.9286, Precision: 0.8333, Recall: 0.7917, F1: 0.8111
Epoch 44/70
Train Loss: 0.0340, Accuracy: 0.9892, Precision: 0.9745, Recall: 0.9779, F1: 0.9761
Validation Loss: 1.3966, Accuracy: 0.8239, Precision: 0.7637, Recall: 0.7070, F1: 0.6974
Testing Loss: 1.2531, Accuracy: 0.8457, Precision: 0.7295, Recall: 0.6563, F1: 0.6757
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 2, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1388, Accuracy: 0.9643, Precision: 0.9714, Recall: 0.9750, F1: 0.9713
Epoch 45/70
Train Loss: 0.0347, Accuracy: 0.9888, Precision: 0.9732, Recall: 0.9711, F1: 0.9721
Validation Loss: 0.9650, Accuracy: 0.8608, Precision: 0.7073, Recall: 0.6711, F1: 0.6867
Testing Loss: 1.0290, Accuracy: 0.8404, Precision: 0.6342, Recall: 0.6236, F1: 0.6263
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 2, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1376, Accuracy: 0.9643, Precision: 0.9714, Recall: 0.9750, F1: 0.9713
Epoch 46/70
Train Loss: 0.0416, Accuracy: 0.9853, Precision: 0.9625, Recall: 0.9532, F1: 0.9575
Validation Loss: 1.2959, Accuracy: 0.8381, Precision: 0.7574, Recall: 0.7415, F1: 0.7165
Testing Loss: 1.1330, Accuracy: 0.8431, Precision: 0.6859, Recall: 0.6542, F1: 0.6601
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 2, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0775, Accuracy: 0.9643, Precision: 0.9714, Recall: 0.9750, F1: 0.9713
Epoch 47/70
Train Loss: 0.0225, Accuracy: 0.9941, Precision: 0.9846, Recall: 0.9846, F1: 0.9846
Validation Loss: 1.0260, Accuracy: 0.8466, Precision: 0.7420, Recall: 0.7588, F1: 0.7247
Testing Loss: 1.0440, Accuracy: 0.8324, Precision: 0.6254, Recall: 0.6149, F1: 0.6138
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0561, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 48/70
Train Loss: 0.0225, Accuracy: 0.9930, Precision: 0.9875, Recall: 0.9812, F1: 0.9842
Validation Loss: 1.3138, Accuracy: 0.8182, Precision: 0.7653, Recall: 0.6643, F1: 0.6408
Testing Loss: 1.2270, Accuracy: 0.8404, Precision: 0.6862, Recall: 0.6114, F1: 0.6383
LM Predictions:  [3, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.2144, Accuracy: 0.9286, Precision: 0.8333, Recall: 0.7917, F1: 0.8095
Epoch 49/70
Train Loss: 0.0224, Accuracy: 0.9930, Precision: 0.9787, Recall: 0.9800, F1: 0.9793
Validation Loss: 1.1966, Accuracy: 0.8438, Precision: 0.7190, Recall: 0.7058, F1: 0.6957
Testing Loss: 1.1291, Accuracy: 0.8351, Precision: 0.6557, Recall: 0.6419, F1: 0.6389
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0227, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 50/70
Train Loss: 0.0084, Accuracy: 0.9983, Precision: 0.9948, Recall: 0.9990, F1: 0.9969
Validation Loss: 1.5400, Accuracy: 0.8409, Precision: 0.7348, Recall: 0.7285, F1: 0.7024
Testing Loss: 1.4085, Accuracy: 0.8404, Precision: 0.6559, Recall: 0.6265, F1: 0.6348
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0315, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 51/70
Train Loss: 0.0167, Accuracy: 0.9941, Precision: 0.9859, Recall: 0.9859, F1: 0.9859
Validation Loss: 1.3998, Accuracy: 0.8494, Precision: 0.7358, Recall: 0.7750, F1: 0.7336
Testing Loss: 1.4635, Accuracy: 0.8351, Precision: 0.6528, Recall: 0.6525, F1: 0.6456
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 0, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0457, Accuracy: 0.9643, Precision: 0.9778, Recall: 0.9500, F1: 0.9597
Epoch 52/70
Train Loss: 0.0227, Accuracy: 0.9927, Precision: 0.9757, Recall: 0.9769, F1: 0.9763
Validation Loss: 1.1815, Accuracy: 0.8523, Precision: 0.7080, Recall: 0.7772, F1: 0.7177
Testing Loss: 1.2140, Accuracy: 0.8457, Precision: 0.6254, Recall: 0.6412, F1: 0.6287
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0858, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 53/70
Train Loss: 0.0134, Accuracy: 0.9965, Precision: 0.9864, Recall: 0.9877, F1: 0.9871
Validation Loss: 1.6709, Accuracy: 0.8182, Precision: 0.7521, Recall: 0.7623, F1: 0.6801
Testing Loss: 1.3535, Accuracy: 0.8271, Precision: 0.6654, Recall: 0.6573, F1: 0.6500
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0015, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 54/70
Train Loss: 0.0179, Accuracy: 0.9930, Precision: 0.9824, Recall: 0.9809, F1: 0.9817
Validation Loss: 1.3010, Accuracy: 0.8267, Precision: 0.6746, Recall: 0.6801, F1: 0.6599
Testing Loss: 1.2757, Accuracy: 0.8351, Precision: 0.6696, Recall: 0.6640, F1: 0.6594
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0216, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 55/70
Train Loss: 0.0241, Accuracy: 0.9934, Precision: 0.9783, Recall: 0.9757, F1: 0.9769
Validation Loss: 1.0060, Accuracy: 0.8267, Precision: 0.6731, Recall: 0.6102, F1: 0.6314
Testing Loss: 1.1255, Accuracy: 0.8298, Precision: 0.6340, Recall: 0.6039, F1: 0.6122
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0298, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 56/70
Train Loss: 0.0162, Accuracy: 0.9941, Precision: 0.9897, Recall: 0.9819, F1: 0.9857
Validation Loss: 1.1690, Accuracy: 0.8381, Precision: 0.7046, Recall: 0.7686, F1: 0.7169
Testing Loss: 1.1557, Accuracy: 0.8457, Precision: 0.6303, Recall: 0.6503, F1: 0.6380
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0243, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 57/70
Train Loss: 0.0217, Accuracy: 0.9934, Precision: 0.9860, Recall: 0.9810, F1: 0.9835
Validation Loss: 1.0293, Accuracy: 0.8352, Precision: 0.7163, Recall: 0.8045, F1: 0.7138
Testing Loss: 0.9450, Accuracy: 0.8378, Precision: 0.6436, Recall: 0.6355, F1: 0.6382
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0358, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 58/70
Train Loss: 0.0117, Accuracy: 0.9969, Precision: 0.9913, Recall: 0.9929, F1: 0.9921
Validation Loss: 1.4433, Accuracy: 0.8381, Precision: 0.7176, Recall: 0.7561, F1: 0.7139
Testing Loss: 1.3346, Accuracy: 0.8404, Precision: 0.6461, Recall: 0.6379, F1: 0.6406
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0016, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 59/70
Train Loss: 0.0129, Accuracy: 0.9969, Precision: 0.9902, Recall: 0.9880, F1: 0.9891
Validation Loss: 1.4308, Accuracy: 0.8409, Precision: 0.7042, Recall: 0.7711, F1: 0.7085
Testing Loss: 1.3630, Accuracy: 0.8324, Precision: 0.6331, Recall: 0.6408, F1: 0.6367
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0052, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0200, Accuracy: 0.9937, Precision: 0.9869, Recall: 0.9859, F1: 0.9864
Validation Loss: 1.1222, Accuracy: 0.8352, Precision: 0.6987, Recall: 0.6526, F1: 0.6716
Testing Loss: 1.1058, Accuracy: 0.8484, Precision: 0.6391, Recall: 0.6477, F1: 0.6410
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0141, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 61/70
Train Loss: 0.0241, Accuracy: 0.9920, Precision: 0.9841, Recall: 0.9801, F1: 0.9821
Validation Loss: 1.1966, Accuracy: 0.8352, Precision: 0.7185, Recall: 0.7368, F1: 0.6899
Testing Loss: 1.3128, Accuracy: 0.8378, Precision: 0.6477, Recall: 0.6227, F1: 0.6297
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0005, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 62/70
Train Loss: 0.0178, Accuracy: 0.9937, Precision: 0.9810, Recall: 0.9810, F1: 0.9810
Validation Loss: 1.4288, Accuracy: 0.8438, Precision: 0.7429, Recall: 0.7413, F1: 0.7201
Testing Loss: 1.3395, Accuracy: 0.8351, Precision: 0.6447, Recall: 0.6128, F1: 0.6260
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0575, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 63/70
Train Loss: 0.0025, Accuracy: 0.9993, Precision: 0.9995, Recall: 0.9995, F1: 0.9995
Validation Loss: 1.6566, Accuracy: 0.8324, Precision: 0.7177, Recall: 0.7325, F1: 0.6970
Testing Loss: 1.4127, Accuracy: 0.8564, Precision: 0.6629, Recall: 0.6552, F1: 0.6561
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0007, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 64/70
Train Loss: 0.0012, Accuracy: 0.9997, Precision: 0.9971, Recall: 0.9997, F1: 0.9984
Validation Loss: 1.7657, Accuracy: 0.8352, Precision: 0.7393, Recall: 0.7260, F1: 0.7052
Testing Loss: 1.5425, Accuracy: 0.8511, Precision: 0.6525, Recall: 0.6371, F1: 0.6426
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0003, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 65/70
Train Loss: 0.0172, Accuracy: 0.9965, Precision: 0.9918, Recall: 0.9812, F1: 0.9863
Validation Loss: 1.3225, Accuracy: 0.8381, Precision: 0.7074, Recall: 0.6974, F1: 0.6856
Testing Loss: 1.3336, Accuracy: 0.8511, Precision: 0.6563, Recall: 0.6458, F1: 0.6475
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0595, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 66/70
Train Loss: 0.0259, Accuracy: 0.9916, Precision: 0.9906, Recall: 0.9871, F1: 0.9888
Validation Loss: 0.9231, Accuracy: 0.8352, Precision: 0.7388, Recall: 0.7744, F1: 0.7028
Testing Loss: 1.0074, Accuracy: 0.8271, Precision: 0.6251, Recall: 0.6108, F1: 0.6148
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0153, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 67/70
Train Loss: 0.0064, Accuracy: 0.9976, Precision: 0.9946, Recall: 0.9894, F1: 0.9920
Validation Loss: 1.2613, Accuracy: 0.8381, Precision: 0.7399, Recall: 0.7884, F1: 0.7179
Testing Loss: 1.2917, Accuracy: 0.8511, Precision: 0.6540, Recall: 0.6354, F1: 0.6435
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0008, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 68/70
Train Loss: 0.0112, Accuracy: 0.9962, Precision: 0.9911, Recall: 0.9912, F1: 0.9911
Validation Loss: 1.4583, Accuracy: 0.8267, Precision: 0.7034, Recall: 0.7631, F1: 0.6652
Testing Loss: 1.4211, Accuracy: 0.8378, Precision: 0.6725, Recall: 0.6488, F1: 0.6555
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0157, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0247, Accuracy: 0.9941, Precision: 0.9849, Recall: 0.9824, F1: 0.9836
Validation Loss: 1.2085, Accuracy: 0.8352, Precision: 0.7170, Recall: 0.7796, F1: 0.6949
Testing Loss: 1.1000, Accuracy: 0.8457, Precision: 0.6756, Recall: 0.6673, F1: 0.6657
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0054, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 70/70
Train Loss: 0.0118, Accuracy: 0.9958, Precision: 0.9882, Recall: 0.9857, F1: 0.9869
Validation Loss: 1.1299, Accuracy: 0.8409, Precision: 0.7038, Recall: 0.6760, F1: 0.6861
Testing Loss: 1.2796, Accuracy: 0.8271, Precision: 0.6761, Recall: 0.6372, F1: 0.6525
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0153, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
For later layers:  [16, 17, 18, 19, 20, 21, 22, 23]
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_1.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.ln_2.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.weight, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.ln_f.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 2.3529, Accuracy: 0.2663, Precision: 0.1459, Recall: 0.1518, F1: 0.1296
Validation Loss: 1.5491, Accuracy: 0.3210, Precision: 0.1173, Recall: 0.1504, F1: 0.1140
Testing Loss: 1.6064, Accuracy: 0.3245, Precision: 0.1354, Recall: 0.1550, F1: 0.1231
LM Predictions:  [2, 2, 2, 2, 5, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 5, 2, 2, 2, 4, 2, 5, 4, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 3.3689, Accuracy: 0.1429, Precision: 0.0700, Recall: 0.1250, F1: 0.0769
Epoch 2/70
Train Loss: 1.4745, Accuracy: 0.3394, Precision: 0.1448, Recall: 0.1598, F1: 0.1440
Validation Loss: 1.4920, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.5453, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.9441, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 3/70
Train Loss: 1.4361, Accuracy: 0.3761, Precision: 0.1481, Recall: 0.1706, F1: 0.1470
Validation Loss: 1.4277, Accuracy: 0.3835, Precision: 0.1746, Recall: 0.1695, F1: 0.0975
Testing Loss: 1.4541, Accuracy: 0.3590, Precision: 0.0600, Recall: 0.1654, F1: 0.0881
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5711, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 4/70
Train Loss: 1.4230, Accuracy: 0.3824, Precision: 0.1726, Recall: 0.1743, F1: 0.1504
Validation Loss: 1.4171, Accuracy: 0.4006, Precision: 0.1407, Recall: 0.1798, F1: 0.1304
Testing Loss: 1.4387, Accuracy: 0.3963, Precision: 0.1398, Recall: 0.1832, F1: 0.1328
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4817, Accuracy: 0.2143, Precision: 0.0500, Recall: 0.2000, F1: 0.0800
Epoch 5/70
Train Loss: 1.4187, Accuracy: 0.3772, Precision: 0.1646, Recall: 0.1721, F1: 0.1480
Validation Loss: 1.4142, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4453, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3659, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 6/70
Train Loss: 1.4075, Accuracy: 0.3810, Precision: 0.1254, Recall: 0.1701, F1: 0.1391
Validation Loss: 1.4250, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4520, Accuracy: 0.3617, Precision: 0.0604, Recall: 0.1667, F1: 0.0887
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5417, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 7/70
Train Loss: 1.3933, Accuracy: 0.3866, Precision: 0.1540, Recall: 0.1741, F1: 0.1456
Validation Loss: 1.4053, Accuracy: 0.3778, Precision: 0.1207, Recall: 0.1692, F1: 0.1202
Testing Loss: 1.4273, Accuracy: 0.4282, Precision: 0.1630, Recall: 0.1982, F1: 0.1499
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3032, Accuracy: 0.1071, Precision: 0.0286, Recall: 0.1000, F1: 0.0444
Epoch 8/70
Train Loss: 1.3958, Accuracy: 0.3859, Precision: 0.1260, Recall: 0.1728, F1: 0.1419
Validation Loss: 1.4146, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4371, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3421, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 9/70
Train Loss: 1.3934, Accuracy: 0.3716, Precision: 0.1747, Recall: 0.1658, F1: 0.1346
Validation Loss: 1.4041, Accuracy: 0.3807, Precision: 0.1289, Recall: 0.1701, F1: 0.1181
Testing Loss: 1.4307, Accuracy: 0.3830, Precision: 0.1411, Recall: 0.1770, F1: 0.1237
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3371, Accuracy: 0.1786, Precision: 0.0417, Recall: 0.1667, F1: 0.0667
Epoch 10/70
Train Loss: 1.3897, Accuracy: 0.3905, Precision: 0.1831, Recall: 0.1748, F1: 0.1436
Validation Loss: 1.4065, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4292, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2869, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 11/70
Train Loss: 1.3852, Accuracy: 0.3835, Precision: 0.1245, Recall: 0.1707, F1: 0.1375
Validation Loss: 1.4102, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4340, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3173, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 12/70
Train Loss: 1.3853, Accuracy: 0.3852, Precision: 0.1264, Recall: 0.1725, F1: 0.1418
Validation Loss: 1.4066, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4382, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3033, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 13/70
Train Loss: 1.3853, Accuracy: 0.3838, Precision: 0.1253, Recall: 0.1700, F1: 0.1338
Validation Loss: 1.3959, Accuracy: 0.4119, Precision: 0.1438, Recall: 0.1855, F1: 0.1383
Testing Loss: 1.4230, Accuracy: 0.4176, Precision: 0.1621, Recall: 0.1932, F1: 0.1452
LM Predictions:  [4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2439, Accuracy: 0.2143, Precision: 0.1030, Recall: 0.1833, F1: 0.1143
Epoch 14/70
Train Loss: 1.3797, Accuracy: 0.3737, Precision: 0.1215, Recall: 0.1671, F1: 0.1368
Validation Loss: 1.4052, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4385, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3058, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 15/70
Train Loss: 1.3756, Accuracy: 0.3898, Precision: 0.1290, Recall: 0.1737, F1: 0.1408
Validation Loss: 1.3982, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4299, Accuracy: 0.3590, Precision: 0.0600, Recall: 0.1654, F1: 0.0881
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2220, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 16/70
Train Loss: 1.3771, Accuracy: 0.3982, Precision: 0.2140, Recall: 0.1781, F1: 0.1461
Validation Loss: 1.3946, Accuracy: 0.3835, Precision: 0.2300, Recall: 0.1695, F1: 0.0974
Testing Loss: 1.4183, Accuracy: 0.3777, Precision: 0.2071, Recall: 0.1742, F1: 0.1060
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2508, Accuracy: 0.1786, Precision: 0.0370, Recall: 0.1667, F1: 0.0606
Epoch 17/70
Train Loss: 1.3751, Accuracy: 0.3905, Precision: 0.1284, Recall: 0.1739, F1: 0.1406
Validation Loss: 1.3869, Accuracy: 0.4460, Precision: 0.1491, Recall: 0.2091, F1: 0.1737
Testing Loss: 1.4056, Accuracy: 0.4043, Precision: 0.1368, Recall: 0.1885, F1: 0.1575
LM Predictions:  [4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 4, 4, 2, 4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 4, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2020, Accuracy: 0.1429, Precision: 0.0400, Recall: 0.1000, F1: 0.0571
Epoch 18/70
Train Loss: 1.3789, Accuracy: 0.3852, Precision: 0.2098, Recall: 0.1736, F1: 0.1453
Validation Loss: 1.3938, Accuracy: 0.4148, Precision: 0.1492, Recall: 0.1869, F1: 0.1408
Testing Loss: 1.4237, Accuracy: 0.4388, Precision: 0.2955, Recall: 0.2098, F1: 0.1779
LM Predictions:  [2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1055, Accuracy: 0.0714, Precision: 0.0182, Recall: 0.0667, F1: 0.0286
Epoch 19/70
Train Loss: 1.3695, Accuracy: 0.4073, Precision: 0.1911, Recall: 0.1817, F1: 0.1477
Validation Loss: 1.4100, Accuracy: 0.4517, Precision: 0.2194, Recall: 0.2131, F1: 0.1847
Testing Loss: 1.4326, Accuracy: 0.4761, Precision: 0.2540, Recall: 0.2281, F1: 0.2029
LM Predictions:  [4, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2844, Accuracy: 0.1786, Precision: 0.0728, Recall: 0.1417, F1: 0.0952
Epoch 20/70
Train Loss: 1.3655, Accuracy: 0.4048, Precision: 0.2048, Recall: 0.1832, F1: 0.1543
Validation Loss: 1.3797, Accuracy: 0.3892, Precision: 0.1681, Recall: 0.1725, F1: 0.1056
Testing Loss: 1.4106, Accuracy: 0.3777, Precision: 0.1677, Recall: 0.1742, F1: 0.1060
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2164, Accuracy: 0.2143, Precision: 0.0444, Recall: 0.2000, F1: 0.0727
Epoch 21/70
Train Loss: 1.3668, Accuracy: 0.4052, Precision: 0.1896, Recall: 0.1823, F1: 0.1518
Validation Loss: 1.3557, Accuracy: 0.3977, Precision: 0.2309, Recall: 0.1766, F1: 0.1116
Testing Loss: 1.3954, Accuracy: 0.3883, Precision: 0.2146, Recall: 0.1792, F1: 0.1153
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2792, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 22/70
Train Loss: 1.3401, Accuracy: 0.4549, Precision: 0.2369, Recall: 0.2060, F1: 0.1741
Validation Loss: 1.2981, Accuracy: 0.4176, Precision: 0.1585, Recall: 0.2039, F1: 0.1492
Testing Loss: 1.3170, Accuracy: 0.4335, Precision: 0.3253, Recall: 0.2050, F1: 0.1577
LM Predictions:  [4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1097, Accuracy: 0.2500, Precision: 0.0560, Recall: 0.1750, F1: 0.0848
Epoch 23/70
Train Loss: 1.2381, Accuracy: 0.5217, Precision: 0.2531, Recall: 0.2413, F1: 0.2127
Validation Loss: 1.0031, Accuracy: 0.6222, Precision: 0.3881, Recall: 0.2936, F1: 0.2538
Testing Loss: 1.0100, Accuracy: 0.6489, Precision: 0.3965, Recall: 0.3055, F1: 0.2668
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6418, Accuracy: 0.2857, Precision: 0.1813, Recall: 0.2500, F1: 0.1501
Epoch 24/70
Train Loss: 1.0799, Accuracy: 0.6074, Precision: 0.2941, Recall: 0.2847, F1: 0.2622
Validation Loss: 1.0336, Accuracy: 0.6534, Precision: 0.3027, Recall: 0.3350, F1: 0.3124
Testing Loss: 0.9985, Accuracy: 0.6915, Precision: 0.3311, Recall: 0.3616, F1: 0.3412
LM Predictions:  [5, 5, 5, 2, 2, 5, 2, 2, 5, 2, 2, 5, 4, 4, 2, 5, 5, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2415, Accuracy: 0.2857, Precision: 0.2172, Recall: 0.2667, F1: 0.1930
Epoch 25/70
Train Loss: 0.9508, Accuracy: 0.6547, Precision: 0.3100, Recall: 0.3239, F1: 0.3103
Validation Loss: 1.0175, Accuracy: 0.6847, Precision: 0.3029, Recall: 0.3319, F1: 0.3008
Testing Loss: 1.0236, Accuracy: 0.6995, Precision: 0.3289, Recall: 0.3471, F1: 0.3236
LM Predictions:  [2, 2, 5, 5, 2, 5, 2, 2, 5, 2, 2, 5, 4, 4, 2, 5, 2, 4, 4, 5, 2, 2, 5, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6039, Accuracy: 0.2857, Precision: 0.2000, Recall: 0.2833, F1: 0.2061
Epoch 26/70
Train Loss: 0.7835, Accuracy: 0.7327, Precision: 0.3528, Recall: 0.3917, F1: 0.3703
Validation Loss: 0.9430, Accuracy: 0.7102, Precision: 0.3352, Recall: 0.3708, F1: 0.3491
Testing Loss: 0.8219, Accuracy: 0.7314, Precision: 0.3465, Recall: 0.3834, F1: 0.3611
LM Predictions:  [5, 5, 5, 5, 2, 5, 5, 2, 2, 2, 2, 5, 2, 4, 2, 5, 5, 4, 4, 5, 4, 2, 5, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3964, Accuracy: 0.2500, Precision: 0.1825, Recall: 0.2500, F1: 0.1832
Epoch 27/70
Train Loss: 0.6953, Accuracy: 0.7607, Precision: 0.5332, Recall: 0.4126, F1: 0.3890
Validation Loss: 0.8283, Accuracy: 0.7301, Precision: 0.5115, Recall: 0.3994, F1: 0.3812
Testing Loss: 0.7193, Accuracy: 0.7633, Precision: 0.3623, Recall: 0.4179, F1: 0.3876
LM Predictions:  [5, 5, 5, 5, 2, 5, 5, 2, 5, 2, 2, 5, 2, 4, 2, 5, 5, 5, 4, 5, 2, 2, 5, 2, 2, 5, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4643, Accuracy: 0.2857, Precision: 0.2952, Recall: 0.2833, F1: 0.2133
Epoch 28/70
Train Loss: 0.6543, Accuracy: 0.7775, Precision: 0.5836, Recall: 0.4238, F1: 0.4011
Validation Loss: 0.7425, Accuracy: 0.7557, Precision: 0.5452, Recall: 0.4348, F1: 0.4377
Testing Loss: 0.6430, Accuracy: 0.7793, Precision: 0.5392, Recall: 0.4638, F1: 0.4694
LM Predictions:  [3, 5, 5, 5, 2, 3, 5, 2, 5, 2, 2, 5, 2, 4, 2, 5, 5, 3, 4, 5, 4, 2, 3, 2, 2, 3, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2851, Accuracy: 0.2500, Precision: 0.1936, Recall: 0.2083, F1: 0.1707
Epoch 29/70
Train Loss: 0.6213, Accuracy: 0.7897, Precision: 0.5504, Recall: 0.4438, F1: 0.4315
Validation Loss: 0.7596, Accuracy: 0.7358, Precision: 0.3620, Recall: 0.4125, F1: 0.3781
Testing Loss: 0.6559, Accuracy: 0.7793, Precision: 0.3770, Recall: 0.4417, F1: 0.4006
LM Predictions:  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.8270, Accuracy: 0.2143, Precision: 0.2928, Recall: 0.2333, F1: 0.1689
Epoch 30/70
Train Loss: 0.5870, Accuracy: 0.7995, Precision: 0.5465, Recall: 0.4730, F1: 0.4731
Validation Loss: 0.7008, Accuracy: 0.7756, Precision: 0.5635, Recall: 0.5377, F1: 0.5456
Testing Loss: 0.6121, Accuracy: 0.8032, Precision: 0.5569, Recall: 0.5513, F1: 0.5378
LM Predictions:  [3, 1, 5, 1, 2, 3, 5, 2, 5, 1, 3, 5, 4, 4, 5, 1, 3, 1, 4, 5, 5, 1, 3, 1, 2, 3, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3822, Accuracy: 0.1786, Precision: 0.2016, Recall: 0.1389, F1: 0.1515
Epoch 31/70
Train Loss: 0.5281, Accuracy: 0.8265, Precision: 0.5764, Recall: 0.5196, F1: 0.5292
Validation Loss: 0.6540, Accuracy: 0.8097, Precision: 0.6148, Recall: 0.5680, F1: 0.5831
Testing Loss: 0.6402, Accuracy: 0.8059, Precision: 0.5661, Recall: 0.5591, F1: 0.5490
LM Predictions:  [3, 1, 5, 1, 3, 3, 5, 2, 5, 1, 3, 5, 4, 4, 5, 1, 3, 1, 4, 5, 5, 1, 1, 1, 2, 3, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4245, Accuracy: 0.1786, Precision: 0.2183, Recall: 0.1389, F1: 0.1576
Epoch 32/70
Train Loss: 0.4932, Accuracy: 0.8359, Precision: 0.5933, Recall: 0.5665, F1: 0.5755
Validation Loss: 0.6051, Accuracy: 0.7926, Precision: 0.5692, Recall: 0.5628, F1: 0.5623
Testing Loss: 0.6011, Accuracy: 0.8112, Precision: 0.5671, Recall: 0.5628, F1: 0.5627
LM Predictions:  [3, 1, 3, 3, 3, 3, 5, 2, 5, 2, 3, 5, 4, 4, 1, 3, 3, 3, 4, 5, 3, 1, 3, 3, 2, 3, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6672, Accuracy: 0.1786, Precision: 0.2194, Recall: 0.1389, F1: 0.1629
Epoch 33/70
Train Loss: 0.4357, Accuracy: 0.8593, Precision: 0.6715, Recall: 0.6119, F1: 0.6164
Validation Loss: 0.6893, Accuracy: 0.7955, Precision: 0.5913, Recall: 0.5476, F1: 0.5621
Testing Loss: 0.6683, Accuracy: 0.8112, Precision: 0.5718, Recall: 0.5559, F1: 0.5515
LM Predictions:  [3, 1, 1, 1, 3, 3, 5, 2, 5, 1, 3, 5, 4, 4, 5, 1, 3, 5, 4, 5, 5, 1, 3, 1, 2, 3, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4721, Accuracy: 0.1786, Precision: 0.2183, Recall: 0.1389, F1: 0.1576
Epoch 34/70
Train Loss: 0.4296, Accuracy: 0.8565, Precision: 0.6300, Recall: 0.6091, F1: 0.6168
Validation Loss: 0.5116, Accuracy: 0.8352, Precision: 0.6494, Recall: 0.6027, F1: 0.6061
Testing Loss: 0.5015, Accuracy: 0.8378, Precision: 0.6105, Recall: 0.6116, F1: 0.6099
LM Predictions:  [3, 1, 3, 3, 3, 3, 5, 5, 5, 1, 3, 5, 3, 4, 5, 5, 3, 3, 4, 5, 3, 1, 3, 3, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6329, Accuracy: 0.1429, Precision: 0.2738, Recall: 0.1111, F1: 0.1386
Epoch 35/70
Train Loss: 0.4065, Accuracy: 0.8670, Precision: 0.6316, Recall: 0.6329, F1: 0.6313
Validation Loss: 0.6116, Accuracy: 0.8125, Precision: 0.6209, Recall: 0.5878, F1: 0.5866
Testing Loss: 0.6797, Accuracy: 0.8032, Precision: 0.6011, Recall: 0.5861, F1: 0.5506
LM Predictions:  [3, 1, 3, 1, 3, 3, 5, 2, 3, 1, 3, 1, 3, 4, 1, 1, 3, 3, 4, 5, 3, 1, 3, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5560, Accuracy: 0.1429, Precision: 0.2222, Recall: 0.0972, F1: 0.1222
Epoch 36/70
Train Loss: 0.3511, Accuracy: 0.8894, Precision: 0.6591, Recall: 0.6679, F1: 0.6632
Validation Loss: 0.6423, Accuracy: 0.8125, Precision: 0.6307, Recall: 0.6061, F1: 0.6154
Testing Loss: 0.5837, Accuracy: 0.8271, Precision: 0.5936, Recall: 0.5764, F1: 0.5771
LM Predictions:  [3, 1, 3, 3, 3, 3, 5, 2, 5, 1, 3, 5, 3, 4, 1, 1, 3, 3, 4, 5, 3, 1, 3, 2, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.5401, Accuracy: 0.1786, Precision: 0.2917, Recall: 0.1389, F1: 0.1750
Epoch 37/70
Train Loss: 0.3354, Accuracy: 0.8912, Precision: 0.7614, Recall: 0.6794, F1: 0.6875
Validation Loss: 0.6462, Accuracy: 0.8153, Precision: 0.6162, Recall: 0.6626, F1: 0.6308
Testing Loss: 0.5607, Accuracy: 0.8324, Precision: 0.6097, Recall: 0.6413, F1: 0.6226
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 3, 3, 1, 3, 5, 3, 4, 1, 3, 3, 3, 4, 5, 3, 3, 3, 2, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.8331, Accuracy: 0.1429, Precision: 0.3056, Recall: 0.1111, F1: 0.1560
Epoch 38/70
Train Loss: 0.3119, Accuracy: 0.8989, Precision: 0.7919, Recall: 0.7009, F1: 0.7115
Validation Loss: 0.6305, Accuracy: 0.8295, Precision: 0.6224, Recall: 0.6527, F1: 0.6270
Testing Loss: 0.6225, Accuracy: 0.8457, Precision: 0.6222, Recall: 0.6596, F1: 0.6317
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 1, 3, 1, 3, 4, 3, 3, 3, 3, 4, 5, 3, 3, 3, 2, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 3.3796, Accuracy: 0.1429, Precision: 0.2500, Recall: 0.0972, F1: 0.1333
Epoch 39/70
Train Loss: 0.2781, Accuracy: 0.9076, Precision: 0.7727, Recall: 0.7216, F1: 0.7218
Validation Loss: 0.6146, Accuracy: 0.8381, Precision: 0.7024, Recall: 0.7105, F1: 0.7024
Testing Loss: 0.5945, Accuracy: 0.8404, Precision: 0.6263, Recall: 0.6395, F1: 0.6300
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5, 3, 4, 2, 3, 3, 3, 4, 3, 3, 3, 3, 2, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6754, Accuracy: 0.1786, Precision: 0.3167, Recall: 0.1389, F1: 0.1828
Epoch 40/70
Train Loss: 0.2576, Accuracy: 0.9188, Precision: 0.8115, Recall: 0.7475, F1: 0.7613
Validation Loss: 0.5709, Accuracy: 0.8324, Precision: 0.6939, Recall: 0.7161, F1: 0.7007
Testing Loss: 0.5716, Accuracy: 0.8484, Precision: 0.6250, Recall: 0.6633, F1: 0.6421
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5, 3, 4, 3, 3, 3, 3, 4, 3, 3, 1, 3, 3, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.8168, Accuracy: 0.1786, Precision: 0.4167, Recall: 0.1389, F1: 0.2056
Epoch 41/70
Train Loss: 0.2419, Accuracy: 0.9199, Precision: 0.7899, Recall: 0.7491, F1: 0.7565
Validation Loss: 0.7271, Accuracy: 0.8210, Precision: 0.6720, Recall: 0.6694, F1: 0.6486
Testing Loss: 0.7013, Accuracy: 0.8191, Precision: 0.5997, Recall: 0.6001, F1: 0.5854
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 1, 3, 4, 0, 3, 3, 3, 4, 3, 3, 4, 4, 2, 2, 3, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8540, Accuracy: 0.2143, Precision: 0.3750, Recall: 0.1389, F1: 0.1870
Epoch 42/70
Train Loss: 0.2063, Accuracy: 0.9314, Precision: 0.8253, Recall: 0.7889, F1: 0.7957
Validation Loss: 0.6370, Accuracy: 0.8438, Precision: 0.6927, Recall: 0.7050, F1: 0.6879
Testing Loss: 0.6270, Accuracy: 0.8590, Precision: 0.6556, Recall: 0.6645, F1: 0.6568
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 1, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 2, 2, 3, 3, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.7325, Accuracy: 0.1429, Precision: 0.2500, Recall: 0.0972, F1: 0.1333
Epoch 43/70
Train Loss: 0.1815, Accuracy: 0.9419, Precision: 0.8429, Recall: 0.8150, F1: 0.8246
Validation Loss: 0.7238, Accuracy: 0.8466, Precision: 0.7143, Recall: 0.7768, F1: 0.7240
Testing Loss: 0.7283, Accuracy: 0.8431, Precision: 0.6168, Recall: 0.6408, F1: 0.6202
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 1, 3, 1, 4, 4, 0, 3, 3, 5, 4, 3, 3, 4, 3, 2, 2, 3, 3, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1101, Accuracy: 0.2143, Precision: 0.3750, Recall: 0.1389, F1: 0.1870
Epoch 44/70
Train Loss: 0.1813, Accuracy: 0.9440, Precision: 0.8452, Recall: 0.8324, F1: 0.8374
Validation Loss: 0.6012, Accuracy: 0.8466, Precision: 0.6446, Recall: 0.6672, F1: 0.6539
Testing Loss: 0.6134, Accuracy: 0.8564, Precision: 0.6295, Recall: 0.6600, F1: 0.6432
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5, 3, 4, 3, 3, 3, 5, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4989, Accuracy: 0.1429, Precision: 0.3333, Recall: 0.1181, F1: 0.1587
Epoch 45/70
Train Loss: 0.1692, Accuracy: 0.9461, Precision: 0.8627, Recall: 0.8369, F1: 0.8449
Validation Loss: 0.6605, Accuracy: 0.8239, Precision: 0.6689, Recall: 0.7211, F1: 0.6813
Testing Loss: 0.6395, Accuracy: 0.8457, Precision: 0.6698, Recall: 0.7083, F1: 0.6863
LM Predictions:  [3, 3, 3, 3, 3, 3, 5, 2, 3, 3, 3, 5, 3, 4, 3, 0, 3, 5, 4, 3, 3, 3, 3, 0, 2, 3, 3, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9731, Accuracy: 0.2500, Precision: 0.5000, Recall: 0.1806, F1: 0.2550
Epoch 46/70
Train Loss: 0.1519, Accuracy: 0.9482, Precision: 0.8669, Recall: 0.8615, F1: 0.8630
Validation Loss: 0.6095, Accuracy: 0.8494, Precision: 0.6997, Recall: 0.6974, F1: 0.6871
Testing Loss: 0.6898, Accuracy: 0.8324, Precision: 0.6978, Recall: 0.6525, F1: 0.6544
LM Predictions:  [3, 1, 2, 5, 2, 3, 5, 2, 0, 1, 2, 5, 3, 4, 0, 0, 3, 5, 3, 0, 2, 3, 5, 0, 2, 5, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.3660, Accuracy: 0.5000, Precision: 0.5238, Recall: 0.3889, F1: 0.3844
Epoch 47/70
Train Loss: 0.1251, Accuracy: 0.9605, Precision: 0.8954, Recall: 0.8807, F1: 0.8864
Validation Loss: 0.7505, Accuracy: 0.8267, Precision: 0.6401, Recall: 0.6248, F1: 0.6278
Testing Loss: 0.7357, Accuracy: 0.8404, Precision: 0.6198, Recall: 0.6247, F1: 0.6181
LM Predictions:  [3, 4, 2, 5, 1, 1, 5, 2, 0, 3, 3, 5, 1, 4, 1, 0, 3, 5, 4, 0, 2, 4, 3, 1, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.1306, Accuracy: 0.5714, Precision: 0.6667, Recall: 0.5486, F1: 0.5417
Epoch 48/70
Train Loss: 0.1150, Accuracy: 0.9622, Precision: 0.9016, Recall: 0.8817, F1: 0.8894
Validation Loss: 0.8658, Accuracy: 0.8381, Precision: 0.7218, Recall: 0.7395, F1: 0.7043
Testing Loss: 0.8175, Accuracy: 0.8351, Precision: 0.7023, Recall: 0.6558, F1: 0.6545
LM Predictions:  [3, 4, 2, 3, 1, 1, 1, 2, 0, 1, 3, 5, 1, 4, 0, 0, 3, 1, 4, 0, 2, 4, 4, 2, 2, 0, 0, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.9589, Accuracy: 0.6071, Precision: 0.6333, Recall: 0.5278, F1: 0.5093
Epoch 49/70
Train Loss: 0.1059, Accuracy: 0.9657, Precision: 0.9116, Recall: 0.8998, F1: 0.9035
Validation Loss: 0.7268, Accuracy: 0.8551, Precision: 0.6878, Recall: 0.6291, F1: 0.6527
Testing Loss: 0.7695, Accuracy: 0.8457, Precision: 0.6860, Recall: 0.6389, F1: 0.6554
LM Predictions:  [3, 4, 2, 5, 2, 3, 0, 2, 0, 3, 3, 5, 1, 4, 0, 0, 3, 0, 4, 0, 2, 4, 2, 0, 2, 5, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.7305, Accuracy: 0.7143, Precision: 0.7440, Recall: 0.5764, F1: 0.6310
Epoch 50/70
Train Loss: 0.0912, Accuracy: 0.9689, Precision: 0.9323, Recall: 0.9095, F1: 0.9198
Validation Loss: 0.8267, Accuracy: 0.8523, Precision: 0.6646, Recall: 0.6356, F1: 0.6485
Testing Loss: 0.8898, Accuracy: 0.8537, Precision: 0.7181, Recall: 0.6483, F1: 0.6679
LM Predictions:  [3, 4, 2, 5, 1, 3, 5, 2, 0, 3, 3, 5, 1, 4, 0, 0, 3, 5, 4, 0, 2, 3, 2, 1, 2, 5, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.9698, Accuracy: 0.5714, Precision: 0.6111, Recall: 0.4931, F1: 0.5076
Epoch 51/70
Train Loss: 0.0804, Accuracy: 0.9741, Precision: 0.9358, Recall: 0.9266, F1: 0.9307
Validation Loss: 0.8813, Accuracy: 0.8494, Precision: 0.7131, Recall: 0.7658, F1: 0.7089
Testing Loss: 0.8407, Accuracy: 0.8378, Precision: 0.6540, Recall: 0.6509, F1: 0.6501
LM Predictions:  [3, 4, 2, 3, 3, 1, 0, 2, 0, 3, 3, 5, 1, 4, 0, 0, 3, 0, 4, 0, 3, 4, 3, 0, 2, 3, 3, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.0010, Accuracy: 0.6429, Precision: 0.8333, Recall: 0.5417, F1: 0.6282
Epoch 52/70
Train Loss: 0.0764, Accuracy: 0.9731, Precision: 0.9245, Recall: 0.9282, F1: 0.9260
Validation Loss: 0.8311, Accuracy: 0.8438, Precision: 0.7027, Recall: 0.6180, F1: 0.6497
Testing Loss: 0.8976, Accuracy: 0.8351, Precision: 0.6324, Recall: 0.5976, F1: 0.6072
LM Predictions:  [2, 4, 2, 5, 1, 1, 0, 2, 0, 5, 3, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 3, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.4743, Accuracy: 0.8214, Precision: 0.7302, Recall: 0.7222, F1: 0.7120
Epoch 53/70
Train Loss: 0.0764, Accuracy: 0.9762, Precision: 0.9385, Recall: 0.9312, F1: 0.9345
Validation Loss: 0.8463, Accuracy: 0.8494, Precision: 0.6900, Recall: 0.7197, F1: 0.6962
Testing Loss: 0.8073, Accuracy: 0.8511, Precision: 0.6823, Recall: 0.6624, F1: 0.6672
LM Predictions:  [2, 4, 2, 5, 1, 1, 0, 2, 0, 3, 3, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 3, 3, 2, 3, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5474, Accuracy: 0.7143, Precision: 0.7222, Recall: 0.6319, F1: 0.6584
Epoch 54/70
Train Loss: 0.0506, Accuracy: 0.9829, Precision: 0.9617, Recall: 0.9579, F1: 0.9594
Validation Loss: 0.9251, Accuracy: 0.8551, Precision: 0.7413, Recall: 0.7523, F1: 0.7216
Testing Loss: 0.9264, Accuracy: 0.8404, Precision: 0.6774, Recall: 0.6385, F1: 0.6539
LM Predictions:  [2, 4, 2, 5, 2, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 3, 3, 2, 0, 5, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.5205, Accuracy: 0.8214, Precision: 0.7708, Recall: 0.7222, F1: 0.7361
Epoch 55/70
Train Loss: 0.0450, Accuracy: 0.9836, Precision: 0.9613, Recall: 0.9576, F1: 0.9589
Validation Loss: 0.9242, Accuracy: 0.8295, Precision: 0.6590, Recall: 0.6432, F1: 0.6492
Testing Loss: 0.9204, Accuracy: 0.8324, Precision: 0.6865, Recall: 0.6444, F1: 0.6576
LM Predictions:  [4, 4, 2, 5, 2, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1456, Accuracy: 0.9643, Precision: 0.9714, Recall: 0.9750, F1: 0.9713
Epoch 56/70
Train Loss: 0.0642, Accuracy: 0.9794, Precision: 0.9543, Recall: 0.9517, F1: 0.9529
Validation Loss: 0.8931, Accuracy: 0.8466, Precision: 0.6997, Recall: 0.6329, F1: 0.6601
Testing Loss: 0.8670, Accuracy: 0.8484, Precision: 0.6756, Recall: 0.6250, F1: 0.6406
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0904, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 57/70
Train Loss: 0.0492, Accuracy: 0.9832, Precision: 0.9418, Recall: 0.9512, F1: 0.9464
Validation Loss: 0.9398, Accuracy: 0.8523, Precision: 0.6652, Recall: 0.6554, F1: 0.6553
Testing Loss: 0.9402, Accuracy: 0.8378, Precision: 0.6797, Recall: 0.6307, F1: 0.6449
LM Predictions:  [2, 4, 2, 5, 3, 1, 0, 2, 0, 3, 2, 5, 1, 4, 0, 0, 3, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.3225, Accuracy: 0.8571, Precision: 0.8095, Recall: 0.7292, F1: 0.7582
Epoch 58/70
Train Loss: 0.0380, Accuracy: 0.9878, Precision: 0.9629, Recall: 0.9710, F1: 0.9669
Validation Loss: 0.9722, Accuracy: 0.8438, Precision: 0.7110, Recall: 0.6022, F1: 0.6349
Testing Loss: 0.9327, Accuracy: 0.8324, Precision: 0.6577, Recall: 0.6209, F1: 0.6304
LM Predictions:  [2, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1688, Accuracy: 0.9643, Precision: 0.9714, Recall: 0.9750, F1: 0.9713
Epoch 59/70
Train Loss: 0.0331, Accuracy: 0.9867, Precision: 0.9568, Recall: 0.9685, F1: 0.9624
Validation Loss: 0.9983, Accuracy: 0.8466, Precision: 0.6579, Recall: 0.6701, F1: 0.6623
Testing Loss: 0.9012, Accuracy: 0.8298, Precision: 0.6300, Recall: 0.6389, F1: 0.6326
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0618, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 60/70
Train Loss: 0.0340, Accuracy: 0.9892, Precision: 0.9637, Recall: 0.9676, F1: 0.9656
Validation Loss: 1.0043, Accuracy: 0.8381, Precision: 0.7079, Recall: 0.7422, F1: 0.6969
Testing Loss: 0.9042, Accuracy: 0.8511, Precision: 0.6633, Recall: 0.6578, F1: 0.6580
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1001, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 61/70
Train Loss: 0.0175, Accuracy: 0.9951, Precision: 0.9899, Recall: 0.9893, F1: 0.9896
Validation Loss: 1.1254, Accuracy: 0.8551, Precision: 0.7086, Recall: 0.6795, F1: 0.6844
Testing Loss: 1.1440, Accuracy: 0.8431, Precision: 0.6913, Recall: 0.6381, F1: 0.6581
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1851, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 62/70
Train Loss: 0.0265, Accuracy: 0.9920, Precision: 0.9800, Recall: 0.9828, F1: 0.9814
Validation Loss: 1.2639, Accuracy: 0.8693, Precision: 0.7725, Recall: 0.6801, F1: 0.7084
Testing Loss: 1.3814, Accuracy: 0.8324, Precision: 0.8431, Recall: 0.6147, F1: 0.6658
LM Predictions:  [2, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 0, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.3604, Accuracy: 0.8929, Precision: 0.7910, Recall: 0.7500, F1: 0.7631
Epoch 63/70
Train Loss: 0.0383, Accuracy: 0.9923, Precision: 0.9851, Recall: 0.9823, F1: 0.9837
Validation Loss: 0.9610, Accuracy: 0.8324, Precision: 0.6958, Recall: 0.6439, F1: 0.6578
Testing Loss: 0.8671, Accuracy: 0.8537, Precision: 0.7586, Recall: 0.6657, F1: 0.6911
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1475, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 64/70
Train Loss: 0.0194, Accuracy: 0.9955, Precision: 0.9878, Recall: 0.9889, F1: 0.9883
Validation Loss: 1.0138, Accuracy: 0.8239, Precision: 0.6534, Recall: 0.6684, F1: 0.6500
Testing Loss: 0.8813, Accuracy: 0.8457, Precision: 0.6868, Recall: 0.6501, F1: 0.6625
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0871, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 65/70
Train Loss: 0.0176, Accuracy: 0.9930, Precision: 0.9805, Recall: 0.9856, F1: 0.9830
Validation Loss: 1.2698, Accuracy: 0.8097, Precision: 0.6711, Recall: 0.6564, F1: 0.6526
Testing Loss: 1.0198, Accuracy: 0.8431, Precision: 0.7247, Recall: 0.6362, F1: 0.6633
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1482, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 66/70
Train Loss: 0.0335, Accuracy: 0.9899, Precision: 0.9641, Recall: 0.9705, F1: 0.9672
Validation Loss: 1.0518, Accuracy: 0.8409, Precision: 0.6717, Recall: 0.6328, F1: 0.6444
Testing Loss: 0.9519, Accuracy: 0.8537, Precision: 0.7639, Recall: 0.6644, F1: 0.6929
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0976, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 67/70
Train Loss: 0.0370, Accuracy: 0.9867, Precision: 0.9665, Recall: 0.9679, F1: 0.9671
Validation Loss: 1.0147, Accuracy: 0.8466, Precision: 0.6779, Recall: 0.6928, F1: 0.6714
Testing Loss: 0.8854, Accuracy: 0.8590, Precision: 0.6612, Recall: 0.6428, F1: 0.6510
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 3, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.1778, Accuracy: 0.9286, Precision: 0.8333, Recall: 0.7708, F1: 0.7984
Epoch 68/70
Train Loss: 0.0176, Accuracy: 0.9955, Precision: 0.9895, Recall: 0.9881, F1: 0.9888
Validation Loss: 1.0281, Accuracy: 0.8324, Precision: 0.6741, Recall: 0.6734, F1: 0.6591
Testing Loss: 0.9559, Accuracy: 0.8378, Precision: 0.6590, Recall: 0.6132, F1: 0.6315
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0255, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 69/70
Train Loss: 0.0088, Accuracy: 0.9983, Precision: 0.9949, Recall: 0.9960, F1: 0.9955
Validation Loss: 1.1283, Accuracy: 0.8267, Precision: 0.6758, Recall: 0.6825, F1: 0.6655
Testing Loss: 0.9670, Accuracy: 0.8617, Precision: 0.7206, Recall: 0.6616, F1: 0.6842
LM Predictions:  [4, 4, 2, 5, 3, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0391, Accuracy: 0.9643, Precision: 0.8333, Recall: 0.8125, F1: 0.8222
Epoch 70/70
Train Loss: 0.0162, Accuracy: 0.9955, Precision: 0.9865, Recall: 0.9874, F1: 0.9869
Validation Loss: 1.1419, Accuracy: 0.8523, Precision: 0.7225, Recall: 0.6966, F1: 0.7062
Testing Loss: 1.1005, Accuracy: 0.8324, Precision: 0.6190, Recall: 0.6009, F1: 0.6045
LM Predictions:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.0393, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
---------------------------------------------------------------------------



