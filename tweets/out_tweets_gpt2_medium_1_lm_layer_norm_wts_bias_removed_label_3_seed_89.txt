---------------------------------------------------------------------------
Results for seed:  89
Model: gpt2-medium, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:2
Noise: 1% with label 3
Label counts for Train:
  Label 4: 966
  Label 2: 1099
  Label 5: 486
  Label 1: 115
  Label 3: 144
  Label 0: 48
Label counts for Validation:
  Label 4: 117
  Label 5: 60
  Label 0: 3
  Label 3: 17
  Label 1: 22
  Label 2: 133
Label counts for Test:
  Label 4: 133
  Label 2: 136
  Label 0: 6
  Label 1: 14
  Label 3: 29
  Label 5: 58
28
Actual labels:  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
Label counts for Train:
  Label 4: 974
  Label 2: 1105
  Label 5: 490
  Label 1: 117
  Label 0: 56
  Label 3: 116
Layer: backbone.transformer.wte.weight, Size: torch.Size([50257, 1024]), req grad: True
Layer: backbone.transformer.wpe.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.0.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.0.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.1.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.1.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.2.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.2.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.3.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.3.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.4.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.4.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.5.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.5.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.6.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.6.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.7.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.7.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.8.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.8.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.9.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.9.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.10.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.10.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.11.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.11.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.12.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.12.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.13.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.13.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.14.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.14.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.15.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.15.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.16.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.16.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.17.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.17.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.18.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.18.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.19.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.19.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.20.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.20.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.21.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.21.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.22.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.22.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.weight, Size: torch.Size([1024, 3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_attn.bias, Size: torch.Size([3072]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.weight, Size: torch.Size([1024, 1024]), req grad: True
Layer: backbone.transformer.h.23.attn.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.weight, Size: torch.Size([1024, 4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_fc.bias, Size: torch.Size([4096]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.weight, Size: torch.Size([4096, 1024]), req grad: True
Layer: backbone.transformer.h.23.mlp.c_proj.bias, Size: torch.Size([1024]), req grad: True
Layer: backbone.score.weight, Size: torch.Size([6, 1024]), req grad: True
Epoch 1/70
Train Loss: 1.4023, Accuracy: 0.3880, Precision: 0.1619, Recall: 0.1761, F1: 0.1489
Validation Loss: 1.4048, Accuracy: 0.3778, Precision: 0.0632, Recall: 0.1667, F1: 0.0916
Testing Loss: 1.4529, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2230, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 2/70
Train Loss: 1.3894, Accuracy: 0.3740, Precision: 0.1219, Recall: 0.1678, F1: 0.1386
Validation Loss: 1.4398, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4881, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2525, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 3/70
Train Loss: 1.3860, Accuracy: 0.3891, Precision: 0.1275, Recall: 0.1746, F1: 0.1443
Validation Loss: 1.4119, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4581, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2815, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 4/70
Train Loss: 1.3867, Accuracy: 0.3814, Precision: 0.1254, Recall: 0.1713, F1: 0.1419
Validation Loss: 1.4275, Accuracy: 0.3778, Precision: 0.0630, Recall: 0.1667, F1: 0.0914
Testing Loss: 1.4698, Accuracy: 0.3617, Precision: 0.0603, Recall: 0.1667, F1: 0.0885
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2900, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 5/70
Train Loss: 1.3758, Accuracy: 0.3940, Precision: 0.2956, Recall: 0.1760, F1: 0.1436
Validation Loss: 1.3946, Accuracy: 0.3807, Precision: 0.1318, Recall: 0.1691, F1: 0.1079
Testing Loss: 1.4294, Accuracy: 0.3830, Precision: 0.1696, Recall: 0.1768, F1: 0.1140
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3002, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 6/70
Train Loss: 1.3714, Accuracy: 0.4031, Precision: 0.1327, Recall: 0.1811, F1: 0.1502
Validation Loss: 1.3808, Accuracy: 0.4062, Precision: 0.1627, Recall: 0.1821, F1: 0.1309
Testing Loss: 1.4171, Accuracy: 0.3856, Precision: 0.1604, Recall: 0.1781, F1: 0.1220
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2306, Accuracy: 0.2143, Precision: 0.0444, Recall: 0.2000, F1: 0.0727
Epoch 7/70
Train Loss: 1.3679, Accuracy: 0.4076, Precision: 0.1348, Recall: 0.1831, F1: 0.1517
Validation Loss: 1.3923, Accuracy: 0.4006, Precision: 0.1763, Recall: 0.1781, F1: 0.1144
Testing Loss: 1.4127, Accuracy: 0.3803, Precision: 0.1914, Recall: 0.1754, F1: 0.1066
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2190, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 8/70
Train Loss: 1.3632, Accuracy: 0.4216, Precision: 0.1409, Recall: 0.1901, F1: 0.1589
Validation Loss: 1.3678, Accuracy: 0.4347, Precision: 0.1452, Recall: 0.2048, F1: 0.1694
Testing Loss: 1.3803, Accuracy: 0.4548, Precision: 0.1517, Recall: 0.2119, F1: 0.1768
LM Predictions:  [4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1545, Accuracy: 0.2500, Precision: 0.1042, Recall: 0.2000, F1: 0.1345
Epoch 9/70
Train Loss: 1.3567, Accuracy: 0.4356, Precision: 0.1445, Recall: 0.1975, F1: 0.1661
Validation Loss: 1.3520, Accuracy: 0.4517, Precision: 0.1504, Recall: 0.2097, F1: 0.1740
Testing Loss: 1.3868, Accuracy: 0.4521, Precision: 0.1542, Recall: 0.2102, F1: 0.1747
LM Predictions:  [4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2825, Accuracy: 0.2857, Precision: 0.1193, Recall: 0.2417, F1: 0.1506
Epoch 10/70
Train Loss: 1.3400, Accuracy: 0.4388, Precision: 0.1878, Recall: 0.1999, F1: 0.1718
Validation Loss: 1.3675, Accuracy: 0.4403, Precision: 0.1572, Recall: 0.2114, F1: 0.1689
Testing Loss: 1.3860, Accuracy: 0.4707, Precision: 0.1649, Recall: 0.2199, F1: 0.1818
LM Predictions:  [4, 4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2506, Accuracy: 0.2500, Precision: 0.1016, Recall: 0.2000, F1: 0.1346
Epoch 11/70
Train Loss: 1.3396, Accuracy: 0.4304, Precision: 0.2536, Recall: 0.1958, F1: 0.1662
Validation Loss: 1.3440, Accuracy: 0.4517, Precision: 0.3462, Recall: 0.2061, F1: 0.1653
Testing Loss: 1.3803, Accuracy: 0.4335, Precision: 0.2835, Recall: 0.2039, F1: 0.1600
LM Predictions:  [2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 5, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3338, Accuracy: 0.2143, Precision: 0.0935, Recall: 0.1917, F1: 0.1023
Epoch 12/70
Train Loss: 1.3265, Accuracy: 0.4542, Precision: 0.2042, Recall: 0.2074, F1: 0.1779
Validation Loss: 1.3582, Accuracy: 0.4403, Precision: 0.1784, Recall: 0.1989, F1: 0.1531
Testing Loss: 1.3774, Accuracy: 0.4335, Precision: 0.3776, Recall: 0.2022, F1: 0.1555
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3460, Accuracy: 0.2143, Precision: 0.0429, Recall: 0.2000, F1: 0.0706
Epoch 13/70
Train Loss: 1.2982, Accuracy: 0.4752, Precision: 0.2223, Recall: 0.2192, F1: 0.1927
Validation Loss: 1.2702, Accuracy: 0.5000, Precision: 0.1682, Recall: 0.2337, F1: 0.1951
Testing Loss: 1.2647, Accuracy: 0.4947, Precision: 0.2913, Recall: 0.2351, F1: 0.2064
LM Predictions:  [4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 5, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2440, Accuracy: 0.1786, Precision: 0.0871, Recall: 0.1500, F1: 0.0995
Epoch 14/70
Train Loss: 1.2802, Accuracy: 0.4923, Precision: 0.2168, Recall: 0.2298, F1: 0.2064
Validation Loss: 1.4052, Accuracy: 0.4205, Precision: 0.2225, Recall: 0.1882, F1: 0.1338
Testing Loss: 1.4388, Accuracy: 0.3989, Precision: 0.2097, Recall: 0.1842, F1: 0.1242
LM Predictions:  [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4614, Accuracy: 0.1786, Precision: 0.0370, Recall: 0.1667, F1: 0.0606
Epoch 15/70
Train Loss: 1.2800, Accuracy: 0.4846, Precision: 0.2116, Recall: 0.2264, F1: 0.2047
Validation Loss: 1.2606, Accuracy: 0.5199, Precision: 0.1794, Recall: 0.2429, F1: 0.2043
Testing Loss: 1.2489, Accuracy: 0.5585, Precision: 0.1911, Recall: 0.2601, F1: 0.2186
LM Predictions:  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4308, Accuracy: 0.1786, Precision: 0.0748, Recall: 0.1583, F1: 0.0859
Epoch 16/70
Train Loss: 1.2056, Accuracy: 0.5406, Precision: 0.2523, Recall: 0.2608, F1: 0.2447
Validation Loss: 1.2217, Accuracy: 0.5170, Precision: 0.2605, Recall: 0.2593, F1: 0.2346
Testing Loss: 1.2159, Accuracy: 0.5426, Precision: 0.2555, Recall: 0.2697, F1: 0.2476
LM Predictions:  [4, 2, 2, 4, 2, 4, 5, 2, 4, 4, 4, 4, 2, 4, 4, 5, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3513, Accuracy: 0.2500, Precision: 0.1079, Recall: 0.2000, F1: 0.1402
Epoch 17/70
Train Loss: 1.1709, Accuracy: 0.5581, Precision: 0.2666, Recall: 0.2685, F1: 0.2523
Validation Loss: 1.0859, Accuracy: 0.5994, Precision: 0.2881, Recall: 0.3215, F1: 0.3031
Testing Loss: 1.0744, Accuracy: 0.6303, Precision: 0.3025, Recall: 0.3461, F1: 0.3214
LM Predictions:  [2, 5, 2, 5, 2, 5, 5, 2, 5, 4, 4, 5, 2, 2, 2, 5, 5, 4, 4, 2, 5, 2, 4, 2, 2, 5, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3849, Accuracy: 0.2143, Precision: 0.1233, Recall: 0.2250, F1: 0.1524
Epoch 18/70
Train Loss: 1.1052, Accuracy: 0.5934, Precision: 0.2802, Recall: 0.2919, F1: 0.2783
Validation Loss: 1.0553, Accuracy: 0.6165, Precision: 0.3055, Recall: 0.3168, F1: 0.3028
Testing Loss: 1.0559, Accuracy: 0.6436, Precision: 0.3166, Recall: 0.3373, F1: 0.3206
LM Predictions:  [2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 4, 2, 2, 2, 2, 5, 5, 2, 4, 2, 5, 2, 4, 2, 2, 2, 4, 2]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3252, Accuracy: 0.1429, Precision: 0.0800, Recall: 0.1250, F1: 0.0795
Epoch 19/70
Train Loss: 1.0669, Accuracy: 0.6095, Precision: 0.2907, Recall: 0.3024, F1: 0.2893
Validation Loss: 1.0502, Accuracy: 0.5824, Precision: 0.2972, Recall: 0.3408, F1: 0.3023
Testing Loss: 1.0548, Accuracy: 0.6250, Precision: 0.3111, Recall: 0.3587, F1: 0.3219
LM Predictions:  [5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 5, 5, 4, 4, 5, 5, 2, 4, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3251, Accuracy: 0.2143, Precision: 0.1387, Recall: 0.2583, F1: 0.1411
Epoch 20/70
Train Loss: 1.0433, Accuracy: 0.6179, Precision: 0.3011, Recall: 0.3132, F1: 0.3019
Validation Loss: 0.9844, Accuracy: 0.6364, Precision: 0.3077, Recall: 0.3295, F1: 0.3127
Testing Loss: 0.9807, Accuracy: 0.6702, Precision: 0.3205, Recall: 0.3531, F1: 0.3331
LM Predictions:  [2, 2, 2, 5, 2, 5, 5, 2, 5, 4, 2, 2, 2, 2, 2, 5, 5, 2, 4, 2, 4, 2, 4, 2, 2, 2, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3526, Accuracy: 0.2500, Precision: 0.1500, Recall: 0.2583, F1: 0.1727
Epoch 21/70
Train Loss: 0.9869, Accuracy: 0.6428, Precision: 0.3092, Recall: 0.3262, F1: 0.3136
Validation Loss: 1.0642, Accuracy: 0.6506, Precision: 0.3395, Recall: 0.3359, F1: 0.3245
Testing Loss: 1.0488, Accuracy: 0.6596, Precision: 0.3350, Recall: 0.3462, F1: 0.3300
LM Predictions:  [2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.6633, Accuracy: 0.2857, Precision: 0.2945, Recall: 0.2750, F1: 0.1746
Epoch 22/70
Train Loss: 0.9705, Accuracy: 0.6508, Precision: 0.3143, Recall: 0.3347, F1: 0.3215
Validation Loss: 0.9569, Accuracy: 0.6506, Precision: 0.3162, Recall: 0.3317, F1: 0.3155
Testing Loss: 0.9223, Accuracy: 0.6995, Precision: 0.3464, Recall: 0.3683, F1: 0.3508
LM Predictions:  [2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 5, 2, 2, 2, 5, 5, 2, 4, 5, 2, 2, 4, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4113, Accuracy: 0.2857, Precision: 0.2056, Recall: 0.2917, F1: 0.1900
Epoch 23/70
Train Loss: 0.9345, Accuracy: 0.6589, Precision: 0.3176, Recall: 0.3405, F1: 0.3267
Validation Loss: 1.0186, Accuracy: 0.6676, Precision: 0.3427, Recall: 0.3517, F1: 0.3384
Testing Loss: 1.0154, Accuracy: 0.6702, Precision: 0.3297, Recall: 0.3529, F1: 0.3342
LM Predictions:  [2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 5, 5, 2, 2, 2, 5, 2, 2, 4, 5, 2, 2, 2, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4672, Accuracy: 0.2857, Precision: 0.3026, Recall: 0.2917, F1: 0.1911
Epoch 24/70
Train Loss: 0.9188, Accuracy: 0.6707, Precision: 0.3267, Recall: 0.3480, F1: 0.3346
Validation Loss: 0.9175, Accuracy: 0.6619, Precision: 0.3303, Recall: 0.3704, F1: 0.3440
Testing Loss: 0.9155, Accuracy: 0.6755, Precision: 0.3324, Recall: 0.3803, F1: 0.3477
LM Predictions:  [2, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 5, 5, 5, 4, 5, 5, 2, 4, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.4733, Accuracy: 0.2143, Precision: 0.1693, Recall: 0.2583, F1: 0.1429
Epoch 25/70
Train Loss: 0.8848, Accuracy: 0.6914, Precision: 0.3355, Recall: 0.3609, F1: 0.3459
Validation Loss: 0.9055, Accuracy: 0.6591, Precision: 0.3279, Recall: 0.3426, F1: 0.3282
Testing Loss: 0.9191, Accuracy: 0.6809, Precision: 0.3354, Recall: 0.3563, F1: 0.3388
LM Predictions:  [2, 2, 2, 2, 2, 5, 5, 2, 5, 2, 5, 5, 2, 2, 2, 5, 5, 2, 4, 5, 2, 2, 4, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3452, Accuracy: 0.2143, Precision: 0.1700, Recall: 0.2083, F1: 0.1413
Epoch 26/70
Train Loss: 0.8911, Accuracy: 0.6868, Precision: 0.3356, Recall: 0.3603, F1: 0.3456
Validation Loss: 0.9330, Accuracy: 0.6790, Precision: 0.3394, Recall: 0.3790, F1: 0.3527
Testing Loss: 0.9002, Accuracy: 0.6755, Precision: 0.3325, Recall: 0.3802, F1: 0.3483
LM Predictions:  [2, 2, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 2, 2, 2, 5, 5, 5, 4, 5, 5, 2, 4, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2839, Accuracy: 0.1786, Precision: 0.1575, Recall: 0.2083, F1: 0.1250
Epoch 27/70
Train Loss: 0.8458, Accuracy: 0.7113, Precision: 0.3995, Recall: 0.3760, F1: 0.3604
Validation Loss: 0.9255, Accuracy: 0.6790, Precision: 0.3335, Recall: 0.3702, F1: 0.3476
Testing Loss: 0.9120, Accuracy: 0.6968, Precision: 0.3385, Recall: 0.3852, F1: 0.3565
LM Predictions:  [2, 2, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 2, 2, 2, 5, 5, 2, 4, 5, 2, 2, 2, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3363, Accuracy: 0.2500, Precision: 0.2890, Recall: 0.2750, F1: 0.1743
Epoch 28/70
Train Loss: 0.8409, Accuracy: 0.7064, Precision: 0.3422, Recall: 0.3732, F1: 0.3560
Validation Loss: 0.9284, Accuracy: 0.6733, Precision: 0.3356, Recall: 0.3897, F1: 0.3509
Testing Loss: 0.8713, Accuracy: 0.6915, Precision: 0.5066, Recall: 0.4006, F1: 0.3670
LM Predictions:  [5, 5, 5, 5, 2, 5, 5, 5, 5, 4, 5, 5, 2, 4, 5, 5, 5, 5, 4, 5, 5, 5, 4, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1538, Accuracy: 0.2143, Precision: 0.1800, Recall: 0.2333, F1: 0.1567
Epoch 29/70
Train Loss: 0.8149, Accuracy: 0.7092, Precision: 0.5095, Recall: 0.3768, F1: 0.3604
Validation Loss: 0.9097, Accuracy: 0.6619, Precision: 0.3151, Recall: 0.3640, F1: 0.3362
Testing Loss: 0.8594, Accuracy: 0.7021, Precision: 0.4987, Recall: 0.3924, F1: 0.3669
LM Predictions:  [4, 5, 5, 4, 2, 5, 5, 5, 5, 4, 5, 5, 2, 4, 2, 5, 4, 5, 4, 5, 4, 4, 4, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1324, Accuracy: 0.2857, Precision: 0.1797, Recall: 0.2583, F1: 0.1985
Epoch 30/70
Train Loss: 0.8073, Accuracy: 0.7173, Precision: 0.5135, Recall: 0.3850, F1: 0.3685
Validation Loss: 0.9065, Accuracy: 0.6733, Precision: 0.3328, Recall: 0.3724, F1: 0.3474
Testing Loss: 0.8367, Accuracy: 0.7181, Precision: 0.3478, Recall: 0.4033, F1: 0.3694
LM Predictions:  [5, 2, 2, 5, 2, 5, 2, 2, 5, 2, 5, 5, 2, 2, 2, 5, 4, 5, 4, 5, 2, 2, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9890, Accuracy: 0.2857, Precision: 0.2905, Recall: 0.2833, F1: 0.2100
Epoch 31/70
Train Loss: 0.7656, Accuracy: 0.7316, Precision: 0.3549, Recall: 0.3924, F1: 0.3720
Validation Loss: 0.9423, Accuracy: 0.6847, Precision: 0.3419, Recall: 0.3918, F1: 0.3573
Testing Loss: 0.9044, Accuracy: 0.7154, Precision: 0.3486, Recall: 0.4071, F1: 0.3690
LM Predictions:  [5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 4, 5, 3, 5, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1331, Accuracy: 0.1786, Precision: 0.2194, Recall: 0.1736, F1: 0.1065
Epoch 32/70
Train Loss: 0.7521, Accuracy: 0.7341, Precision: 0.4575, Recall: 0.3987, F1: 0.3838
Validation Loss: 0.9719, Accuracy: 0.6761, Precision: 0.3403, Recall: 0.3706, F1: 0.3501
Testing Loss: 0.8423, Accuracy: 0.7074, Precision: 0.4278, Recall: 0.4041, F1: 0.3825
LM Predictions:  [5, 2, 5, 5, 2, 5, 2, 2, 2, 5, 5, 5, 2, 2, 2, 5, 5, 5, 4, 2, 3, 2, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.3219, Accuracy: 0.2143, Precision: 0.2308, Recall: 0.2014, F1: 0.1309
Epoch 33/70
Train Loss: 0.7338, Accuracy: 0.7376, Precision: 0.4578, Recall: 0.4010, F1: 0.3834
Validation Loss: 0.8800, Accuracy: 0.6733, Precision: 0.3616, Recall: 0.3943, F1: 0.3730
Testing Loss: 0.8168, Accuracy: 0.6941, Precision: 0.3926, Recall: 0.4027, F1: 0.3815
LM Predictions:  [5, 5, 3, 5, 2, 5, 5, 3, 5, 5, 5, 5, 4, 4, 2, 5, 5, 5, 4, 5, 3, 3, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0177, Accuracy: 0.2500, Precision: 0.1944, Recall: 0.2361, F1: 0.1606
Epoch 34/70
Train Loss: 0.7421, Accuracy: 0.7418, Precision: 0.4588, Recall: 0.4133, F1: 0.4031
Validation Loss: 0.8517, Accuracy: 0.6960, Precision: 0.3866, Recall: 0.4110, F1: 0.3946
Testing Loss: 0.7701, Accuracy: 0.7261, Precision: 0.4012, Recall: 0.4185, F1: 0.4024
LM Predictions:  [5, 5, 2, 5, 2, 5, 5, 3, 5, 2, 5, 5, 2, 4, 5, 5, 5, 5, 4, 3, 3, 3, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1052, Accuracy: 0.2500, Precision: 0.2556, Recall: 0.2222, F1: 0.1749
Epoch 35/70
Train Loss: 0.7037, Accuracy: 0.7512, Precision: 0.4939, Recall: 0.4152, F1: 0.4044
Validation Loss: 0.8908, Accuracy: 0.6790, Precision: 0.5202, Recall: 0.3879, F1: 0.3776
Testing Loss: 0.7981, Accuracy: 0.7314, Precision: 0.4213, Recall: 0.4367, F1: 0.4194
LM Predictions:  [5, 5, 2, 5, 2, 5, 2, 3, 3, 5, 5, 5, 3, 4, 5, 5, 5, 5, 4, 3, 2, 3, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.1694, Accuracy: 0.2857, Precision: 0.2738, Recall: 0.2500, F1: 0.1991
Epoch 36/70
Train Loss: 0.7070, Accuracy: 0.7540, Precision: 0.5390, Recall: 0.4259, F1: 0.4193
Validation Loss: 1.1131, Accuracy: 0.6193, Precision: 0.3636, Recall: 0.3761, F1: 0.3389
Testing Loss: 0.9459, Accuracy: 0.6915, Precision: 0.4299, Recall: 0.4208, F1: 0.3932
LM Predictions:  [5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 5, 5, 3, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.2316, Accuracy: 0.2857, Precision: 0.3623, Recall: 0.2569, F1: 0.1879
Epoch 37/70
Train Loss: 0.6775, Accuracy: 0.7631, Precision: 0.6259, Recall: 0.4366, F1: 0.4298
Validation Loss: 0.8595, Accuracy: 0.7102, Precision: 0.4017, Recall: 0.4159, F1: 0.4026
Testing Loss: 0.8026, Accuracy: 0.7340, Precision: 0.4297, Recall: 0.4255, F1: 0.4101
LM Predictions:  [5, 5, 2, 5, 2, 5, 5, 2, 5, 5, 5, 5, 2, 4, 5, 5, 5, 5, 4, 3, 3, 3, 5, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 2.0856, Accuracy: 0.2857, Precision: 0.2693, Recall: 0.2500, F1: 0.1936
Epoch 38/70
Train Loss: 0.6569, Accuracy: 0.7761, Precision: 0.5057, Recall: 0.4449, F1: 0.4387
Validation Loss: 0.9205, Accuracy: 0.6733, Precision: 0.3561, Recall: 0.3839, F1: 0.3677
Testing Loss: 0.8519, Accuracy: 0.7287, Precision: 0.4117, Recall: 0.4215, F1: 0.4051
LM Predictions:  [5, 5, 2, 4, 4, 5, 5, 2, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8366, Accuracy: 0.3929, Precision: 0.2798, Recall: 0.3125, F1: 0.2667
Epoch 39/70
Train Loss: 0.6375, Accuracy: 0.7757, Precision: 0.4912, Recall: 0.4488, F1: 0.4417
Validation Loss: 0.9793, Accuracy: 0.6449, Precision: 0.3436, Recall: 0.3700, F1: 0.3448
Testing Loss: 0.8720, Accuracy: 0.7128, Precision: 0.3830, Recall: 0.4052, F1: 0.3833
LM Predictions:  [5, 5, 4, 4, 4, 5, 5, 3, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 4, 4, 5, 4, 2, 5, 4, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8900, Accuracy: 0.2500, Precision: 0.2500, Recall: 0.1736, F1: 0.1518
Epoch 40/70
Train Loss: 0.6377, Accuracy: 0.7733, Precision: 0.4738, Recall: 0.4580, F1: 0.4534
Validation Loss: 0.9214, Accuracy: 0.6903, Precision: 0.3804, Recall: 0.4106, F1: 0.3864
Testing Loss: 0.8257, Accuracy: 0.7394, Precision: 0.4209, Recall: 0.4395, F1: 0.4156
LM Predictions:  [5, 5, 5, 5, 2, 5, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 3, 3, 2, 5, 2, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9832, Accuracy: 0.2500, Precision: 0.2434, Recall: 0.2361, F1: 0.1580
Epoch 41/70
Train Loss: 0.6203, Accuracy: 0.7817, Precision: 0.5264, Recall: 0.4678, F1: 0.4630
Validation Loss: 0.8583, Accuracy: 0.6960, Precision: 0.4706, Recall: 0.4013, F1: 0.3955
Testing Loss: 0.8063, Accuracy: 0.7181, Precision: 0.4119, Recall: 0.4088, F1: 0.3926
LM Predictions:  [5, 5, 2, 5, 4, 5, 5, 3, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 3, 4, 5, 2, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6691, Accuracy: 0.3571, Precision: 0.2579, Recall: 0.2847, F1: 0.2413
Epoch 42/70
Train Loss: 0.6110, Accuracy: 0.7838, Precision: 0.5332, Recall: 0.4648, F1: 0.4620
Validation Loss: 0.9293, Accuracy: 0.6903, Precision: 0.4453, Recall: 0.4048, F1: 0.3865
Testing Loss: 0.8317, Accuracy: 0.7340, Precision: 0.4147, Recall: 0.4289, F1: 0.4097
LM Predictions:  [5, 5, 2, 5, 4, 5, 2, 3, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6905, Accuracy: 0.3929, Precision: 0.2698, Recall: 0.3264, F1: 0.2598
Epoch 43/70
Train Loss: 0.5812, Accuracy: 0.7953, Precision: 0.5060, Recall: 0.4854, F1: 0.4808
Validation Loss: 0.9958, Accuracy: 0.6761, Precision: 0.3746, Recall: 0.4062, F1: 0.3854
Testing Loss: 0.8251, Accuracy: 0.7633, Precision: 0.4502, Recall: 0.4872, F1: 0.4662
LM Predictions:  [4, 5, 3, 5, 4, 5, 5, 3, 5, 1, 5, 5, 3, 4, 5, 5, 4, 5, 4, 3, 3, 3, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.9098, Accuracy: 0.3214, Precision: 0.3718, Recall: 0.2569, F1: 0.2346
Epoch 44/70
Train Loss: 0.6010, Accuracy: 0.7887, Precision: 0.5362, Recall: 0.4801, F1: 0.4782
Validation Loss: 0.8881, Accuracy: 0.6989, Precision: 0.4425, Recall: 0.3981, F1: 0.3858
Testing Loss: 0.8144, Accuracy: 0.7420, Precision: 0.5043, Recall: 0.4474, F1: 0.4438
LM Predictions:  [4, 5, 2, 5, 4, 5, 5, 3, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.7411, Accuracy: 0.3929, Precision: 0.2746, Recall: 0.3056, F1: 0.2579
Epoch 45/70
Train Loss: 0.5733, Accuracy: 0.8048, Precision: 0.5887, Recall: 0.5095, F1: 0.5123
Validation Loss: 0.9344, Accuracy: 0.7102, Precision: 0.4391, Recall: 0.3796, F1: 0.3737
Testing Loss: 0.8207, Accuracy: 0.7447, Precision: 0.4554, Recall: 0.4156, F1: 0.4109
LM Predictions:  [4, 5, 2, 5, 4, 5, 5, 3, 2, 5, 2, 5, 2, 4, 5, 5, 4, 5, 4, 3, 3, 2, 2, 2, 2, 5, 2, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6422, Accuracy: 0.4286, Precision: 0.2862, Recall: 0.3403, F1: 0.2838
Epoch 46/70
Train Loss: 0.5716, Accuracy: 0.7939, Precision: 0.5367, Recall: 0.4996, F1: 0.5011
Validation Loss: 0.8647, Accuracy: 0.7045, Precision: 0.4587, Recall: 0.4142, F1: 0.4023
Testing Loss: 0.7743, Accuracy: 0.7420, Precision: 0.5964, Recall: 0.4580, F1: 0.4542
LM Predictions:  [4, 5, 2, 5, 4, 5, 5, 3, 5, 5, 5, 5, 3, 4, 5, 5, 4, 5, 4, 3, 3, 1, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5710, Accuracy: 0.3929, Precision: 0.3254, Recall: 0.3264, F1: 0.2764
Epoch 47/70
Train Loss: 0.5473, Accuracy: 0.8058, Precision: 0.5374, Recall: 0.5087, F1: 0.5087
Validation Loss: 0.8562, Accuracy: 0.7159, Precision: 0.5539, Recall: 0.4255, F1: 0.4095
Testing Loss: 0.7738, Accuracy: 0.7500, Precision: 0.4393, Recall: 0.4458, F1: 0.4274
LM Predictions:  [4, 5, 2, 4, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 4, 5, 4, 3, 4, 4, 5, 2, 2, 5, 4, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6749, Accuracy: 0.3214, Precision: 0.2148, Recall: 0.2222, F1: 0.1989
Epoch 48/70
Train Loss: 0.5411, Accuracy: 0.8132, Precision: 0.5649, Recall: 0.5203, F1: 0.5248
Validation Loss: 0.8632, Accuracy: 0.7301, Precision: 0.4841, Recall: 0.4298, F1: 0.4318
Testing Loss: 0.7784, Accuracy: 0.7580, Precision: 0.5184, Recall: 0.4645, F1: 0.4721
LM Predictions:  [2, 5, 2, 2, 4, 1, 2, 2, 5, 5, 2, 5, 3, 4, 5, 5, 4, 5, 4, 3, 2, 4, 2, 2, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.6579, Accuracy: 0.5000, Precision: 0.4659, Recall: 0.4375, F1: 0.4125
Epoch 49/70
Train Loss: 0.5382, Accuracy: 0.8097, Precision: 0.5414, Recall: 0.5110, F1: 0.5106
Validation Loss: 0.9312, Accuracy: 0.6960, Precision: 0.4629, Recall: 0.4527, F1: 0.4326
Testing Loss: 0.8306, Accuracy: 0.7553, Precision: 0.5160, Recall: 0.5386, F1: 0.5250
LM Predictions:  [4, 5, 3, 1, 4, 1, 5, 3, 3, 1, 5, 5, 3, 4, 3, 5, 4, 1, 4, 3, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.7969, Accuracy: 0.3571, Precision: 0.3333, Recall: 0.3194, F1: 0.2956
Epoch 50/70
Train Loss: 0.4995, Accuracy: 0.8293, Precision: 0.5676, Recall: 0.5453, F1: 0.5484
Validation Loss: 0.8655, Accuracy: 0.7301, Precision: 0.4713, Recall: 0.4479, F1: 0.4510
Testing Loss: 0.8210, Accuracy: 0.7553, Precision: 0.4842, Recall: 0.4888, F1: 0.4807
LM Predictions:  [4, 5, 2, 4, 4, 5, 5, 3, 3, 1, 5, 3, 4, 4, 5, 5, 4, 5, 4, 3, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5230, Accuracy: 0.3214, Precision: 0.2528, Recall: 0.2222, F1: 0.2229
Epoch 51/70
Train Loss: 0.5125, Accuracy: 0.8188, Precision: 0.5702, Recall: 0.5375, F1: 0.5426
Validation Loss: 0.8906, Accuracy: 0.7216, Precision: 0.5642, Recall: 0.4392, F1: 0.4288
Testing Loss: 0.8161, Accuracy: 0.7527, Precision: 0.4518, Recall: 0.4501, F1: 0.4296
LM Predictions:  [5, 5, 2, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 3, 4, 5, 2, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4712, Accuracy: 0.3929, Precision: 0.2892, Recall: 0.3264, F1: 0.2566
Epoch 52/70
Train Loss: 0.4982, Accuracy: 0.8338, Precision: 0.6123, Recall: 0.5588, F1: 0.5624
Validation Loss: 0.9772, Accuracy: 0.7301, Precision: 0.5517, Recall: 0.4505, F1: 0.4442
Testing Loss: 0.9415, Accuracy: 0.7340, Precision: 0.4171, Recall: 0.4249, F1: 0.3976
LM Predictions:  [4, 5, 2, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 4, 5, 5, 4, 5, 4, 5, 4, 4, 5, 1, 2, 5, 5, 5]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5103, Accuracy: 0.4286, Precision: 0.3971, Recall: 0.4167, F1: 0.3262
Epoch 53/70
Train Loss: 0.4978, Accuracy: 0.8261, Precision: 0.5753, Recall: 0.5517, F1: 0.5554
Validation Loss: 0.8752, Accuracy: 0.7159, Precision: 0.3994, Recall: 0.4393, F1: 0.4168
Testing Loss: 0.7725, Accuracy: 0.7606, Precision: 0.5245, Recall: 0.4811, F1: 0.4856
LM Predictions:  [3, 5, 2, 4, 4, 1, 5, 3, 3, 5, 2, 3, 3, 4, 3, 5, 4, 5, 4, 3, 3, 4, 2, 3, 2, 5, 2, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4179, Accuracy: 0.3929, Precision: 0.4667, Recall: 0.3403, F1: 0.3847
Epoch 54/70
Train Loss: 0.4739, Accuracy: 0.8387, Precision: 0.6196, Recall: 0.5742, F1: 0.5830
Validation Loss: 0.8458, Accuracy: 0.7216, Precision: 0.4030, Recall: 0.4385, F1: 0.4184
Testing Loss: 0.7425, Accuracy: 0.7606, Precision: 0.4571, Recall: 0.4921, F1: 0.4714
LM Predictions:  [3, 5, 2, 5, 4, 3, 5, 3, 3, 5, 5, 3, 4, 4, 3, 5, 4, 5, 4, 3, 3, 4, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4725, Accuracy: 0.3571, Precision: 0.3556, Recall: 0.2847, F1: 0.2738
Epoch 55/70
Train Loss: 0.4692, Accuracy: 0.8404, Precision: 0.6052, Recall: 0.5748, F1: 0.5777
Validation Loss: 0.9878, Accuracy: 0.7102, Precision: 0.4504, Recall: 0.4642, F1: 0.4458
Testing Loss: 0.8607, Accuracy: 0.7420, Precision: 0.4911, Recall: 0.5177, F1: 0.4966
LM Predictions:  [3, 5, 1, 5, 4, 1, 5, 3, 3, 5, 5, 3, 4, 4, 3, 5, 4, 5, 4, 3, 3, 1, 5, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8973, Accuracy: 0.3214, Precision: 0.4056, Recall: 0.3194, F1: 0.2883
Epoch 56/70
Train Loss: 0.4679, Accuracy: 0.8443, Precision: 0.6057, Recall: 0.5785, F1: 0.5819
Validation Loss: 0.8996, Accuracy: 0.7273, Precision: 0.4593, Recall: 0.4432, F1: 0.4420
Testing Loss: 0.7959, Accuracy: 0.7660, Precision: 0.5494, Recall: 0.5089, F1: 0.5229
LM Predictions:  [4, 1, 2, 4, 4, 3, 5, 3, 3, 1, 2, 3, 4, 4, 3, 5, 4, 5, 4, 3, 3, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4246, Accuracy: 0.3929, Precision: 0.3333, Recall: 0.2778, F1: 0.3000
Epoch 57/70
Train Loss: 0.4711, Accuracy: 0.8321, Precision: 0.5801, Recall: 0.5555, F1: 0.5578
Validation Loss: 0.9814, Accuracy: 0.6790, Precision: 0.4011, Recall: 0.4374, F1: 0.4015
Testing Loss: 0.8098, Accuracy: 0.7580, Precision: 0.5083, Recall: 0.5189, F1: 0.4905
LM Predictions:  [3, 3, 2, 3, 4, 3, 5, 3, 3, 3, 5, 3, 4, 4, 3, 5, 4, 3, 4, 3, 3, 4, 5, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.8242, Accuracy: 0.2857, Precision: 0.3389, Recall: 0.2014, F1: 0.2394
Epoch 58/70
Train Loss: 0.4487, Accuracy: 0.8439, Precision: 0.6037, Recall: 0.5852, F1: 0.5881
Validation Loss: 0.8992, Accuracy: 0.7074, Precision: 0.4487, Recall: 0.4512, F1: 0.4409
Testing Loss: 0.7762, Accuracy: 0.7713, Precision: 0.5270, Recall: 0.5254, F1: 0.5248
LM Predictions:  [3, 3, 2, 4, 4, 1, 5, 3, 3, 1, 2, 3, 4, 4, 3, 5, 4, 1, 4, 3, 3, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5283, Accuracy: 0.3929, Precision: 0.3968, Recall: 0.3403, F1: 0.3587
Epoch 59/70
Train Loss: 0.4060, Accuracy: 0.8625, Precision: 0.7407, Recall: 0.6266, F1: 0.6377
Validation Loss: 0.9507, Accuracy: 0.7301, Precision: 0.4898, Recall: 0.4433, F1: 0.4421
Testing Loss: 0.7762, Accuracy: 0.7926, Precision: 0.4852, Recall: 0.5085, F1: 0.4956
LM Predictions:  [3, 5, 2, 5, 4, 3, 0, 3, 3, 5, 5, 3, 3, 4, 3, 5, 4, 5, 4, 3, 3, 4, 2, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2685, Accuracy: 0.4286, Precision: 0.5625, Recall: 0.3333, F1: 0.3597
Epoch 60/70
Train Loss: 0.4004, Accuracy: 0.8607, Precision: 0.7640, Recall: 0.6309, F1: 0.6423
Validation Loss: 1.1048, Accuracy: 0.7074, Precision: 0.3917, Recall: 0.4151, F1: 0.4001
Testing Loss: 0.9136, Accuracy: 0.7527, Precision: 0.4381, Recall: 0.4466, F1: 0.4401
LM Predictions:  [4, 5, 2, 4, 4, 3, 0, 3, 3, 5, 2, 3, 4, 4, 3, 5, 4, 5, 4, 3, 3, 4, 2, 3, 2, 5, 4, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4768, Accuracy: 0.4286, Precision: 0.4778, Recall: 0.2986, F1: 0.3251
Epoch 61/70
Train Loss: 0.4171, Accuracy: 0.8474, Precision: 0.7611, Recall: 0.5884, F1: 0.5938
Validation Loss: 1.1299, Accuracy: 0.7273, Precision: 0.4177, Recall: 0.4148, F1: 0.4102
Testing Loss: 0.9515, Accuracy: 0.7633, Precision: 0.4735, Recall: 0.4427, F1: 0.4430
LM Predictions:  [3, 5, 2, 2, 4, 3, 0, 3, 3, 5, 2, 3, 3, 4, 5, 5, 4, 5, 4, 3, 2, 4, 2, 2, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.3990, Accuracy: 0.4643, Precision: 0.5079, Recall: 0.3472, F1: 0.3601
Epoch 62/70
Train Loss: 0.3846, Accuracy: 0.8618, Precision: 0.6936, Recall: 0.6278, F1: 0.6400
Validation Loss: 1.0045, Accuracy: 0.7188, Precision: 0.4662, Recall: 0.4649, F1: 0.4633
Testing Loss: 0.8548, Accuracy: 0.7606, Precision: 0.5077, Recall: 0.5221, F1: 0.5008
LM Predictions:  [3, 1, 2, 4, 4, 3, 0, 3, 3, 1, 2, 3, 3, 4, 3, 3, 4, 5, 4, 3, 3, 4, 2, 3, 2, 3, 4, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.5314, Accuracy: 0.3929, Precision: 0.4583, Recall: 0.2569, F1: 0.2954
Epoch 63/70
Train Loss: 0.3955, Accuracy: 0.8611, Precision: 0.6950, Recall: 0.6057, F1: 0.6095
Validation Loss: 0.9494, Accuracy: 0.7472, Precision: 0.5008, Recall: 0.4602, F1: 0.4653
Testing Loss: 0.8537, Accuracy: 0.7633, Precision: 0.5292, Recall: 0.4949, F1: 0.5030
LM Predictions:  [3, 1, 2, 5, 4, 1, 0, 3, 3, 5, 5, 3, 3, 4, 3, 5, 4, 5, 4, 3, 2, 4, 2, 2, 2, 5, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.1197, Accuracy: 0.5357, Precision: 0.6214, Recall: 0.4653, F1: 0.4753
Epoch 64/70
Train Loss: 0.3698, Accuracy: 0.8737, Precision: 0.7146, Recall: 0.6460, F1: 0.6595
Validation Loss: 0.9627, Accuracy: 0.7330, Precision: 0.4906, Recall: 0.4526, F1: 0.4574
Testing Loss: 0.9000, Accuracy: 0.7553, Precision: 0.4945, Recall: 0.4674, F1: 0.4661
LM Predictions:  [3, 5, 2, 5, 4, 1, 5, 5, 3, 5, 5, 3, 3, 4, 5, 5, 4, 5, 4, 3, 2, 4, 2, 2, 2, 5, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.0646, Accuracy: 0.5000, Precision: 0.5121, Recall: 0.4444, F1: 0.4418
Epoch 65/70
Train Loss: 0.3687, Accuracy: 0.8691, Precision: 0.7034, Recall: 0.6312, F1: 0.6435
Validation Loss: 0.9733, Accuracy: 0.7330, Precision: 0.5158, Recall: 0.4583, F1: 0.4619
Testing Loss: 0.8186, Accuracy: 0.7686, Precision: 0.5410, Recall: 0.5048, F1: 0.5143
LM Predictions:  [3, 1, 2, 5, 4, 3, 0, 3, 3, 5, 2, 3, 3, 4, 3, 3, 4, 5, 4, 3, 2, 4, 2, 3, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2328, Accuracy: 0.5357, Precision: 0.6250, Recall: 0.4097, F1: 0.4564
Epoch 66/70
Train Loss: 0.3766, Accuracy: 0.8646, Precision: 0.6807, Recall: 0.6197, F1: 0.6277
Validation Loss: 0.9781, Accuracy: 0.7301, Precision: 0.4863, Recall: 0.4786, F1: 0.4734
Testing Loss: 0.8189, Accuracy: 0.7500, Precision: 0.4779, Recall: 0.4868, F1: 0.4817
LM Predictions:  [3, 1, 2, 5, 4, 3, 0, 3, 3, 5, 5, 3, 3, 4, 3, 0, 4, 0, 4, 3, 3, 4, 2, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.2436, Accuracy: 0.5000, Precision: 0.6000, Recall: 0.3750, F1: 0.4413
Epoch 67/70
Train Loss: 0.3510, Accuracy: 0.8772, Precision: 0.7455, Recall: 0.6482, F1: 0.6619
Validation Loss: 1.0678, Accuracy: 0.7131, Precision: 0.5191, Recall: 0.4605, F1: 0.4420
Testing Loss: 0.9135, Accuracy: 0.7633, Precision: 0.5271, Recall: 0.5115, F1: 0.5009
LM Predictions:  [3, 1, 2, 3, 4, 3, 0, 3, 3, 3, 2, 3, 3, 4, 3, 3, 4, 0, 4, 3, 3, 4, 2, 3, 2, 3, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.4734, Accuracy: 0.4286, Precision: 0.6667, Recall: 0.2986, F1: 0.3949
Epoch 68/70
Train Loss: 0.3556, Accuracy: 0.8789, Precision: 0.7723, Recall: 0.6544, F1: 0.6721
Validation Loss: 0.9525, Accuracy: 0.7443, Precision: 0.5163, Recall: 0.4833, F1: 0.4865
Testing Loss: 0.8563, Accuracy: 0.7527, Precision: 0.4977, Recall: 0.4781, F1: 0.4743
LM Predictions:  [3, 1, 2, 5, 4, 5, 0, 3, 5, 5, 2, 5, 3, 4, 0, 0, 4, 0, 4, 3, 3, 4, 2, 3, 2, 5, 5, 3]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.0320, Accuracy: 0.6071, Precision: 0.5952, Recall: 0.4653, F1: 0.4939
Epoch 69/70
Train Loss: 0.3460, Accuracy: 0.8842, Precision: 0.7359, Recall: 0.6643, F1: 0.6816
Validation Loss: 1.0138, Accuracy: 0.7386, Precision: 0.6030, Recall: 0.4626, F1: 0.4747
Testing Loss: 0.9593, Accuracy: 0.7606, Precision: 0.5295, Recall: 0.4773, F1: 0.4936
LM Predictions:  [3, 4, 2, 5, 4, 1, 0, 2, 3, 5, 2, 3, 4, 4, 0, 0, 4, 0, 4, 3, 2, 4, 2, 3, 2, 1, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 0.7494, Accuracy: 0.7500, Precision: 0.7292, Recall: 0.6042, F1: 0.6498
Epoch 70/70
Train Loss: 0.3165, Accuracy: 0.8845, Precision: 0.7400, Recall: 0.6770, F1: 0.6952
Validation Loss: 1.0001, Accuracy: 0.7273, Precision: 0.4721, Recall: 0.4805, F1: 0.4647
Testing Loss: 0.8549, Accuracy: 0.7686, Precision: 0.5166, Recall: 0.5139, F1: 0.5076
LM Predictions:  [3, 1, 2, 5, 4, 3, 0, 3, 3, 5, 5, 5, 3, 4, 3, 0, 4, 0, 4, 3, 3, 4, 2, 3, 2, 3, 5, 4]
LM Labels:  [4, 4, 2, 5, 4, 1, 0, 2, 0, 5, 2, 5, 1, 4, 0, 0, 4, 0, 4, 0, 2, 4, 2, 0, 2, 0, 5, 4]
LM Loss: 1.0673, Accuracy: 0.5714, Precision: 0.6333, Recall: 0.4375, F1: 0.4930
Label Memorization Analysis: 
LM Loss: 1.0673, Accuracy: 0.5714, Precision: 0.6333, Recall: 0.4375, F1: 0.4930
---------------------------------------------------------------------------



