13007 13007
10405 10405 2602 2602
Model: facebook/vit-msn-small, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:1
Noise: 1% with label 6
Label counts for Train:
  Label 9: 900
  Label 7: 469
  Label 3: 707
  Label 10: 818
  Label 5: 379
  Label 0: 819
  Label 2: 534
  Label 12: 618
  Label 6: 924
  Label 13: 834
  Label 1: 789
  Label 4: 808
  Label 11: 709
  Label 14: 664
  Label 8: 433
Label counts for Validation:
  Label 6: 115
  Label 4: 101
  Label 0: 103
  Label 11: 88
  Label 12: 78
  Label 7: 58
  Label 9: 112
  Label 3: 89
  Label 8: 54
  Label 1: 99
  Label 13: 105
  Label 2: 67
  Label 5: 47
  Label 14: 83
  Label 10: 102
Label counts for Test:
  Label 0: 102
  Label 3: 88
  Label 1: 98
  Label 13: 104
  Label 7: 59
  Label 10: 103
  Label 8: 54
  Label 4: 101
  Label 11: 89
  Label 2: 67
  Label 6: 116
  Label 5: 47
  Label 14: 83
  Label 12: 77
  Label 9: 113
104
Actual labels:  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
Label counts for Train:
  Label 9: 906
  Label 7: 474
  Label 3: 713
  Label 10: 822
  Label 5: 389
  Label 0: 826
  Label 2: 542
  Label 12: 628
  Label 6: 820
  Label 13: 840
  Label 1: 795
  Label 4: 814
  Label 11: 716
  Label 14: 673
  Label 8: 447
10405
(3, 224, 224)
For early layers:  [0, 1, 2, 3]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 2.0834, Accuracy: 0.3337, Precision: 0.3311, Recall: 0.3149, F1: 0.3112
Validation Loss: 1.7399, Accuracy: 0.4450, Precision: 0.4659, Recall: 0.4322, F1: 0.4210
Testing Loss: 1.6767, Accuracy: 0.4573, Precision: 0.4945, Recall: 0.4494, F1: 0.4416
LM Predictions:  [14, 13, 0, 13, 0, 12, 6, 4, 0, 0, 0, 0, 9, 10, 0, 0, 9, 9, 0, 0, 0, 11, 14, 11, 12, 0, 14, 0, 6, 9, 13, 14, 14, 14, 0, 0, 3, 13, 8, 1, 1, 0, 0, 9, 13, 0, 6, 13, 13, 0, 0, 14, 9, 13, 0, 0, 13, 13, 13, 6, 3, 11, 0, 4, 13, 6, 1, 9, 11, 3, 3, 6, 0, 6, 12, 0, 13, 0, 3, 6, 1, 6, 4, 14, 14, 0, 13, 14, 13, 14, 14, 14, 6, 9, 13, 8, 9, 4, 6, 0, 0, 6, 0, 0]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 3.4647, Accuracy: 0.1058, Precision: 0.1211, Recall: 0.1032, F1: 0.0756
Epoch 2/70
Train Loss: 1.4260, Accuracy: 0.5480, Precision: 0.5465, Recall: 0.5372, F1: 0.5388
Validation Loss: 1.3284, Accuracy: 0.5665, Precision: 0.5955, Recall: 0.5597, F1: 0.5560
Testing Loss: 1.2331, Accuracy: 0.6088, Precision: 0.6440, Recall: 0.5992, F1: 0.6024
LM Predictions:  [6, 13, 2, 13, 6, 2, 6, 10, 6, 10, 6, 6, 14, 10, 2, 6, 6, 14, 6, 6, 6, 1, 14, 11, 2, 6, 4, 6, 6, 6, 6, 10, 2, 14, 6, 6, 14, 6, 1, 6, 1, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 6, 6, 6, 0, 13, 13, 6, 6, 6, 6, 6, 6, 6, 14, 6, 14, 13, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 10, 11, 11, 6, 6, 6, 13, 6, 6, 6, 6, 14, 6, 14, 4, 8, 14, 4, 6, 6, 6, 6, 6, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 3.7815, Accuracy: 0.0481, Precision: 0.0911, Recall: 0.0548, F1: 0.0609
Epoch 3/70
Train Loss: 0.9493, Accuracy: 0.7036, Precision: 0.7047, Recall: 0.6987, F1: 0.7008
Validation Loss: 1.0800, Accuracy: 0.6449, Precision: 0.6710, Recall: 0.6502, F1: 0.6477
Testing Loss: 1.0334, Accuracy: 0.6726, Precision: 0.6913, Recall: 0.6760, F1: 0.6742
LM Predictions:  [6, 0, 0, 13, 6, 12, 6, 6, 0, 2, 6, 6, 8, 0, 12, 0, 2, 4, 6, 6, 0, 8, 2, 0, 2, 4, 4, 0, 0, 6, 6, 6, 2, 8, 0, 6, 10, 6, 13, 2, 1, 0, 0, 0, 0, 8, 0, 6, 0, 0, 13, 4, 6, 14, 0, 0, 13, 6, 0, 2, 4, 6, 0, 6, 14, 8, 13, 13, 6, 8, 0, 6, 0, 0, 6, 6, 0, 0, 4, 6, 8, 6, 4, 6, 2, 0, 13, 4, 0, 6, 9, 14, 6, 2, 4, 8, 2, 4, 0, 6, 0, 2, 0, 4]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 3.1215, Accuracy: 0.1827, Precision: 0.1392, Recall: 0.1680, F1: 0.1208
Epoch 4/70
Train Loss: 0.5364, Accuracy: 0.8424, Precision: 0.8452, Recall: 0.8400, F1: 0.8423
Validation Loss: 1.0488, Accuracy: 0.6772, Precision: 0.7115, Recall: 0.6716, F1: 0.6818
Testing Loss: 1.0269, Accuracy: 0.6772, Precision: 0.7240, Recall: 0.6708, F1: 0.6853
LM Predictions:  [6, 3, 0, 13, 6, 12, 6, 6, 0, 12, 6, 6, 13, 0, 12, 13, 9, 4, 0, 0, 9, 8, 0, 5, 6, 0, 2, 14, 0, 6, 0, 10, 13, 5, 14, 0, 6, 13, 0, 0, 5, 14, 0, 0, 0, 5, 0, 6, 0, 0, 0, 6, 6, 14, 0, 0, 13, 13, 0, 2, 6, 6, 0, 5, 14, 6, 6, 13, 6, 13, 14, 6, 0, 0, 12, 6, 0, 14, 4, 6, 4, 6, 9, 6, 11, 0, 0, 4, 5, 6, 9, 13, 6, 2, 4, 8, 9, 4, 6, 6, 0, 0, 6, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 2.5689, Accuracy: 0.2885, Precision: 0.3692, Recall: 0.2761, F1: 0.2621
Epoch 5/70
Train Loss: 0.2417, Accuracy: 0.9391, Precision: 0.9407, Recall: 0.9385, F1: 0.9395
Validation Loss: 1.0072, Accuracy: 0.6972, Precision: 0.7167, Recall: 0.6960, F1: 0.7015
Testing Loss: 1.0169, Accuracy: 0.7002, Precision: 0.7211, Recall: 0.7049, F1: 0.7060
LM Predictions:  [5, 9, 4, 13, 8, 5, 6, 3, 0, 12, 6, 8, 13, 11, 12, 0, 6, 12, 14, 11, 9, 4, 2, 11, 6, 4, 2, 14, 5, 6, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 14, 6, 0, 6, 3, 0, 7, 6, 6, 0, 8, 6, 14, 0, 3, 13, 6, 14, 6, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 0, 6, 0, 6, 11, 6, 0, 14, 8, 6, 1, 6, 9, 6, 2, 8, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 6, 6, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 1.0000, Accuracy: 0.6731, Precision: 0.8353, Recall: 0.6063, F1: 0.6844
Epoch 6/70
Train Loss: 0.1045, Accuracy: 0.9794, Precision: 0.9804, Recall: 0.9795, F1: 0.9800
Validation Loss: 1.1189, Accuracy: 0.7018, Precision: 0.7223, Recall: 0.7044, F1: 0.7068
Testing Loss: 1.0765, Accuracy: 0.7018, Precision: 0.7172, Recall: 0.7003, F1: 0.7032
LM Predictions:  [5, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 6, 8, 8, 14, 0, 3, 6, 6, 6, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 3, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 6, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 6, 12, 11, 6, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.6597, Accuracy: 0.7885, Precision: 0.8743, Recall: 0.7315, F1: 0.7924
Epoch 7/70
Train Loss: 0.0861, Accuracy: 0.9811, Precision: 0.9820, Recall: 0.9814, F1: 0.9817
Validation Loss: 1.1877, Accuracy: 0.6733, Precision: 0.7033, Recall: 0.6710, F1: 0.6807
Testing Loss: 1.1451, Accuracy: 0.6995, Precision: 0.7239, Recall: 0.6989, F1: 0.7070
LM Predictions:  [6, 9, 4, 13, 8, 5, 6, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 6, 0, 6, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4944, Accuracy: 0.8654, Precision: 0.9044, Recall: 0.8024, F1: 0.8449
Epoch 8/70
Train Loss: 0.0805, Accuracy: 0.9811, Precision: 0.9821, Recall: 0.9808, F1: 0.9814
Validation Loss: 1.3309, Accuracy: 0.6733, Precision: 0.6882, Recall: 0.6842, F1: 0.6738
Testing Loss: 1.3366, Accuracy: 0.6764, Precision: 0.6918, Recall: 0.6821, F1: 0.6750
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 1, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 3, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4283, Accuracy: 0.9327, Precision: 0.8898, Recall: 0.8597, F1: 0.8720
Epoch 9/70
Train Loss: 0.0937, Accuracy: 0.9736, Precision: 0.9747, Recall: 0.9739, F1: 0.9743
Validation Loss: 1.2850, Accuracy: 0.6756, Precision: 0.6999, Recall: 0.6800, F1: 0.6787
Testing Loss: 1.2094, Accuracy: 0.7125, Precision: 0.7344, Recall: 0.7158, F1: 0.7158
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 0, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3626, Accuracy: 0.8942, Precision: 0.8967, Recall: 0.8432, F1: 0.8649
Epoch 10/70
Train Loss: 0.0767, Accuracy: 0.9780, Precision: 0.9788, Recall: 0.9784, F1: 0.9786
Validation Loss: 1.3255, Accuracy: 0.6879, Precision: 0.7170, Recall: 0.6825, F1: 0.6918
Testing Loss: 1.2216, Accuracy: 0.7025, Precision: 0.7248, Recall: 0.6950, F1: 0.7029
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 10, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 9, 11, 9, 4, 2, 7, 6, 4, 2, 0, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 0, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 0, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.5035, Accuracy: 0.8750, Precision: 0.8715, Recall: 0.8139, F1: 0.8365
Epoch 11/70
Train Loss: 0.0495, Accuracy: 0.9880, Precision: 0.9885, Recall: 0.9884, F1: 0.9884
Validation Loss: 1.2352, Accuracy: 0.6925, Precision: 0.7052, Recall: 0.6950, F1: 0.6931
Testing Loss: 1.2084, Accuracy: 0.7118, Precision: 0.7208, Recall: 0.7148, F1: 0.7112
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 10, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 3, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3678, Accuracy: 0.8942, Precision: 0.8846, Recall: 0.8231, F1: 0.8507
Epoch 12/70
Train Loss: 0.0669, Accuracy: 0.9802, Precision: 0.9806, Recall: 0.9805, F1: 0.9805
Validation Loss: 1.5432, Accuracy: 0.6426, Precision: 0.6935, Recall: 0.6372, F1: 0.6472
Testing Loss: 1.4318, Accuracy: 0.6726, Precision: 0.7194, Recall: 0.6699, F1: 0.6795
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 4, 0, 12, 9, 8, 13, 11, 12, 13, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 6, 0, 5, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 6, 0, 12, 1, 8, 5, 5, 6, 11, 14, 6, 0, 6, 11, 9, 0, 14, 4, 5, 1, 6, 9, 11, 5, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.5788, Accuracy: 0.8558, Precision: 0.8798, Recall: 0.7946, F1: 0.8245
Epoch 13/70
Train Loss: 0.0579, Accuracy: 0.9837, Precision: 0.9832, Recall: 0.9835, F1: 0.9834
Validation Loss: 1.3690, Accuracy: 0.6772, Precision: 0.6933, Recall: 0.6880, F1: 0.6807
Testing Loss: 1.3088, Accuracy: 0.7010, Precision: 0.7121, Recall: 0.7092, F1: 0.7012
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 2, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2587, Accuracy: 0.9135, Precision: 0.9065, Recall: 0.8558, F1: 0.8757
Epoch 14/70
Train Loss: 0.0457, Accuracy: 0.9871, Precision: 0.9878, Recall: 0.9875, F1: 0.9876
Validation Loss: 1.4488, Accuracy: 0.6741, Precision: 0.6894, Recall: 0.6715, F1: 0.6710
Testing Loss: 1.2994, Accuracy: 0.7071, Precision: 0.7214, Recall: 0.7073, F1: 0.7076
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 11, 12, 1, 3, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3334, Accuracy: 0.9135, Precision: 0.9028, Recall: 0.8456, F1: 0.8690
Epoch 15/70
Train Loss: 0.0481, Accuracy: 0.9864, Precision: 0.9864, Recall: 0.9861, F1: 0.9863
Validation Loss: 1.4732, Accuracy: 0.6595, Precision: 0.6813, Recall: 0.6643, F1: 0.6572
Testing Loss: 1.4173, Accuracy: 0.6779, Precision: 0.6953, Recall: 0.6837, F1: 0.6745
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 2, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 2, 0, 8, 0, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1467, Accuracy: 0.9519, Precision: 0.9056, Recall: 0.8860, F1: 0.8919
Epoch 16/70
Train Loss: 0.0658, Accuracy: 0.9799, Precision: 0.9802, Recall: 0.9797, F1: 0.9799
Validation Loss: 1.3550, Accuracy: 0.6925, Precision: 0.7202, Recall: 0.6892, F1: 0.6975
Testing Loss: 1.3496, Accuracy: 0.7110, Precision: 0.7323, Recall: 0.7033, F1: 0.7120
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 6, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2263, Accuracy: 0.9327, Precision: 0.9222, Recall: 0.8589, F1: 0.8851
Epoch 17/70
Train Loss: 0.0333, Accuracy: 0.9904, Precision: 0.9904, Recall: 0.9907, F1: 0.9905
Validation Loss: 1.4452, Accuracy: 0.6864, Precision: 0.6984, Recall: 0.6864, F1: 0.6849
Testing Loss: 1.3917, Accuracy: 0.7056, Precision: 0.7218, Recall: 0.7072, F1: 0.7051
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 3, 8, 0, 6, 4, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2457, Accuracy: 0.9231, Precision: 0.8891, Recall: 0.8547, F1: 0.8687
Epoch 18/70
Train Loss: 0.0635, Accuracy: 0.9800, Precision: 0.9800, Recall: 0.9796, F1: 0.9798
Validation Loss: 1.3937, Accuracy: 0.6933, Precision: 0.7299, Recall: 0.6972, F1: 0.7017
Testing Loss: 1.3939, Accuracy: 0.6925, Precision: 0.7137, Recall: 0.6949, F1: 0.6922
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 5, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2071, Accuracy: 0.9135, Precision: 0.9072, Recall: 0.8404, F1: 0.8683
Epoch 19/70
Train Loss: 0.0431, Accuracy: 0.9866, Precision: 0.9869, Recall: 0.9870, F1: 0.9870
Validation Loss: 1.4073, Accuracy: 0.6987, Precision: 0.7165, Recall: 0.6995, F1: 0.7020
Testing Loss: 1.3107, Accuracy: 0.7087, Precision: 0.7135, Recall: 0.7087, F1: 0.7081
LM Predictions:  [7, 9, 4, 6, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 3, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3018, Accuracy: 0.9038, Precision: 0.9116, Recall: 0.8372, F1: 0.8689
Epoch 20/70
Train Loss: 0.0417, Accuracy: 0.9868, Precision: 0.9873, Recall: 0.9873, F1: 0.9873
Validation Loss: 1.3046, Accuracy: 0.7048, Precision: 0.7084, Recall: 0.7040, F1: 0.7029
Testing Loss: 1.2552, Accuracy: 0.7241, Precision: 0.7359, Recall: 0.7236, F1: 0.7255
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 6, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2605, Accuracy: 0.9231, Precision: 0.9133, Recall: 0.8629, F1: 0.8824
Epoch 21/70
Train Loss: 0.0414, Accuracy: 0.9873, Precision: 0.9876, Recall: 0.9875, F1: 0.9876
Validation Loss: 1.6262, Accuracy: 0.6656, Precision: 0.6871, Recall: 0.6623, F1: 0.6590
Testing Loss: 1.4294, Accuracy: 0.6810, Precision: 0.6904, Recall: 0.6745, F1: 0.6713
LM Predictions:  [7, 9, 4, 13, 8, 2, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 2, 4, 2, 8, 6, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 1, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 6, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 2, 1, 2, 4, 14, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3851, Accuracy: 0.8558, Precision: 0.8781, Recall: 0.7953, F1: 0.8244
Epoch 22/70
Train Loss: 0.0395, Accuracy: 0.9870, Precision: 0.9875, Recall: 0.9869, F1: 0.9872
Validation Loss: 1.3535, Accuracy: 0.7041, Precision: 0.7257, Recall: 0.6971, F1: 0.7032
Testing Loss: 1.3245, Accuracy: 0.7087, Precision: 0.7333, Recall: 0.6998, F1: 0.7080
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2595, Accuracy: 0.9038, Precision: 0.9111, Recall: 0.8280, F1: 0.8640
Epoch 23/70
Train Loss: 0.0391, Accuracy: 0.9872, Precision: 0.9873, Recall: 0.9875, F1: 0.9874
Validation Loss: 1.4297, Accuracy: 0.7056, Precision: 0.7196, Recall: 0.7071, F1: 0.7058
Testing Loss: 1.4136, Accuracy: 0.7018, Precision: 0.7189, Recall: 0.7057, F1: 0.7015
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 6, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 13, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 6, 0, 14, 8, 6, 1, 6, 9, 11, 11, 13, 3, 8, 5, 5, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3022, Accuracy: 0.8750, Precision: 0.8890, Recall: 0.8001, F1: 0.8339
Epoch 24/70
Train Loss: 0.0577, Accuracy: 0.9805, Precision: 0.9807, Recall: 0.9800, F1: 0.9803
Validation Loss: 1.4733, Accuracy: 0.6856, Precision: 0.6981, Recall: 0.6978, F1: 0.6922
Testing Loss: 1.4048, Accuracy: 0.6902, Precision: 0.7037, Recall: 0.6923, F1: 0.6927
LM Predictions:  [7, 9, 8, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 4, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2164, Accuracy: 0.9038, Precision: 0.8961, Recall: 0.8319, F1: 0.8579
Epoch 25/70
Train Loss: 0.0458, Accuracy: 0.9838, Precision: 0.9837, Recall: 0.9834, F1: 0.9835
Validation Loss: 1.4275, Accuracy: 0.6941, Precision: 0.7073, Recall: 0.6917, F1: 0.6940
Testing Loss: 1.3524, Accuracy: 0.7071, Precision: 0.7269, Recall: 0.7052, F1: 0.7111
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 2, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1937, Accuracy: 0.9135, Precision: 0.9145, Recall: 0.8462, F1: 0.8762
Epoch 26/70
Train Loss: 0.0300, Accuracy: 0.9903, Precision: 0.9904, Recall: 0.9903, F1: 0.9903
Validation Loss: 1.4874, Accuracy: 0.6802, Precision: 0.6940, Recall: 0.6794, F1: 0.6773
Testing Loss: 1.4168, Accuracy: 0.6972, Precision: 0.7224, Recall: 0.6977, F1: 0.6972
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 9, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 7, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2786, Accuracy: 0.8846, Precision: 0.9003, Recall: 0.8194, F1: 0.8524
Epoch 27/70
Train Loss: 0.0355, Accuracy: 0.9878, Precision: 0.9881, Recall: 0.9881, F1: 0.9881
Validation Loss: 1.5989, Accuracy: 0.6664, Precision: 0.6921, Recall: 0.6687, F1: 0.6688
Testing Loss: 1.6113, Accuracy: 0.6687, Precision: 0.6988, Recall: 0.6708, F1: 0.6729
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 2, 14, 11, 9, 4, 2, 6, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 2, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2241, Accuracy: 0.9135, Precision: 0.8998, Recall: 0.8359, F1: 0.8604
Epoch 28/70
Train Loss: 0.0459, Accuracy: 0.9847, Precision: 0.9841, Recall: 0.9843, F1: 0.9842
Validation Loss: 1.4547, Accuracy: 0.6979, Precision: 0.7150, Recall: 0.6989, F1: 0.7024
Testing Loss: 1.3803, Accuracy: 0.7064, Precision: 0.7263, Recall: 0.7069, F1: 0.7118
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1799, Accuracy: 0.9231, Precision: 0.9050, Recall: 0.8597, F1: 0.8766
Epoch 29/70
Train Loss: 0.0152, Accuracy: 0.9951, Precision: 0.9952, Recall: 0.9951, F1: 0.9951
Validation Loss: 1.3593, Accuracy: 0.7248, Precision: 0.7343, Recall: 0.7270, F1: 0.7273
Testing Loss: 1.3519, Accuracy: 0.7202, Precision: 0.7258, Recall: 0.7227, F1: 0.7214
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1280, Accuracy: 0.9423, Precision: 0.9127, Recall: 0.8716, F1: 0.8889
Epoch 30/70
Train Loss: 0.0151, Accuracy: 0.9953, Precision: 0.9954, Recall: 0.9955, F1: 0.9955
Validation Loss: 1.4939, Accuracy: 0.7010, Precision: 0.7041, Recall: 0.7019, F1: 0.6965
Testing Loss: 1.4419, Accuracy: 0.7048, Precision: 0.7081, Recall: 0.7056, F1: 0.7002
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1262, Accuracy: 0.9615, Precision: 0.9133, Recall: 0.9060, F1: 0.9077
Epoch 31/70
Train Loss: 0.0751, Accuracy: 0.9771, Precision: 0.9768, Recall: 0.9773, F1: 0.9770
Validation Loss: 1.4462, Accuracy: 0.7041, Precision: 0.7116, Recall: 0.7105, F1: 0.7063
Testing Loss: 1.3814, Accuracy: 0.7125, Precision: 0.7186, Recall: 0.7157, F1: 0.7126
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1873, Accuracy: 0.9327, Precision: 0.9050, Recall: 0.8808, F1: 0.8901
Epoch 32/70
Train Loss: 0.0189, Accuracy: 0.9935, Precision: 0.9938, Recall: 0.9936, F1: 0.9937
Validation Loss: 1.4858, Accuracy: 0.6956, Precision: 0.7075, Recall: 0.6960, F1: 0.6951
Testing Loss: 1.4098, Accuracy: 0.7048, Precision: 0.7316, Recall: 0.7080, F1: 0.7128
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 0, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2649, Accuracy: 0.9038, Precision: 0.9056, Recall: 0.8353, F1: 0.8647
Epoch 33/70
Train Loss: 0.0433, Accuracy: 0.9852, Precision: 0.9853, Recall: 0.9849, F1: 0.9851
Validation Loss: 1.6389, Accuracy: 0.6687, Precision: 0.6906, Recall: 0.6764, F1: 0.6748
Testing Loss: 1.5544, Accuracy: 0.6741, Precision: 0.6988, Recall: 0.6768, F1: 0.6793
LM Predictions:  [7, 9, 2, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 9, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 0, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3091, Accuracy: 0.8654, Precision: 0.8837, Recall: 0.8043, F1: 0.8350
Epoch 34/70
Train Loss: 0.0333, Accuracy: 0.9892, Precision: 0.9893, Recall: 0.9894, F1: 0.9893
Validation Loss: 1.4762, Accuracy: 0.7079, Precision: 0.7282, Recall: 0.7054, F1: 0.7091
Testing Loss: 1.3317, Accuracy: 0.7225, Precision: 0.7348, Recall: 0.7208, F1: 0.7222
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1879, Accuracy: 0.9038, Precision: 0.9108, Recall: 0.8388, F1: 0.8702
Epoch 35/70
Train Loss: 0.0385, Accuracy: 0.9859, Precision: 0.9863, Recall: 0.9858, F1: 0.9860
Validation Loss: 1.5761, Accuracy: 0.6795, Precision: 0.6969, Recall: 0.6837, F1: 0.6841
Testing Loss: 1.5124, Accuracy: 0.6856, Precision: 0.7042, Recall: 0.6905, F1: 0.6891
LM Predictions:  [7, 9, 0, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1428, Accuracy: 0.9423, Precision: 0.9133, Recall: 0.8664, F1: 0.8867
Epoch 36/70
Train Loss: 0.0255, Accuracy: 0.9907, Precision: 0.9905, Recall: 0.9903, F1: 0.9904
Validation Loss: 1.6890, Accuracy: 0.6826, Precision: 0.7265, Recall: 0.6777, F1: 0.6892
Testing Loss: 1.5397, Accuracy: 0.7002, Precision: 0.7335, Recall: 0.6953, F1: 0.7041
LM Predictions:  [6, 9, 4, 13, 8, 5, 6, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 6, 11, 9, 4, 2, 7, 6, 4, 6, 8, 5, 10, 12, 10, 8, 5, 14, 14, 6, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2746, Accuracy: 0.8846, Precision: 0.9139, Recall: 0.8091, F1: 0.8520
Epoch 37/70
Train Loss: 0.0419, Accuracy: 0.9858, Precision: 0.9860, Recall: 0.9860, F1: 0.9860
Validation Loss: 1.4850, Accuracy: 0.6941, Precision: 0.7060, Recall: 0.6934, F1: 0.6925
Testing Loss: 1.3761, Accuracy: 0.7071, Precision: 0.7102, Recall: 0.7082, F1: 0.7040
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 10, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2087, Accuracy: 0.9038, Precision: 0.9052, Recall: 0.8313, F1: 0.8646
Epoch 38/70
Train Loss: 0.0173, Accuracy: 0.9937, Precision: 0.9938, Recall: 0.9935, F1: 0.9936
Validation Loss: 1.5167, Accuracy: 0.6972, Precision: 0.7159, Recall: 0.6958, F1: 0.6981
Testing Loss: 1.4779, Accuracy: 0.7010, Precision: 0.7149, Recall: 0.7014, F1: 0.7018
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 4, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1501, Accuracy: 0.9423, Precision: 0.9111, Recall: 0.8683, F1: 0.8868
Epoch 39/70
Train Loss: 0.0145, Accuracy: 0.9943, Precision: 0.9943, Recall: 0.9943, F1: 0.9943
Validation Loss: 1.7987, Accuracy: 0.6418, Precision: 0.6969, Recall: 0.6403, F1: 0.6365
Testing Loss: 1.7238, Accuracy: 0.6457, Precision: 0.7010, Recall: 0.6507, F1: 0.6496
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 2, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 11, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2430, Accuracy: 0.8846, Precision: 0.8954, Recall: 0.8102, F1: 0.8461
Epoch 40/70
Train Loss: 0.0439, Accuracy: 0.9862, Precision: 0.9862, Recall: 0.9855, F1: 0.9859
Validation Loss: 1.5807, Accuracy: 0.6879, Precision: 0.6971, Recall: 0.6904, F1: 0.6888
Testing Loss: 1.3542, Accuracy: 0.7264, Precision: 0.7354, Recall: 0.7296, F1: 0.7281
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1280, Accuracy: 0.9423, Precision: 0.9228, Recall: 0.8693, F1: 0.8927
Epoch 41/70
Train Loss: 0.0375, Accuracy: 0.9866, Precision: 0.9869, Recall: 0.9871, F1: 0.9870
Validation Loss: 1.4392, Accuracy: 0.7095, Precision: 0.7230, Recall: 0.7098, F1: 0.7143
Testing Loss: 1.3238, Accuracy: 0.7287, Precision: 0.7356, Recall: 0.7290, F1: 0.7298
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1122, Accuracy: 0.9423, Precision: 0.9038, Recall: 0.8835, F1: 0.8909
Epoch 42/70
Train Loss: 0.0080, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.3959, Accuracy: 0.7271, Precision: 0.7375, Recall: 0.7282, F1: 0.7308
Testing Loss: 1.2835, Accuracy: 0.7410, Precision: 0.7449, Recall: 0.7429, F1: 0.7426
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1506, Accuracy: 0.9231, Precision: 0.9038, Recall: 0.8613, F1: 0.8776
Epoch 43/70
Train Loss: 0.0506, Accuracy: 0.9842, Precision: 0.9847, Recall: 0.9844, F1: 0.9845
Validation Loss: 1.4933, Accuracy: 0.6979, Precision: 0.7081, Recall: 0.6992, F1: 0.6972
Testing Loss: 1.4408, Accuracy: 0.7033, Precision: 0.7136, Recall: 0.7078, F1: 0.7044
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 6, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1504, Accuracy: 0.9231, Precision: 0.9127, Recall: 0.8502, F1: 0.8781
Epoch 44/70
Train Loss: 0.0306, Accuracy: 0.9881, Precision: 0.9879, Recall: 0.9880, F1: 0.9880
Validation Loss: 1.5502, Accuracy: 0.6995, Precision: 0.7215, Recall: 0.6981, F1: 0.7025
Testing Loss: 1.4441, Accuracy: 0.7095, Precision: 0.7309, Recall: 0.7088, F1: 0.7125
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1272, Accuracy: 0.9327, Precision: 0.9127, Recall: 0.8649, F1: 0.8854
Epoch 45/70
Train Loss: 0.0174, Accuracy: 0.9936, Precision: 0.9938, Recall: 0.9938, F1: 0.9938
Validation Loss: 1.5937, Accuracy: 0.6856, Precision: 0.7271, Recall: 0.6868, F1: 0.6930
Testing Loss: 1.4939, Accuracy: 0.7041, Precision: 0.7306, Recall: 0.7044, F1: 0.7073
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1702, Accuracy: 0.9038, Precision: 0.9219, Recall: 0.8290, F1: 0.8693
Epoch 46/70
Train Loss: 0.0085, Accuracy: 0.9970, Precision: 0.9971, Recall: 0.9972, F1: 0.9971
Validation Loss: 1.4382, Accuracy: 0.7256, Precision: 0.7358, Recall: 0.7229, F1: 0.7256
Testing Loss: 1.3541, Accuracy: 0.7387, Precision: 0.7494, Recall: 0.7392, F1: 0.7413
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1554, Accuracy: 0.9231, Precision: 0.9038, Recall: 0.8650, F1: 0.8817
Epoch 47/70
Train Loss: 0.0066, Accuracy: 0.9969, Precision: 0.9971, Recall: 0.9969, F1: 0.9970
Validation Loss: 1.4218, Accuracy: 0.7302, Precision: 0.7382, Recall: 0.7313, F1: 0.7314
Testing Loss: 1.3828, Accuracy: 0.7348, Precision: 0.7422, Recall: 0.7386, F1: 0.7367
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1621, Accuracy: 0.9038, Precision: 0.9133, Recall: 0.8362, F1: 0.8678
Epoch 48/70
Train Loss: 0.0548, Accuracy: 0.9840, Precision: 0.9840, Recall: 0.9838, F1: 0.9839
Validation Loss: 1.5520, Accuracy: 0.6703, Precision: 0.6773, Recall: 0.6727, F1: 0.6682
Testing Loss: 1.4580, Accuracy: 0.7002, Precision: 0.7011, Recall: 0.6977, F1: 0.6955
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 14, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 6, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 9, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2945, Accuracy: 0.9135, Precision: 0.8926, Recall: 0.8391, F1: 0.8587
Epoch 49/70
Train Loss: 0.0542, Accuracy: 0.9815, Precision: 0.9821, Recall: 0.9819, F1: 0.9820
Validation Loss: 1.4900, Accuracy: 0.7041, Precision: 0.7157, Recall: 0.7050, F1: 0.7072
Testing Loss: 1.3779, Accuracy: 0.7141, Precision: 0.7163, Recall: 0.7102, F1: 0.7117
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1548, Accuracy: 0.9038, Precision: 0.9124, Recall: 0.8335, F1: 0.8671
Epoch 50/70
Train Loss: 0.0306, Accuracy: 0.9885, Precision: 0.9883, Recall: 0.9885, F1: 0.9884
Validation Loss: 1.5761, Accuracy: 0.6925, Precision: 0.7029, Recall: 0.6954, F1: 0.6923
Testing Loss: 1.4841, Accuracy: 0.6887, Precision: 0.6951, Recall: 0.6905, F1: 0.6872
LM Predictions:  [7, 9, 4, 13, 0, 5, 1, 6, 6, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 14, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2239, Accuracy: 0.9038, Precision: 0.9036, Recall: 0.8378, F1: 0.8671
Epoch 51/70
Train Loss: 0.0195, Accuracy: 0.9929, Precision: 0.9931, Recall: 0.9931, F1: 0.9931
Validation Loss: 1.5042, Accuracy: 0.6995, Precision: 0.7151, Recall: 0.7045, F1: 0.7057
Testing Loss: 1.5377, Accuracy: 0.6972, Precision: 0.7158, Recall: 0.6982, F1: 0.7020
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 6, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2207, Accuracy: 0.9038, Precision: 0.9038, Recall: 0.8491, F1: 0.8717
Epoch 52/70
Train Loss: 0.0142, Accuracy: 0.9941, Precision: 0.9943, Recall: 0.9942, F1: 0.9942
Validation Loss: 1.5834, Accuracy: 0.6879, Precision: 0.6971, Recall: 0.6897, F1: 0.6827
Testing Loss: 1.6408, Accuracy: 0.6895, Precision: 0.7014, Recall: 0.6886, F1: 0.6851
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 1, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 12, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1705, Accuracy: 0.9135, Precision: 0.8939, Recall: 0.8462, F1: 0.8651
Epoch 53/70
Train Loss: 0.0364, Accuracy: 0.9883, Precision: 0.9882, Recall: 0.9884, F1: 0.9883
Validation Loss: 1.4665, Accuracy: 0.7064, Precision: 0.7154, Recall: 0.7032, F1: 0.7056
Testing Loss: 1.4795, Accuracy: 0.6987, Precision: 0.6995, Recall: 0.6943, F1: 0.6924
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1744, Accuracy: 0.9038, Precision: 0.9022, Recall: 0.8514, F1: 0.8728
Epoch 54/70
Train Loss: 0.0323, Accuracy: 0.9891, Precision: 0.9897, Recall: 0.9896, F1: 0.9897
Validation Loss: 1.4652, Accuracy: 0.7041, Precision: 0.7237, Recall: 0.6995, F1: 0.7065
Testing Loss: 1.4628, Accuracy: 0.7095, Precision: 0.7198, Recall: 0.7037, F1: 0.7077
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1545, Accuracy: 0.9231, Precision: 0.9050, Recall: 0.8705, F1: 0.8837
Epoch 55/70
Train Loss: 0.0132, Accuracy: 0.9943, Precision: 0.9945, Recall: 0.9944, F1: 0.9945
Validation Loss: 1.5232, Accuracy: 0.7095, Precision: 0.7327, Recall: 0.7025, F1: 0.7128
Testing Loss: 1.4572, Accuracy: 0.7156, Precision: 0.7290, Recall: 0.7069, F1: 0.7148
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 9, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1669, Accuracy: 0.9135, Precision: 0.8939, Recall: 0.8542, F1: 0.8692
Epoch 56/70
Train Loss: 0.0284, Accuracy: 0.9901, Precision: 0.9906, Recall: 0.9903, F1: 0.9905
Validation Loss: 1.4814, Accuracy: 0.7179, Precision: 0.7313, Recall: 0.7141, F1: 0.7182
Testing Loss: 1.4389, Accuracy: 0.7256, Precision: 0.7390, Recall: 0.7184, F1: 0.7240
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1638, Accuracy: 0.9038, Precision: 0.9022, Recall: 0.8470, F1: 0.8690
Epoch 57/70
Train Loss: 0.0323, Accuracy: 0.9888, Precision: 0.9887, Recall: 0.9887, F1: 0.9887
Validation Loss: 1.4647, Accuracy: 0.7087, Precision: 0.7155, Recall: 0.7096, F1: 0.7097
Testing Loss: 1.3759, Accuracy: 0.7325, Precision: 0.7357, Recall: 0.7289, F1: 0.7296
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1802, Accuracy: 0.8942, Precision: 0.9022, Recall: 0.8340, F1: 0.8621
Epoch 58/70
Train Loss: 0.0291, Accuracy: 0.9890, Precision: 0.9890, Recall: 0.9890, F1: 0.9890
Validation Loss: 1.5863, Accuracy: 0.7010, Precision: 0.7100, Recall: 0.6986, F1: 0.6972
Testing Loss: 1.4538, Accuracy: 0.7079, Precision: 0.7103, Recall: 0.7075, F1: 0.7046
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 2, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1714, Accuracy: 0.9038, Precision: 0.8948, Recall: 0.8488, F1: 0.8668
Epoch 59/70
Train Loss: 0.0191, Accuracy: 0.9928, Precision: 0.9928, Recall: 0.9929, F1: 0.9928
Validation Loss: 1.6010, Accuracy: 0.6941, Precision: 0.7018, Recall: 0.6935, F1: 0.6915
Testing Loss: 1.4763, Accuracy: 0.7087, Precision: 0.7108, Recall: 0.7050, F1: 0.7031
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1212, Accuracy: 0.9423, Precision: 0.9038, Recall: 0.8835, F1: 0.8909
Epoch 60/70
Train Loss: 0.0316, Accuracy: 0.9884, Precision: 0.9885, Recall: 0.9887, F1: 0.9886
Validation Loss: 1.7050, Accuracy: 0.6879, Precision: 0.7119, Recall: 0.6871, F1: 0.6915
Testing Loss: 1.5429, Accuracy: 0.6972, Precision: 0.7162, Recall: 0.6961, F1: 0.6985
LM Predictions:  [7, 9, 4, 13, 8, 2, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 14, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1944, Accuracy: 0.8846, Precision: 0.8874, Recall: 0.8393, F1: 0.8590
Epoch 61/70
Train Loss: 0.0241, Accuracy: 0.9917, Precision: 0.9921, Recall: 0.9918, F1: 0.9920
Validation Loss: 1.5327, Accuracy: 0.7148, Precision: 0.7289, Recall: 0.7095, F1: 0.7155
Testing Loss: 1.4624, Accuracy: 0.7118, Precision: 0.7211, Recall: 0.7058, F1: 0.7096
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1444, Accuracy: 0.9327, Precision: 0.9136, Recall: 0.8697, F1: 0.8881
Epoch 62/70
Train Loss: 0.0146, Accuracy: 0.9938, Precision: 0.9943, Recall: 0.9941, F1: 0.9942
Validation Loss: 1.5882, Accuracy: 0.7041, Precision: 0.7116, Recall: 0.7039, F1: 0.7050
Testing Loss: 1.4382, Accuracy: 0.7141, Precision: 0.7238, Recall: 0.7107, F1: 0.7141
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1886, Accuracy: 0.9231, Precision: 0.9139, Recall: 0.8470, F1: 0.8750
Epoch 63/70
Train Loss: 0.0074, Accuracy: 0.9966, Precision: 0.9966, Recall: 0.9968, F1: 0.9967
Validation Loss: 1.5238, Accuracy: 0.7241, Precision: 0.7349, Recall: 0.7233, F1: 0.7265
Testing Loss: 1.3645, Accuracy: 0.7294, Precision: 0.7291, Recall: 0.7249, F1: 0.7260
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1798, Accuracy: 0.9038, Precision: 0.9228, Recall: 0.8280, F1: 0.8695
Epoch 64/70
Train Loss: 0.0063, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.5364, Accuracy: 0.7287, Precision: 0.7371, Recall: 0.7289, F1: 0.7293
Testing Loss: 1.3819, Accuracy: 0.7256, Precision: 0.7302, Recall: 0.7234, F1: 0.7245
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1468, Accuracy: 0.9038, Precision: 0.9136, Recall: 0.8319, F1: 0.8661
Epoch 65/70
Train Loss: 0.0059, Accuracy: 0.9972, Precision: 0.9973, Recall: 0.9972, F1: 0.9973
Validation Loss: 1.5499, Accuracy: 0.7194, Precision: 0.7291, Recall: 0.7189, F1: 0.7205
Testing Loss: 1.4069, Accuracy: 0.7310, Precision: 0.7391, Recall: 0.7285, F1: 0.7301
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1101, Accuracy: 0.9423, Precision: 0.9050, Recall: 0.8863, F1: 0.8925
Epoch 66/70
Train Loss: 0.0067, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.5343, Accuracy: 0.7233, Precision: 0.7342, Recall: 0.7233, F1: 0.7262
Testing Loss: 1.3971, Accuracy: 0.7264, Precision: 0.7315, Recall: 0.7245, F1: 0.7254
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1331, Accuracy: 0.9327, Precision: 0.9124, Recall: 0.8668, F1: 0.8865
Epoch 67/70
Train Loss: 0.0062, Accuracy: 0.9966, Precision: 0.9967, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.5423, Accuracy: 0.7264, Precision: 0.7387, Recall: 0.7266, F1: 0.7297
Testing Loss: 1.3939, Accuracy: 0.7348, Precision: 0.7425, Recall: 0.7297, F1: 0.7335
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1725, Accuracy: 0.9038, Precision: 0.9108, Recall: 0.8388, F1: 0.8714
Epoch 68/70
Train Loss: 0.0063, Accuracy: 0.9967, Precision: 0.9969, Recall: 0.9967, F1: 0.9968
Validation Loss: 1.5540, Accuracy: 0.7210, Precision: 0.7314, Recall: 0.7234, F1: 0.7233
Testing Loss: 1.4095, Accuracy: 0.7333, Precision: 0.7375, Recall: 0.7323, F1: 0.7310
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.0981, Accuracy: 0.9423, Precision: 0.9228, Recall: 0.8693, F1: 0.8927
Epoch 69/70
Train Loss: 0.1010, Accuracy: 0.9685, Precision: 0.9686, Recall: 0.9687, F1: 0.9686
Validation Loss: 1.5470, Accuracy: 0.6902, Precision: 0.7201, Recall: 0.6898, F1: 0.6969
Testing Loss: 1.4103, Accuracy: 0.6925, Precision: 0.7306, Recall: 0.6894, F1: 0.7020
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 2, 2, 8, 5, 10, 12, 10, 6, 5, 14, 14, 7, 13, 4, 9, 5, 8, 6, 8, 14, 3, 0, 0, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 6, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 11, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3746, Accuracy: 0.8365, Precision: 0.8744, Recall: 0.7675, F1: 0.8110
Epoch 70/70
Train Loss: 0.0248, Accuracy: 0.9912, Precision: 0.9909, Recall: 0.9907, F1: 0.9908
Validation Loss: 1.5411, Accuracy: 0.7079, Precision: 0.7261, Recall: 0.7094, F1: 0.7118
Testing Loss: 1.4374, Accuracy: 0.7179, Precision: 0.7220, Recall: 0.7143, F1: 0.7143
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 11, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1614, Accuracy: 0.8942, Precision: 0.9056, Recall: 0.8217, F1: 0.8550
For middle layers:  [4, 5, 6, 7]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 1.3279, Accuracy: 0.5892, Precision: 0.5959, Recall: 0.5748, F1: 0.5788
Validation Loss: 0.8752, Accuracy: 0.7364, Precision: 0.7712, Recall: 0.7279, F1: 0.7382
Testing Loss: 0.8514, Accuracy: 0.7287, Precision: 0.7721, Recall: 0.7173, F1: 0.7324
LM Predictions:  [0, 6, 6, 13, 0, 12, 6, 6, 11, 6, 6, 14, 6, 6, 6, 0, 6, 6, 6, 6, 6, 13, 6, 11, 6, 6, 14, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 13, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 11, 14, 6, 14, 6, 6, 6, 11, 6, 14, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 11, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 4.1586, Accuracy: 0.0288, Precision: 0.1022, Recall: 0.0296, F1: 0.0434
Epoch 2/70
Train Loss: 0.5770, Accuracy: 0.8309, Precision: 0.8314, Recall: 0.8266, F1: 0.8287
Validation Loss: 0.6906, Accuracy: 0.7694, Precision: 0.8100, Recall: 0.7666, F1: 0.7733
Testing Loss: 0.7391, Accuracy: 0.7563, Precision: 0.7988, Recall: 0.7562, F1: 0.7624
LM Predictions:  [0, 0, 0, 13, 0, 12, 6, 6, 0, 6, 6, 4, 13, 6, 12, 4, 9, 14, 0, 0, 0, 8, 0, 11, 8, 4, 2, 0, 0, 6, 0, 6, 13, 0, 0, 4, 14, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0, 6, 6, 6, 6, 14, 9, 0, 6, 5, 0, 8, 0, 14, 0, 0, 14, 0, 0, 0, 14, 6, 14, 6, 0, 0, 0, 6, 0, 0, 6, 6, 6, 11, 6, 6, 0, 0, 0, 6, 0, 6, 6, 6, 6, 6, 5, 8, 0, 4, 6, 6, 0, 6, 0, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 3.4149, Accuracy: 0.1635, Precision: 0.2272, Recall: 0.1531, F1: 0.1309
Epoch 3/70
Train Loss: 0.2609, Accuracy: 0.9308, Precision: 0.9326, Recall: 0.9288, F1: 0.9306
Validation Loss: 0.7709, Accuracy: 0.7717, Precision: 0.7920, Recall: 0.7744, F1: 0.7750
Testing Loss: 0.7302, Accuracy: 0.7786, Precision: 0.8022, Recall: 0.7833, F1: 0.7848
LM Predictions:  [0, 13, 4, 13, 1, 12, 6, 6, 0, 12, 6, 14, 13, 6, 12, 4, 12, 6, 6, 6, 12, 4, 12, 12, 4, 1, 2, 2, 5, 6, 14, 12, 4, 5, 14, 14, 6, 13, 8, 9, 5, 12, 0, 8, 13, 6, 0, 6, 0, 0, 6, 6, 8, 14, 0, 13, 6, 5, 6, 12, 6, 14, 0, 12, 11, 8, 5, 5, 14, 11, 14, 6, 0, 6, 6, 6, 0, 14, 8, 6, 8, 6, 6, 6, 6, 13, 3, 8, 0, 6, 12, 13, 14, 12, 4, 8, 14, 4, 0, 6, 0, 6, 6, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 1.9756, Accuracy: 0.4135, Precision: 0.4959, Recall: 0.3556, F1: 0.3591
Epoch 4/70
Train Loss: 0.1146, Accuracy: 0.9739, Precision: 0.9748, Recall: 0.9735, F1: 0.9741
Validation Loss: 0.7020, Accuracy: 0.7917, Precision: 0.7988, Recall: 0.7915, F1: 0.7908
Testing Loss: 0.6973, Accuracy: 0.7994, Precision: 0.8146, Recall: 0.7972, F1: 0.8022
LM Predictions:  [4, 9, 4, 13, 8, 5, 7, 4, 0, 12, 6, 4, 13, 8, 12, 12, 12, 12, 14, 11, 9, 4, 2, 12, 6, 4, 2, 8, 5, 4, 12, 10, 8, 5, 14, 4, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 4, 6, 2, 6, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 6, 6, 0, 14, 8, 6, 7, 6, 9, 2, 2, 13, 3, 8, 5, 7, 12, 6, 6, 2, 4, 8, 11, 4, 6, 4, 0, 14, 5, 4]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.9646, Accuracy: 0.6923, Precision: 0.7965, Recall: 0.6074, F1: 0.6437
Epoch 5/70
Train Loss: 0.0673, Accuracy: 0.9838, Precision: 0.9844, Recall: 0.9837, F1: 0.9840
Validation Loss: 0.9308, Accuracy: 0.7456, Precision: 0.7625, Recall: 0.7480, F1: 0.7460
Testing Loss: 0.8827, Accuracy: 0.7533, Precision: 0.7706, Recall: 0.7529, F1: 0.7533
LM Predictions:  [6, 9, 4, 13, 8, 5, 1, 4, 0, 12, 6, 8, 3, 11, 12, 12, 1, 14, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 6, 14, 10, 10, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 6, 0, 4, 0, 2, 13, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 0, 6, 0, 14, 8, 6, 1, 6, 9, 6, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 6, 3, 6, 0, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.7332, Accuracy: 0.7596, Precision: 0.8167, Recall: 0.6965, F1: 0.7346
Epoch 6/70
Train Loss: 0.0770, Accuracy: 0.9802, Precision: 0.9811, Recall: 0.9798, F1: 0.9805
Validation Loss: 0.9596, Accuracy: 0.7456, Precision: 0.7705, Recall: 0.7595, F1: 0.7411
Testing Loss: 0.9652, Accuracy: 0.7479, Precision: 0.7711, Recall: 0.7569, F1: 0.7419
LM Predictions:  [0, 9, 4, 13, 8, 5, 5, 6, 0, 12, 5, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 10, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 0, 8, 8, 14, 12, 3, 2, 4, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 0, 0, 14, 8, 5, 1, 1, 9, 11, 0, 13, 3, 8, 5, 7, 12, 14, 1, 2, 4, 8, 11, 5, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4028, Accuracy: 0.8750, Precision: 0.8425, Recall: 0.7967, F1: 0.8077
Epoch 7/70
Train Loss: 0.0630, Accuracy: 0.9836, Precision: 0.9837, Recall: 0.9839, F1: 0.9838
Validation Loss: 0.9127, Accuracy: 0.7517, Precision: 0.7660, Recall: 0.7586, F1: 0.7545
Testing Loss: 0.8769, Accuracy: 0.7663, Precision: 0.7810, Recall: 0.7711, F1: 0.7686
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 6, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2690, Accuracy: 0.9231, Precision: 0.9038, Recall: 0.8713, F1: 0.8851
Epoch 8/70
Train Loss: 0.0643, Accuracy: 0.9830, Precision: 0.9828, Recall: 0.9829, F1: 0.9828
Validation Loss: 0.9307, Accuracy: 0.7725, Precision: 0.7853, Recall: 0.7672, F1: 0.7702
Testing Loss: 0.8936, Accuracy: 0.7832, Precision: 0.8080, Recall: 0.7795, F1: 0.7857
LM Predictions:  [7, 9, 8, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 11, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2686, Accuracy: 0.9135, Precision: 0.8912, Recall: 0.8567, F1: 0.8697
Epoch 9/70
Train Loss: 0.0398, Accuracy: 0.9889, Precision: 0.9892, Recall: 0.9891, F1: 0.9892
Validation Loss: 0.9283, Accuracy: 0.7817, Precision: 0.7888, Recall: 0.7790, F1: 0.7771
Testing Loss: 0.8343, Accuracy: 0.7963, Precision: 0.8044, Recall: 0.7939, F1: 0.7947
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 14, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2770, Accuracy: 0.9231, Precision: 0.8995, Recall: 0.8705, F1: 0.8794
Epoch 10/70
Train Loss: 0.0552, Accuracy: 0.9833, Precision: 0.9837, Recall: 0.9831, F1: 0.9834
Validation Loss: 0.9961, Accuracy: 0.7533, Precision: 0.7668, Recall: 0.7498, F1: 0.7530
Testing Loss: 0.9798, Accuracy: 0.7586, Precision: 0.7783, Recall: 0.7549, F1: 0.7590
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 6, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 5, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 6, 8, 14, 0, 3, 6, 13, 14, 2, 2, 12, 0, 6, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 6, 7, 12, 13, 1, 2, 5, 8, 11, 4, 5, 3, 12, 11, 5, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4736, Accuracy: 0.8365, Precision: 0.8909, Recall: 0.8004, F1: 0.8369
Epoch 11/70
Train Loss: 0.0482, Accuracy: 0.9847, Precision: 0.9846, Recall: 0.9848, F1: 0.9847
Validation Loss: 0.9507, Accuracy: 0.7871, Precision: 0.8040, Recall: 0.7816, F1: 0.7858
Testing Loss: 0.8906, Accuracy: 0.8009, Precision: 0.8166, Recall: 0.7960, F1: 0.8014
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 0, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 6, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3517, Accuracy: 0.8846, Precision: 0.8967, Recall: 0.8294, F1: 0.8563
Epoch 12/70
Train Loss: 0.0441, Accuracy: 0.9862, Precision: 0.9867, Recall: 0.9866, F1: 0.9866
Validation Loss: 0.9264, Accuracy: 0.7817, Precision: 0.7920, Recall: 0.7732, F1: 0.7764
Testing Loss: 0.9432, Accuracy: 0.7817, Precision: 0.7925, Recall: 0.7769, F1: 0.7804
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 6, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2748, Accuracy: 0.9231, Precision: 0.9139, Recall: 0.8633, F1: 0.8839
Epoch 13/70
Train Loss: 0.0511, Accuracy: 0.9838, Precision: 0.9835, Recall: 0.9834, F1: 0.9834
Validation Loss: 0.9490, Accuracy: 0.7694, Precision: 0.7719, Recall: 0.7701, F1: 0.7652
Testing Loss: 0.9634, Accuracy: 0.7832, Precision: 0.7865, Recall: 0.7866, F1: 0.7823
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 5, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4388, Accuracy: 0.8846, Precision: 0.8971, Recall: 0.8276, F1: 0.8549
Epoch 14/70
Train Loss: 0.0260, Accuracy: 0.9926, Precision: 0.9924, Recall: 0.9926, F1: 0.9925
Validation Loss: 1.2531, Accuracy: 0.7233, Precision: 0.7759, Recall: 0.7134, F1: 0.7261
Testing Loss: 1.2432, Accuracy: 0.7225, Precision: 0.7898, Recall: 0.7109, F1: 0.7271
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 11, 11, 11, 12, 12, 1, 6, 7, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 11, 14, 11, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 6, 2, 14, 6, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4183, Accuracy: 0.8269, Precision: 0.8639, Recall: 0.7922, F1: 0.8140
Epoch 15/70
Train Loss: 0.0552, Accuracy: 0.9829, Precision: 0.9828, Recall: 0.9828, F1: 0.9828
Validation Loss: 1.0972, Accuracy: 0.7571, Precision: 0.7909, Recall: 0.7463, F1: 0.7575
Testing Loss: 1.0245, Accuracy: 0.7602, Precision: 0.7958, Recall: 0.7504, F1: 0.7628
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 9, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3815, Accuracy: 0.8846, Precision: 0.8989, Recall: 0.8293, F1: 0.8608
Epoch 16/70
Train Loss: 0.0480, Accuracy: 0.9860, Precision: 0.9855, Recall: 0.9855, F1: 0.9855
Validation Loss: 1.0652, Accuracy: 0.7533, Precision: 0.7852, Recall: 0.7496, F1: 0.7553
Testing Loss: 1.0682, Accuracy: 0.7656, Precision: 0.8033, Recall: 0.7581, F1: 0.7669
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 6, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 4, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2922, Accuracy: 0.8942, Precision: 0.9021, Recall: 0.8261, F1: 0.8569
Epoch 17/70
Train Loss: 0.0310, Accuracy: 0.9901, Precision: 0.9906, Recall: 0.9907, F1: 0.9907
Validation Loss: 1.1292, Accuracy: 0.7540, Precision: 0.7754, Recall: 0.7531, F1: 0.7550
Testing Loss: 1.1216, Accuracy: 0.7556, Precision: 0.7843, Recall: 0.7576, F1: 0.7598
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 0, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 0, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 0, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 0, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2103, Accuracy: 0.9038, Precision: 0.8856, Recall: 0.8571, F1: 0.8614
Epoch 18/70
Train Loss: 0.0279, Accuracy: 0.9911, Precision: 0.9910, Recall: 0.9911, F1: 0.9910
Validation Loss: 1.0182, Accuracy: 0.7656, Precision: 0.7893, Recall: 0.7624, F1: 0.7684
Testing Loss: 1.0302, Accuracy: 0.7786, Precision: 0.7998, Recall: 0.7737, F1: 0.7799
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 0, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 0, 0, 3, 2, 13, 0, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3593, Accuracy: 0.8942, Precision: 0.8884, Recall: 0.8483, F1: 0.8604
Epoch 19/70
Train Loss: 0.0423, Accuracy: 0.9862, Precision: 0.9863, Recall: 0.9863, F1: 0.9863
Validation Loss: 1.0308, Accuracy: 0.7717, Precision: 0.7804, Recall: 0.7685, F1: 0.7688
Testing Loss: 0.9859, Accuracy: 0.7840, Precision: 0.7930, Recall: 0.7813, F1: 0.7825
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 0, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1779, Accuracy: 0.9423, Precision: 0.9056, Recall: 0.8746, F1: 0.8871
Epoch 20/70
Train Loss: 0.0384, Accuracy: 0.9876, Precision: 0.9877, Recall: 0.9874, F1: 0.9875
Validation Loss: 1.0128, Accuracy: 0.7863, Precision: 0.7950, Recall: 0.7855, F1: 0.7856
Testing Loss: 0.9451, Accuracy: 0.7971, Precision: 0.8064, Recall: 0.7984, F1: 0.7980
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1905, Accuracy: 0.9038, Precision: 0.9038, Recall: 0.8447, F1: 0.8692
Epoch 21/70
Train Loss: 0.0103, Accuracy: 0.9966, Precision: 0.9969, Recall: 0.9967, F1: 0.9968
Validation Loss: 0.9671, Accuracy: 0.7932, Precision: 0.7945, Recall: 0.7945, F1: 0.7927
Testing Loss: 0.9124, Accuracy: 0.8094, Precision: 0.8091, Recall: 0.8114, F1: 0.8090
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1500, Accuracy: 0.9327, Precision: 0.9136, Recall: 0.8652, F1: 0.8855
Epoch 22/70
Train Loss: 0.0089, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9964, F1: 0.9964
Validation Loss: 0.9738, Accuracy: 0.8055, Precision: 0.8126, Recall: 0.8046, F1: 0.8070
Testing Loss: 0.9282, Accuracy: 0.8055, Precision: 0.8116, Recall: 0.8070, F1: 0.8071
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1272, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8693, F1: 0.8883
Epoch 23/70
Train Loss: 0.0081, Accuracy: 0.9965, Precision: 0.9966, Recall: 0.9966, F1: 0.9966
Validation Loss: 1.0110, Accuracy: 0.8071, Precision: 0.8185, Recall: 0.8092, F1: 0.8093
Testing Loss: 0.9548, Accuracy: 0.8125, Precision: 0.8202, Recall: 0.8147, F1: 0.8138
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.0904, Accuracy: 0.9615, Precision: 0.9038, Recall: 0.9050, F1: 0.9033
Epoch 24/70
Train Loss: 0.0074, Accuracy: 0.9970, Precision: 0.9971, Recall: 0.9972, F1: 0.9971
Validation Loss: 0.9480, Accuracy: 0.8078, Precision: 0.8217, Recall: 0.8085, F1: 0.8126
Testing Loss: 0.9255, Accuracy: 0.8148, Precision: 0.8261, Recall: 0.8119, F1: 0.8170
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 6, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 6, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2478, Accuracy: 0.8942, Precision: 0.9171, Recall: 0.8324, F1: 0.8708
Epoch 25/70
Train Loss: 0.0072, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.9735, Accuracy: 0.8155, Precision: 0.8273, Recall: 0.8166, F1: 0.8186
Testing Loss: 0.9817, Accuracy: 0.8155, Precision: 0.8217, Recall: 0.8185, F1: 0.8182
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1678, Accuracy: 0.9231, Precision: 0.9127, Recall: 0.8531, F1: 0.8797
Epoch 26/70
Train Loss: 0.0074, Accuracy: 0.9972, Precision: 0.9972, Recall: 0.9973, F1: 0.9973
Validation Loss: 1.1051, Accuracy: 0.7848, Precision: 0.7937, Recall: 0.7887, F1: 0.7858
Testing Loss: 1.0233, Accuracy: 0.7994, Precision: 0.8061, Recall: 0.7989, F1: 0.7977
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2302, Accuracy: 0.9038, Precision: 0.9219, Recall: 0.8319, F1: 0.8697
Epoch 27/70
Train Loss: 0.1536, Accuracy: 0.9532, Precision: 0.9537, Recall: 0.9518, F1: 0.9528
Validation Loss: 0.9723, Accuracy: 0.7733, Precision: 0.7729, Recall: 0.7796, F1: 0.7717
Testing Loss: 0.9734, Accuracy: 0.7809, Precision: 0.7831, Recall: 0.7827, F1: 0.7794
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 11, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2106, Accuracy: 0.8846, Precision: 0.9052, Recall: 0.8141, F1: 0.8481
Epoch 28/70
Train Loss: 0.0224, Accuracy: 0.9914, Precision: 0.9917, Recall: 0.9916, F1: 0.9917
Validation Loss: 1.1527, Accuracy: 0.7494, Precision: 0.7688, Recall: 0.7466, F1: 0.7468
Testing Loss: 1.1509, Accuracy: 0.7656, Precision: 0.7805, Recall: 0.7591, F1: 0.7606
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 4, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 14, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2098, Accuracy: 0.8750, Precision: 0.8954, Recall: 0.8154, F1: 0.8488
Epoch 29/70
Train Loss: 0.0229, Accuracy: 0.9920, Precision: 0.9921, Recall: 0.9921, F1: 0.9921
Validation Loss: 1.0286, Accuracy: 0.7740, Precision: 0.7752, Recall: 0.7787, F1: 0.7722
Testing Loss: 1.0933, Accuracy: 0.7648, Precision: 0.7686, Recall: 0.7660, F1: 0.7613
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1252, Accuracy: 0.9615, Precision: 0.9139, Recall: 0.8922, F1: 0.9001
Epoch 30/70
Train Loss: 0.0361, Accuracy: 0.9876, Precision: 0.9879, Recall: 0.9876, F1: 0.9878
Validation Loss: 1.1308, Accuracy: 0.7417, Precision: 0.7605, Recall: 0.7397, F1: 0.7395
Testing Loss: 1.1624, Accuracy: 0.7617, Precision: 0.7764, Recall: 0.7513, F1: 0.7513
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 8, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 6, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 0, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2158, Accuracy: 0.9231, Precision: 0.9094, Recall: 0.8602, F1: 0.8808
Epoch 31/70
Train Loss: 0.0443, Accuracy: 0.9850, Precision: 0.9844, Recall: 0.9846, F1: 0.9845
Validation Loss: 1.0765, Accuracy: 0.7594, Precision: 0.7609, Recall: 0.7620, F1: 0.7557
Testing Loss: 1.0737, Accuracy: 0.7686, Precision: 0.7685, Recall: 0.7690, F1: 0.7641
LM Predictions:  [7, 9, 0, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2495, Accuracy: 0.8942, Precision: 0.8943, Recall: 0.8403, F1: 0.8607
Epoch 32/70
Train Loss: 0.0283, Accuracy: 0.9901, Precision: 0.9893, Recall: 0.9897, F1: 0.9895
Validation Loss: 1.1962, Accuracy: 0.7463, Precision: 0.7789, Recall: 0.7430, F1: 0.7514
Testing Loss: 1.2528, Accuracy: 0.7379, Precision: 0.7767, Recall: 0.7357, F1: 0.7464
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1624, Accuracy: 0.9231, Precision: 0.9136, Recall: 0.8578, F1: 0.8823
Epoch 33/70
Train Loss: 0.0134, Accuracy: 0.9947, Precision: 0.9950, Recall: 0.9948, F1: 0.9949
Validation Loss: 1.0952, Accuracy: 0.7648, Precision: 0.7792, Recall: 0.7628, F1: 0.7653
Testing Loss: 1.1346, Accuracy: 0.7625, Precision: 0.7773, Recall: 0.7563, F1: 0.7631
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 6, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2171, Accuracy: 0.8942, Precision: 0.9108, Recall: 0.8329, F1: 0.8659
Epoch 34/70
Train Loss: 0.0345, Accuracy: 0.9874, Precision: 0.9876, Recall: 0.9876, F1: 0.9876
Validation Loss: 1.0370, Accuracy: 0.7748, Precision: 0.7816, Recall: 0.7748, F1: 0.7716
Testing Loss: 1.0591, Accuracy: 0.7840, Precision: 0.7954, Recall: 0.7893, F1: 0.7873
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1347, Accuracy: 0.9231, Precision: 0.9050, Recall: 0.8653, F1: 0.8803
Epoch 35/70
Train Loss: 0.0333, Accuracy: 0.9888, Precision: 0.9892, Recall: 0.9888, F1: 0.9890
Validation Loss: 1.0352, Accuracy: 0.7802, Precision: 0.8023, Recall: 0.7796, F1: 0.7877
Testing Loss: 1.0345, Accuracy: 0.7840, Precision: 0.8035, Recall: 0.7771, F1: 0.7855
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1305, Accuracy: 0.9615, Precision: 0.9139, Recall: 0.8922, F1: 0.9001
Epoch 36/70
Train Loss: 0.0290, Accuracy: 0.9892, Precision: 0.9891, Recall: 0.9889, F1: 0.9890
Validation Loss: 1.0977, Accuracy: 0.7556, Precision: 0.7616, Recall: 0.7602, F1: 0.7555
Testing Loss: 1.1064, Accuracy: 0.7656, Precision: 0.7714, Recall: 0.7626, F1: 0.7618
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1315, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8737, F1: 0.8908
Epoch 37/70
Train Loss: 0.0291, Accuracy: 0.9886, Precision: 0.9883, Recall: 0.9884, F1: 0.9884
Validation Loss: 1.0524, Accuracy: 0.7763, Precision: 0.7740, Recall: 0.7819, F1: 0.7725
Testing Loss: 1.0191, Accuracy: 0.7909, Precision: 0.7896, Recall: 0.7948, F1: 0.7897
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1213, Accuracy: 0.9231, Precision: 0.9139, Recall: 0.8685, F1: 0.8870
Epoch 38/70
Train Loss: 0.0265, Accuracy: 0.9908, Precision: 0.9908, Recall: 0.9906, F1: 0.9907
Validation Loss: 1.1924, Accuracy: 0.7610, Precision: 0.7767, Recall: 0.7670, F1: 0.7639
Testing Loss: 1.1508, Accuracy: 0.7709, Precision: 0.7912, Recall: 0.7735, F1: 0.7744
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1367, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8875, F1: 0.8981
Epoch 39/70
Train Loss: 0.0207, Accuracy: 0.9930, Precision: 0.9928, Recall: 0.9930, F1: 0.9929
Validation Loss: 1.2318, Accuracy: 0.7433, Precision: 0.7552, Recall: 0.7430, F1: 0.7398
Testing Loss: 1.1930, Accuracy: 0.7610, Precision: 0.7819, Recall: 0.7584, F1: 0.7599
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 8, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 6, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2432, Accuracy: 0.8654, Precision: 0.9056, Recall: 0.7961, F1: 0.8437
Epoch 40/70
Train Loss: 0.0275, Accuracy: 0.9907, Precision: 0.9906, Recall: 0.9902, F1: 0.9904
Validation Loss: 1.0850, Accuracy: 0.7725, Precision: 0.7721, Recall: 0.7805, F1: 0.7732
Testing Loss: 1.0937, Accuracy: 0.7855, Precision: 0.7867, Recall: 0.7882, F1: 0.7856
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1156, Accuracy: 0.9327, Precision: 0.9228, Recall: 0.8537, F1: 0.8829
Epoch 41/70
Train Loss: 0.0203, Accuracy: 0.9925, Precision: 0.9925, Recall: 0.9928, F1: 0.9926
Validation Loss: 1.1560, Accuracy: 0.7640, Precision: 0.7735, Recall: 0.7668, F1: 0.7646
Testing Loss: 1.0805, Accuracy: 0.7748, Precision: 0.7812, Recall: 0.7750, F1: 0.7749
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1269, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8875, F1: 0.8981
Epoch 42/70
Train Loss: 0.0296, Accuracy: 0.9888, Precision: 0.9889, Recall: 0.9885, F1: 0.9887
Validation Loss: 1.2874, Accuracy: 0.7471, Precision: 0.7651, Recall: 0.7483, F1: 0.7486
Testing Loss: 1.2103, Accuracy: 0.7602, Precision: 0.7827, Recall: 0.7584, F1: 0.7638
LM Predictions:  [7, 9, 2, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2039, Accuracy: 0.9038, Precision: 0.8948, Recall: 0.8451, F1: 0.8655
Epoch 43/70
Train Loss: 0.0248, Accuracy: 0.9921, Precision: 0.9919, Recall: 0.9920, F1: 0.9919
Validation Loss: 1.1751, Accuracy: 0.7610, Precision: 0.7677, Recall: 0.7607, F1: 0.7584
Testing Loss: 1.1181, Accuracy: 0.7756, Precision: 0.7882, Recall: 0.7701, F1: 0.7731
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 0, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 6, 2, 6, 14, 2, 6, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2165, Accuracy: 0.9038, Precision: 0.8985, Recall: 0.8503, F1: 0.8685
Epoch 44/70
Train Loss: 0.0284, Accuracy: 0.9892, Precision: 0.9894, Recall: 0.9893, F1: 0.9893
Validation Loss: 1.2523, Accuracy: 0.7487, Precision: 0.7684, Recall: 0.7471, F1: 0.7472
Testing Loss: 1.2886, Accuracy: 0.7433, Precision: 0.7570, Recall: 0.7416, F1: 0.7410
LM Predictions:  [6, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 6, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 6, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 6, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 6, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 6, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2724, Accuracy: 0.8846, Precision: 0.9120, Recall: 0.8084, F1: 0.8468
Epoch 45/70
Train Loss: 0.0312, Accuracy: 0.9899, Precision: 0.9897, Recall: 0.9896, F1: 0.9897
Validation Loss: 1.1729, Accuracy: 0.7625, Precision: 0.7710, Recall: 0.7631, F1: 0.7643
Testing Loss: 1.1117, Accuracy: 0.7848, Precision: 0.7930, Recall: 0.7833, F1: 0.7855
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 6, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1803, Accuracy: 0.9135, Precision: 0.9221, Recall: 0.8531, F1: 0.8837
Epoch 46/70
Train Loss: 0.0157, Accuracy: 0.9935, Precision: 0.9936, Recall: 0.9936, F1: 0.9936
Validation Loss: 1.1643, Accuracy: 0.7663, Precision: 0.7779, Recall: 0.7672, F1: 0.7674
Testing Loss: 1.2153, Accuracy: 0.7625, Precision: 0.7818, Recall: 0.7633, F1: 0.7679
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1599, Accuracy: 0.9038, Precision: 0.9111, Recall: 0.8332, F1: 0.8675
Epoch 47/70
Train Loss: 0.0204, Accuracy: 0.9921, Precision: 0.9920, Recall: 0.9921, F1: 0.9920
Validation Loss: 1.3229, Accuracy: 0.7448, Precision: 0.7461, Recall: 0.7516, F1: 0.7407
Testing Loss: 1.3042, Accuracy: 0.7540, Precision: 0.7620, Recall: 0.7593, F1: 0.7523
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 4, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1296, Accuracy: 0.9423, Precision: 0.9130, Recall: 0.8793, F1: 0.8928
Epoch 48/70
Train Loss: 0.0309, Accuracy: 0.9895, Precision: 0.9897, Recall: 0.9897, F1: 0.9897
Validation Loss: 1.2609, Accuracy: 0.7594, Precision: 0.7697, Recall: 0.7647, F1: 0.7587
Testing Loss: 1.2968, Accuracy: 0.7594, Precision: 0.7716, Recall: 0.7590, F1: 0.7580
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 0, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 0, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1480, Accuracy: 0.8942, Precision: 0.8997, Recall: 0.8268, F1: 0.8564
Epoch 49/70
Train Loss: 0.0279, Accuracy: 0.9890, Precision: 0.9892, Recall: 0.9893, F1: 0.9892
Validation Loss: 1.1498, Accuracy: 0.7533, Precision: 0.7577, Recall: 0.7533, F1: 0.7506
Testing Loss: 1.2320, Accuracy: 0.7694, Precision: 0.7802, Recall: 0.7708, F1: 0.7706
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1225, Accuracy: 0.9423, Precision: 0.9136, Recall: 0.8808, F1: 0.8941
Epoch 50/70
Train Loss: 0.0135, Accuracy: 0.9948, Precision: 0.9950, Recall: 0.9950, F1: 0.9950
Validation Loss: 1.2450, Accuracy: 0.7548, Precision: 0.7813, Recall: 0.7504, F1: 0.7499
Testing Loss: 1.2581, Accuracy: 0.7633, Precision: 0.7773, Recall: 0.7600, F1: 0.7576
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 0, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1513, Accuracy: 0.9327, Precision: 0.9056, Recall: 0.8658, F1: 0.8829
Epoch 51/70
Train Loss: 0.0227, Accuracy: 0.9916, Precision: 0.9918, Recall: 0.9916, F1: 0.9917
Validation Loss: 1.2893, Accuracy: 0.7394, Precision: 0.7520, Recall: 0.7423, F1: 0.7389
Testing Loss: 1.3705, Accuracy: 0.7433, Precision: 0.7635, Recall: 0.7500, F1: 0.7438
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 12, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1404, Accuracy: 0.9519, Precision: 0.9089, Recall: 0.8856, F1: 0.8927
Epoch 52/70
Train Loss: 0.0334, Accuracy: 0.9889, Precision: 0.9889, Recall: 0.9892, F1: 0.9890
Validation Loss: 1.2706, Accuracy: 0.7571, Precision: 0.7859, Recall: 0.7532, F1: 0.7606
Testing Loss: 1.2775, Accuracy: 0.7540, Precision: 0.7830, Recall: 0.7450, F1: 0.7543
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 4, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1453, Accuracy: 0.9231, Precision: 0.8894, Recall: 0.8613, F1: 0.8743
Epoch 53/70
Train Loss: 0.0250, Accuracy: 0.9906, Precision: 0.9908, Recall: 0.9909, F1: 0.9909
Validation Loss: 1.1806, Accuracy: 0.7394, Precision: 0.7576, Recall: 0.7338, F1: 0.7364
Testing Loss: 1.2253, Accuracy: 0.7648, Precision: 0.7821, Recall: 0.7554, F1: 0.7603
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1521, Accuracy: 0.8942, Precision: 0.9022, Recall: 0.8340, F1: 0.8633
Epoch 54/70
Train Loss: 0.0220, Accuracy: 0.9918, Precision: 0.9918, Recall: 0.9917, F1: 0.9918
Validation Loss: 1.0629, Accuracy: 0.7832, Precision: 0.7920, Recall: 0.7840, F1: 0.7849
Testing Loss: 1.1492, Accuracy: 0.7740, Precision: 0.7834, Recall: 0.7738, F1: 0.7759
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1431, Accuracy: 0.9135, Precision: 0.9050, Recall: 0.8549, F1: 0.8727
Epoch 55/70
Train Loss: 0.0150, Accuracy: 0.9939, Precision: 0.9943, Recall: 0.9940, F1: 0.9941
Validation Loss: 1.2051, Accuracy: 0.7594, Precision: 0.7693, Recall: 0.7557, F1: 0.7575
Testing Loss: 1.2437, Accuracy: 0.7563, Precision: 0.7715, Recall: 0.7510, F1: 0.7564
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 1, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2301, Accuracy: 0.8942, Precision: 0.9016, Recall: 0.8221, F1: 0.8538
Epoch 56/70
Train Loss: 0.0303, Accuracy: 0.9893, Precision: 0.9892, Recall: 0.9891, F1: 0.9892
Validation Loss: 1.0756, Accuracy: 0.7809, Precision: 0.7793, Recall: 0.7859, F1: 0.7805
Testing Loss: 1.1916, Accuracy: 0.7686, Precision: 0.7755, Recall: 0.7686, F1: 0.7706
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1267, Accuracy: 0.9519, Precision: 0.9139, Recall: 0.8811, F1: 0.8940
Epoch 57/70
Train Loss: 0.0169, Accuracy: 0.9931, Precision: 0.9934, Recall: 0.9934, F1: 0.9934
Validation Loss: 1.1898, Accuracy: 0.7571, Precision: 0.7630, Recall: 0.7551, F1: 0.7559
Testing Loss: 1.1704, Accuracy: 0.7725, Precision: 0.7764, Recall: 0.7676, F1: 0.7692
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1746, Accuracy: 0.8942, Precision: 0.9133, Recall: 0.8359, F1: 0.8676
Epoch 58/70
Train Loss: 0.0095, Accuracy: 0.9961, Precision: 0.9962, Recall: 0.9960, F1: 0.9961
Validation Loss: 1.0769, Accuracy: 0.7879, Precision: 0.7903, Recall: 0.7897, F1: 0.7890
Testing Loss: 1.0978, Accuracy: 0.7779, Precision: 0.7861, Recall: 0.7780, F1: 0.7806
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1459, Accuracy: 0.9135, Precision: 0.9228, Recall: 0.8359, F1: 0.8721
Epoch 59/70
Train Loss: 0.0056, Accuracy: 0.9969, Precision: 0.9971, Recall: 0.9971, F1: 0.9971
Validation Loss: 1.0761, Accuracy: 0.7917, Precision: 0.7975, Recall: 0.7925, F1: 0.7933
Testing Loss: 1.1290, Accuracy: 0.7871, Precision: 0.7969, Recall: 0.7877, F1: 0.7897
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1344, Accuracy: 0.9135, Precision: 0.9050, Recall: 0.8542, F1: 0.8755
Epoch 60/70
Train Loss: 0.0056, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.0836, Accuracy: 0.7925, Precision: 0.7962, Recall: 0.7924, F1: 0.7929
Testing Loss: 1.1336, Accuracy: 0.7879, Precision: 0.7981, Recall: 0.7877, F1: 0.7898
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1022, Accuracy: 0.9519, Precision: 0.9225, Recall: 0.8823, F1: 0.8998
Epoch 61/70
Train Loss: 0.0056, Accuracy: 0.9968, Precision: 0.9969, Recall: 0.9969, F1: 0.9969
Validation Loss: 1.0909, Accuracy: 0.7963, Precision: 0.7944, Recall: 0.7976, F1: 0.7937
Testing Loss: 1.0958, Accuracy: 0.7932, Precision: 0.7976, Recall: 0.7946, F1: 0.7941
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1101, Accuracy: 0.9423, Precision: 0.9038, Recall: 0.8828, F1: 0.8912
Epoch 62/70
Train Loss: 0.0057, Accuracy: 0.9972, Precision: 0.9971, Recall: 0.9973, F1: 0.9972
Validation Loss: 1.0967, Accuracy: 0.7917, Precision: 0.8002, Recall: 0.7915, F1: 0.7934
Testing Loss: 1.1120, Accuracy: 0.7909, Precision: 0.8041, Recall: 0.7876, F1: 0.7932
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2361, Accuracy: 0.8750, Precision: 0.9022, Recall: 0.8137, F1: 0.8496
Epoch 63/70
Train Loss: 0.0059, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9970, F1: 0.9971
Validation Loss: 1.0968, Accuracy: 0.7955, Precision: 0.7937, Recall: 0.7963, F1: 0.7933
Testing Loss: 1.1442, Accuracy: 0.7917, Precision: 0.7972, Recall: 0.7904, F1: 0.7914
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1453, Accuracy: 0.9135, Precision: 0.9124, Recall: 0.8439, F1: 0.8735
Epoch 64/70
Train Loss: 0.0057, Accuracy: 0.9972, Precision: 0.9973, Recall: 0.9972, F1: 0.9972
Validation Loss: 1.1141, Accuracy: 0.7948, Precision: 0.7984, Recall: 0.7960, F1: 0.7945
Testing Loss: 1.0882, Accuracy: 0.7963, Precision: 0.8049, Recall: 0.7944, F1: 0.7978
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1569, Accuracy: 0.9327, Precision: 0.9139, Recall: 0.8589, F1: 0.8807
Epoch 65/70
Train Loss: 0.0673, Accuracy: 0.9787, Precision: 0.9780, Recall: 0.9778, F1: 0.9779
Validation Loss: 1.2294, Accuracy: 0.7202, Precision: 0.7360, Recall: 0.7210, F1: 0.7160
Testing Loss: 1.2134, Accuracy: 0.7448, Precision: 0.7601, Recall: 0.7395, F1: 0.7403
LM Predictions:  [7, 9, 4, 13, 1, 5, 6, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 6, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 6, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 6, 12, 6, 1, 2, 4, 8, 14, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3237, Accuracy: 0.8846, Precision: 0.8856, Recall: 0.8239, F1: 0.8500
Epoch 66/70
Train Loss: 0.0462, Accuracy: 0.9857, Precision: 0.9856, Recall: 0.9856, F1: 0.9856
Validation Loss: 1.0731, Accuracy: 0.7855, Precision: 0.7870, Recall: 0.7883, F1: 0.7859
Testing Loss: 1.1322, Accuracy: 0.7763, Precision: 0.7806, Recall: 0.7743, F1: 0.7751
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1682, Accuracy: 0.9231, Precision: 0.9050, Recall: 0.8653, F1: 0.8815
Epoch 67/70
Train Loss: 0.0079, Accuracy: 0.9960, Precision: 0.9960, Recall: 0.9960, F1: 0.9960
Validation Loss: 1.1021, Accuracy: 0.7709, Precision: 0.7732, Recall: 0.7694, F1: 0.7690
Testing Loss: 1.1388, Accuracy: 0.7717, Precision: 0.7821, Recall: 0.7680, F1: 0.7723
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1487, Accuracy: 0.8942, Precision: 0.9050, Recall: 0.8364, F1: 0.8635
Epoch 68/70
Train Loss: 0.0066, Accuracy: 0.9965, Precision: 0.9970, Recall: 0.9966, F1: 0.9968
Validation Loss: 1.1823, Accuracy: 0.7487, Precision: 0.7549, Recall: 0.7541, F1: 0.7515
Testing Loss: 1.1548, Accuracy: 0.7456, Precision: 0.7584, Recall: 0.7455, F1: 0.7486
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 8, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 6, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 11, 11, 2, 6, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2514, Accuracy: 0.8462, Precision: 0.8903, Recall: 0.7852, F1: 0.8250
Epoch 69/70
Train Loss: 0.0408, Accuracy: 0.9856, Precision: 0.9851, Recall: 0.9852, F1: 0.9852
Validation Loss: 1.3415, Accuracy: 0.7317, Precision: 0.7419, Recall: 0.7259, F1: 0.7300
Testing Loss: 1.2409, Accuracy: 0.7402, Precision: 0.7509, Recall: 0.7385, F1: 0.7404
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 0, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1781, Accuracy: 0.9327, Precision: 0.8978, Recall: 0.8745, F1: 0.8825
Epoch 70/70
Train Loss: 0.0192, Accuracy: 0.9934, Precision: 0.9930, Recall: 0.9935, F1: 0.9932
Validation Loss: 1.2401, Accuracy: 0.7594, Precision: 0.7666, Recall: 0.7590, F1: 0.7574
Testing Loss: 1.1931, Accuracy: 0.7756, Precision: 0.7822, Recall: 0.7682, F1: 0.7713
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 2, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1414, Accuracy: 0.9038, Precision: 0.8948, Recall: 0.8462, F1: 0.8667
For later layers:  [8, 9, 10, 11]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 0.9222, Accuracy: 0.7196, Precision: 0.7310, Recall: 0.7130, F1: 0.7201
Validation Loss: 0.5178, Accuracy: 0.8424, Precision: 0.8552, Recall: 0.8435, F1: 0.8441
Testing Loss: 0.5323, Accuracy: 0.8432, Precision: 0.8534, Recall: 0.8460, F1: 0.8446
LM Predictions:  [0, 6, 0, 13, 0, 6, 6, 6, 0, 12, 6, 13, 13, 6, 12, 13, 6, 6, 6, 6, 0, 6, 0, 0, 6, 4, 0, 0, 6, 6, 0, 4, 0, 6, 6, 0, 6, 13, 0, 9, 6, 0, 6, 6, 6, 0, 6, 6, 0, 6, 6, 6, 6, 14, 0, 6, 6, 6, 6, 13, 0, 14, 6, 6, 14, 6, 0, 5, 14, 6, 0, 6, 0, 0, 0, 6, 0, 0, 6, 6, 8, 13, 6, 6, 6, 6, 0, 4, 6, 6, 0, 14, 6, 2, 4, 8, 0, 0, 6, 6, 6, 6, 0, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 4.1018, Accuracy: 0.1635, Precision: 0.3975, Recall: 0.1527, F1: 0.1674
Epoch 2/70
Train Loss: 0.2798, Accuracy: 0.9247, Precision: 0.9282, Recall: 0.9238, F1: 0.9259
Validation Loss: 0.4828, Accuracy: 0.8455, Precision: 0.8520, Recall: 0.8476, F1: 0.8445
Testing Loss: 0.5041, Accuracy: 0.8486, Precision: 0.8518, Recall: 0.8557, F1: 0.8491
LM Predictions:  [0, 6, 13, 13, 8, 6, 6, 6, 0, 12, 6, 8, 13, 8, 12, 4, 6, 13, 6, 6, 9, 13, 2, 0, 13, 4, 2, 0, 5, 6, 0, 9, 8, 5, 14, 14, 14, 13, 8, 9, 0, 0, 0, 0, 6, 0, 6, 6, 0, 6, 6, 6, 14, 14, 0, 6, 6, 13, 6, 2, 0, 14, 0, 6, 0, 8, 5, 5, 14, 6, 0, 6, 0, 6, 0, 6, 0, 0, 6, 6, 7, 6, 6, 6, 14, 13, 3, 8, 0, 6, 8, 13, 6, 2, 4, 8, 0, 4, 0, 6, 6, 6, 6, 6]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 2.8254, Accuracy: 0.3750, Precision: 0.5037, Recall: 0.3268, F1: 0.3421
Epoch 3/70
Train Loss: 0.0998, Accuracy: 0.9790, Precision: 0.9803, Recall: 0.9785, F1: 0.9793
Validation Loss: 0.5318, Accuracy: 0.8478, Precision: 0.8522, Recall: 0.8550, F1: 0.8472
Testing Loss: 0.5468, Accuracy: 0.8501, Precision: 0.8572, Recall: 0.8607, F1: 0.8513
LM Predictions:  [5, 3, 4, 13, 8, 5, 5, 6, 0, 12, 6, 8, 13, 11, 12, 5, 5, 12, 14, 11, 9, 4, 2, 0, 5, 4, 2, 0, 5, 10, 6, 10, 8, 5, 14, 14, 7, 13, 5, 9, 5, 0, 0, 0, 14, 0, 0, 7, 0, 6, 5, 6, 8, 14, 0, 6, 2, 6, 14, 2, 2, 12, 0, 6, 14, 8, 5, 5, 12, 11, 14, 14, 0, 6, 5, 6, 0, 14, 8, 6, 1, 14, 4, 6, 2, 13, 3, 8, 5, 5, 12, 6, 1, 2, 4, 8, 11, 4, 0, 6, 6, 2, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 1.1496, Accuracy: 0.6346, Precision: 0.7826, Recall: 0.5674, F1: 0.6127
Epoch 4/70
Train Loss: 0.0442, Accuracy: 0.9922, Precision: 0.9926, Recall: 0.9919, F1: 0.9923
Validation Loss: 0.4915, Accuracy: 0.8670, Precision: 0.8719, Recall: 0.8604, F1: 0.8644
Testing Loss: 0.5336, Accuracy: 0.8486, Precision: 0.8549, Recall: 0.8457, F1: 0.8481
LM Predictions:  [11, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 5, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 6, 14, 6, 0, 7, 6, 2, 6, 6, 8, 14, 12, 3, 2, 6, 14, 2, 2, 11, 0, 12, 1, 8, 5, 5, 11, 11, 14, 6, 0, 6, 11, 0, 0, 14, 8, 6, 10, 11, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.7341, Accuracy: 0.7981, Precision: 0.8646, Recall: 0.7378, F1: 0.7822
Epoch 5/70
Train Loss: 0.0243, Accuracy: 0.9957, Precision: 0.9959, Recall: 0.9957, F1: 0.9958
Validation Loss: 0.5812, Accuracy: 0.8555, Precision: 0.8518, Recall: 0.8588, F1: 0.8527
Testing Loss: 0.5600, Accuracy: 0.8478, Precision: 0.8424, Recall: 0.8519, F1: 0.8448
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 8, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3450, Accuracy: 0.9135, Precision: 0.8975, Recall: 0.8510, F1: 0.8709
Epoch 6/70
Train Loss: 0.0316, Accuracy: 0.9923, Precision: 0.9927, Recall: 0.9925, F1: 0.9926
Validation Loss: 0.8592, Accuracy: 0.7671, Precision: 0.7847, Recall: 0.7750, F1: 0.7682
Testing Loss: 0.7768, Accuracy: 0.7756, Precision: 0.7953, Recall: 0.7821, F1: 0.7733
LM Predictions:  [5, 9, 4, 13, 8, 12, 1, 6, 0, 12, 6, 4, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 14, 10, 8, 5, 14, 14, 14, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 2, 6, 2, 10, 14, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 6, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 6, 12, 6, 1, 2, 4, 8, 14, 4, 5, 6, 6, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.6738, Accuracy: 0.7692, Precision: 0.8481, Recall: 0.7117, F1: 0.7456
Epoch 7/70
Train Loss: 0.1026, Accuracy: 0.9712, Precision: 0.9719, Recall: 0.9707, F1: 0.9713
Validation Loss: 0.6415, Accuracy: 0.8255, Precision: 0.8331, Recall: 0.8282, F1: 0.8246
Testing Loss: 0.6492, Accuracy: 0.8217, Precision: 0.8319, Recall: 0.8240, F1: 0.8209
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 8, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 0, 8, 5, 1, 1, 9, 11, 2, 8, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2963, Accuracy: 0.8942, Precision: 0.8864, Recall: 0.8380, F1: 0.8539
Epoch 8/70
Train Loss: 0.0240, Accuracy: 0.9943, Precision: 0.9947, Recall: 0.9946, F1: 0.9946
Validation Loss: 0.6142, Accuracy: 0.8501, Precision: 0.8473, Recall: 0.8544, F1: 0.8483
Testing Loss: 0.5550, Accuracy: 0.8570, Precision: 0.8599, Recall: 0.8623, F1: 0.8586
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3145, Accuracy: 0.9231, Precision: 0.9127, Recall: 0.8494, F1: 0.8756
Epoch 9/70
Train Loss: 0.0421, Accuracy: 0.9867, Precision: 0.9869, Recall: 0.9864, F1: 0.9867
Validation Loss: 0.7309, Accuracy: 0.8248, Precision: 0.8281, Recall: 0.8198, F1: 0.8189
Testing Loss: 0.6972, Accuracy: 0.8370, Precision: 0.8382, Recall: 0.8355, F1: 0.8333
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2649, Accuracy: 0.9135, Precision: 0.9127, Recall: 0.8383, F1: 0.8696
Epoch 10/70
Train Loss: 0.0341, Accuracy: 0.9900, Precision: 0.9901, Recall: 0.9902, F1: 0.9901
Validation Loss: 0.7274, Accuracy: 0.8286, Precision: 0.8480, Recall: 0.8202, F1: 0.8268
Testing Loss: 0.7354, Accuracy: 0.8117, Precision: 0.8431, Recall: 0.8031, F1: 0.8117
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 6, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 6, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 6, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 6, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.4346, Accuracy: 0.8365, Precision: 0.8989, Recall: 0.7781, F1: 0.8276
Epoch 11/70
Train Loss: 0.0389, Accuracy: 0.9887, Precision: 0.9891, Recall: 0.9887, F1: 0.9888
Validation Loss: 0.7889, Accuracy: 0.8194, Precision: 0.8238, Recall: 0.8186, F1: 0.8162
Testing Loss: 0.7803, Accuracy: 0.8248, Precision: 0.8352, Recall: 0.8289, F1: 0.8234
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 4, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3341, Accuracy: 0.8942, Precision: 0.9114, Recall: 0.8238, F1: 0.8614
Epoch 12/70
Train Loss: 0.0334, Accuracy: 0.9888, Precision: 0.9887, Recall: 0.9884, F1: 0.9885
Validation Loss: 0.6529, Accuracy: 0.8440, Precision: 0.8544, Recall: 0.8416, F1: 0.8456
Testing Loss: 0.7000, Accuracy: 0.8347, Precision: 0.8523, Recall: 0.8334, F1: 0.8384
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 6, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2892, Accuracy: 0.8846, Precision: 0.9104, Recall: 0.8102, F1: 0.8525
Epoch 13/70
Train Loss: 0.0268, Accuracy: 0.9907, Precision: 0.9909, Recall: 0.9909, F1: 0.9909
Validation Loss: 0.7010, Accuracy: 0.8486, Precision: 0.8630, Recall: 0.8513, F1: 0.8531
Testing Loss: 0.6351, Accuracy: 0.8532, Precision: 0.8620, Recall: 0.8561, F1: 0.8577
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 6, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2070, Accuracy: 0.8942, Precision: 0.9215, Recall: 0.8303, F1: 0.8693
Epoch 14/70
Train Loss: 0.0192, Accuracy: 0.9942, Precision: 0.9942, Recall: 0.9943, F1: 0.9943
Validation Loss: 0.7330, Accuracy: 0.8317, Precision: 0.8492, Recall: 0.8306, F1: 0.8355
Testing Loss: 0.7375, Accuracy: 0.8378, Precision: 0.8592, Recall: 0.8397, F1: 0.8431
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 11, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3424, Accuracy: 0.8846, Precision: 0.9044, Recall: 0.8094, F1: 0.8454
Epoch 15/70
Train Loss: 0.0441, Accuracy: 0.9855, Precision: 0.9852, Recall: 0.9851, F1: 0.9851
Validation Loss: 0.7551, Accuracy: 0.8163, Precision: 0.8230, Recall: 0.8153, F1: 0.8166
Testing Loss: 0.7829, Accuracy: 0.8317, Precision: 0.8393, Recall: 0.8310, F1: 0.8314
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 6, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 6, 3, 8, 6, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2908, Accuracy: 0.8654, Precision: 0.9222, Recall: 0.7932, F1: 0.8439
Epoch 16/70
Train Loss: 0.0464, Accuracy: 0.9842, Precision: 0.9848, Recall: 0.9846, F1: 0.9847
Validation Loss: 0.6877, Accuracy: 0.8424, Precision: 0.8498, Recall: 0.8423, F1: 0.8440
Testing Loss: 0.7342, Accuracy: 0.8378, Precision: 0.8431, Recall: 0.8402, F1: 0.8391
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1678, Accuracy: 0.9231, Precision: 0.9139, Recall: 0.8608, F1: 0.8822
Epoch 17/70
Train Loss: 0.0127, Accuracy: 0.9959, Precision: 0.9958, Recall: 0.9959, F1: 0.9959
Validation Loss: 0.6966, Accuracy: 0.8493, Precision: 0.8574, Recall: 0.8452, F1: 0.8494
Testing Loss: 0.7172, Accuracy: 0.8478, Precision: 0.8594, Recall: 0.8476, F1: 0.8511
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2112, Accuracy: 0.9038, Precision: 0.9022, Recall: 0.8507, F1: 0.8731
Epoch 18/70
Train Loss: 0.0087, Accuracy: 0.9971, Precision: 0.9974, Recall: 0.9971, F1: 0.9972
Validation Loss: 0.6769, Accuracy: 0.8493, Precision: 0.8571, Recall: 0.8479, F1: 0.8510
Testing Loss: 0.6908, Accuracy: 0.8517, Precision: 0.8597, Recall: 0.8549, F1: 0.8559
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1248, Accuracy: 0.9519, Precision: 0.9222, Recall: 0.8767, F1: 0.8963
Epoch 19/70
Train Loss: 0.0091, Accuracy: 0.9965, Precision: 0.9966, Recall: 0.9967, F1: 0.9966
Validation Loss: 0.6750, Accuracy: 0.8593, Precision: 0.8658, Recall: 0.8559, F1: 0.8588
Testing Loss: 0.6909, Accuracy: 0.8609, Precision: 0.8678, Recall: 0.8612, F1: 0.8628
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2069, Accuracy: 0.9231, Precision: 0.9139, Recall: 0.8577, F1: 0.8798
Epoch 20/70
Train Loss: 0.0078, Accuracy: 0.9970, Precision: 0.9971, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.6852, Accuracy: 0.8578, Precision: 0.8625, Recall: 0.8565, F1: 0.8573
Testing Loss: 0.7019, Accuracy: 0.8563, Precision: 0.8641, Recall: 0.8582, F1: 0.8591
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2490, Accuracy: 0.9038, Precision: 0.9127, Recall: 0.8264, F1: 0.8626
Epoch 21/70
Train Loss: 0.0084, Accuracy: 0.9966, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.6626, Accuracy: 0.8601, Precision: 0.8580, Recall: 0.8611, F1: 0.8586
Testing Loss: 0.6915, Accuracy: 0.8563, Precision: 0.8597, Recall: 0.8599, F1: 0.8580
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1908, Accuracy: 0.9231, Precision: 0.9228, Recall: 0.8458, F1: 0.8791
Epoch 22/70
Train Loss: 0.0077, Accuracy: 0.9969, Precision: 0.9969, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.7151, Accuracy: 0.8586, Precision: 0.8608, Recall: 0.8596, F1: 0.8589
Testing Loss: 0.6942, Accuracy: 0.8640, Precision: 0.8673, Recall: 0.8657, F1: 0.8650
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2770, Accuracy: 0.8942, Precision: 0.9022, Recall: 0.8332, F1: 0.8625
Epoch 23/70
Train Loss: 0.0077, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9969, F1: 0.9968
Validation Loss: 0.6904, Accuracy: 0.8624, Precision: 0.8661, Recall: 0.8618, F1: 0.8631
Testing Loss: 0.6717, Accuracy: 0.8632, Precision: 0.8671, Recall: 0.8658, F1: 0.8658
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2426, Accuracy: 0.8942, Precision: 0.9111, Recall: 0.8213, F1: 0.8605
Epoch 24/70
Train Loss: 0.0874, Accuracy: 0.9715, Precision: 0.9712, Recall: 0.9713, F1: 0.9712
Validation Loss: 0.7424, Accuracy: 0.8148, Precision: 0.8202, Recall: 0.8153, F1: 0.8156
Testing Loss: 0.7758, Accuracy: 0.8009, Precision: 0.8092, Recall: 0.8015, F1: 0.8011
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 6, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 14, 9, 5, 8, 6, 8, 14, 3, 0, 6, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 6, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 6, 0, 14, 8, 5, 1, 1, 9, 11, 2, 6, 3, 8, 5, 5, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 14, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3696, Accuracy: 0.8558, Precision: 0.8914, Recall: 0.7787, F1: 0.8255
Epoch 25/70
Train Loss: 0.0604, Accuracy: 0.9804, Precision: 0.9794, Recall: 0.9795, F1: 0.9794
Validation Loss: 0.7229, Accuracy: 0.8332, Precision: 0.8427, Recall: 0.8306, F1: 0.8335
Testing Loss: 0.7403, Accuracy: 0.8347, Precision: 0.8461, Recall: 0.8313, F1: 0.8353
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 6, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 0, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2229, Accuracy: 0.8846, Precision: 0.8943, Recall: 0.8374, F1: 0.8612
Epoch 26/70
Train Loss: 0.0158, Accuracy: 0.9941, Precision: 0.9945, Recall: 0.9943, F1: 0.9944
Validation Loss: 0.8756, Accuracy: 0.8063, Precision: 0.8164, Recall: 0.8139, F1: 0.8087
Testing Loss: 0.8378, Accuracy: 0.8309, Precision: 0.8405, Recall: 0.8379, F1: 0.8309
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 14, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1745, Accuracy: 0.8942, Precision: 0.9037, Recall: 0.8169, F1: 0.8533
Epoch 27/70
Train Loss: 0.0121, Accuracy: 0.9959, Precision: 0.9960, Recall: 0.9959, F1: 0.9960
Validation Loss: 0.7100, Accuracy: 0.8493, Precision: 0.8518, Recall: 0.8484, F1: 0.8496
Testing Loss: 0.7178, Accuracy: 0.8532, Precision: 0.8604, Recall: 0.8535, F1: 0.8558
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.0996, Accuracy: 0.9615, Precision: 0.9225, Recall: 0.8934, F1: 0.9059
Epoch 28/70
Train Loss: 0.0063, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 0.7204, Accuracy: 0.8509, Precision: 0.8514, Recall: 0.8507, F1: 0.8496
Testing Loss: 0.7186, Accuracy: 0.8555, Precision: 0.8550, Recall: 0.8551, F1: 0.8541
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1683, Accuracy: 0.8942, Precision: 0.9108, Recall: 0.8277, F1: 0.8641
Epoch 29/70
Train Loss: 0.0058, Accuracy: 0.9971, Precision: 0.9973, Recall: 0.9972, F1: 0.9972
Validation Loss: 0.6979, Accuracy: 0.8624, Precision: 0.8639, Recall: 0.8624, F1: 0.8623
Testing Loss: 0.7101, Accuracy: 0.8540, Precision: 0.8580, Recall: 0.8549, F1: 0.8551
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2516, Accuracy: 0.8750, Precision: 0.9022, Recall: 0.8174, F1: 0.8525
Epoch 30/70
Train Loss: 0.0063, Accuracy: 0.9966, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.7204, Accuracy: 0.8555, Precision: 0.8551, Recall: 0.8563, F1: 0.8548
Testing Loss: 0.7227, Accuracy: 0.8586, Precision: 0.8569, Recall: 0.8602, F1: 0.8576
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1315, Accuracy: 0.9231, Precision: 0.9050, Recall: 0.8634, F1: 0.8807
Epoch 31/70
Train Loss: 0.0064, Accuracy: 0.9966, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.7431, Accuracy: 0.8540, Precision: 0.8549, Recall: 0.8543, F1: 0.8537
Testing Loss: 0.7428, Accuracy: 0.8624, Precision: 0.8615, Recall: 0.8640, F1: 0.8611
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1319, Accuracy: 0.9327, Precision: 0.9050, Recall: 0.8752, F1: 0.8852
Epoch 32/70
Train Loss: 0.0064, Accuracy: 0.9970, Precision: 0.9971, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.7576, Accuracy: 0.8447, Precision: 0.8490, Recall: 0.8450, F1: 0.8451
Testing Loss: 0.7543, Accuracy: 0.8547, Precision: 0.8580, Recall: 0.8569, F1: 0.8546
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1430, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8700, F1: 0.8868
Epoch 33/70
Train Loss: 0.0067, Accuracy: 0.9968, Precision: 0.9969, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.7294, Accuracy: 0.8555, Precision: 0.8561, Recall: 0.8564, F1: 0.8551
Testing Loss: 0.7566, Accuracy: 0.8470, Precision: 0.8478, Recall: 0.8497, F1: 0.8466
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1824, Accuracy: 0.9038, Precision: 0.9038, Recall: 0.8491, F1: 0.8729
Epoch 34/70
Train Loss: 0.0060, Accuracy: 0.9972, Precision: 0.9974, Recall: 0.9972, F1: 0.9973
Validation Loss: 0.7490, Accuracy: 0.8655, Precision: 0.8702, Recall: 0.8638, F1: 0.8645
Testing Loss: 0.7363, Accuracy: 0.8540, Precision: 0.8575, Recall: 0.8511, F1: 0.8523
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1124, Accuracy: 0.9615, Precision: 0.9133, Recall: 0.9060, F1: 0.9077
Epoch 35/70
Train Loss: 0.0596, Accuracy: 0.9812, Precision: 0.9819, Recall: 0.9810, F1: 0.9814
Validation Loss: 0.9611, Accuracy: 0.7679, Precision: 0.7851, Recall: 0.7652, F1: 0.7652
Testing Loss: 0.9518, Accuracy: 0.7694, Precision: 0.7881, Recall: 0.7701, F1: 0.7697
LM Predictions:  [5, 6, 4, 13, 8, 5, 0, 6, 0, 12, 6, 14, 13, 11, 12, 13, 1, 14, 14, 11, 6, 4, 2, 4, 6, 4, 2, 8, 5, 6, 12, 4, 8, 5, 14, 14, 6, 13, 14, 14, 5, 8, 6, 8, 14, 3, 0, 4, 6, 0, 14, 8, 14, 14, 12, 3, 2, 13, 14, 2, 2, 11, 0, 4, 14, 8, 5, 5, 11, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 5, 4, 6, 9, 11, 2, 13, 4, 8, 5, 7, 12, 13, 1, 2, 4, 4, 11, 4, 5, 3, 6, 5, 5, 14]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.9662, Accuracy: 0.6538, Precision: 0.7307, Recall: 0.5738, F1: 0.5892
Epoch 36/70
Train Loss: 0.0729, Accuracy: 0.9768, Precision: 0.9761, Recall: 0.9757, F1: 0.9759
Validation Loss: 0.7747, Accuracy: 0.8286, Precision: 0.8437, Recall: 0.8291, F1: 0.8336
Testing Loss: 0.8007, Accuracy: 0.8278, Precision: 0.8374, Recall: 0.8282, F1: 0.8294
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 0, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 3, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1668, Accuracy: 0.9135, Precision: 0.8963, Recall: 0.8403, F1: 0.8637
Epoch 37/70
Train Loss: 0.0245, Accuracy: 0.9911, Precision: 0.9911, Recall: 0.9909, F1: 0.9910
Validation Loss: 0.8428, Accuracy: 0.8263, Precision: 0.8341, Recall: 0.8264, F1: 0.8268
Testing Loss: 0.8600, Accuracy: 0.8163, Precision: 0.8230, Recall: 0.8175, F1: 0.8144
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1575, Accuracy: 0.9038, Precision: 0.9139, Recall: 0.8293, F1: 0.8654
Epoch 38/70
Train Loss: 0.0083, Accuracy: 0.9959, Precision: 0.9960, Recall: 0.9958, F1: 0.9959
Validation Loss: 0.7568, Accuracy: 0.8424, Precision: 0.8399, Recall: 0.8455, F1: 0.8415
Testing Loss: 0.7237, Accuracy: 0.8517, Precision: 0.8530, Recall: 0.8529, F1: 0.8519
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1120, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8693, F1: 0.8883
Epoch 39/70
Train Loss: 0.0054, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9971, F1: 0.9972
Validation Loss: 0.7702, Accuracy: 0.8532, Precision: 0.8564, Recall: 0.8552, F1: 0.8546
Testing Loss: 0.7382, Accuracy: 0.8501, Precision: 0.8557, Recall: 0.8515, F1: 0.8521
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.0916, Accuracy: 0.9808, Precision: 0.9887, Recall: 0.9742, F1: 0.9797
Epoch 40/70
Train Loss: 0.0050, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9973, F1: 0.9972
Validation Loss: 0.7652, Accuracy: 0.8517, Precision: 0.8509, Recall: 0.8564, F1: 0.8530
Testing Loss: 0.7220, Accuracy: 0.8532, Precision: 0.8540, Recall: 0.8548, F1: 0.8539
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.0902, Accuracy: 0.9712, Precision: 0.9139, Recall: 0.9101, F1: 0.9103
Epoch 41/70
Train Loss: 0.0053, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9971, F1: 0.9970
Validation Loss: 0.7608, Accuracy: 0.8501, Precision: 0.8544, Recall: 0.8538, F1: 0.8526
Testing Loss: 0.7371, Accuracy: 0.8463, Precision: 0.8534, Recall: 0.8473, F1: 0.8487
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1008, Accuracy: 0.9615, Precision: 0.9139, Recall: 0.9053, F1: 0.9076
Epoch 42/70
Train Loss: 0.0053, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9971, F1: 0.9970
Validation Loss: 0.7531, Accuracy: 0.8563, Precision: 0.8636, Recall: 0.8547, F1: 0.8579
Testing Loss: 0.7379, Accuracy: 0.8524, Precision: 0.8599, Recall: 0.8495, F1: 0.8536
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1412, Accuracy: 0.9327, Precision: 0.9136, Recall: 0.8689, F1: 0.8872
Epoch 43/70
Train Loss: 0.0053, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.7597, Accuracy: 0.8593, Precision: 0.8641, Recall: 0.8620, F1: 0.8622
Testing Loss: 0.7403, Accuracy: 0.8563, Precision: 0.8611, Recall: 0.8554, F1: 0.8574
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1446, Accuracy: 0.9038, Precision: 0.9222, Recall: 0.8287, F1: 0.8671
Epoch 44/70
Train Loss: 0.0054, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9970, F1: 0.9971
Validation Loss: 0.7910, Accuracy: 0.8524, Precision: 0.8536, Recall: 0.8566, F1: 0.8530
Testing Loss: 0.7673, Accuracy: 0.8432, Precision: 0.8433, Recall: 0.8451, F1: 0.8425
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1378, Accuracy: 0.9423, Precision: 0.9133, Recall: 0.8806, F1: 0.8932
Epoch 45/70
Train Loss: 0.0750, Accuracy: 0.9784, Precision: 0.9778, Recall: 0.9775, F1: 0.9776
Validation Loss: 0.9145, Accuracy: 0.7894, Precision: 0.8200, Recall: 0.7861, F1: 0.7963
Testing Loss: 0.9708, Accuracy: 0.7740, Precision: 0.8129, Recall: 0.7729, F1: 0.7832
LM Predictions:  [0, 9, 4, 13, 8, 5, 0, 6, 0, 12, 6, 0, 13, 6, 12, 12, 1, 12, 0, 6, 9, 4, 2, 0, 6, 4, 2, 10, 5, 10, 12, 10, 0, 4, 14, 14, 7, 13, 8, 9, 5, 10, 6, 0, 14, 14, 0, 6, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 6, 14, 0, 0, 1, 8, 5, 0, 14, 11, 14, 6, 0, 6, 0, 6, 0, 14, 8, 6, 1, 6, 6, 0, 2, 13, 3, 8, 5, 7, 12, 6, 6, 2, 4, 0, 11, 4, 5, 6, 0, 14, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.9943, Accuracy: 0.6346, Precision: 0.8416, Recall: 0.5912, F1: 0.6527
Epoch 46/70
Train Loss: 0.0717, Accuracy: 0.9755, Precision: 0.9756, Recall: 0.9753, F1: 0.9754
Validation Loss: 0.8695, Accuracy: 0.8217, Precision: 0.8372, Recall: 0.8215, F1: 0.8240
Testing Loss: 0.8527, Accuracy: 0.8201, Precision: 0.8323, Recall: 0.8205, F1: 0.8232
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 6, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 11, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1960, Accuracy: 0.8846, Precision: 0.8931, Recall: 0.8329, F1: 0.8576
Epoch 47/70
Train Loss: 0.0154, Accuracy: 0.9946, Precision: 0.9948, Recall: 0.9946, F1: 0.9947
Validation Loss: 0.7200, Accuracy: 0.8524, Precision: 0.8605, Recall: 0.8533, F1: 0.8553
Testing Loss: 0.7383, Accuracy: 0.8478, Precision: 0.8588, Recall: 0.8453, F1: 0.8500
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1604, Accuracy: 0.8846, Precision: 0.9171, Recall: 0.8205, F1: 0.8624
Epoch 48/70
Train Loss: 0.0062, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9964, F1: 0.9965
Validation Loss: 0.7379, Accuracy: 0.8517, Precision: 0.8641, Recall: 0.8517, F1: 0.8562
Testing Loss: 0.7429, Accuracy: 0.8486, Precision: 0.8609, Recall: 0.8466, F1: 0.8518
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1289, Accuracy: 0.9135, Precision: 0.9139, Recall: 0.8404, F1: 0.8715
Epoch 49/70
Train Loss: 0.0048, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.7573, Accuracy: 0.8532, Precision: 0.8606, Recall: 0.8541, F1: 0.8562
Testing Loss: 0.7326, Accuracy: 0.8540, Precision: 0.8617, Recall: 0.8528, F1: 0.8562
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1586, Accuracy: 0.8750, Precision: 0.9108, Recall: 0.8054, F1: 0.8508
Epoch 50/70
Train Loss: 0.0048, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.7585, Accuracy: 0.8540, Precision: 0.8633, Recall: 0.8526, F1: 0.8561
Testing Loss: 0.7531, Accuracy: 0.8540, Precision: 0.8666, Recall: 0.8524, F1: 0.8577
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2025, Accuracy: 0.8654, Precision: 0.9022, Recall: 0.8062, F1: 0.8465
Epoch 51/70
Train Loss: 0.0051, Accuracy: 0.9972, Precision: 0.9974, Recall: 0.9972, F1: 0.9973
Validation Loss: 0.7448, Accuracy: 0.8532, Precision: 0.8615, Recall: 0.8535, F1: 0.8563
Testing Loss: 0.7350, Accuracy: 0.8501, Precision: 0.8596, Recall: 0.8509, F1: 0.8538
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1304, Accuracy: 0.9423, Precision: 0.9228, Recall: 0.8664, F1: 0.8911
Epoch 52/70
Train Loss: 0.0049, Accuracy: 0.9970, Precision: 0.9970, Recall: 0.9972, F1: 0.9971
Validation Loss: 0.7715, Accuracy: 0.8532, Precision: 0.8629, Recall: 0.8529, F1: 0.8565
Testing Loss: 0.7616, Accuracy: 0.8509, Precision: 0.8607, Recall: 0.8507, F1: 0.8540
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1770, Accuracy: 0.8942, Precision: 0.9136, Recall: 0.8245, F1: 0.8629
Epoch 53/70
Train Loss: 0.0053, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9970, F1: 0.9971
Validation Loss: 0.7952, Accuracy: 0.8501, Precision: 0.8551, Recall: 0.8506, F1: 0.8510
Testing Loss: 0.7770, Accuracy: 0.8509, Precision: 0.8553, Recall: 0.8512, F1: 0.8524
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1378, Accuracy: 0.9231, Precision: 0.9111, Recall: 0.8510, F1: 0.8770
Epoch 54/70
Train Loss: 0.0054, Accuracy: 0.9971, Precision: 0.9971, Recall: 0.9973, F1: 0.9972
Validation Loss: 0.7979, Accuracy: 0.8509, Precision: 0.8658, Recall: 0.8487, F1: 0.8541
Testing Loss: 0.8113, Accuracy: 0.8424, Precision: 0.8586, Recall: 0.8408, F1: 0.8463
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1533, Accuracy: 0.9135, Precision: 0.9050, Recall: 0.8594, F1: 0.8765
Epoch 55/70
Train Loss: 0.0767, Accuracy: 0.9755, Precision: 0.9762, Recall: 0.9755, F1: 0.9758
Validation Loss: 0.8629, Accuracy: 0.7886, Precision: 0.8142, Recall: 0.7873, F1: 0.7928
Testing Loss: 0.8473, Accuracy: 0.7940, Precision: 0.8182, Recall: 0.7929, F1: 0.7971
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 13, 4, 2, 7, 6, 4, 2, 8, 0, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 0, 9, 0, 14, 8, 6, 1, 1, 9, 2, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 0, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.3578, Accuracy: 0.8750, Precision: 0.8791, Recall: 0.8115, F1: 0.8348
Epoch 56/70
Train Loss: 0.0587, Accuracy: 0.9801, Precision: 0.9801, Recall: 0.9797, F1: 0.9799
Validation Loss: 0.7567, Accuracy: 0.8355, Precision: 0.8436, Recall: 0.8361, F1: 0.8371
Testing Loss: 0.7849, Accuracy: 0.8255, Precision: 0.8360, Recall: 0.8283, F1: 0.8288
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1502, Accuracy: 0.9038, Precision: 0.9038, Recall: 0.8498, F1: 0.8714
Epoch 57/70
Train Loss: 0.0118, Accuracy: 0.9958, Precision: 0.9959, Recall: 0.9957, F1: 0.9958
Validation Loss: 0.7934, Accuracy: 0.8332, Precision: 0.8376, Recall: 0.8345, F1: 0.8344
Testing Loss: 0.7906, Accuracy: 0.8394, Precision: 0.8445, Recall: 0.8433, F1: 0.8422
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1040, Accuracy: 0.9615, Precision: 0.9050, Recall: 0.9034, F1: 0.9024
Epoch 58/70
Train Loss: 0.0051, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9967, F1: 0.9968
Validation Loss: 0.8012, Accuracy: 0.8340, Precision: 0.8362, Recall: 0.8387, F1: 0.8370
Testing Loss: 0.8061, Accuracy: 0.8424, Precision: 0.8478, Recall: 0.8468, F1: 0.8459
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1224, Accuracy: 0.9327, Precision: 0.9038, Recall: 0.8716, F1: 0.8852
Epoch 59/70
Train Loss: 0.0045, Accuracy: 0.9972, Precision: 0.9972, Recall: 0.9974, F1: 0.9973
Validation Loss: 0.7985, Accuracy: 0.8378, Precision: 0.8404, Recall: 0.8388, F1: 0.8392
Testing Loss: 0.7968, Accuracy: 0.8424, Precision: 0.8510, Recall: 0.8441, F1: 0.8465
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1687, Accuracy: 0.8846, Precision: 0.9038, Recall: 0.8269, F1: 0.8584
Epoch 60/70
Train Loss: 0.0048, Accuracy: 0.9971, Precision: 0.9973, Recall: 0.9971, F1: 0.9972
Validation Loss: 0.8075, Accuracy: 0.8409, Precision: 0.8421, Recall: 0.8426, F1: 0.8416
Testing Loss: 0.8127, Accuracy: 0.8432, Precision: 0.8487, Recall: 0.8454, F1: 0.8457
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1175, Accuracy: 0.9327, Precision: 0.9139, Recall: 0.8633, F1: 0.8845
Epoch 61/70
Train Loss: 0.0049, Accuracy: 0.9967, Precision: 0.9968, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.8048, Accuracy: 0.8417, Precision: 0.8456, Recall: 0.8417, F1: 0.8431
Testing Loss: 0.7969, Accuracy: 0.8401, Precision: 0.8493, Recall: 0.8419, F1: 0.8445
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1506, Accuracy: 0.8942, Precision: 0.9022, Recall: 0.8403, F1: 0.8655
Epoch 62/70
Train Loss: 0.0049, Accuracy: 0.9969, Precision: 0.9971, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.8130, Accuracy: 0.8424, Precision: 0.8423, Recall: 0.8431, F1: 0.8418
Testing Loss: 0.8091, Accuracy: 0.8509, Precision: 0.8563, Recall: 0.8541, F1: 0.8542
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 12, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 3, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1278, Accuracy: 0.9231, Precision: 0.9133, Recall: 0.8648, F1: 0.8833
Epoch 63/70
Train Loss: 0.0049, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9972, F1: 0.9972
Validation Loss: 0.8128, Accuracy: 0.8417, Precision: 0.8441, Recall: 0.8408, F1: 0.8419
Testing Loss: 0.8183, Accuracy: 0.8432, Precision: 0.8513, Recall: 0.8465, F1: 0.8477
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 6, 0, 6, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 6, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.2023, Accuracy: 0.8942, Precision: 0.9050, Recall: 0.8371, F1: 0.8631
Epoch 64/70
Train Loss: 0.0052, Accuracy: 0.9972, Precision: 0.9974, Recall: 0.9973, F1: 0.9973
Validation Loss: 0.7910, Accuracy: 0.8478, Precision: 0.8510, Recall: 0.8499, F1: 0.8498
Testing Loss: 0.8214, Accuracy: 0.8432, Precision: 0.8515, Recall: 0.8444, F1: 0.8463
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 6, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1226, Accuracy: 0.9423, Precision: 0.9139, Recall: 0.8767, F1: 0.8909
Epoch 65/70
Train Loss: 0.0970, Accuracy: 0.9692, Precision: 0.9688, Recall: 0.9687, F1: 0.9688
Validation Loss: 0.9030, Accuracy: 0.7971, Precision: 0.8036, Recall: 0.8008, F1: 0.7989
Testing Loss: 0.9262, Accuracy: 0.8071, Precision: 0.8105, Recall: 0.8161, F1: 0.8097
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 5, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 6, 11, 9, 0, 14, 8, 5, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1598, Accuracy: 0.9423, Precision: 0.8989, Recall: 0.8812, F1: 0.8871
Epoch 66/70
Train Loss: 0.0217, Accuracy: 0.9922, Precision: 0.9925, Recall: 0.9922, F1: 0.9924
Validation Loss: 0.8735, Accuracy: 0.8155, Precision: 0.8181, Recall: 0.8185, F1: 0.8150
Testing Loss: 0.9887, Accuracy: 0.8148, Precision: 0.8269, Recall: 0.8211, F1: 0.8185
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 12, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1166, Accuracy: 0.9519, Precision: 0.9050, Recall: 0.8967, F1: 0.8989
Epoch 67/70
Train Loss: 0.0057, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9972, F1: 0.9972
Validation Loss: 0.8080, Accuracy: 0.8386, Precision: 0.8430, Recall: 0.8370, F1: 0.8387
Testing Loss: 0.8755, Accuracy: 0.8370, Precision: 0.8443, Recall: 0.8390, F1: 0.8402
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 6, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 6, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1270, Accuracy: 0.9038, Precision: 0.9022, Recall: 0.8451, F1: 0.8694
Epoch 68/70
Train Loss: 0.0045, Accuracy: 0.9972, Precision: 0.9974, Recall: 0.9972, F1: 0.9973
Validation Loss: 0.8012, Accuracy: 0.8355, Precision: 0.8365, Recall: 0.8347, F1: 0.8349
Testing Loss: 0.8572, Accuracy: 0.8394, Precision: 0.8415, Recall: 0.8418, F1: 0.8405
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1028, Accuracy: 0.9519, Precision: 0.9127, Recall: 0.8827, F1: 0.8950
Epoch 69/70
Train Loss: 0.0044, Accuracy: 0.9969, Precision: 0.9969, Recall: 0.9970, F1: 0.9969
Validation Loss: 0.7995, Accuracy: 0.8394, Precision: 0.8405, Recall: 0.8388, F1: 0.8388
Testing Loss: 0.8648, Accuracy: 0.8409, Precision: 0.8439, Recall: 0.8419, F1: 0.8418
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 6, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 8, 6, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1049, Accuracy: 0.9423, Precision: 0.9111, Recall: 0.8732, F1: 0.8891
Epoch 70/70
Train Loss: 0.0047, Accuracy: 0.9970, Precision: 0.9970, Recall: 0.9972, F1: 0.9971
Validation Loss: 0.8058, Accuracy: 0.8409, Precision: 0.8449, Recall: 0.8397, F1: 0.8410
Testing Loss: 0.8599, Accuracy: 0.8447, Precision: 0.8510, Recall: 0.8456, F1: 0.8471
LM Predictions:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 10, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 6, 2, 10, 8, 8, 14, 0, 3, 2, 13, 14, 2, 2, 14, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 6, 1, 6, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Labels:  [7, 9, 4, 13, 8, 5, 1, 3, 0, 12, 9, 8, 13, 11, 12, 12, 1, 12, 14, 11, 9, 4, 2, 7, 4, 4, 2, 8, 5, 10, 12, 10, 8, 5, 14, 14, 7, 13, 8, 9, 5, 10, 0, 8, 14, 3, 0, 7, 0, 2, 10, 8, 8, 14, 12, 3, 2, 13, 14, 2, 2, 12, 0, 12, 1, 8, 5, 5, 14, 11, 14, 8, 0, 3, 11, 9, 0, 14, 8, 5, 1, 1, 9, 11, 2, 13, 3, 8, 5, 7, 12, 13, 1, 2, 4, 8, 11, 4, 5, 3, 12, 11, 5, 8]
LM Loss: 0.1131, Accuracy: 0.9423, Precision: 0.9038, Recall: 0.8879, F1: 0.8934
