13007 13007
10405 10405 2602 2602
Model: facebook/vit-msn-small, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 6
Label counts for Train:
  Label 8: 433
  Label 1: 789
  Label 6: 924
  Label 14: 664
  Label 12: 618
  Label 10: 818
  Label 4: 808
  Label 2: 534
  Label 11: 709
  Label 7: 469
  Label 0: 819
  Label 3: 707
  Label 9: 900
  Label 13: 834
  Label 5: 379
Label counts for Validation:
  Label 7: 59
  Label 13: 104
  Label 14: 83
  Label 12: 78
  Label 6: 115
  Label 1: 98
  Label 11: 89
  Label 8: 54
  Label 10: 102
  Label 0: 103
  Label 2: 67
  Label 9: 112
  Label 5: 47
  Label 3: 89
  Label 4: 101
Label counts for Test:
  Label 7: 58
  Label 10: 103
  Label 11: 88
  Label 2: 67
  Label 6: 116
  Label 3: 88
  Label 4: 101
  Label 8: 54
  Label 9: 113
  Label 1: 99
  Label 0: 102
  Label 13: 105
  Label 12: 77
  Label 14: 83
  Label 5: 47
104
Actual labels:  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
Label counts for Train:
  Label 8: 435
  Label 1: 799
  Label 6: 820
  Label 14: 668
  Label 12: 625
  Label 10: 827
  Label 4: 815
  Label 2: 538
  Label 11: 714
  Label 7: 478
  Label 0: 827
  Label 3: 716
  Label 9: 909
  Label 13: 845
  Label 5: 389
10405
(3, 224, 224)
For early layers:  [0, 1, 2, 3]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 2.1300, Accuracy: 0.3272, Precision: 0.3232, Recall: 0.3066, F1: 0.3021
Validation Loss: 1.7157, Accuracy: 0.4466, Precision: 0.4433, Recall: 0.4342, F1: 0.4259
Testing Loss: 1.6687, Accuracy: 0.4704, Precision: 0.4997, Recall: 0.4638, F1: 0.4632
LM Predictions:  [13, 6, 13, 2, 14, 14, 6, 6, 3, 0, 0, 5, 13, 11, 0, 6, 13, 6, 13, 0, 13, 0, 13, 6, 6, 3, 0, 0, 0, 13, 0, 7, 3, 3, 0, 9, 0, 6, 7, 14, 0, 13, 6, 14, 2, 2, 14, 13, 6, 3, 13, 0, 3, 13, 10, 10, 4, 0, 3, 6, 6, 6, 0, 2, 6, 5, 13, 6, 0, 0, 2, 0, 6, 9, 6, 12, 8, 14, 0, 13, 13, 0, 9, 14, 13, 6, 9, 3, 0, 13, 0, 14, 0, 0, 0, 13, 6, 6, 13, 9, 6, 0, 13, 10]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.4800, Accuracy: 0.1058, Precision: 0.1209, Recall: 0.0749, F1: 0.0756
Epoch 2/70
Train Loss: 1.4727, Accuracy: 0.5333, Precision: 0.5328, Recall: 0.5233, F1: 0.5253
Validation Loss: 1.2714, Accuracy: 0.5888, Precision: 0.5973, Recall: 0.5874, F1: 0.5810
Testing Loss: 1.2360, Accuracy: 0.6049, Precision: 0.6209, Recall: 0.6107, F1: 0.6026
LM Predictions:  [6, 0, 0, 6, 6, 6, 8, 6, 6, 12, 0, 5, 0, 6, 0, 6, 6, 0, 13, 6, 13, 6, 13, 6, 0, 4, 0, 0, 0, 13, 6, 7, 3, 3, 6, 0, 10, 6, 0, 6, 0, 3, 6, 0, 0, 6, 0, 0, 6, 0, 6, 0, 6, 0, 14, 8, 6, 6, 10, 6, 8, 6, 0, 4, 6, 0, 0, 6, 1, 0, 0, 14, 0, 0, 8, 12, 8, 6, 6, 0, 0, 0, 14, 0, 13, 6, 9, 6, 0, 3, 0, 14, 0, 0, 0, 0, 0, 6, 13, 9, 0, 0, 6, 10]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.5724, Accuracy: 0.0865, Precision: 0.1550, Recall: 0.0647, F1: 0.0664
Epoch 3/70
Train Loss: 0.9773, Accuracy: 0.6957, Precision: 0.6990, Recall: 0.6927, F1: 0.6948
Validation Loss: 1.0786, Accuracy: 0.6580, Precision: 0.6930, Recall: 0.6419, F1: 0.6542
Testing Loss: 1.0208, Accuracy: 0.6849, Precision: 0.7259, Recall: 0.6757, F1: 0.6879
LM Predictions:  [13, 6, 6, 0, 6, 0, 6, 6, 6, 12, 0, 5, 0, 6, 0, 6, 0, 0, 11, 6, 13, 6, 13, 6, 0, 4, 0, 0, 0, 6, 6, 0, 3, 6, 6, 0, 0, 6, 0, 6, 0, 0, 6, 6, 4, 6, 0, 0, 6, 0, 6, 0, 4, 0, 14, 9, 6, 6, 1, 6, 4, 6, 6, 4, 6, 14, 6, 6, 1, 0, 0, 0, 0, 0, 6, 12, 0, 6, 0, 0, 0, 1, 14, 0, 13, 6, 9, 6, 0, 3, 0, 6, 0, 0, 0, 6, 0, 4, 13, 6, 0, 0, 6, 4]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.4796, Accuracy: 0.1250, Precision: 0.3012, Recall: 0.1010, F1: 0.1219
Epoch 4/70
Train Loss: 0.5679, Accuracy: 0.8323, Precision: 0.8369, Recall: 0.8313, F1: 0.8338
Validation Loss: 0.9416, Accuracy: 0.7010, Precision: 0.7151, Recall: 0.6923, F1: 0.6978
Testing Loss: 0.8952, Accuracy: 0.7248, Precision: 0.7413, Recall: 0.7215, F1: 0.7253
LM Predictions:  [13, 6, 6, 14, 6, 6, 6, 6, 6, 3, 6, 5, 0, 6, 0, 6, 6, 0, 6, 12, 6, 0, 13, 4, 4, 7, 3, 0, 6, 6, 6, 7, 3, 6, 6, 0, 8, 4, 7, 6, 0, 11, 4, 6, 4, 6, 6, 7, 2, 3, 6, 0, 10, 0, 0, 9, 6, 6, 2, 6, 12, 6, 3, 2, 6, 14, 6, 6, 0, 6, 0, 0, 1, 6, 6, 0, 14, 6, 0, 6, 0, 6, 10, 14, 6, 6, 9, 6, 0, 6, 0, 6, 0, 0, 0, 6, 4, 4, 13, 6, 4, 6, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 2.4591, Accuracy: 0.2981, Precision: 0.6689, Recall: 0.2886, F1: 0.3390
Epoch 5/70
Train Loss: 0.2627, Accuracy: 0.9342, Precision: 0.9368, Recall: 0.9344, F1: 0.9356
Validation Loss: 1.0324, Accuracy: 0.6872, Precision: 0.7119, Recall: 0.6806, F1: 0.6852
Testing Loss: 0.9400, Accuracy: 0.7187, Precision: 0.7455, Recall: 0.7176, F1: 0.7205
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 14, 14, 6, 5, 0, 6, 11, 6, 0, 0, 1, 12, 13, 6, 13, 4, 6, 14, 12, 5, 3, 6, 6, 6, 3, 2, 14, 9, 7, 4, 7, 9, 0, 6, 4, 6, 0, 1, 6, 0, 2, 10, 13, 1, 10, 13, 0, 9, 9, 6, 2, 13, 5, 6, 1, 5, 6, 12, 6, 0, 1, 0, 14, 14, 1, 6, 9, 8, 14, 6, 5, 6, 6, 1, 10, 14, 0, 6, 9, 14, 6, 6, 1, 14, 1, 14, 1, 6, 1, 6, 13, 12, 1, 6, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.6028, Accuracy: 0.5192, Precision: 0.7948, Recall: 0.4981, F1: 0.5431
Epoch 6/70
Train Loss: 0.1110, Accuracy: 0.9784, Precision: 0.9793, Recall: 0.9786, F1: 0.9790
Validation Loss: 1.1031, Accuracy: 0.7102, Precision: 0.7336, Recall: 0.7001, F1: 0.7052
Testing Loss: 1.0564, Accuracy: 0.7087, Precision: 0.7375, Recall: 0.7046, F1: 0.7085
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 11, 11, 5, 3, 0, 11, 12, 6, 6, 13, 4, 6, 14, 12, 5, 3, 3, 0, 10, 3, 2, 14, 9, 7, 4, 7, 9, 7, 11, 4, 3, 4, 6, 7, 7, 6, 10, 13, 1, 10, 8, 0, 9, 9, 14, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 0, 10, 14, 3, 6, 7, 9, 8, 14, 6, 5, 12, 5, 4, 10, 14, 0, 3, 6, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 6, 4, 0, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.8995, Accuracy: 0.7596, Precision: 0.8374, Recall: 0.7434, F1: 0.7725
Epoch 7/70
Train Loss: 0.0959, Accuracy: 0.9771, Precision: 0.9779, Recall: 0.9775, F1: 0.9777
Validation Loss: 1.1562, Accuracy: 0.6964, Precision: 0.7149, Recall: 0.6942, F1: 0.7006
Testing Loss: 1.0235, Accuracy: 0.7187, Precision: 0.7290, Recall: 0.7143, F1: 0.7188
LM Predictions:  [13, 6, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 6, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 0, 3, 6, 6, 10, 3, 6, 14, 9, 7, 4, 7, 9, 6, 11, 6, 6, 0, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 14, 2, 6, 12, 13, 13, 5, 5, 0, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 6, 13, 0, 1, 0, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.6971, Accuracy: 0.7596, Precision: 0.8756, Recall: 0.7160, F1: 0.7729
Epoch 8/70
Train Loss: 0.0906, Accuracy: 0.9777, Precision: 0.9785, Recall: 0.9778, F1: 0.9782
Validation Loss: 1.2015, Accuracy: 0.6949, Precision: 0.7075, Recall: 0.6904, F1: 0.6934
Testing Loss: 1.0832, Accuracy: 0.7271, Precision: 0.7462, Recall: 0.7259, F1: 0.7291
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 0, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 4, 3, 6, 7, 9, 8, 14, 6, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 6, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.6805, Accuracy: 0.8269, Precision: 0.8995, Recall: 0.7904, F1: 0.8375
Epoch 9/70
Train Loss: 0.0816, Accuracy: 0.9790, Precision: 0.9801, Recall: 0.9797, F1: 0.9799
Validation Loss: 1.2296, Accuracy: 0.6910, Precision: 0.6977, Recall: 0.6952, F1: 0.6921
Testing Loss: 1.0502, Accuracy: 0.7394, Precision: 0.7476, Recall: 0.7452, F1: 0.7423
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 5, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 6, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 6, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.4635, Accuracy: 0.8462, Precision: 0.9041, Recall: 0.8021, F1: 0.8464
Epoch 10/70
Train Loss: 0.0573, Accuracy: 0.9857, Precision: 0.9861, Recall: 0.9860, F1: 0.9860
Validation Loss: 1.3208, Accuracy: 0.6818, Precision: 0.7023, Recall: 0.6826, F1: 0.6837
Testing Loss: 1.1601, Accuracy: 0.7133, Precision: 0.7241, Recall: 0.7125, F1: 0.7127
LM Predictions:  [13, 1, 10, 14, 0, 13, 1, 0, 13, 3, 6, 5, 0, 5, 11, 5, 5, 0, 11, 9, 6, 9, 13, 5, 6, 13, 12, 5, 3, 3, 0, 10, 13, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 5, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 13, 5, 3, 1, 7, 9, 8, 2, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 3, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 6, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5895, Accuracy: 0.7981, Precision: 0.8396, Recall: 0.7507, F1: 0.7817
Epoch 11/70
Train Loss: 0.0906, Accuracy: 0.9727, Precision: 0.9735, Recall: 0.9731, F1: 0.9733
Validation Loss: 1.2900, Accuracy: 0.6972, Precision: 0.7260, Recall: 0.6931, F1: 0.6990
Testing Loss: 1.2222, Accuracy: 0.7010, Precision: 0.7199, Recall: 0.6975, F1: 0.7012
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 13, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 12, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 0, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3772, Accuracy: 0.8846, Precision: 0.8973, Recall: 0.8139, F1: 0.8463
Epoch 12/70
Train Loss: 0.0603, Accuracy: 0.9825, Precision: 0.9828, Recall: 0.9825, F1: 0.9827
Validation Loss: 1.2722, Accuracy: 0.6972, Precision: 0.7134, Recall: 0.6864, F1: 0.6939
Testing Loss: 1.0858, Accuracy: 0.7325, Precision: 0.7505, Recall: 0.7234, F1: 0.7292
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 6, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 6, 7, 5, 6, 5, 4, 10, 7, 6, 3, 9, 13, 6, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3354, Accuracy: 0.8654, Precision: 0.9206, Recall: 0.8068, F1: 0.8554
Epoch 13/70
Train Loss: 0.0541, Accuracy: 0.9845, Precision: 0.9853, Recall: 0.9852, F1: 0.9852
Validation Loss: 1.2890, Accuracy: 0.6979, Precision: 0.7108, Recall: 0.6962, F1: 0.6971
Testing Loss: 1.2057, Accuracy: 0.7279, Precision: 0.7402, Recall: 0.7305, F1: 0.7307
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2321, Accuracy: 0.9038, Precision: 0.9177, Recall: 0.8529, F1: 0.8812
Epoch 14/70
Train Loss: 0.0489, Accuracy: 0.9865, Precision: 0.9866, Recall: 0.9864, F1: 0.9865
Validation Loss: 1.3449, Accuracy: 0.6795, Precision: 0.7022, Recall: 0.6729, F1: 0.6752
Testing Loss: 1.3025, Accuracy: 0.7179, Precision: 0.7382, Recall: 0.7100, F1: 0.7138
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 3, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 12, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1816, Accuracy: 0.9327, Precision: 0.9019, Recall: 0.8590, F1: 0.8729
Epoch 15/70
Train Loss: 0.0784, Accuracy: 0.9757, Precision: 0.9762, Recall: 0.9762, F1: 0.9762
Validation Loss: 1.3672, Accuracy: 0.6910, Precision: 0.6927, Recall: 0.6917, F1: 0.6865
Testing Loss: 1.2665, Accuracy: 0.7187, Precision: 0.7304, Recall: 0.7178, F1: 0.7143
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 10, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 6, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 8, 8, 8, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3093, Accuracy: 0.8750, Precision: 0.8757, Recall: 0.8198, F1: 0.8364
Epoch 16/70
Train Loss: 0.0311, Accuracy: 0.9910, Precision: 0.9912, Recall: 0.9913, F1: 0.9912
Validation Loss: 1.4259, Accuracy: 0.6933, Precision: 0.7032, Recall: 0.6926, F1: 0.6918
Testing Loss: 1.3315, Accuracy: 0.7210, Precision: 0.7296, Recall: 0.7263, F1: 0.7218
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 6, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 14, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5157, Accuracy: 0.8462, Precision: 0.9043, Recall: 0.8037, F1: 0.8447
Epoch 17/70
Train Loss: 0.0590, Accuracy: 0.9819, Precision: 0.9826, Recall: 0.9824, F1: 0.9825
Validation Loss: 1.3330, Accuracy: 0.7133, Precision: 0.7276, Recall: 0.7089, F1: 0.7128
Testing Loss: 1.1663, Accuracy: 0.7479, Precision: 0.7615, Recall: 0.7501, F1: 0.7514
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3061, Accuracy: 0.8846, Precision: 0.9176, Recall: 0.8354, F1: 0.8708
Epoch 18/70
Train Loss: 0.0280, Accuracy: 0.9912, Precision: 0.9918, Recall: 0.9916, F1: 0.9917
Validation Loss: 1.4365, Accuracy: 0.6872, Precision: 0.7152, Recall: 0.6791, F1: 0.6831
Testing Loss: 1.3051, Accuracy: 0.7033, Precision: 0.7436, Recall: 0.6958, F1: 0.7017
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 10, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 6, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3491, Accuracy: 0.8558, Precision: 0.9109, Recall: 0.7999, F1: 0.8455
Epoch 19/70
Train Loss: 0.0748, Accuracy: 0.9755, Precision: 0.9756, Recall: 0.9759, F1: 0.9757
Validation Loss: 1.4233, Accuracy: 0.6833, Precision: 0.7061, Recall: 0.6776, F1: 0.6829
Testing Loss: 1.2934, Accuracy: 0.7125, Precision: 0.7287, Recall: 0.7094, F1: 0.7131
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 13, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2656, Accuracy: 0.8750, Precision: 0.9156, Recall: 0.8221, F1: 0.8610
Epoch 20/70
Train Loss: 0.0348, Accuracy: 0.9890, Precision: 0.9895, Recall: 0.9895, F1: 0.9895
Validation Loss: 1.3339, Accuracy: 0.7087, Precision: 0.7302, Recall: 0.7014, F1: 0.7100
Testing Loss: 1.1604, Accuracy: 0.7425, Precision: 0.7623, Recall: 0.7363, F1: 0.7434
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 14, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2904, Accuracy: 0.8846, Precision: 0.9038, Recall: 0.8307, F1: 0.8603
Epoch 21/70
Train Loss: 0.0260, Accuracy: 0.9917, Precision: 0.9923, Recall: 0.9920, F1: 0.9921
Validation Loss: 1.5701, Accuracy: 0.6795, Precision: 0.7036, Recall: 0.6768, F1: 0.6770
Testing Loss: 1.3485, Accuracy: 0.7187, Precision: 0.7509, Recall: 0.7196, F1: 0.7229
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 14, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 14, 9, 14, 2, 13, 12, 13, 13, 5, 6, 12, 6, 11, 10, 10, 14, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 1, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3527, Accuracy: 0.8750, Precision: 0.8744, Recall: 0.8230, F1: 0.8381
Epoch 22/70
Train Loss: 0.0668, Accuracy: 0.9784, Precision: 0.9793, Recall: 0.9789, F1: 0.9791
Validation Loss: 1.4368, Accuracy: 0.6879, Precision: 0.7170, Recall: 0.6837, F1: 0.6927
Testing Loss: 1.2427, Accuracy: 0.7271, Precision: 0.7507, Recall: 0.7204, F1: 0.7300
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 6, 1, 10, 6, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3281, Accuracy: 0.8365, Precision: 0.9176, Recall: 0.7761, F1: 0.8293
Epoch 23/70
Train Loss: 0.0229, Accuracy: 0.9925, Precision: 0.9931, Recall: 0.9930, F1: 0.9930
Validation Loss: 1.4245, Accuracy: 0.7110, Precision: 0.7298, Recall: 0.7049, F1: 0.7123
Testing Loss: 1.2536, Accuracy: 0.7394, Precision: 0.7544, Recall: 0.7331, F1: 0.7390
LM Predictions:  [13, 1, 13, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2830, Accuracy: 0.8942, Precision: 0.9071, Recall: 0.8564, F1: 0.8783
Epoch 24/70
Train Loss: 0.0417, Accuracy: 0.9872, Precision: 0.9878, Recall: 0.9878, F1: 0.9878
Validation Loss: 1.4538, Accuracy: 0.6818, Precision: 0.6982, Recall: 0.6855, F1: 0.6856
Testing Loss: 1.3690, Accuracy: 0.7095, Precision: 0.7170, Recall: 0.7065, F1: 0.7056
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 12, 13, 5, 6, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3047, Accuracy: 0.8750, Precision: 0.9071, Recall: 0.8376, F1: 0.8648
Epoch 25/70
Train Loss: 0.0565, Accuracy: 0.9820, Precision: 0.9822, Recall: 0.9820, F1: 0.9821
Validation Loss: 1.4197, Accuracy: 0.6910, Precision: 0.7004, Recall: 0.6909, F1: 0.6924
Testing Loss: 1.2188, Accuracy: 0.7417, Precision: 0.7448, Recall: 0.7399, F1: 0.7401
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1884, Accuracy: 0.9038, Precision: 0.9200, Recall: 0.8457, F1: 0.8771
Epoch 26/70
Train Loss: 0.0284, Accuracy: 0.9892, Precision: 0.9892, Recall: 0.9893, F1: 0.9893
Validation Loss: 1.4447, Accuracy: 0.6972, Precision: 0.7023, Recall: 0.6933, F1: 0.6949
Testing Loss: 1.2163, Accuracy: 0.7417, Precision: 0.7520, Recall: 0.7355, F1: 0.7351
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1978, Accuracy: 0.9135, Precision: 0.9167, Recall: 0.8634, F1: 0.8860
Epoch 27/70
Train Loss: 0.0480, Accuracy: 0.9848, Precision: 0.9849, Recall: 0.9844, F1: 0.9847
Validation Loss: 1.4440, Accuracy: 0.7056, Precision: 0.7126, Recall: 0.7019, F1: 0.7027
Testing Loss: 1.2639, Accuracy: 0.7425, Precision: 0.7436, Recall: 0.7431, F1: 0.7397
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 0, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1717, Accuracy: 0.9327, Precision: 0.9102, Recall: 0.8841, F1: 0.8939
Epoch 28/70
Train Loss: 0.0297, Accuracy: 0.9898, Precision: 0.9902, Recall: 0.9900, F1: 0.9901
Validation Loss: 1.4428, Accuracy: 0.7156, Precision: 0.7404, Recall: 0.7075, F1: 0.7158
Testing Loss: 1.2756, Accuracy: 0.7341, Precision: 0.7533, Recall: 0.7300, F1: 0.7373
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 14, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 0, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 0, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3122, Accuracy: 0.8846, Precision: 0.8952, Recall: 0.8383, F1: 0.8580
Epoch 29/70
Train Loss: 0.0285, Accuracy: 0.9907, Precision: 0.9910, Recall: 0.9909, F1: 0.9910
Validation Loss: 1.3762, Accuracy: 0.7264, Precision: 0.7396, Recall: 0.7168, F1: 0.7234
Testing Loss: 1.1144, Accuracy: 0.7694, Precision: 0.7754, Recall: 0.7657, F1: 0.7687
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 14, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1601, Accuracy: 0.9231, Precision: 0.9073, Recall: 0.8731, F1: 0.8874
Epoch 30/70
Train Loss: 0.0351, Accuracy: 0.9889, Precision: 0.9890, Recall: 0.9889, F1: 0.9890
Validation Loss: 1.6792, Accuracy: 0.6610, Precision: 0.6889, Recall: 0.6580, F1: 0.6560
Testing Loss: 1.4202, Accuracy: 0.7033, Precision: 0.7241, Recall: 0.7026, F1: 0.6985
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 6, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 10, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 3, 7, 5, 6, 5, 1, 10, 7, 0, 3, 9, 13, 2, 3, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2737, Accuracy: 0.8558, Precision: 0.8957, Recall: 0.7826, F1: 0.8202
Epoch 31/70
Train Loss: 0.0570, Accuracy: 0.9802, Precision: 0.9807, Recall: 0.9809, F1: 0.9808
Validation Loss: 1.4769, Accuracy: 0.6910, Precision: 0.7068, Recall: 0.6908, F1: 0.6912
Testing Loss: 1.3443, Accuracy: 0.7102, Precision: 0.7206, Recall: 0.7111, F1: 0.7104
LM Predictions:  [13, 1, 10, 3, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 8, 9, 13, 1, 8, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2567, Accuracy: 0.8750, Precision: 0.8844, Recall: 0.8157, F1: 0.8383
Epoch 32/70
Train Loss: 0.0231, Accuracy: 0.9919, Precision: 0.9924, Recall: 0.9923, F1: 0.9923
Validation Loss: 1.4159, Accuracy: 0.7102, Precision: 0.7340, Recall: 0.7028, F1: 0.7141
Testing Loss: 1.2336, Accuracy: 0.7417, Precision: 0.7558, Recall: 0.7394, F1: 0.7444
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 6, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2676, Accuracy: 0.8846, Precision: 0.9183, Recall: 0.8354, F1: 0.8723
Epoch 33/70
Train Loss: 0.0276, Accuracy: 0.9903, Precision: 0.9907, Recall: 0.9904, F1: 0.9905
Validation Loss: 1.4648, Accuracy: 0.7118, Precision: 0.7245, Recall: 0.7193, F1: 0.7151
Testing Loss: 1.3409, Accuracy: 0.7179, Precision: 0.7231, Recall: 0.7228, F1: 0.7154
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1203, Accuracy: 0.9615, Precision: 0.9211, Recall: 0.9014, F1: 0.9103
Epoch 34/70
Train Loss: 0.0355, Accuracy: 0.9876, Precision: 0.9877, Recall: 0.9877, F1: 0.9877
Validation Loss: 1.5752, Accuracy: 0.6895, Precision: 0.6912, Recall: 0.6898, F1: 0.6828
Testing Loss: 1.4756, Accuracy: 0.7064, Precision: 0.7111, Recall: 0.7103, F1: 0.6996
LM Predictions:  [13, 1, 10, 14, 6, 14, 1, 0, 3, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 6, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 3, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2533, Accuracy: 0.8750, Precision: 0.8949, Recall: 0.8377, F1: 0.8575
Epoch 35/70
Train Loss: 0.0461, Accuracy: 0.9843, Precision: 0.9845, Recall: 0.9847, F1: 0.9846
Validation Loss: 1.4571, Accuracy: 0.6902, Precision: 0.7274, Recall: 0.6724, F1: 0.6856
Testing Loss: 1.3402, Accuracy: 0.7110, Precision: 0.7461, Recall: 0.7031, F1: 0.7129
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 0, 5, 0, 11, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 6, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 14, 10, 13, 1, 10, 8, 0, 11, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 0, 6, 6, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5039, Accuracy: 0.7981, Precision: 0.8644, Recall: 0.7556, F1: 0.7963
Epoch 36/70
Train Loss: 0.0311, Accuracy: 0.9889, Precision: 0.9894, Recall: 0.9890, F1: 0.9892
Validation Loss: 1.4897, Accuracy: 0.6995, Precision: 0.7267, Recall: 0.6932, F1: 0.7015
Testing Loss: 1.2924, Accuracy: 0.7271, Precision: 0.7583, Recall: 0.7232, F1: 0.7320
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 0, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2130, Accuracy: 0.8942, Precision: 0.9116, Recall: 0.8325, F1: 0.8658
Epoch 37/70
Train Loss: 0.0110, Accuracy: 0.9957, Precision: 0.9960, Recall: 0.9960, F1: 0.9960
Validation Loss: 1.4100, Accuracy: 0.7241, Precision: 0.7276, Recall: 0.7191, F1: 0.7199
Testing Loss: 1.2897, Accuracy: 0.7479, Precision: 0.7544, Recall: 0.7469, F1: 0.7467
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1732, Accuracy: 0.8942, Precision: 0.9176, Recall: 0.8408, F1: 0.8729
Epoch 38/70
Train Loss: 0.0083, Accuracy: 0.9964, Precision: 0.9968, Recall: 0.9967, F1: 0.9967
Validation Loss: 1.4006, Accuracy: 0.7302, Precision: 0.7353, Recall: 0.7246, F1: 0.7253
Testing Loss: 1.2498, Accuracy: 0.7548, Precision: 0.7629, Recall: 0.7548, F1: 0.7538
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1420, Accuracy: 0.9231, Precision: 0.9217, Recall: 0.8592, F1: 0.8848
Epoch 39/70
Train Loss: 0.0084, Accuracy: 0.9962, Precision: 0.9965, Recall: 0.9964, F1: 0.9965
Validation Loss: 1.3625, Accuracy: 0.7387, Precision: 0.7414, Recall: 0.7345, F1: 0.7350
Testing Loss: 1.2321, Accuracy: 0.7640, Precision: 0.7712, Recall: 0.7628, F1: 0.7635
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1684, Accuracy: 0.9135, Precision: 0.9183, Recall: 0.8625, F1: 0.8869
Epoch 40/70
Train Loss: 0.0372, Accuracy: 0.9878, Precision: 0.9877, Recall: 0.9877, F1: 0.9877
Validation Loss: 1.5514, Accuracy: 0.6526, Precision: 0.6869, Recall: 0.6462, F1: 0.6547
Testing Loss: 1.4421, Accuracy: 0.6687, Precision: 0.7033, Recall: 0.6605, F1: 0.6729
LM Predictions:  [13, 1, 10, 14, 6, 13, 4, 0, 13, 0, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 6, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 6, 9, 7, 4, 7, 6, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 13, 0, 9, 9, 12, 2, 13, 12, 13, 6, 5, 5, 12, 7, 11, 10, 10, 4, 3, 1, 7, 9, 9, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 11, 1, 3, 1, 10, 1, 11, 4, 9, 13, 6, 4, 6, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5910, Accuracy: 0.7981, Precision: 0.8032, Recall: 0.7097, F1: 0.7448
Epoch 41/70
Train Loss: 0.0922, Accuracy: 0.9704, Precision: 0.9701, Recall: 0.9698, F1: 0.9699
Validation Loss: 1.4343, Accuracy: 0.7064, Precision: 0.7207, Recall: 0.7049, F1: 0.7080
Testing Loss: 1.2990, Accuracy: 0.7371, Precision: 0.7417, Recall: 0.7400, F1: 0.7369
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 6, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2430, Accuracy: 0.8558, Precision: 0.9189, Recall: 0.8156, F1: 0.8595
Epoch 42/70
Train Loss: 0.0262, Accuracy: 0.9909, Precision: 0.9911, Recall: 0.9910, F1: 0.9910
Validation Loss: 1.3857, Accuracy: 0.7256, Precision: 0.7422, Recall: 0.7188, F1: 0.7257
Testing Loss: 1.2272, Accuracy: 0.7633, Precision: 0.7664, Recall: 0.7581, F1: 0.7596
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1337, Accuracy: 0.9423, Precision: 0.9194, Recall: 0.8769, F1: 0.8930
Epoch 43/70
Train Loss: 0.0085, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.3519, Accuracy: 0.7271, Precision: 0.7316, Recall: 0.7265, F1: 0.7267
Testing Loss: 1.2163, Accuracy: 0.7740, Precision: 0.7711, Recall: 0.7729, F1: 0.7705
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1267, Accuracy: 0.9327, Precision: 0.9212, Recall: 0.8658, F1: 0.8880
Epoch 44/70
Train Loss: 0.0070, Accuracy: 0.9965, Precision: 0.9968, Recall: 0.9969, F1: 0.9968
Validation Loss: 1.3911, Accuracy: 0.7294, Precision: 0.7337, Recall: 0.7277, F1: 0.7280
Testing Loss: 1.2670, Accuracy: 0.7663, Precision: 0.7651, Recall: 0.7647, F1: 0.7615
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1425, Accuracy: 0.9231, Precision: 0.9204, Recall: 0.8695, F1: 0.8918
Epoch 45/70
Train Loss: 0.0072, Accuracy: 0.9965, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.4010, Accuracy: 0.7341, Precision: 0.7462, Recall: 0.7270, F1: 0.7326
Testing Loss: 1.2547, Accuracy: 0.7725, Precision: 0.7741, Recall: 0.7677, F1: 0.7684
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2427, Accuracy: 0.8654, Precision: 0.9155, Recall: 0.8266, F1: 0.8647
Epoch 46/70
Train Loss: 0.0074, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9967, F1: 0.9967
Validation Loss: 1.3971, Accuracy: 0.7387, Precision: 0.7438, Recall: 0.7376, F1: 0.7382
Testing Loss: 1.2603, Accuracy: 0.7725, Precision: 0.7711, Recall: 0.7712, F1: 0.7689
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1627, Accuracy: 0.9231, Precision: 0.9177, Recall: 0.8651, F1: 0.8894
Epoch 47/70
Train Loss: 0.0079, Accuracy: 0.9966, Precision: 0.9970, Recall: 0.9969, F1: 0.9969
Validation Loss: 1.4139, Accuracy: 0.7394, Precision: 0.7480, Recall: 0.7387, F1: 0.7404
Testing Loss: 1.2651, Accuracy: 0.7733, Precision: 0.7748, Recall: 0.7722, F1: 0.7706
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1807, Accuracy: 0.9038, Precision: 0.9185, Recall: 0.8519, F1: 0.8799
Epoch 48/70
Train Loss: 0.0075, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 1.4877, Accuracy: 0.7225, Precision: 0.7391, Recall: 0.7194, F1: 0.7240
Testing Loss: 1.3217, Accuracy: 0.7617, Precision: 0.7670, Recall: 0.7624, F1: 0.7612
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1377, Accuracy: 0.9423, Precision: 0.9183, Recall: 0.8879, F1: 0.9022
Epoch 49/70
Train Loss: 0.0942, Accuracy: 0.9704, Precision: 0.9706, Recall: 0.9706, F1: 0.9706
Validation Loss: 1.4546, Accuracy: 0.6895, Precision: 0.7055, Recall: 0.6855, F1: 0.6859
Testing Loss: 1.2819, Accuracy: 0.7095, Precision: 0.7189, Recall: 0.7068, F1: 0.7065
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 4, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 6, 6, 8, 0, 9, 9, 12, 2, 13, 12, 13, 6, 5, 6, 0, 7, 11, 10, 10, 0, 3, 1, 7, 0, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.4421, Accuracy: 0.8462, Precision: 0.8878, Recall: 0.8151, F1: 0.8454
Epoch 50/70
Train Loss: 0.0734, Accuracy: 0.9741, Precision: 0.9738, Recall: 0.9743, F1: 0.9740
Validation Loss: 1.3575, Accuracy: 0.7179, Precision: 0.7271, Recall: 0.7201, F1: 0.7187
Testing Loss: 1.1626, Accuracy: 0.7463, Precision: 0.7430, Recall: 0.7455, F1: 0.7422
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 6, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 6, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2657, Accuracy: 0.8654, Precision: 0.9164, Recall: 0.8208, F1: 0.8607
Epoch 51/70
Train Loss: 0.0234, Accuracy: 0.9899, Precision: 0.9902, Recall: 0.9904, F1: 0.9903
Validation Loss: 1.5224, Accuracy: 0.7102, Precision: 0.7349, Recall: 0.7083, F1: 0.7125
Testing Loss: 1.3416, Accuracy: 0.7294, Precision: 0.7461, Recall: 0.7305, F1: 0.7303
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 0, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2055, Accuracy: 0.8942, Precision: 0.9155, Recall: 0.8484, F1: 0.8772
Epoch 52/70
Train Loss: 0.0115, Accuracy: 0.9954, Precision: 0.9958, Recall: 0.9957, F1: 0.9958
Validation Loss: 1.4288, Accuracy: 0.7202, Precision: 0.7266, Recall: 0.7176, F1: 0.7189
Testing Loss: 1.2434, Accuracy: 0.7633, Precision: 0.7679, Recall: 0.7601, F1: 0.7606
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1818, Accuracy: 0.8654, Precision: 0.9193, Recall: 0.8144, F1: 0.8586
Epoch 53/70
Train Loss: 0.0161, Accuracy: 0.9936, Precision: 0.9940, Recall: 0.9939, F1: 0.9940
Validation Loss: 1.6550, Accuracy: 0.6672, Precision: 0.6797, Recall: 0.6726, F1: 0.6643
Testing Loss: 1.5082, Accuracy: 0.7079, Precision: 0.7095, Recall: 0.7132, F1: 0.7026
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 6, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 5, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 13, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2471, Accuracy: 0.8750, Precision: 0.9096, Recall: 0.8297, F1: 0.8573
Epoch 54/70
Train Loss: 0.0501, Accuracy: 0.9806, Precision: 0.9812, Recall: 0.9811, F1: 0.9811
Validation Loss: 1.4738, Accuracy: 0.7095, Precision: 0.7149, Recall: 0.7086, F1: 0.7047
Testing Loss: 1.3620, Accuracy: 0.7379, Precision: 0.7384, Recall: 0.7403, F1: 0.7334
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1393, Accuracy: 0.9519, Precision: 0.9204, Recall: 0.8938, F1: 0.9053
Epoch 55/70
Train Loss: 0.0259, Accuracy: 0.9899, Precision: 0.9902, Recall: 0.9900, F1: 0.9901
Validation Loss: 1.4646, Accuracy: 0.7010, Precision: 0.7004, Recall: 0.6980, F1: 0.6952
Testing Loss: 1.2917, Accuracy: 0.7302, Precision: 0.7269, Recall: 0.7324, F1: 0.7264
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1753, Accuracy: 0.8654, Precision: 0.9185, Recall: 0.8231, F1: 0.8642
Epoch 56/70
Train Loss: 0.0251, Accuracy: 0.9909, Precision: 0.9914, Recall: 0.9914, F1: 0.9914
Validation Loss: 1.5263, Accuracy: 0.6949, Precision: 0.7149, Recall: 0.6885, F1: 0.6955
Testing Loss: 1.3671, Accuracy: 0.7279, Precision: 0.7455, Recall: 0.7214, F1: 0.7271
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 1, 6, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2173, Accuracy: 0.8365, Precision: 0.9126, Recall: 0.8024, F1: 0.8500
Epoch 57/70
Train Loss: 0.0280, Accuracy: 0.9901, Precision: 0.9908, Recall: 0.9910, F1: 0.9909
Validation Loss: 1.6052, Accuracy: 0.6856, Precision: 0.6887, Recall: 0.6855, F1: 0.6790
Testing Loss: 1.4175, Accuracy: 0.7233, Precision: 0.7330, Recall: 0.7220, F1: 0.7185
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 1, 2, 12, 7, 1, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 3, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2588, Accuracy: 0.8750, Precision: 0.8876, Recall: 0.8270, F1: 0.8480
Epoch 58/70
Train Loss: 0.0340, Accuracy: 0.9870, Precision: 0.9877, Recall: 0.9879, F1: 0.9878
Validation Loss: 1.4896, Accuracy: 0.7141, Precision: 0.7360, Recall: 0.7049, F1: 0.7127
Testing Loss: 1.2868, Accuracy: 0.7425, Precision: 0.7683, Recall: 0.7350, F1: 0.7436
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 6, 12, 2, 6, 12, 6, 13, 1, 6, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 13, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3067, Accuracy: 0.7981, Precision: 0.9064, Recall: 0.7653, F1: 0.8245
Epoch 59/70
Train Loss: 0.0181, Accuracy: 0.9922, Precision: 0.9927, Recall: 0.9928, F1: 0.9927
Validation Loss: 1.5306, Accuracy: 0.7064, Precision: 0.7146, Recall: 0.7056, F1: 0.7061
Testing Loss: 1.2957, Accuracy: 0.7479, Precision: 0.7574, Recall: 0.7459, F1: 0.7481
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1532, Accuracy: 0.9038, Precision: 0.9211, Recall: 0.8518, F1: 0.8808
Epoch 60/70
Train Loss: 0.0351, Accuracy: 0.9875, Precision: 0.9876, Recall: 0.9879, F1: 0.9877
Validation Loss: 1.7682, Accuracy: 0.6603, Precision: 0.7104, Recall: 0.6474, F1: 0.6570
Testing Loss: 1.5672, Accuracy: 0.7018, Precision: 0.7450, Recall: 0.6905, F1: 0.6981
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 6, 11, 5, 5, 6, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 6, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 6, 10, 13, 1, 10, 13, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 13, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2985, Accuracy: 0.8173, Precision: 0.9038, Recall: 0.7399, F1: 0.8034
Epoch 61/70
Train Loss: 0.0254, Accuracy: 0.9907, Precision: 0.9910, Recall: 0.9907, F1: 0.9908
Validation Loss: 1.4986, Accuracy: 0.7095, Precision: 0.7321, Recall: 0.7062, F1: 0.7147
Testing Loss: 1.3089, Accuracy: 0.7364, Precision: 0.7428, Recall: 0.7312, F1: 0.7333
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 6, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1971, Accuracy: 0.8846, Precision: 0.9199, Recall: 0.8353, F1: 0.8734
Epoch 62/70
Train Loss: 0.0113, Accuracy: 0.9950, Precision: 0.9952, Recall: 0.9953, F1: 0.9953
Validation Loss: 1.5540, Accuracy: 0.7210, Precision: 0.7392, Recall: 0.7191, F1: 0.7225
Testing Loss: 1.3034, Accuracy: 0.7425, Precision: 0.7426, Recall: 0.7422, F1: 0.7399
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1166, Accuracy: 0.9327, Precision: 0.9194, Recall: 0.8761, F1: 0.8945
Epoch 63/70
Train Loss: 0.0351, Accuracy: 0.9865, Precision: 0.9869, Recall: 0.9868, F1: 0.9868
Validation Loss: 1.5292, Accuracy: 0.7087, Precision: 0.7221, Recall: 0.7137, F1: 0.7091
Testing Loss: 1.4925, Accuracy: 0.7194, Precision: 0.7326, Recall: 0.7208, F1: 0.7172
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 3, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 6, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1986, Accuracy: 0.8846, Precision: 0.9115, Recall: 0.8381, F1: 0.8693
Epoch 64/70
Train Loss: 0.0235, Accuracy: 0.9911, Precision: 0.9917, Recall: 0.9914, F1: 0.9916
Validation Loss: 1.6717, Accuracy: 0.6979, Precision: 0.7217, Recall: 0.7025, F1: 0.6930
Testing Loss: 1.5274, Accuracy: 0.7233, Precision: 0.7286, Recall: 0.7272, F1: 0.7170
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 12, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1076, Accuracy: 0.9519, Precision: 0.9111, Recall: 0.8709, F1: 0.8836
Epoch 65/70
Train Loss: 0.0220, Accuracy: 0.9913, Precision: 0.9916, Recall: 0.9917, F1: 0.9916
Validation Loss: 1.5314, Accuracy: 0.7064, Precision: 0.7167, Recall: 0.7049, F1: 0.7075
Testing Loss: 1.4431, Accuracy: 0.7371, Precision: 0.7543, Recall: 0.7352, F1: 0.7366
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1569, Accuracy: 0.9135, Precision: 0.9176, Recall: 0.8619, F1: 0.8869
Epoch 66/70
Train Loss: 0.0142, Accuracy: 0.9944, Precision: 0.9949, Recall: 0.9949, F1: 0.9949
Validation Loss: 1.8917, Accuracy: 0.6679, Precision: 0.7259, Recall: 0.6628, F1: 0.6724
Testing Loss: 1.6959, Accuracy: 0.6910, Precision: 0.7377, Recall: 0.6890, F1: 0.7005
LM Predictions:  [13, 1, 6, 0, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 0, 9, 7, 4, 7, 9, 0, 0, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 0, 10, 5, 3, 1, 7, 9, 8, 14, 0, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2946, Accuracy: 0.8269, Precision: 0.8981, Recall: 0.7648, F1: 0.8057
Epoch 67/70
Train Loss: 0.0451, Accuracy: 0.9846, Precision: 0.9849, Recall: 0.9848, F1: 0.9849
Validation Loss: 1.4851, Accuracy: 0.7110, Precision: 0.7199, Recall: 0.7080, F1: 0.7068
Testing Loss: 1.3536, Accuracy: 0.7325, Precision: 0.7406, Recall: 0.7294, F1: 0.7307
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1584, Accuracy: 0.9038, Precision: 0.9199, Recall: 0.8558, F1: 0.8806
Epoch 68/70
Train Loss: 0.0245, Accuracy: 0.9902, Precision: 0.9904, Recall: 0.9904, F1: 0.9904
Validation Loss: 1.5741, Accuracy: 0.7048, Precision: 0.7169, Recall: 0.7056, F1: 0.7057
Testing Loss: 1.4030, Accuracy: 0.7448, Precision: 0.7538, Recall: 0.7471, F1: 0.7478
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1564, Accuracy: 0.9423, Precision: 0.9273, Recall: 0.8766, F1: 0.8987
Epoch 69/70
Train Loss: 0.0089, Accuracy: 0.9951, Precision: 0.9953, Recall: 0.9953, F1: 0.9953
Validation Loss: 1.4813, Accuracy: 0.7256, Precision: 0.7282, Recall: 0.7253, F1: 0.7255
Testing Loss: 1.3684, Accuracy: 0.7533, Precision: 0.7545, Recall: 0.7531, F1: 0.7506
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1474, Accuracy: 0.9135, Precision: 0.9183, Recall: 0.8517, F1: 0.8795
Epoch 70/70
Train Loss: 0.0059, Accuracy: 0.9963, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 1.4736, Accuracy: 0.7264, Precision: 0.7289, Recall: 0.7247, F1: 0.7259
Testing Loss: 1.3601, Accuracy: 0.7540, Precision: 0.7578, Recall: 0.7519, F1: 0.7518
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1606, Accuracy: 0.8846, Precision: 0.9193, Recall: 0.8366, F1: 0.8738
For middle layers:  [4, 5, 6, 7]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 1.3625, Accuracy: 0.5741, Precision: 0.5841, Recall: 0.5614, F1: 0.5666
Validation Loss: 0.8803, Accuracy: 0.7179, Precision: 0.7350, Recall: 0.7103, F1: 0.7102
Testing Loss: 0.8277, Accuracy: 0.7433, Precision: 0.7681, Recall: 0.7351, F1: 0.7387
LM Predictions:  [6, 6, 13, 3, 6, 0, 6, 6, 6, 0, 0, 6, 6, 6, 0, 14, 6, 6, 0, 9, 13, 6, 13, 6, 6, 0, 13, 6, 0, 13, 6, 0, 4, 7, 6, 0, 0, 0, 0, 6, 0, 0, 0, 6, 0, 13, 6, 6, 0, 0, 13, 0, 3, 13, 14, 11, 9, 6, 9, 13, 13, 6, 6, 0, 6, 6, 13, 6, 0, 0, 11, 0, 6, 0, 11, 12, 0, 13, 13, 13, 13, 14, 14, 14, 6, 6, 6, 6, 6, 6, 0, 14, 11, 6, 0, 6, 6, 6, 13, 6, 6, 6, 13, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.8088, Accuracy: 0.0769, Precision: 0.0466, Recall: 0.0544, F1: 0.0423
Epoch 2/70
Train Loss: 0.6082, Accuracy: 0.8197, Precision: 0.8218, Recall: 0.8165, F1: 0.8189
Validation Loss: 0.8603, Accuracy: 0.7256, Precision: 0.8070, Recall: 0.7221, F1: 0.7321
Testing Loss: 0.7957, Accuracy: 0.7317, Precision: 0.7977, Recall: 0.7264, F1: 0.7346
LM Predictions:  [6, 1, 0, 14, 6, 0, 6, 6, 6, 0, 0, 5, 6, 6, 0, 5, 0, 0, 0, 6, 13, 0, 13, 5, 0, 14, 13, 0, 0, 6, 0, 0, 0, 0, 14, 9, 0, 4, 0, 6, 0, 1, 0, 6, 0, 6, 6, 6, 0, 0, 6, 0, 10, 0, 0, 11, 0, 6, 11, 0, 0, 13, 0, 0, 6, 14, 0, 6, 0, 0, 11, 0, 0, 0, 9, 0, 0, 9, 0, 0, 0, 14, 14, 14, 6, 0, 9, 6, 0, 6, 0, 9, 11, 0, 14, 0, 9, 6, 0, 12, 9, 0, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.3748, Accuracy: 0.1731, Precision: 0.3199, Recall: 0.1607, F1: 0.1557
Epoch 3/70
Train Loss: 0.2725, Accuracy: 0.9272, Precision: 0.9298, Recall: 0.9256, F1: 0.9276
Validation Loss: 0.6981, Accuracy: 0.7786, Precision: 0.7969, Recall: 0.7739, F1: 0.7791
Testing Loss: 0.6717, Accuracy: 0.7986, Precision: 0.8131, Recall: 0.7938, F1: 0.7974
LM Predictions:  [6, 1, 6, 14, 6, 6, 7, 6, 0, 6, 6, 5, 6, 6, 11, 14, 6, 6, 11, 9, 13, 6, 13, 4, 6, 14, 12, 6, 0, 13, 6, 14, 6, 6, 14, 9, 6, 4, 7, 9, 6, 11, 6, 6, 4, 6, 6, 13, 2, 6, 6, 1, 6, 13, 0, 9, 9, 6, 2, 13, 8, 13, 6, 6, 6, 12, 6, 6, 0, 6, 4, 14, 6, 0, 9, 0, 14, 13, 6, 7, 6, 14, 14, 14, 6, 0, 9, 0, 6, 12, 0, 9, 1, 6, 1, 6, 4, 6, 13, 12, 4, 6, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 2.1204, Accuracy: 0.3462, Precision: 0.5170, Recall: 0.3472, F1: 0.3739
Epoch 4/70
Train Loss: 0.1282, Accuracy: 0.9691, Precision: 0.9706, Recall: 0.9686, F1: 0.9695
Validation Loss: 0.8358, Accuracy: 0.7579, Precision: 0.7894, Recall: 0.7596, F1: 0.7602
Testing Loss: 0.7702, Accuracy: 0.7748, Precision: 0.7960, Recall: 0.7780, F1: 0.7764
LM Predictions:  [13, 1, 6, 14, 6, 13, 6, 6, 13, 9, 6, 5, 0, 6, 11, 5, 6, 0, 11, 6, 13, 6, 13, 4, 4, 14, 13, 5, 6, 3, 6, 6, 13, 6, 14, 9, 5, 4, 7, 9, 6, 11, 4, 3, 4, 6, 6, 7, 2, 6, 13, 1, 10, 8, 0, 9, 9, 6, 2, 6, 12, 6, 13, 6, 5, 13, 6, 11, 0, 6, 5, 3, 6, 5, 9, 8, 14, 13, 5, 6, 5, 4, 6, 14, 0, 0, 9, 13, 7, 12, 13, 3, 1, 6, 14, 6, 6, 6, 13, 12, 6, 6, 13, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.4174, Accuracy: 0.5385, Precision: 0.7922, Recall: 0.5493, F1: 0.6039
Epoch 5/70
Train Loss: 0.0902, Accuracy: 0.9774, Precision: 0.9789, Recall: 0.9779, F1: 0.9784
Validation Loss: 0.8669, Accuracy: 0.7633, Precision: 0.7810, Recall: 0.7582, F1: 0.7624
Testing Loss: 0.7682, Accuracy: 0.7855, Precision: 0.8060, Recall: 0.7770, F1: 0.7812
LM Predictions:  [13, 1, 6, 14, 6, 6, 12, 0, 13, 3, 0, 5, 0, 6, 12, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 6, 3, 3, 6, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 13, 2, 6, 13, 1, 10, 8, 0, 9, 6, 12, 2, 6, 12, 6, 13, 5, 5, 12, 13, 11, 6, 4, 5, 3, 6, 7, 9, 8, 14, 7, 5, 9, 5, 4, 6, 7, 0, 4, 9, 13, 2, 12, 1, 3, 1, 0, 1, 6, 2, 9, 13, 6, 2, 9, 13, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.8833, Accuracy: 0.6923, Precision: 0.8265, Recall: 0.6832, F1: 0.7176
Epoch 6/70
Train Loss: 0.0672, Accuracy: 0.9826, Precision: 0.9829, Recall: 0.9828, F1: 0.9829
Validation Loss: 0.8798, Accuracy: 0.7663, Precision: 0.7818, Recall: 0.7641, F1: 0.7671
Testing Loss: 0.8013, Accuracy: 0.7925, Precision: 0.8016, Recall: 0.7868, F1: 0.7898
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 2, 7, 7, 2, 10, 6, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 0, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 6, 1, 6, 2, 9, 13, 1, 2, 9, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.8901, Accuracy: 0.8077, Precision: 0.8848, Recall: 0.7844, F1: 0.8159
Epoch 7/70
Train Loss: 0.0731, Accuracy: 0.9783, Precision: 0.9786, Recall: 0.9782, F1: 0.9784
Validation Loss: 0.9056, Accuracy: 0.7733, Precision: 0.7804, Recall: 0.7765, F1: 0.7714
Testing Loss: 0.8188, Accuracy: 0.7832, Precision: 0.7873, Recall: 0.7839, F1: 0.7795
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 9, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 0, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 0, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3801, Accuracy: 0.9038, Precision: 0.9058, Recall: 0.8612, F1: 0.8790
Epoch 8/70
Train Loss: 0.0616, Accuracy: 0.9831, Precision: 0.9831, Recall: 0.9829, F1: 0.9830
Validation Loss: 1.0415, Accuracy: 0.7456, Precision: 0.7560, Recall: 0.7594, F1: 0.7412
Testing Loss: 0.9396, Accuracy: 0.7809, Precision: 0.7831, Recall: 0.7912, F1: 0.7757
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 2, 9, 13, 1, 2, 9, 5, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2686, Accuracy: 0.9038, Precision: 0.8984, Recall: 0.8566, F1: 0.8714
Epoch 9/70
Train Loss: 0.0495, Accuracy: 0.9864, Precision: 0.9870, Recall: 0.9872, F1: 0.9871
Validation Loss: 0.9254, Accuracy: 0.7756, Precision: 0.8005, Recall: 0.7665, F1: 0.7765
Testing Loss: 0.8256, Accuracy: 0.8025, Precision: 0.8197, Recall: 0.7928, F1: 0.7999
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 6, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 6, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 6, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 6, 2, 3, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5609, Accuracy: 0.8558, Precision: 0.9193, Recall: 0.8096, F1: 0.8553
Epoch 10/70
Train Loss: 0.0526, Accuracy: 0.9844, Precision: 0.9849, Recall: 0.9851, F1: 0.9850
Validation Loss: 0.9249, Accuracy: 0.7771, Precision: 0.7887, Recall: 0.7751, F1: 0.7772
Testing Loss: 0.8511, Accuracy: 0.8002, Precision: 0.8123, Recall: 0.7960, F1: 0.7981
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 0, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 13, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 13, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 9, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 13, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3034, Accuracy: 0.8942, Precision: 0.8891, Recall: 0.8227, F1: 0.8455
Epoch 11/70
Train Loss: 0.0555, Accuracy: 0.9818, Precision: 0.9822, Recall: 0.9815, F1: 0.9819
Validation Loss: 0.9336, Accuracy: 0.7886, Precision: 0.7886, Recall: 0.7881, F1: 0.7861
Testing Loss: 0.7697, Accuracy: 0.8071, Precision: 0.8065, Recall: 0.8023, F1: 0.8015
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2622, Accuracy: 0.9231, Precision: 0.9212, Recall: 0.8584, F1: 0.8849
Epoch 12/70
Train Loss: 0.0437, Accuracy: 0.9864, Precision: 0.9859, Recall: 0.9856, F1: 0.9857
Validation Loss: 1.0627, Accuracy: 0.7494, Precision: 0.7507, Recall: 0.7557, F1: 0.7452
Testing Loss: 0.9659, Accuracy: 0.7725, Precision: 0.7676, Recall: 0.7725, F1: 0.7631
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 0, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 8, 13, 13, 5, 5, 8, 7, 11, 10, 10, 5, 14, 1, 7, 9, 8, 8, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3424, Accuracy: 0.8750, Precision: 0.8573, Recall: 0.8206, F1: 0.8208
Epoch 13/70
Train Loss: 0.0635, Accuracy: 0.9798, Precision: 0.9796, Recall: 0.9801, F1: 0.9798
Validation Loss: 1.0145, Accuracy: 0.7586, Precision: 0.7815, Recall: 0.7549, F1: 0.7579
Testing Loss: 0.9164, Accuracy: 0.7871, Precision: 0.8082, Recall: 0.7807, F1: 0.7844
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 6, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 6, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3387, Accuracy: 0.8750, Precision: 0.9200, Recall: 0.8121, F1: 0.8580
Epoch 14/70
Train Loss: 0.0269, Accuracy: 0.9919, Precision: 0.9920, Recall: 0.9922, F1: 0.9921
Validation Loss: 0.9057, Accuracy: 0.7902, Precision: 0.7946, Recall: 0.7907, F1: 0.7887
Testing Loss: 0.8030, Accuracy: 0.8109, Precision: 0.8124, Recall: 0.8100, F1: 0.8076
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 6, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1853, Accuracy: 0.9327, Precision: 0.9217, Recall: 0.8657, F1: 0.8876
Epoch 15/70
Train Loss: 0.0279, Accuracy: 0.9913, Precision: 0.9919, Recall: 0.9921, F1: 0.9920
Validation Loss: 1.0019, Accuracy: 0.7625, Precision: 0.7770, Recall: 0.7592, F1: 0.7618
Testing Loss: 0.8509, Accuracy: 0.7978, Precision: 0.8065, Recall: 0.7942, F1: 0.7957
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 13, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 6, 7, 0, 4, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3572, Accuracy: 0.8750, Precision: 0.9083, Recall: 0.8215, F1: 0.8524
Epoch 16/70
Train Loss: 0.0609, Accuracy: 0.9802, Precision: 0.9806, Recall: 0.9798, F1: 0.9802
Validation Loss: 1.1439, Accuracy: 0.7510, Precision: 0.7767, Recall: 0.7589, F1: 0.7546
Testing Loss: 1.0917, Accuracy: 0.7533, Precision: 0.7778, Recall: 0.7569, F1: 0.7512
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 13, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 8, 1, 3, 13, 10, 1, 6, 4, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2793, Accuracy: 0.8942, Precision: 0.9009, Recall: 0.8425, F1: 0.8608
Epoch 17/70
Train Loss: 0.0426, Accuracy: 0.9861, Precision: 0.9860, Recall: 0.9862, F1: 0.9861
Validation Loss: 0.9773, Accuracy: 0.7733, Precision: 0.7819, Recall: 0.7657, F1: 0.7710
Testing Loss: 0.8988, Accuracy: 0.7986, Precision: 0.8112, Recall: 0.7810, F1: 0.7881
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 14, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3096, Accuracy: 0.8750, Precision: 0.9031, Recall: 0.8393, F1: 0.8645
Epoch 18/70
Train Loss: 0.0258, Accuracy: 0.9922, Precision: 0.9920, Recall: 0.9920, F1: 0.9920
Validation Loss: 0.9738, Accuracy: 0.7879, Precision: 0.7900, Recall: 0.7859, F1: 0.7856
Testing Loss: 0.8489, Accuracy: 0.8032, Precision: 0.8010, Recall: 0.7950, F1: 0.7957
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2312, Accuracy: 0.9038, Precision: 0.9211, Recall: 0.8480, F1: 0.8804
Epoch 19/70
Train Loss: 0.0145, Accuracy: 0.9946, Precision: 0.9950, Recall: 0.9949, F1: 0.9949
Validation Loss: 0.9450, Accuracy: 0.7955, Precision: 0.7972, Recall: 0.7927, F1: 0.7931
Testing Loss: 0.8377, Accuracy: 0.8171, Precision: 0.8189, Recall: 0.8095, F1: 0.8101
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2129, Accuracy: 0.9231, Precision: 0.9211, Recall: 0.8578, F1: 0.8846
Epoch 20/70
Train Loss: 0.0126, Accuracy: 0.9952, Precision: 0.9955, Recall: 0.9956, F1: 0.9956
Validation Loss: 1.1951, Accuracy: 0.7371, Precision: 0.7636, Recall: 0.7344, F1: 0.7359
Testing Loss: 1.1320, Accuracy: 0.7517, Precision: 0.7805, Recall: 0.7472, F1: 0.7497
LM Predictions:  [13, 1, 10, 14, 6, 6, 14, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 9, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 14, 6, 7, 9, 8, 14, 7, 5, 6, 5, 9, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.4055, Accuracy: 0.8173, Precision: 0.8795, Recall: 0.7759, F1: 0.8054
Epoch 21/70
Train Loss: 0.0895, Accuracy: 0.9700, Precision: 0.9702, Recall: 0.9701, F1: 0.9701
Validation Loss: 1.0052, Accuracy: 0.7617, Precision: 0.7690, Recall: 0.7648, F1: 0.7637
Testing Loss: 0.9002, Accuracy: 0.7832, Precision: 0.7894, Recall: 0.7784, F1: 0.7799
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 0, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2597, Accuracy: 0.8654, Precision: 0.9102, Recall: 0.8277, F1: 0.8612
Epoch 22/70
Train Loss: 0.0232, Accuracy: 0.9924, Precision: 0.9923, Recall: 0.9924, F1: 0.9923
Validation Loss: 0.9895, Accuracy: 0.7802, Precision: 0.7880, Recall: 0.7748, F1: 0.7766
Testing Loss: 0.8593, Accuracy: 0.8040, Precision: 0.8135, Recall: 0.8010, F1: 0.8032
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2032, Accuracy: 0.9038, Precision: 0.9176, Recall: 0.8514, F1: 0.8770
Epoch 23/70
Train Loss: 0.0381, Accuracy: 0.9864, Precision: 0.9869, Recall: 0.9869, F1: 0.9869
Validation Loss: 1.0972, Accuracy: 0.7548, Precision: 0.7803, Recall: 0.7485, F1: 0.7532
Testing Loss: 1.0061, Accuracy: 0.7702, Precision: 0.7878, Recall: 0.7625, F1: 0.7664
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 6, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 11, 9, 12, 2, 13, 12, 6, 13, 5, 5, 6, 6, 11, 10, 10, 5, 3, 6, 7, 9, 12, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3077, Accuracy: 0.8462, Precision: 0.8907, Recall: 0.7741, F1: 0.8212
Epoch 24/70
Train Loss: 0.0355, Accuracy: 0.9873, Precision: 0.9876, Recall: 0.9877, F1: 0.9876
Validation Loss: 1.0915, Accuracy: 0.7679, Precision: 0.7754, Recall: 0.7696, F1: 0.7691
Testing Loss: 0.9531, Accuracy: 0.7932, Precision: 0.7962, Recall: 0.7912, F1: 0.7895
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1847, Accuracy: 0.8846, Precision: 0.9176, Recall: 0.8370, F1: 0.8693
Epoch 25/70
Train Loss: 0.0344, Accuracy: 0.9875, Precision: 0.9878, Recall: 0.9877, F1: 0.9878
Validation Loss: 1.0677, Accuracy: 0.7617, Precision: 0.7754, Recall: 0.7547, F1: 0.7577
Testing Loss: 0.9824, Accuracy: 0.7986, Precision: 0.8061, Recall: 0.7883, F1: 0.7928
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 6, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 6, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1844, Accuracy: 0.9038, Precision: 0.9211, Recall: 0.8388, F1: 0.8715
Epoch 26/70
Train Loss: 0.0352, Accuracy: 0.9866, Precision: 0.9872, Recall: 0.9871, F1: 0.9872
Validation Loss: 1.2336, Accuracy: 0.7494, Precision: 0.7691, Recall: 0.7483, F1: 0.7493
Testing Loss: 1.0775, Accuracy: 0.7709, Precision: 0.7926, Recall: 0.7649, F1: 0.7662
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 6, 14, 9, 7, 11, 14, 9, 6, 11, 4, 3, 4, 6, 7, 13, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3006, Accuracy: 0.8654, Precision: 0.8867, Recall: 0.8131, F1: 0.8426
Epoch 27/70
Train Loss: 0.0267, Accuracy: 0.9900, Precision: 0.9897, Recall: 0.9902, F1: 0.9900
Validation Loss: 1.0668, Accuracy: 0.7771, Precision: 0.7798, Recall: 0.7726, F1: 0.7728
Testing Loss: 1.0181, Accuracy: 0.7809, Precision: 0.7883, Recall: 0.7753, F1: 0.7759
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2584, Accuracy: 0.8942, Precision: 0.9206, Recall: 0.8354, F1: 0.8710
Epoch 28/70
Train Loss: 0.0237, Accuracy: 0.9905, Precision: 0.9912, Recall: 0.9909, F1: 0.9911
Validation Loss: 1.0872, Accuracy: 0.7679, Precision: 0.7719, Recall: 0.7663, F1: 0.7665
Testing Loss: 0.9321, Accuracy: 0.8002, Precision: 0.8016, Recall: 0.7937, F1: 0.7955
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3640, Accuracy: 0.8462, Precision: 0.9167, Recall: 0.8075, F1: 0.8510
Epoch 29/70
Train Loss: 0.0333, Accuracy: 0.9889, Precision: 0.9889, Recall: 0.9886, F1: 0.9887
Validation Loss: 1.1560, Accuracy: 0.7548, Precision: 0.7558, Recall: 0.7572, F1: 0.7508
Testing Loss: 1.0228, Accuracy: 0.7794, Precision: 0.7787, Recall: 0.7809, F1: 0.7740
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2034, Accuracy: 0.9038, Precision: 0.9183, Recall: 0.8547, F1: 0.8827
Epoch 30/70
Train Loss: 0.0469, Accuracy: 0.9842, Precision: 0.9835, Recall: 0.9836, F1: 0.9835
Validation Loss: 1.0864, Accuracy: 0.7748, Precision: 0.7715, Recall: 0.7783, F1: 0.7709
Testing Loss: 0.9882, Accuracy: 0.7802, Precision: 0.7797, Recall: 0.7813, F1: 0.7760
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1466, Accuracy: 0.9423, Precision: 0.9199, Recall: 0.8835, F1: 0.8992
Epoch 31/70
Train Loss: 0.0174, Accuracy: 0.9936, Precision: 0.9936, Recall: 0.9938, F1: 0.9937
Validation Loss: 1.0700, Accuracy: 0.7809, Precision: 0.7816, Recall: 0.7816, F1: 0.7791
Testing Loss: 0.9763, Accuracy: 0.7948, Precision: 0.7923, Recall: 0.7900, F1: 0.7871
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2719, Accuracy: 0.8846, Precision: 0.9176, Recall: 0.8499, F1: 0.8760
Epoch 32/70
Train Loss: 0.0296, Accuracy: 0.9892, Precision: 0.9896, Recall: 0.9895, F1: 0.9895
Validation Loss: 1.2476, Accuracy: 0.7325, Precision: 0.7384, Recall: 0.7325, F1: 0.7265
Testing Loss: 1.1138, Accuracy: 0.7617, Precision: 0.7712, Recall: 0.7652, F1: 0.7587
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 9, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 1, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2379, Accuracy: 0.8942, Precision: 0.9079, Recall: 0.8407, F1: 0.8682
Epoch 33/70
Train Loss: 0.0366, Accuracy: 0.9865, Precision: 0.9869, Recall: 0.9871, F1: 0.9869
Validation Loss: 1.0424, Accuracy: 0.7709, Precision: 0.7669, Recall: 0.7725, F1: 0.7674
Testing Loss: 0.9297, Accuracy: 0.8094, Precision: 0.8091, Recall: 0.8084, F1: 0.8056
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2438, Accuracy: 0.8654, Precision: 0.9183, Recall: 0.8216, F1: 0.8637
Epoch 34/70
Train Loss: 0.0098, Accuracy: 0.9956, Precision: 0.9959, Recall: 0.9959, F1: 0.9959
Validation Loss: 1.0643, Accuracy: 0.7809, Precision: 0.7795, Recall: 0.7866, F1: 0.7793
Testing Loss: 0.9543, Accuracy: 0.8086, Precision: 0.8075, Recall: 0.8096, F1: 0.8050
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1078, Accuracy: 0.9423, Precision: 0.9176, Recall: 0.8944, F1: 0.9031
Epoch 35/70
Train Loss: 0.0077, Accuracy: 0.9962, Precision: 0.9964, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.0194, Accuracy: 0.7948, Precision: 0.8039, Recall: 0.7937, F1: 0.7968
Testing Loss: 0.9001, Accuracy: 0.8186, Precision: 0.8239, Recall: 0.8154, F1: 0.8177
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2482, Accuracy: 0.8846, Precision: 0.9199, Recall: 0.8410, F1: 0.8728
Epoch 36/70
Train Loss: 0.0072, Accuracy: 0.9965, Precision: 0.9969, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.0425, Accuracy: 0.7963, Precision: 0.7937, Recall: 0.7986, F1: 0.7934
Testing Loss: 0.9456, Accuracy: 0.8178, Precision: 0.8163, Recall: 0.8168, F1: 0.8130
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1240, Accuracy: 0.9327, Precision: 0.9155, Recall: 0.8805, F1: 0.8955
Epoch 37/70
Train Loss: 0.0077, Accuracy: 0.9960, Precision: 0.9963, Recall: 0.9964, F1: 0.9963
Validation Loss: 1.0085, Accuracy: 0.7932, Precision: 0.7955, Recall: 0.7917, F1: 0.7917
Testing Loss: 0.9156, Accuracy: 0.8163, Precision: 0.8228, Recall: 0.8113, F1: 0.8139
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2026, Accuracy: 0.9135, Precision: 0.9167, Recall: 0.8698, F1: 0.8893
Epoch 38/70
Train Loss: 0.0074, Accuracy: 0.9965, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.0447, Accuracy: 0.8009, Precision: 0.8008, Recall: 0.8008, F1: 0.7985
Testing Loss: 0.9590, Accuracy: 0.8071, Precision: 0.8152, Recall: 0.8059, F1: 0.8056
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2269, Accuracy: 0.8942, Precision: 0.9155, Recall: 0.8555, F1: 0.8811
Epoch 39/70
Train Loss: 0.0080, Accuracy: 0.9961, Precision: 0.9964, Recall: 0.9964, F1: 0.9964
Validation Loss: 1.1070, Accuracy: 0.7817, Precision: 0.7852, Recall: 0.7792, F1: 0.7767
Testing Loss: 0.9822, Accuracy: 0.8109, Precision: 0.8145, Recall: 0.8089, F1: 0.8065
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2262, Accuracy: 0.9038, Precision: 0.9194, Recall: 0.8466, F1: 0.8762
Epoch 40/70
Train Loss: 0.0080, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.0418, Accuracy: 0.7971, Precision: 0.8004, Recall: 0.7936, F1: 0.7950
Testing Loss: 0.9537, Accuracy: 0.8155, Precision: 0.8189, Recall: 0.8114, F1: 0.8121
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2180, Accuracy: 0.8846, Precision: 0.9183, Recall: 0.8407, F1: 0.8748
Epoch 41/70
Train Loss: 0.1106, Accuracy: 0.9661, Precision: 0.9660, Recall: 0.9653, F1: 0.9657
Validation Loss: 1.1482, Accuracy: 0.7463, Precision: 0.7549, Recall: 0.7434, F1: 0.7463
Testing Loss: 0.9554, Accuracy: 0.8009, Precision: 0.8042, Recall: 0.7934, F1: 0.7958
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 14, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 6, 10, 3, 2, 6, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 0, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3769, Accuracy: 0.8077, Precision: 0.8893, Recall: 0.7730, F1: 0.8240
Epoch 42/70
Train Loss: 0.0427, Accuracy: 0.9849, Precision: 0.9852, Recall: 0.9852, F1: 0.9852
Validation Loss: 1.1394, Accuracy: 0.7540, Precision: 0.7576, Recall: 0.7539, F1: 0.7502
Testing Loss: 0.9958, Accuracy: 0.7840, Precision: 0.7900, Recall: 0.7834, F1: 0.7790
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 14, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1927, Accuracy: 0.9231, Precision: 0.9049, Recall: 0.8643, F1: 0.8805
Epoch 43/70
Train Loss: 0.0177, Accuracy: 0.9935, Precision: 0.9938, Recall: 0.9938, F1: 0.9938
Validation Loss: 1.1495, Accuracy: 0.7663, Precision: 0.7703, Recall: 0.7652, F1: 0.7639
Testing Loss: 1.0255, Accuracy: 0.7978, Precision: 0.7997, Recall: 0.7946, F1: 0.7930
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1952, Accuracy: 0.8462, Precision: 0.9155, Recall: 0.8068, F1: 0.8501
Epoch 44/70
Train Loss: 0.0264, Accuracy: 0.9910, Precision: 0.9915, Recall: 0.9912, F1: 0.9914
Validation Loss: 1.3712, Accuracy: 0.7317, Precision: 0.7540, Recall: 0.7355, F1: 0.7312
Testing Loss: 1.2570, Accuracy: 0.7517, Precision: 0.7746, Recall: 0.7492, F1: 0.7464
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 7, 12, 1, 3, 1, 10, 0, 11, 1, 9, 13, 1, 1, 0, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2415, Accuracy: 0.8846, Precision: 0.8983, Recall: 0.8363, F1: 0.8612
Epoch 45/70
Train Loss: 0.0437, Accuracy: 0.9858, Precision: 0.9859, Recall: 0.9861, F1: 0.9860
Validation Loss: 1.1398, Accuracy: 0.7579, Precision: 0.7805, Recall: 0.7540, F1: 0.7564
Testing Loss: 1.0527, Accuracy: 0.7756, Precision: 0.7894, Recall: 0.7748, F1: 0.7716
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 0, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 3, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 0, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 13, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2864, Accuracy: 0.8462, Precision: 0.8887, Recall: 0.8069, F1: 0.8382
Epoch 46/70
Train Loss: 0.0140, Accuracy: 0.9944, Precision: 0.9948, Recall: 0.9945, F1: 0.9947
Validation Loss: 1.0650, Accuracy: 0.7863, Precision: 0.7879, Recall: 0.7876, F1: 0.7855
Testing Loss: 0.9764, Accuracy: 0.8086, Precision: 0.8100, Recall: 0.8064, F1: 0.8062
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1102, Accuracy: 0.9615, Precision: 0.9217, Recall: 0.9007, F1: 0.9094
Epoch 47/70
Train Loss: 0.0150, Accuracy: 0.9934, Precision: 0.9938, Recall: 0.9938, F1: 0.9938
Validation Loss: 1.1668, Accuracy: 0.7540, Precision: 0.7683, Recall: 0.7444, F1: 0.7482
Testing Loss: 1.0508, Accuracy: 0.7832, Precision: 0.7962, Recall: 0.7723, F1: 0.7756
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 0, 0, 4, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1995, Accuracy: 0.9327, Precision: 0.9027, Recall: 0.8769, F1: 0.8879
Epoch 48/70
Train Loss: 0.0484, Accuracy: 0.9820, Precision: 0.9823, Recall: 0.9822, F1: 0.9823
Validation Loss: 1.1207, Accuracy: 0.7625, Precision: 0.7710, Recall: 0.7603, F1: 0.7630
Testing Loss: 1.0061, Accuracy: 0.8071, Precision: 0.8135, Recall: 0.8021, F1: 0.8059
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1505, Accuracy: 0.9327, Precision: 0.9193, Recall: 0.8807, F1: 0.8980
Epoch 49/70
Train Loss: 0.0148, Accuracy: 0.9931, Precision: 0.9934, Recall: 0.9934, F1: 0.9934
Validation Loss: 1.1696, Accuracy: 0.7571, Precision: 0.7681, Recall: 0.7545, F1: 0.7561
Testing Loss: 1.0150, Accuracy: 0.7925, Precision: 0.8044, Recall: 0.7871, F1: 0.7908
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 3, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1934, Accuracy: 0.9038, Precision: 0.9109, Recall: 0.8577, F1: 0.8803
Epoch 50/70
Train Loss: 0.0152, Accuracy: 0.9938, Precision: 0.9938, Recall: 0.9939, F1: 0.9939
Validation Loss: 1.2511, Accuracy: 0.7479, Precision: 0.7791, Recall: 0.7332, F1: 0.7470
Testing Loss: 1.1489, Accuracy: 0.7725, Precision: 0.8038, Recall: 0.7593, F1: 0.7718
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 6, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 6, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 6, 6, 5, 4, 6, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3283, Accuracy: 0.8077, Precision: 0.9250, Recall: 0.7718, F1: 0.8322
Epoch 51/70
Train Loss: 0.0424, Accuracy: 0.9847, Precision: 0.9846, Recall: 0.9845, F1: 0.9845
Validation Loss: 1.0641, Accuracy: 0.7725, Precision: 0.7777, Recall: 0.7697, F1: 0.7704
Testing Loss: 0.9622, Accuracy: 0.8055, Precision: 0.8115, Recall: 0.8034, F1: 0.8018
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 6, 7, 0, 3, 9, 13, 6, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2121, Accuracy: 0.8462, Precision: 0.9155, Recall: 0.7945, F1: 0.8458
Epoch 52/70
Train Loss: 0.0082, Accuracy: 0.9952, Precision: 0.9953, Recall: 0.9955, F1: 0.9954
Validation Loss: 1.0561, Accuracy: 0.7855, Precision: 0.7874, Recall: 0.7840, F1: 0.7837
Testing Loss: 0.9349, Accuracy: 0.8217, Precision: 0.8264, Recall: 0.8228, F1: 0.8234
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1486, Accuracy: 0.9135, Precision: 0.9199, Recall: 0.8605, F1: 0.8880
Epoch 53/70
Train Loss: 0.0055, Accuracy: 0.9965, Precision: 0.9967, Recall: 0.9969, F1: 0.9968
Validation Loss: 1.0272, Accuracy: 0.7925, Precision: 0.7940, Recall: 0.7906, F1: 0.7905
Testing Loss: 0.9263, Accuracy: 0.8178, Precision: 0.8227, Recall: 0.8198, F1: 0.8200
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1596, Accuracy: 0.9038, Precision: 0.9204, Recall: 0.8466, F1: 0.8789
Epoch 54/70
Train Loss: 0.0059, Accuracy: 0.9963, Precision: 0.9967, Recall: 0.9965, F1: 0.9966
Validation Loss: 1.0631, Accuracy: 0.7894, Precision: 0.7893, Recall: 0.7890, F1: 0.7872
Testing Loss: 0.9423, Accuracy: 0.8194, Precision: 0.8228, Recall: 0.8218, F1: 0.8210
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1642, Accuracy: 0.9038, Precision: 0.9199, Recall: 0.8501, F1: 0.8817
Epoch 55/70
Train Loss: 0.0057, Accuracy: 0.9966, Precision: 0.9969, Recall: 0.9970, F1: 0.9969
Validation Loss: 1.0364, Accuracy: 0.7932, Precision: 0.7948, Recall: 0.7917, F1: 0.7921
Testing Loss: 0.9362, Accuracy: 0.8232, Precision: 0.8319, Recall: 0.8235, F1: 0.8264
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2012, Accuracy: 0.8654, Precision: 0.9183, Recall: 0.8166, F1: 0.8595
Epoch 56/70
Train Loss: 0.0063, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.0744, Accuracy: 0.7886, Precision: 0.7928, Recall: 0.7865, F1: 0.7868
Testing Loss: 0.9318, Accuracy: 0.8263, Precision: 0.8310, Recall: 0.8277, F1: 0.8282
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1737, Accuracy: 0.9038, Precision: 0.9164, Recall: 0.8481, F1: 0.8757
Epoch 57/70
Train Loss: 0.0062, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 1.0731, Accuracy: 0.7971, Precision: 0.7980, Recall: 0.7947, F1: 0.7947
Testing Loss: 0.9754, Accuracy: 0.8209, Precision: 0.8271, Recall: 0.8207, F1: 0.8209
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1949, Accuracy: 0.8942, Precision: 0.9206, Recall: 0.8440, F1: 0.8774
Epoch 58/70
Train Loss: 0.0646, Accuracy: 0.9797, Precision: 0.9802, Recall: 0.9801, F1: 0.9802
Validation Loss: 1.0876, Accuracy: 0.7579, Precision: 0.7656, Recall: 0.7578, F1: 0.7589
Testing Loss: 0.9689, Accuracy: 0.7978, Precision: 0.8031, Recall: 0.7897, F1: 0.7929
LM Predictions:  [6, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 6, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 7, 7, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3145, Accuracy: 0.8365, Precision: 0.9065, Recall: 0.7809, F1: 0.8331
Epoch 59/70
Train Loss: 0.0478, Accuracy: 0.9849, Precision: 0.9845, Recall: 0.9846, F1: 0.9845
Validation Loss: 1.1606, Accuracy: 0.7625, Precision: 0.7800, Recall: 0.7569, F1: 0.7639
Testing Loss: 1.0331, Accuracy: 0.7925, Precision: 0.8028, Recall: 0.7829, F1: 0.7902
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 0, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 0, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2078, Accuracy: 0.8846, Precision: 0.9028, Recall: 0.8249, F1: 0.8521
Epoch 60/70
Train Loss: 0.0162, Accuracy: 0.9929, Precision: 0.9930, Recall: 0.9929, F1: 0.9930
Validation Loss: 1.2126, Accuracy: 0.7502, Precision: 0.7520, Recall: 0.7488, F1: 0.7475
Testing Loss: 0.9755, Accuracy: 0.8071, Precision: 0.8053, Recall: 0.7998, F1: 0.7996
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1923, Accuracy: 0.8558, Precision: 0.9164, Recall: 0.8091, F1: 0.8545
Epoch 61/70
Train Loss: 0.0213, Accuracy: 0.9923, Precision: 0.9925, Recall: 0.9926, F1: 0.9926
Validation Loss: 1.3529, Accuracy: 0.7241, Precision: 0.7478, Recall: 0.7173, F1: 0.7214
Testing Loss: 1.1426, Accuracy: 0.7733, Precision: 0.8028, Recall: 0.7662, F1: 0.7728
LM Predictions:  [13, 0, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 13, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 13, 2, 13, 12, 6, 13, 5, 5, 9, 7, 6, 10, 10, 5, 3, 1, 7, 9, 8, 13, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 6, 4, 9, 7, 6]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3148, Accuracy: 0.8558, Precision: 0.8946, Recall: 0.7822, F1: 0.8174
Epoch 62/70
Train Loss: 0.0318, Accuracy: 0.9890, Precision: 0.9895, Recall: 0.9894, F1: 0.9895
Validation Loss: 1.2644, Accuracy: 0.7617, Precision: 0.7776, Recall: 0.7547, F1: 0.7583
Testing Loss: 1.0823, Accuracy: 0.7963, Precision: 0.8129, Recall: 0.7921, F1: 0.7949
LM Predictions:  [13, 4, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 6, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 9, 6, 6, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2287, Accuracy: 0.8365, Precision: 0.9031, Recall: 0.7921, F1: 0.8278
Epoch 63/70
Train Loss: 0.0261, Accuracy: 0.9910, Precision: 0.9917, Recall: 0.9912, F1: 0.9915
Validation Loss: 1.3467, Accuracy: 0.7341, Precision: 0.7421, Recall: 0.7349, F1: 0.7298
Testing Loss: 1.1424, Accuracy: 0.7663, Precision: 0.7756, Recall: 0.7661, F1: 0.7617
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1554, Accuracy: 0.8942, Precision: 0.9199, Recall: 0.8439, F1: 0.8779
Epoch 64/70
Train Loss: 0.0229, Accuracy: 0.9907, Precision: 0.9907, Recall: 0.9912, F1: 0.9909
Validation Loss: 1.2519, Accuracy: 0.7610, Precision: 0.7678, Recall: 0.7574, F1: 0.7584
Testing Loss: 1.0577, Accuracy: 0.7948, Precision: 0.8096, Recall: 0.7880, F1: 0.7904
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 6, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1949, Accuracy: 0.8654, Precision: 0.9176, Recall: 0.8110, F1: 0.8562
Epoch 65/70
Train Loss: 0.0173, Accuracy: 0.9928, Precision: 0.9930, Recall: 0.9928, F1: 0.9929
Validation Loss: 1.3181, Accuracy: 0.7533, Precision: 0.7650, Recall: 0.7555, F1: 0.7513
Testing Loss: 1.1545, Accuracy: 0.7748, Precision: 0.7784, Recall: 0.7742, F1: 0.7720
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 14, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1603, Accuracy: 0.9135, Precision: 0.9084, Recall: 0.8497, F1: 0.8712
Epoch 66/70
Train Loss: 0.0232, Accuracy: 0.9913, Precision: 0.9920, Recall: 0.9916, F1: 0.9918
Validation Loss: 1.2089, Accuracy: 0.7602, Precision: 0.7674, Recall: 0.7602, F1: 0.7570
Testing Loss: 0.9840, Accuracy: 0.7978, Precision: 0.8049, Recall: 0.8027, F1: 0.8008
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1848, Accuracy: 0.8750, Precision: 0.9267, Recall: 0.8236, F1: 0.8671
Epoch 67/70
Train Loss: 0.0204, Accuracy: 0.9918, Precision: 0.9923, Recall: 0.9922, F1: 0.9922
Validation Loss: 1.4220, Accuracy: 0.7379, Precision: 0.7475, Recall: 0.7417, F1: 0.7332
Testing Loss: 1.1567, Accuracy: 0.7779, Precision: 0.7886, Recall: 0.7857, F1: 0.7751
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 1, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 5, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 5, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2222, Accuracy: 0.9135, Precision: 0.9044, Recall: 0.8604, F1: 0.8785
Epoch 68/70
Train Loss: 0.0242, Accuracy: 0.9899, Precision: 0.9895, Recall: 0.9894, F1: 0.9895
Validation Loss: 1.2505, Accuracy: 0.7610, Precision: 0.7637, Recall: 0.7639, F1: 0.7589
Testing Loss: 1.0192, Accuracy: 0.8032, Precision: 0.8055, Recall: 0.8043, F1: 0.8016
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1178, Accuracy: 0.9327, Precision: 0.9199, Recall: 0.8754, F1: 0.8941
Epoch 69/70
Train Loss: 0.0159, Accuracy: 0.9934, Precision: 0.9937, Recall: 0.9938, F1: 0.9938
Validation Loss: 1.3352, Accuracy: 0.7425, Precision: 0.7633, Recall: 0.7474, F1: 0.7482
Testing Loss: 1.0254, Accuracy: 0.7940, Precision: 0.8093, Recall: 0.7946, F1: 0.7945
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 0, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 6, 2, 10, 13, 0, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 0, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3051, Accuracy: 0.8269, Precision: 0.8996, Recall: 0.7913, F1: 0.8330
Epoch 70/70
Train Loss: 0.0246, Accuracy: 0.9899, Precision: 0.9899, Recall: 0.9897, F1: 0.9898
Validation Loss: 1.3233, Accuracy: 0.7364, Precision: 0.7420, Recall: 0.7409, F1: 0.7370
Testing Loss: 1.1461, Accuracy: 0.7656, Precision: 0.7641, Recall: 0.7700, F1: 0.7613
LM Predictions:  [13, 0, 10, 14, 3, 6, 1, 0, 0, 3, 5, 5, 13, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1837, Accuracy: 0.8846, Precision: 0.8955, Recall: 0.8366, F1: 0.8583
For later layers:  [8, 9, 10, 11]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 0.9305, Accuracy: 0.7213, Precision: 0.7298, Recall: 0.7146, F1: 0.7204
Validation Loss: 0.5143, Accuracy: 0.8317, Precision: 0.8342, Recall: 0.8310, F1: 0.8288
Testing Loss: 0.5090, Accuracy: 0.8447, Precision: 0.8510, Recall: 0.8468, F1: 0.8442
LM Predictions:  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 13, 6, 13, 6, 6, 14, 6, 6, 6, 6, 6, 6, 6, 6, 14, 0, 0, 11, 0, 6, 6, 0, 4, 6, 6, 6, 6, 6, 6, 0, 6, 0, 10, 6, 0, 6, 6, 6, 3, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 13, 6, 0, 6, 6, 10, 12, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 9, 1, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.7080, Accuracy: 0.1058, Precision: 0.3338, Recall: 0.0974, F1: 0.1400
Epoch 2/70
Train Loss: 0.2898, Accuracy: 0.9205, Precision: 0.9253, Recall: 0.9214, F1: 0.9233
Validation Loss: 0.4989, Accuracy: 0.8332, Precision: 0.8570, Recall: 0.8257, F1: 0.8360
Testing Loss: 0.4714, Accuracy: 0.8632, Precision: 0.8865, Recall: 0.8535, F1: 0.8647
LM Predictions:  [6, 0, 6, 14, 6, 6, 6, 6, 0, 9, 0, 5, 6, 6, 6, 5, 6, 0, 11, 0, 6, 0, 0, 6, 6, 14, 12, 0, 0, 6, 6, 0, 3, 2, 6, 0, 8, 4, 0, 9, 6, 0, 4, 6, 4, 6, 6, 0, 0, 0, 6, 0, 10, 6, 0, 9, 6, 6, 11, 6, 12, 13, 6, 0, 6, 9, 0, 6, 6, 6, 9, 0, 6, 0, 9, 12, 14, 0, 6, 6, 0, 6, 6, 0, 0, 6, 6, 0, 6, 12, 0, 13, 1, 6, 0, 6, 0, 6, 13, 0, 0, 6, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 3.1806, Accuracy: 0.2500, Precision: 0.6376, Recall: 0.2480, F1: 0.3018
Epoch 3/70
Train Loss: 0.0989, Accuracy: 0.9797, Precision: 0.9812, Recall: 0.9801, F1: 0.9806
Validation Loss: 0.5033, Accuracy: 0.8578, Precision: 0.8572, Recall: 0.8560, F1: 0.8542
Testing Loss: 0.4633, Accuracy: 0.8586, Precision: 0.8600, Recall: 0.8569, F1: 0.8572
LM Predictions:  [13, 0, 6, 14, 6, 13, 1, 6, 0, 3, 0, 5, 0, 5, 12, 5, 6, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 6, 6, 6, 6, 3, 2, 14, 9, 7, 4, 7, 9, 6, 6, 4, 6, 4, 6, 7, 0, 0, 5, 13, 1, 10, 8, 0, 9, 9, 6, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 6, 6, 5, 3, 6, 0, 9, 8, 14, 6, 5, 6, 5, 4, 14, 7, 0, 13, 9, 0, 6, 12, 6, 3, 1, 6, 1, 6, 4, 9, 13, 1, 4, 9, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.1961, Accuracy: 0.6250, Precision: 0.8510, Recall: 0.6039, F1: 0.6566
Epoch 4/70
Train Loss: 0.0547, Accuracy: 0.9896, Precision: 0.9904, Recall: 0.9896, F1: 0.9900
Validation Loss: 0.5805, Accuracy: 0.8363, Precision: 0.8418, Recall: 0.8391, F1: 0.8340
Testing Loss: 0.5585, Accuracy: 0.8440, Precision: 0.8524, Recall: 0.8453, F1: 0.8416
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 6, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 14, 3, 2, 14, 9, 7, 4, 7, 9, 0, 6, 4, 6, 4, 6, 7, 7, 2, 6, 13, 1, 10, 8, 0, 9, 9, 6, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 6, 6, 5, 3, 1, 0, 9, 8, 14, 7, 5, 6, 5, 4, 6, 7, 0, 3, 9, 13, 2, 12, 6, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.7877, Accuracy: 0.7788, Precision: 0.8955, Recall: 0.7428, F1: 0.7921
Epoch 5/70
Train Loss: 0.0532, Accuracy: 0.9875, Precision: 0.9883, Recall: 0.9882, F1: 0.9882
Validation Loss: 0.6661, Accuracy: 0.8109, Precision: 0.8466, Recall: 0.8107, F1: 0.8172
Testing Loss: 0.7246, Accuracy: 0.8163, Precision: 0.8516, Recall: 0.8156, F1: 0.8178
LM Predictions:  [6, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 6, 6, 11, 5, 5, 6, 11, 6, 6, 6, 13, 4, 6, 14, 12, 5, 3, 6, 6, 6, 3, 2, 14, 9, 7, 4, 7, 6, 6, 11, 4, 6, 4, 1, 7, 6, 2, 6, 6, 1, 10, 6, 0, 9, 9, 6, 2, 6, 12, 13, 6, 5, 5, 6, 6, 6, 6, 6, 5, 3, 6, 6, 9, 8, 14, 7, 5, 6, 6, 4, 6, 7, 6, 3, 9, 0, 6, 12, 1, 3, 1, 6, 1, 6, 1, 9, 13, 1, 1, 9, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.2229, Accuracy: 0.6058, Precision: 0.9133, Recall: 0.5778, F1: 0.6823
Epoch 6/70
Train Loss: 0.0547, Accuracy: 0.9859, Precision: 0.9864, Recall: 0.9862, F1: 0.9863
Validation Loss: 0.6475, Accuracy: 0.8340, Precision: 0.8432, Recall: 0.8305, F1: 0.8329
Testing Loss: 0.6506, Accuracy: 0.8347, Precision: 0.8430, Recall: 0.8279, F1: 0.8305
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 6, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 13, 13, 13, 5, 5, 12, 6, 6, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.5782, Accuracy: 0.8365, Precision: 0.9119, Recall: 0.7853, F1: 0.8336
Epoch 7/70
Train Loss: 0.0301, Accuracy: 0.9935, Precision: 0.9938, Recall: 0.9938, F1: 0.9938
Validation Loss: 0.6809, Accuracy: 0.8286, Precision: 0.8431, Recall: 0.8259, F1: 0.8290
Testing Loss: 0.6379, Accuracy: 0.8378, Precision: 0.8509, Recall: 0.8374, F1: 0.8406
LM Predictions:  [13, 1, 6, 14, 3, 13, 4, 0, 0, 3, 13, 6, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 6, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 0, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 6, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.6410, Accuracy: 0.8269, Precision: 0.9019, Recall: 0.7901, F1: 0.8356
Epoch 8/70
Train Loss: 0.0336, Accuracy: 0.9913, Precision: 0.9917, Recall: 0.9913, F1: 0.9915
Validation Loss: 0.7061, Accuracy: 0.8248, Precision: 0.8441, Recall: 0.8196, F1: 0.8238
Testing Loss: 0.7064, Accuracy: 0.8317, Precision: 0.8581, Recall: 0.8247, F1: 0.8332
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 9, 9, 0, 11, 4, 3, 4, 6, 7, 4, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 6, 9, 12, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3795, Accuracy: 0.8750, Precision: 0.8961, Recall: 0.8042, F1: 0.8328
Epoch 9/70
Train Loss: 0.0558, Accuracy: 0.9828, Precision: 0.9824, Recall: 0.9819, F1: 0.9822
Validation Loss: 0.6936, Accuracy: 0.8271, Precision: 0.8407, Recall: 0.8246, F1: 0.8232
Testing Loss: 0.6848, Accuracy: 0.8294, Precision: 0.8441, Recall: 0.8279, F1: 0.8310
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 5, 14, 12, 5, 3, 6, 6, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 6, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 6, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 4, 5, 6, 5, 4, 10, 7, 0, 10, 9, 0, 2, 12, 1, 3, 1, 10, 14, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.4341, Accuracy: 0.8462, Precision: 0.8797, Recall: 0.7940, F1: 0.8270
Epoch 10/70
Train Loss: 0.0441, Accuracy: 0.9861, Precision: 0.9862, Recall: 0.9861, F1: 0.9862
Validation Loss: 0.6482, Accuracy: 0.8440, Precision: 0.8481, Recall: 0.8400, F1: 0.8412
Testing Loss: 0.6746, Accuracy: 0.8540, Precision: 0.8618, Recall: 0.8529, F1: 0.8538
LM Predictions:  [13, 6, 10, 14, 6, 6, 1, 6, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.6486, Accuracy: 0.8173, Precision: 0.9143, Recall: 0.7844, F1: 0.8352
Epoch 11/70
Train Loss: 0.0234, Accuracy: 0.9936, Precision: 0.9939, Recall: 0.9938, F1: 0.9938
Validation Loss: 0.6712, Accuracy: 0.8394, Precision: 0.8528, Recall: 0.8386, F1: 0.8406
Testing Loss: 0.6711, Accuracy: 0.8524, Precision: 0.8632, Recall: 0.8534, F1: 0.8541
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 6, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.4000, Accuracy: 0.8750, Precision: 0.9199, Recall: 0.8127, F1: 0.8582
Epoch 12/70
Train Loss: 0.0185, Accuracy: 0.9951, Precision: 0.9954, Recall: 0.9953, F1: 0.9953
Validation Loss: 0.6337, Accuracy: 0.8470, Precision: 0.8478, Recall: 0.8488, F1: 0.8457
Testing Loss: 0.5794, Accuracy: 0.8578, Precision: 0.8614, Recall: 0.8581, F1: 0.8556
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2031, Accuracy: 0.9423, Precision: 0.9167, Recall: 0.8901, F1: 0.9016
Epoch 13/70
Train Loss: 0.0138, Accuracy: 0.9962, Precision: 0.9965, Recall: 0.9964, F1: 0.9964
Validation Loss: 0.6459, Accuracy: 0.8586, Precision: 0.8635, Recall: 0.8564, F1: 0.8573
Testing Loss: 0.5726, Accuracy: 0.8647, Precision: 0.8706, Recall: 0.8631, F1: 0.8633
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2256, Accuracy: 0.9135, Precision: 0.9194, Recall: 0.8523, F1: 0.8789
Epoch 14/70
Train Loss: 0.0108, Accuracy: 0.9964, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 0.6021, Accuracy: 0.8640, Precision: 0.8663, Recall: 0.8601, F1: 0.8620
Testing Loss: 0.5468, Accuracy: 0.8709, Precision: 0.8752, Recall: 0.8680, F1: 0.8704
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2240, Accuracy: 0.9327, Precision: 0.9176, Recall: 0.8731, F1: 0.8903
Epoch 15/70
Train Loss: 0.0094, Accuracy: 0.9970, Precision: 0.9973, Recall: 0.9972, F1: 0.9973
Validation Loss: 0.6016, Accuracy: 0.8601, Precision: 0.8620, Recall: 0.8573, F1: 0.8586
Testing Loss: 0.5562, Accuracy: 0.8724, Precision: 0.8766, Recall: 0.8695, F1: 0.8710
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2735, Accuracy: 0.8846, Precision: 0.9167, Recall: 0.8435, F1: 0.8737
Epoch 16/70
Train Loss: 0.0101, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.5910, Accuracy: 0.8647, Precision: 0.8691, Recall: 0.8615, F1: 0.8640
Testing Loss: 0.5294, Accuracy: 0.8793, Precision: 0.8831, Recall: 0.8734, F1: 0.8769
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2599, Accuracy: 0.8942, Precision: 0.9194, Recall: 0.8413, F1: 0.8719
Epoch 17/70
Train Loss: 0.0091, Accuracy: 0.9964, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.6083, Accuracy: 0.8686, Precision: 0.8702, Recall: 0.8672, F1: 0.8674
Testing Loss: 0.5188, Accuracy: 0.8809, Precision: 0.8807, Recall: 0.8774, F1: 0.8779
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3850, Accuracy: 0.8750, Precision: 0.9176, Recall: 0.8207, F1: 0.8611
Epoch 18/70
Train Loss: 0.0321, Accuracy: 0.9902, Precision: 0.9907, Recall: 0.9905, F1: 0.9906
Validation Loss: 0.9024, Accuracy: 0.7356, Precision: 0.7555, Recall: 0.7442, F1: 0.7353
Testing Loss: 0.8323, Accuracy: 0.7602, Precision: 0.7778, Recall: 0.7674, F1: 0.7600
LM Predictions:  [13, 0, 6, 14, 6, 6, 10, 6, 0, 3, 0, 6, 0, 6, 12, 6, 6, 0, 6, 12, 6, 9, 8, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 6, 5, 12, 6, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 14, 0, 10, 8, 0, 9, 9, 14, 2, 6, 12, 13, 13, 14, 5, 12, 6, 11, 10, 10, 4, 3, 6, 10, 9, 12, 14, 7, 5, 12, 5, 4, 14, 7, 0, 3, 9, 0, 6, 12, 14, 9, 1, 14, 1, 6, 1, 6, 14, 12, 1, 14, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.1633, Accuracy: 0.5673, Precision: 0.7373, Recall: 0.5602, F1: 0.5878
Epoch 19/70
Train Loss: 0.1249, Accuracy: 0.9597, Precision: 0.9595, Recall: 0.9592, F1: 0.9593
Validation Loss: 0.7307, Accuracy: 0.8232, Precision: 0.8246, Recall: 0.8281, F1: 0.8208
Testing Loss: 0.7202, Accuracy: 0.8301, Precision: 0.8338, Recall: 0.8360, F1: 0.8295
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 14, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3193, Accuracy: 0.8462, Precision: 0.9043, Recall: 0.8068, F1: 0.8447
Epoch 20/70
Train Loss: 0.0245, Accuracy: 0.9914, Precision: 0.9917, Recall: 0.9917, F1: 0.9917
Validation Loss: 0.7135, Accuracy: 0.8355, Precision: 0.8474, Recall: 0.8321, F1: 0.8363
Testing Loss: 0.7595, Accuracy: 0.8463, Precision: 0.8543, Recall: 0.8432, F1: 0.8461
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2827, Accuracy: 0.8654, Precision: 0.9167, Recall: 0.8295, F1: 0.8654
Epoch 21/70
Train Loss: 0.0143, Accuracy: 0.9946, Precision: 0.9949, Recall: 0.9947, F1: 0.9948
Validation Loss: 0.6279, Accuracy: 0.8455, Precision: 0.8508, Recall: 0.8415, F1: 0.8451
Testing Loss: 0.6717, Accuracy: 0.8570, Precision: 0.8602, Recall: 0.8551, F1: 0.8567
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2401, Accuracy: 0.8462, Precision: 0.9193, Recall: 0.8041, F1: 0.8491
Epoch 22/70
Train Loss: 0.0333, Accuracy: 0.9884, Precision: 0.9888, Recall: 0.9884, F1: 0.9886
Validation Loss: 0.7152, Accuracy: 0.8317, Precision: 0.8302, Recall: 0.8283, F1: 0.8270
Testing Loss: 0.7156, Accuracy: 0.8424, Precision: 0.8466, Recall: 0.8453, F1: 0.8426
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 3, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 0, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 12, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3099, Accuracy: 0.8365, Precision: 0.8938, Recall: 0.8010, F1: 0.8364
Epoch 23/70
Train Loss: 0.0385, Accuracy: 0.9861, Precision: 0.9861, Recall: 0.9860, F1: 0.9861
Validation Loss: 0.7541, Accuracy: 0.8340, Precision: 0.8359, Recall: 0.8319, F1: 0.8312
Testing Loss: 0.7386, Accuracy: 0.8440, Precision: 0.8489, Recall: 0.8451, F1: 0.8437
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 4, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2098, Accuracy: 0.8750, Precision: 0.9111, Recall: 0.8401, F1: 0.8661
Epoch 24/70
Train Loss: 0.0222, Accuracy: 0.9918, Precision: 0.9924, Recall: 0.9920, F1: 0.9922
Validation Loss: 0.7606, Accuracy: 0.8301, Precision: 0.8329, Recall: 0.8301, F1: 0.8282
Testing Loss: 0.7475, Accuracy: 0.8478, Precision: 0.8584, Recall: 0.8505, F1: 0.8493
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2256, Accuracy: 0.9038, Precision: 0.9193, Recall: 0.8646, F1: 0.8847
Epoch 25/70
Train Loss: 0.0098, Accuracy: 0.9960, Precision: 0.9963, Recall: 0.9962, F1: 0.9962
Validation Loss: 0.6585, Accuracy: 0.8601, Precision: 0.8607, Recall: 0.8564, F1: 0.8577
Testing Loss: 0.6783, Accuracy: 0.8624, Precision: 0.8682, Recall: 0.8636, F1: 0.8642
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2204, Accuracy: 0.8942, Precision: 0.9155, Recall: 0.8564, F1: 0.8811
Epoch 26/70
Train Loss: 0.0082, Accuracy: 0.9961, Precision: 0.9964, Recall: 0.9964, F1: 0.9964
Validation Loss: 0.6766, Accuracy: 0.8586, Precision: 0.8600, Recall: 0.8545, F1: 0.8557
Testing Loss: 0.6714, Accuracy: 0.8647, Precision: 0.8677, Recall: 0.8685, F1: 0.8665
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1730, Accuracy: 0.8942, Precision: 0.9155, Recall: 0.8465, F1: 0.8759
Epoch 27/70
Train Loss: 0.0075, Accuracy: 0.9968, Precision: 0.9971, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.6693, Accuracy: 0.8663, Precision: 0.8675, Recall: 0.8637, F1: 0.8639
Testing Loss: 0.6678, Accuracy: 0.8693, Precision: 0.8699, Recall: 0.8723, F1: 0.8704
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.0953, Accuracy: 0.9615, Precision: 0.9194, Recall: 0.8976, F1: 0.9067
Epoch 28/70
Train Loss: 0.0077, Accuracy: 0.9960, Precision: 0.9963, Recall: 0.9962, F1: 0.9963
Validation Loss: 0.6811, Accuracy: 0.8609, Precision: 0.8612, Recall: 0.8613, F1: 0.8594
Testing Loss: 0.6668, Accuracy: 0.8709, Precision: 0.8705, Recall: 0.8736, F1: 0.8715
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1043, Accuracy: 0.9712, Precision: 0.9199, Recall: 0.9103, F1: 0.9140
Epoch 29/70
Train Loss: 0.0071, Accuracy: 0.9969, Precision: 0.9972, Recall: 0.9972, F1: 0.9972
Validation Loss: 0.7029, Accuracy: 0.8601, Precision: 0.8626, Recall: 0.8600, F1: 0.8581
Testing Loss: 0.6842, Accuracy: 0.8632, Precision: 0.8630, Recall: 0.8694, F1: 0.8652
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1902, Accuracy: 0.9231, Precision: 0.9183, Recall: 0.8658, F1: 0.8883
Epoch 30/70
Train Loss: 0.0074, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 0.7010, Accuracy: 0.8578, Precision: 0.8621, Recall: 0.8562, F1: 0.8559
Testing Loss: 0.6934, Accuracy: 0.8655, Precision: 0.8683, Recall: 0.8681, F1: 0.8660
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1669, Accuracy: 0.9038, Precision: 0.9194, Recall: 0.8516, F1: 0.8788
Epoch 31/70
Train Loss: 0.0075, Accuracy: 0.9970, Precision: 0.9973, Recall: 0.9973, F1: 0.9973
Validation Loss: 0.6918, Accuracy: 0.8532, Precision: 0.8588, Recall: 0.8488, F1: 0.8518
Testing Loss: 0.6791, Accuracy: 0.8716, Precision: 0.8795, Recall: 0.8740, F1: 0.8759
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.3029, Accuracy: 0.8654, Precision: 0.9189, Recall: 0.8230, F1: 0.8634
Epoch 32/70
Train Loss: 0.0859, Accuracy: 0.9719, Precision: 0.9724, Recall: 0.9723, F1: 0.9723
Validation Loss: 0.8393, Accuracy: 0.8140, Precision: 0.8274, Recall: 0.8105, F1: 0.8152
Testing Loss: 0.7483, Accuracy: 0.8155, Precision: 0.8280, Recall: 0.8162, F1: 0.8182
LM Predictions:  [13, 1, 6, 14, 6, 6, 4, 0, 0, 3, 0, 5, 0, 5, 11, 6, 5, 6, 6, 6, 13, 9, 6, 4, 4, 14, 12, 5, 3, 3, 0, 0, 3, 2, 14, 9, 7, 4, 7, 6, 0, 11, 4, 6, 0, 6, 6, 0, 2, 0, 13, 0, 10, 8, 0, 9, 9, 6, 2, 13, 12, 13, 13, 5, 6, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 0, 0, 6, 6, 3, 9, 0, 2, 4, 0, 3, 1, 0, 1, 11, 1, 6, 6, 1, 1, 9, 0, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.8521, Accuracy: 0.6442, Precision: 0.8544, Recall: 0.6486, F1: 0.7089
Epoch 33/70
Train Loss: 0.0483, Accuracy: 0.9840, Precision: 0.9839, Recall: 0.9834, F1: 0.9837
Validation Loss: 0.8481, Accuracy: 0.8117, Precision: 0.8175, Recall: 0.8147, F1: 0.8104
Testing Loss: 0.7751, Accuracy: 0.8370, Precision: 0.8460, Recall: 0.8413, F1: 0.8393
LM Predictions:  [6, 1, 10, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 6, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 6, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 14, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2566, Accuracy: 0.8654, Precision: 0.9065, Recall: 0.8145, F1: 0.8491
Epoch 34/70
Train Loss: 0.0129, Accuracy: 0.9950, Precision: 0.9954, Recall: 0.9953, F1: 0.9954
Validation Loss: 0.7605, Accuracy: 0.8378, Precision: 0.8372, Recall: 0.8385, F1: 0.8361
Testing Loss: 0.7184, Accuracy: 0.8578, Precision: 0.8609, Recall: 0.8599, F1: 0.8585
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 8, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1655, Accuracy: 0.8846, Precision: 0.8976, Recall: 0.8391, F1: 0.8615
Epoch 35/70
Train Loss: 0.0087, Accuracy: 0.9961, Precision: 0.9964, Recall: 0.9963, F1: 0.9964
Validation Loss: 0.7896, Accuracy: 0.8340, Precision: 0.8468, Recall: 0.8286, F1: 0.8339
Testing Loss: 0.7621, Accuracy: 0.8470, Precision: 0.8617, Recall: 0.8437, F1: 0.8477
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2256, Accuracy: 0.8462, Precision: 0.9176, Recall: 0.8119, F1: 0.8552
Epoch 36/70
Train Loss: 0.0081, Accuracy: 0.9961, Precision: 0.9964, Recall: 0.9964, F1: 0.9964
Validation Loss: 0.8206, Accuracy: 0.8294, Precision: 0.8306, Recall: 0.8330, F1: 0.8274
Testing Loss: 0.7952, Accuracy: 0.8478, Precision: 0.8514, Recall: 0.8535, F1: 0.8476
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1564, Accuracy: 0.8750, Precision: 0.9193, Recall: 0.8263, F1: 0.8624
Epoch 37/70
Train Loss: 0.0716, Accuracy: 0.9766, Precision: 0.9768, Recall: 0.9762, F1: 0.9765
Validation Loss: 0.8449, Accuracy: 0.8217, Precision: 0.8284, Recall: 0.8187, F1: 0.8221
Testing Loss: 0.6840, Accuracy: 0.8478, Precision: 0.8574, Recall: 0.8456, F1: 0.8486
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 0, 3, 2, 14, 9, 7, 4, 7, 9, 6, 6, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 13, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 6, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2796, Accuracy: 0.8269, Precision: 0.9028, Recall: 0.7785, F1: 0.8305
Epoch 38/70
Train Loss: 0.0216, Accuracy: 0.9923, Precision: 0.9929, Recall: 0.9926, F1: 0.9927
Validation Loss: 0.8788, Accuracy: 0.8155, Precision: 0.8185, Recall: 0.8178, F1: 0.8157
Testing Loss: 0.7321, Accuracy: 0.8509, Precision: 0.8539, Recall: 0.8511, F1: 0.8504
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 6, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1245, Accuracy: 0.9615, Precision: 0.9199, Recall: 0.9029, F1: 0.9101
Epoch 39/70
Train Loss: 0.0134, Accuracy: 0.9942, Precision: 0.9945, Recall: 0.9947, F1: 0.9946
Validation Loss: 0.8023, Accuracy: 0.8409, Precision: 0.8411, Recall: 0.8424, F1: 0.8409
Testing Loss: 0.6627, Accuracy: 0.8640, Precision: 0.8647, Recall: 0.8630, F1: 0.8624
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1540, Accuracy: 0.9038, Precision: 0.9164, Recall: 0.8558, F1: 0.8834
Epoch 40/70
Train Loss: 0.0063, Accuracy: 0.9959, Precision: 0.9962, Recall: 0.9962, F1: 0.9962
Validation Loss: 0.8148, Accuracy: 0.8417, Precision: 0.8452, Recall: 0.8430, F1: 0.8427
Testing Loss: 0.6565, Accuracy: 0.8678, Precision: 0.8685, Recall: 0.8656, F1: 0.8665
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2036, Accuracy: 0.8462, Precision: 0.9176, Recall: 0.8047, F1: 0.8519
Epoch 41/70
Train Loss: 0.0062, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.8229, Accuracy: 0.8440, Precision: 0.8487, Recall: 0.8449, F1: 0.8453
Testing Loss: 0.6721, Accuracy: 0.8655, Precision: 0.8669, Recall: 0.8652, F1: 0.8651
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1137, Accuracy: 0.9423, Precision: 0.9176, Recall: 0.8896, F1: 0.9014
Epoch 42/70
Train Loss: 0.0062, Accuracy: 0.9965, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 0.8144, Accuracy: 0.8378, Precision: 0.8403, Recall: 0.8404, F1: 0.8391
Testing Loss: 0.6730, Accuracy: 0.8701, Precision: 0.8681, Recall: 0.8737, F1: 0.8696
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1561, Accuracy: 0.9135, Precision: 0.9194, Recall: 0.8575, F1: 0.8832
Epoch 43/70
Train Loss: 0.0062, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 0.8251, Accuracy: 0.8478, Precision: 0.8585, Recall: 0.8488, F1: 0.8514
Testing Loss: 0.6820, Accuracy: 0.8601, Precision: 0.8648, Recall: 0.8571, F1: 0.8598
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2375, Accuracy: 0.8558, Precision: 0.9176, Recall: 0.8172, F1: 0.8556
Epoch 44/70
Train Loss: 0.0071, Accuracy: 0.9966, Precision: 0.9969, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.8136, Accuracy: 0.8447, Precision: 0.8510, Recall: 0.8453, F1: 0.8469
Testing Loss: 0.7122, Accuracy: 0.8670, Precision: 0.8738, Recall: 0.8674, F1: 0.8684
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2697, Accuracy: 0.8462, Precision: 0.9167, Recall: 0.8066, F1: 0.8510
Epoch 45/70
Train Loss: 0.0070, Accuracy: 0.9965, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 0.7983, Accuracy: 0.8447, Precision: 0.8487, Recall: 0.8468, F1: 0.8469
Testing Loss: 0.6676, Accuracy: 0.8755, Precision: 0.8762, Recall: 0.8758, F1: 0.8755
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1489, Accuracy: 0.9231, Precision: 0.9164, Recall: 0.8675, F1: 0.8885
Epoch 46/70
Train Loss: 0.0184, Accuracy: 0.9931, Precision: 0.9934, Recall: 0.9934, F1: 0.9934
Validation Loss: 0.8943, Accuracy: 0.7625, Precision: 0.7861, Recall: 0.7461, F1: 0.7502
Testing Loss: 0.8111, Accuracy: 0.7725, Precision: 0.8029, Recall: 0.7552, F1: 0.7568
LM Predictions:  [13, 0, 6, 14, 6, 13, 1, 6, 13, 6, 13, 5, 0, 5, 11, 0, 6, 0, 11, 12, 6, 9, 13, 4, 4, 14, 6, 6, 6, 6, 6, 10, 3, 6, 14, 9, 14, 4, 6, 9, 6, 6, 4, 6, 4, 6, 7, 7, 2, 6, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 6, 6, 6, 6, 11, 0, 0, 5, 3, 6, 7, 9, 8, 8, 9, 6, 6, 0, 4, 0, 7, 6, 0, 9, 13, 2, 12, 0, 3, 1, 6, 3, 11, 1, 14, 14, 0, 1, 6, 6, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 1.2439, Accuracy: 0.5577, Precision: 0.7866, Recall: 0.5683, F1: 0.6196
Epoch 47/70
Train Loss: 0.0990, Accuracy: 0.9661, Precision: 0.9664, Recall: 0.9662, F1: 0.9662
Validation Loss: 0.8225, Accuracy: 0.8240, Precision: 0.8324, Recall: 0.8229, F1: 0.8259
Testing Loss: 0.7794, Accuracy: 0.8278, Precision: 0.8349, Recall: 0.8263, F1: 0.8276
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 1, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1980, Accuracy: 0.8558, Precision: 0.9138, Recall: 0.8141, F1: 0.8533
Epoch 48/70
Train Loss: 0.0191, Accuracy: 0.9923, Precision: 0.9927, Recall: 0.9925, F1: 0.9926
Validation Loss: 0.8377, Accuracy: 0.8347, Precision: 0.8403, Recall: 0.8325, F1: 0.8351
Testing Loss: 0.7288, Accuracy: 0.8578, Precision: 0.8598, Recall: 0.8543, F1: 0.8558
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1262, Accuracy: 0.9231, Precision: 0.9199, Recall: 0.8725, F1: 0.8921
Epoch 49/70
Train Loss: 0.0143, Accuracy: 0.9938, Precision: 0.9943, Recall: 0.9941, F1: 0.9942
Validation Loss: 0.8733, Accuracy: 0.8148, Precision: 0.8216, Recall: 0.8193, F1: 0.8173
Testing Loss: 0.7430, Accuracy: 0.8486, Precision: 0.8479, Recall: 0.8491, F1: 0.8471
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 14, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 0, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1608, Accuracy: 0.9231, Precision: 0.8994, Recall: 0.8416, F1: 0.8598
Epoch 50/70
Train Loss: 0.0112, Accuracy: 0.9952, Precision: 0.9954, Recall: 0.9954, F1: 0.9954
Validation Loss: 0.8697, Accuracy: 0.8255, Precision: 0.8245, Recall: 0.8261, F1: 0.8227
Testing Loss: 0.7944, Accuracy: 0.8493, Precision: 0.8479, Recall: 0.8472, F1: 0.8460
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1310, Accuracy: 0.9327, Precision: 0.9194, Recall: 0.8799, F1: 0.8957
Epoch 51/70
Train Loss: 0.0363, Accuracy: 0.9880, Precision: 0.9877, Recall: 0.9871, F1: 0.9874
Validation Loss: 0.8760, Accuracy: 0.8278, Precision: 0.8376, Recall: 0.8271, F1: 0.8286
Testing Loss: 0.8087, Accuracy: 0.8409, Precision: 0.8476, Recall: 0.8370, F1: 0.8392
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1351, Accuracy: 0.9423, Precision: 0.9217, Recall: 0.8769, F1: 0.8962
Epoch 52/70
Train Loss: 0.0107, Accuracy: 0.9959, Precision: 0.9960, Recall: 0.9963, F1: 0.9961
Validation Loss: 0.8193, Accuracy: 0.8332, Precision: 0.8372, Recall: 0.8335, F1: 0.8345
Testing Loss: 0.7461, Accuracy: 0.8532, Precision: 0.8620, Recall: 0.8523, F1: 0.8558
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2463, Accuracy: 0.8269, Precision: 0.9155, Recall: 0.7919, F1: 0.8411
Epoch 53/70
Train Loss: 0.0280, Accuracy: 0.9896, Precision: 0.9898, Recall: 0.9900, F1: 0.9899
Validation Loss: 0.8989, Accuracy: 0.8263, Precision: 0.8379, Recall: 0.8228, F1: 0.8262
Testing Loss: 0.8899, Accuracy: 0.8363, Precision: 0.8467, Recall: 0.8343, F1: 0.8353
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 6, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1813, Accuracy: 0.8846, Precision: 0.9204, Recall: 0.8235, F1: 0.8650
Epoch 54/70
Train Loss: 0.0282, Accuracy: 0.9904, Precision: 0.9910, Recall: 0.9908, F1: 0.9909
Validation Loss: 0.8329, Accuracy: 0.8324, Precision: 0.8385, Recall: 0.8342, F1: 0.8336
Testing Loss: 0.7402, Accuracy: 0.8478, Precision: 0.8518, Recall: 0.8508, F1: 0.8492
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1724, Accuracy: 0.8750, Precision: 0.9155, Recall: 0.8257, F1: 0.8627
Epoch 55/70
Train Loss: 0.0191, Accuracy: 0.9918, Precision: 0.9918, Recall: 0.9921, F1: 0.9920
Validation Loss: 0.9579, Accuracy: 0.8086, Precision: 0.8208, Recall: 0.8047, F1: 0.8088
Testing Loss: 0.8729, Accuracy: 0.8271, Precision: 0.8386, Recall: 0.8239, F1: 0.8267
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2135, Accuracy: 0.8654, Precision: 0.9167, Recall: 0.8283, F1: 0.8642
Epoch 56/70
Train Loss: 0.0203, Accuracy: 0.9917, Precision: 0.9923, Recall: 0.9921, F1: 0.9922
Validation Loss: 0.8990, Accuracy: 0.8140, Precision: 0.8219, Recall: 0.8138, F1: 0.8111
Testing Loss: 0.9024, Accuracy: 0.8286, Precision: 0.8329, Recall: 0.8277, F1: 0.8241
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 13, 7, 5, 6, 5, 4, 10, 7, 6, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2599, Accuracy: 0.8750, Precision: 0.9102, Recall: 0.8305, F1: 0.8632
Epoch 57/70
Train Loss: 0.0264, Accuracy: 0.9899, Precision: 0.9904, Recall: 0.9904, F1: 0.9904
Validation Loss: 0.8594, Accuracy: 0.8294, Precision: 0.8333, Recall: 0.8300, F1: 0.8285
Testing Loss: 0.8106, Accuracy: 0.8447, Precision: 0.8474, Recall: 0.8442, F1: 0.8439
LM Predictions:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1422, Accuracy: 0.9231, Precision: 0.9273, Recall: 0.8680, F1: 0.8928
Epoch 58/70
Train Loss: 0.0089, Accuracy: 0.9956, Precision: 0.9958, Recall: 0.9958, F1: 0.9958
Validation Loss: 0.9270, Accuracy: 0.8224, Precision: 0.8334, Recall: 0.8206, F1: 0.8231
Testing Loss: 0.8865, Accuracy: 0.8370, Precision: 0.8501, Recall: 0.8350, F1: 0.8386
LM Predictions:  [13, 1, 6, 14, 3, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1216, Accuracy: 0.9615, Precision: 0.9217, Recall: 0.8985, F1: 0.9078
Epoch 59/70
Train Loss: 0.0085, Accuracy: 0.9960, Precision: 0.9962, Recall: 0.9962, F1: 0.9962
Validation Loss: 0.9968, Accuracy: 0.8178, Precision: 0.8197, Recall: 0.8220, F1: 0.8128
Testing Loss: 0.8846, Accuracy: 0.8432, Precision: 0.8445, Recall: 0.8477, F1: 0.8391
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1371, Accuracy: 0.9231, Precision: 0.9176, Recall: 0.8749, F1: 0.8935
Epoch 60/70
Train Loss: 0.0426, Accuracy: 0.9852, Precision: 0.9851, Recall: 0.9852, F1: 0.9852
Validation Loss: 0.8661, Accuracy: 0.8140, Precision: 0.8131, Recall: 0.8159, F1: 0.8114
Testing Loss: 0.8496, Accuracy: 0.8363, Precision: 0.8364, Recall: 0.8377, F1: 0.8342
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 0, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 11, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2034, Accuracy: 0.8558, Precision: 0.8952, Recall: 0.8071, F1: 0.8423
Epoch 61/70
Train Loss: 0.0165, Accuracy: 0.9934, Precision: 0.9937, Recall: 0.9937, F1: 0.9937
Validation Loss: 1.0231, Accuracy: 0.7978, Precision: 0.8162, Recall: 0.7967, F1: 0.7970
Testing Loss: 0.9293, Accuracy: 0.8263, Precision: 0.8372, Recall: 0.8252, F1: 0.8241
LM Predictions:  [13, 8, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 1, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 14, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2316, Accuracy: 0.8846, Precision: 0.8773, Recall: 0.8355, F1: 0.8468
Epoch 62/70
Train Loss: 0.0132, Accuracy: 0.9941, Precision: 0.9944, Recall: 0.9943, F1: 0.9944
Validation Loss: 0.8483, Accuracy: 0.8378, Precision: 0.8385, Recall: 0.8371, F1: 0.8360
Testing Loss: 0.7488, Accuracy: 0.8540, Precision: 0.8595, Recall: 0.8554, F1: 0.8555
LM Predictions:  [13, 1, 10, 14, 3, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1216, Accuracy: 0.9423, Precision: 0.9176, Recall: 0.8856, F1: 0.8984
Epoch 63/70
Train Loss: 0.0058, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.8550, Accuracy: 0.8355, Precision: 0.8397, Recall: 0.8340, F1: 0.8343
Testing Loss: 0.7362, Accuracy: 0.8624, Precision: 0.8666, Recall: 0.8603, F1: 0.8622
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 6, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2165, Accuracy: 0.8750, Precision: 0.9199, Recall: 0.8256, F1: 0.8615
Epoch 64/70
Train Loss: 0.0075, Accuracy: 0.9960, Precision: 0.9963, Recall: 0.9963, F1: 0.9963
Validation Loss: 0.8130, Accuracy: 0.8424, Precision: 0.8439, Recall: 0.8397, F1: 0.8408
Testing Loss: 0.7626, Accuracy: 0.8524, Precision: 0.8597, Recall: 0.8489, F1: 0.8529
LM Predictions:  [13, 1, 6, 14, 3, 6, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1860, Accuracy: 0.8750, Precision: 0.9167, Recall: 0.8319, F1: 0.8667
Epoch 65/70
Train Loss: 0.0059, Accuracy: 0.9964, Precision: 0.9968, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.8054, Accuracy: 0.8440, Precision: 0.8433, Recall: 0.8418, F1: 0.8417
Testing Loss: 0.7457, Accuracy: 0.8593, Precision: 0.8656, Recall: 0.8578, F1: 0.8606
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1468, Accuracy: 0.9135, Precision: 0.9167, Recall: 0.8707, F1: 0.8888
Epoch 66/70
Train Loss: 0.0060, Accuracy: 0.9962, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 0.8099, Accuracy: 0.8440, Precision: 0.8436, Recall: 0.8412, F1: 0.8412
Testing Loss: 0.7446, Accuracy: 0.8570, Precision: 0.8632, Recall: 0.8565, F1: 0.8584
LM Predictions:  [13, 1, 10, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 4, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2264, Accuracy: 0.8654, Precision: 0.9176, Recall: 0.8267, F1: 0.8597
Epoch 67/70
Train Loss: 0.0066, Accuracy: 0.9966, Precision: 0.9970, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.7915, Accuracy: 0.8455, Precision: 0.8465, Recall: 0.8446, F1: 0.8444
Testing Loss: 0.7454, Accuracy: 0.8540, Precision: 0.8597, Recall: 0.8545, F1: 0.8558
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 13, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 6, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1608, Accuracy: 0.9038, Precision: 0.9183, Recall: 0.8575, F1: 0.8824
Epoch 68/70
Train Loss: 0.0066, Accuracy: 0.9966, Precision: 0.9969, Recall: 0.9968, F1: 0.9969
Validation Loss: 0.8214, Accuracy: 0.8424, Precision: 0.8410, Recall: 0.8447, F1: 0.8406
Testing Loss: 0.7627, Accuracy: 0.8578, Precision: 0.8608, Recall: 0.8587, F1: 0.8576
LM Predictions:  [13, 1, 6, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 4, 9, 13, 1, 4, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.1617, Accuracy: 0.9135, Precision: 0.9164, Recall: 0.8548, F1: 0.8793
Epoch 69/70
Train Loss: 0.0064, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.8117, Accuracy: 0.8432, Precision: 0.8458, Recall: 0.8436, F1: 0.8425
Testing Loss: 0.7447, Accuracy: 0.8532, Precision: 0.8577, Recall: 0.8549, F1: 0.8550
LM Predictions:  [13, 1, 6, 14, 6, 6, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 6, 9, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2633, Accuracy: 0.8462, Precision: 0.9185, Recall: 0.8069, F1: 0.8503
Epoch 70/70
Train Loss: 0.0675, Accuracy: 0.9764, Precision: 0.9771, Recall: 0.9765, F1: 0.9768
Validation Loss: 0.8990, Accuracy: 0.8155, Precision: 0.8168, Recall: 0.8136, F1: 0.8125
Testing Loss: 0.8627, Accuracy: 0.8248, Precision: 0.8291, Recall: 0.8253, F1: 0.8247
LM Predictions:  [13, 1, 10, 14, 6, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 6, 12, 13, 6, 13, 4, 6, 14, 12, 5, 3, 6, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 6, 4, 6, 7, 7, 2, 10, 13, 7, 10, 8, 0, 9, 9, 12, 2, 6, 12, 6, 13, 5, 5, 12, 6, 11, 10, 10, 5, 3, 6, 7, 9, 8, 14, 7, 5, 12, 5, 4, 6, 7, 0, 3, 9, 0, 2, 12, 1, 3, 1, 10, 1, 6, 1, 9, 13, 1, 1, 9, 7, 0]
LM Labels:  [13, 1, 10, 14, 3, 13, 1, 0, 0, 3, 13, 5, 0, 5, 11, 5, 5, 0, 11, 12, 13, 9, 13, 4, 4, 14, 12, 5, 3, 3, 10, 10, 3, 2, 14, 9, 7, 4, 7, 9, 0, 11, 4, 3, 4, 1, 7, 7, 2, 10, 13, 1, 10, 8, 0, 9, 9, 12, 2, 13, 12, 13, 13, 5, 5, 12, 7, 11, 10, 10, 5, 3, 1, 7, 9, 8, 14, 7, 5, 12, 5, 4, 10, 7, 0, 3, 9, 13, 2, 12, 1, 3, 1, 10, 1, 11, 4, 9, 13, 1, 1, 9, 7, 0]
LM Loss: 0.2412, Accuracy: 0.8462, Precision: 0.9102, Recall: 0.8050, F1: 0.8477
