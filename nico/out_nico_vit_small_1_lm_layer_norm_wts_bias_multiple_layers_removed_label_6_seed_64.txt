13007 13007
10405 10405 2602 2602
Model: facebook/vit-msn-small, Batch size: 16, Epochs: 70
Learning rate: 2e-05, Device: cuda:0
Noise: 1% with label 6
Label counts for Train:
  Label 12: 618
  Label 10: 818
  Label 6: 924
  Label 7: 469
  Label 9: 900
  Label 0: 819
  Label 2: 534
  Label 3: 707
  Label 13: 834
  Label 14: 664
  Label 8: 433
  Label 5: 379
  Label 4: 808
  Label 1: 789
  Label 11: 709
Label counts for Validation:
  Label 13: 105
  Label 14: 83
  Label 12: 77
  Label 6: 115
  Label 8: 54
  Label 3: 89
  Label 1: 98
  Label 9: 112
  Label 0: 103
  Label 7: 59
  Label 4: 101
  Label 5: 47
  Label 11: 88
  Label 10: 103
  Label 2: 67
Label counts for Test:
  Label 2: 67
  Label 9: 113
  Label 4: 101
  Label 12: 78
  Label 14: 83
  Label 10: 102
  Label 11: 89
  Label 13: 104
  Label 7: 58
  Label 6: 116
  Label 8: 54
  Label 0: 102
  Label 1: 99
  Label 3: 88
  Label 5: 47
104
Actual labels:  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
Label counts for Train:
  Label 12: 624
  Label 10: 826
  Label 6: 820
  Label 7: 476
  Label 9: 909
  Label 0: 826
  Label 2: 540
  Label 14: 672
  Label 3: 715
  Label 13: 841
  Label 8: 438
  Label 5: 383
  Label 4: 815
  Label 1: 803
  Label 11: 717
10405
(3, 224, 224)
For early layers:  [0, 1, 2, 3]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 2.0983, Accuracy: 0.3207, Precision: 0.3260, Recall: 0.3051, F1: 0.3034
Validation Loss: 1.6148, Accuracy: 0.4927, Precision: 0.5082, Recall: 0.4854, F1: 0.4775
Testing Loss: 1.6463, Accuracy: 0.4858, Precision: 0.4876, Recall: 0.4839, F1: 0.4702
LM Predictions:  [6, 3, 0, 6, 6, 5, 6, 14, 6, 6, 6, 6, 9, 5, 3, 6, 6, 2, 6, 12, 4, 6, 6, 4, 6, 13, 9, 0, 0, 6, 6, 6, 9, 6, 3, 6, 0, 5, 4, 13, 6, 12, 9, 13, 6, 3, 0, 3, 13, 2, 0, 0, 0, 0, 0, 0, 3, 13, 0, 6, 6, 0, 1, 3, 9, 6, 0, 6, 6, 7, 14, 0, 6, 6, 0, 0, 0, 6, 8, 6, 4, 8, 0, 6, 13, 6, 3, 6, 3, 0, 4, 4, 0, 9, 0, 6, 0, 5, 12, 6, 9, 0, 4, 13]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 3.6286, Accuracy: 0.0673, Precision: 0.1357, Recall: 0.0630, F1: 0.0650
Epoch 2/70
Train Loss: 1.4039, Accuracy: 0.5541, Precision: 0.5546, Recall: 0.5459, F1: 0.5481
Validation Loss: 1.1791, Accuracy: 0.6311, Precision: 0.6468, Recall: 0.6266, F1: 0.6246
Testing Loss: 1.1879, Accuracy: 0.6326, Precision: 0.6533, Recall: 0.6343, F1: 0.6318
LM Predictions:  [6, 0, 0, 0, 0, 14, 13, 14, 6, 0, 6, 6, 0, 4, 6, 6, 4, 3, 0, 11, 4, 0, 6, 4, 6, 6, 0, 0, 0, 6, 6, 14, 14, 6, 14, 0, 6, 6, 14, 6, 6, 12, 0, 13, 6, 6, 0, 0, 6, 14, 0, 0, 0, 0, 6, 0, 14, 6, 0, 0, 6, 0, 1, 14, 11, 0, 0, 6, 13, 13, 14, 0, 6, 6, 0, 6, 6, 14, 0, 0, 0, 0, 13, 14, 6, 6, 0, 2, 14, 0, 0, 4, 6, 13, 12, 6, 0, 0, 12, 6, 13, 6, 4, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 3.7308, Accuracy: 0.0865, Precision: 0.1312, Recall: 0.0841, F1: 0.0639
Epoch 3/70
Train Loss: 0.9147, Accuracy: 0.7094, Precision: 0.7127, Recall: 0.7056, F1: 0.7082
Validation Loss: 0.9815, Accuracy: 0.6849, Precision: 0.7113, Recall: 0.6762, F1: 0.6879
Testing Loss: 0.9750, Accuracy: 0.6918, Precision: 0.7207, Recall: 0.6873, F1: 0.6985
LM Predictions:  [6, 0, 0, 6, 0, 6, 0, 14, 6, 0, 9, 6, 0, 6, 6, 6, 4, 8, 9, 11, 11, 6, 6, 6, 6, 6, 0, 0, 2, 6, 6, 6, 6, 0, 6, 6, 6, 6, 9, 6, 6, 6, 0, 6, 6, 6, 0, 0, 6, 9, 6, 6, 0, 0, 6, 6, 0, 6, 0, 0, 1, 0, 8, 14, 6, 6, 0, 6, 6, 13, 14, 0, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 2, 14, 0, 0, 6, 0, 9, 0, 6, 6, 9, 6, 6, 9, 6, 6, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 3.4942, Accuracy: 0.1154, Precision: 0.1838, Recall: 0.1062, F1: 0.0996
Epoch 4/70
Train Loss: 0.5237, Accuracy: 0.8447, Precision: 0.8487, Recall: 0.8445, F1: 0.8465
Validation Loss: 0.8888, Accuracy: 0.7179, Precision: 0.7421, Recall: 0.7133, F1: 0.7186
Testing Loss: 0.8363, Accuracy: 0.7264, Precision: 0.7475, Recall: 0.7245, F1: 0.7285
LM Predictions:  [13, 4, 6, 6, 4, 4, 0, 14, 0, 0, 9, 6, 0, 0, 6, 0, 6, 4, 9, 8, 11, 6, 0, 4, 6, 13, 0, 0, 2, 6, 6, 0, 4, 9, 6, 6, 0, 14, 14, 3, 6, 6, 0, 13, 4, 10, 0, 1, 6, 14, 0, 0, 0, 0, 13, 0, 14, 6, 0, 0, 1, 1, 1, 0, 14, 11, 14, 6, 3, 13, 0, 0, 6, 0, 11, 2, 0, 6, 0, 0, 0, 0, 0, 14, 0, 0, 10, 1, 6, 0, 1, 6, 0, 14, 0, 6, 8, 9, 6, 6, 6, 0, 6, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 2.3513, Accuracy: 0.2981, Precision: 0.4610, Recall: 0.2687, F1: 0.2914
Epoch 5/70
Train Loss: 0.2358, Accuracy: 0.9400, Precision: 0.9428, Recall: 0.9395, F1: 0.9411
Validation Loss: 0.9267, Accuracy: 0.7202, Precision: 0.7338, Recall: 0.7212, F1: 0.7196
Testing Loss: 0.8928, Accuracy: 0.7387, Precision: 0.7538, Recall: 0.7449, F1: 0.7395
LM Predictions:  [13, 4, 2, 6, 4, 10, 3, 14, 5, 11, 9, 6, 0, 2, 6, 6, 4, 4, 9, 8, 11, 1, 6, 6, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 6, 13, 13, 11, 6, 13, 12, 6, 6, 4, 6, 14, 1, 6, 6, 6, 6, 13, 0, 13, 6, 14, 6, 0, 1, 11, 1, 1, 0, 14, 9, 14, 6, 3, 11, 6, 1, 6, 6, 6, 2, 6, 12, 10, 6, 3, 1, 0, 2, 6, 0, 10, 1, 5, 0, 1, 6, 14, 9, 14, 6, 8, 12, 6, 6, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.2027, Accuracy: 0.6346, Precision: 0.8533, Recall: 0.5921, F1: 0.6681
Epoch 6/70
Train Loss: 0.1034, Accuracy: 0.9802, Precision: 0.9815, Recall: 0.9803, F1: 0.9809
Validation Loss: 0.9718, Accuracy: 0.7333, Precision: 0.7394, Recall: 0.7313, F1: 0.7295
Testing Loss: 0.9530, Accuracy: 0.7456, Precision: 0.7501, Recall: 0.7495, F1: 0.7419
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 6, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 6, 13, 11, 10, 13, 12, 0, 13, 4, 10, 7, 1, 13, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 10, 1, 1, 14, 7, 11, 2, 3, 12, 6, 11, 3, 1, 12, 2, 11, 6, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.4917, Accuracy: 0.8654, Precision: 0.8963, Recall: 0.8179, F1: 0.8505
Epoch 7/70
Train Loss: 0.0905, Accuracy: 0.9791, Precision: 0.9804, Recall: 0.9795, F1: 0.9799
Validation Loss: 1.1732, Accuracy: 0.6933, Precision: 0.7364, Recall: 0.6925, F1: 0.7018
Testing Loss: 1.1107, Accuracy: 0.7010, Precision: 0.7481, Recall: 0.7073, F1: 0.7157
LM Predictions:  [13, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 6, 3, 4, 4, 14, 8, 11, 6, 6, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 6, 13, 14, 0, 13, 12, 6, 13, 4, 10, 7, 1, 7, 14, 14, 6, 13, 0, 13, 13, 14, 6, 0, 0, 11, 0, 1, 0, 6, 14, 14, 10, 6, 0, 12, 0, 14, 6, 7, 2, 3, 0, 10, 11, 0, 1, 12, 14, 11, 0, 10, 1, 5, 0, 0, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.9371, Accuracy: 0.7019, Precision: 0.8435, Recall: 0.6814, F1: 0.7259
Epoch 8/70
Train Loss: 0.1049, Accuracy: 0.9716, Precision: 0.9729, Recall: 0.9727, F1: 0.9728
Validation Loss: 1.1664, Accuracy: 0.7048, Precision: 0.7299, Recall: 0.6984, F1: 0.7025
Testing Loss: 1.1238, Accuracy: 0.7095, Precision: 0.7456, Recall: 0.7061, F1: 0.7116
LM Predictions:  [8, 4, 2, 10, 6, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 6, 7, 6, 13, 13, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 14, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 9, 11, 12, 1, 14, 7, 6, 2, 13, 12, 10, 11, 3, 1, 12, 2, 11, 6, 10, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 12, 9, 12, 3, 13, 13]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.4386, Accuracy: 0.8558, Precision: 0.8881, Recall: 0.8102, F1: 0.8336
Epoch 9/70
Train Loss: 0.0781, Accuracy: 0.9796, Precision: 0.9806, Recall: 0.9805, F1: 0.9806
Validation Loss: 1.2355, Accuracy: 0.7041, Precision: 0.7314, Recall: 0.7070, F1: 0.7026
Testing Loss: 1.1867, Accuracy: 0.7071, Precision: 0.7434, Recall: 0.7110, F1: 0.7099
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 4, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3692, Accuracy: 0.9231, Precision: 0.9250, Recall: 0.8616, F1: 0.8891
Epoch 10/70
Train Loss: 0.0718, Accuracy: 0.9790, Precision: 0.9794, Recall: 0.9795, F1: 0.9795
Validation Loss: 1.0845, Accuracy: 0.7233, Precision: 0.7249, Recall: 0.7248, F1: 0.7217
Testing Loss: 0.9958, Accuracy: 0.7548, Precision: 0.7544, Recall: 0.7590, F1: 0.7541
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 6, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2434, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8770, F1: 0.9024
Epoch 11/70
Train Loss: 0.0640, Accuracy: 0.9807, Precision: 0.9811, Recall: 0.9811, F1: 0.9811
Validation Loss: 1.1521, Accuracy: 0.7271, Precision: 0.7339, Recall: 0.7296, F1: 0.7261
Testing Loss: 1.0711, Accuracy: 0.7410, Precision: 0.7439, Recall: 0.7488, F1: 0.7411
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 3, 9, 4, 9, 7, 10, 1, 13, 14, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2345, Accuracy: 0.9327, Precision: 0.9176, Recall: 0.8587, F1: 0.8835
Epoch 12/70
Train Loss: 0.0247, Accuracy: 0.9943, Precision: 0.9946, Recall: 0.9946, F1: 0.9946
Validation Loss: 1.0764, Accuracy: 0.7294, Precision: 0.7410, Recall: 0.7310, F1: 0.7324
Testing Loss: 1.0164, Accuracy: 0.7602, Precision: 0.7687, Recall: 0.7643, F1: 0.7641
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1916, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8997, F1: 0.9154
Epoch 13/70
Train Loss: 0.0921, Accuracy: 0.9713, Precision: 0.9723, Recall: 0.9722, F1: 0.9722
Validation Loss: 1.2126, Accuracy: 0.7187, Precision: 0.7358, Recall: 0.7164, F1: 0.7158
Testing Loss: 1.1169, Accuracy: 0.7356, Precision: 0.7460, Recall: 0.7385, F1: 0.7327
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 6, 4, 9, 8, 11, 1, 1, 6, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 6, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 6, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3067, Accuracy: 0.9038, Precision: 0.9333, Recall: 0.8401, F1: 0.8808
Epoch 14/70
Train Loss: 0.0511, Accuracy: 0.9849, Precision: 0.9847, Recall: 0.9850, F1: 0.9849
Validation Loss: 1.2182, Accuracy: 0.7256, Precision: 0.7387, Recall: 0.7262, F1: 0.7257
Testing Loss: 1.1509, Accuracy: 0.7394, Precision: 0.7589, Recall: 0.7416, F1: 0.7405
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 11, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3295, Accuracy: 0.9038, Precision: 0.9259, Recall: 0.8374, F1: 0.8730
Epoch 15/70
Train Loss: 0.0634, Accuracy: 0.9797, Precision: 0.9800, Recall: 0.9799, F1: 0.9799
Validation Loss: 1.2932, Accuracy: 0.6902, Precision: 0.7091, Recall: 0.6935, F1: 0.6917
Testing Loss: 1.1531, Accuracy: 0.7248, Precision: 0.7429, Recall: 0.7296, F1: 0.7286
LM Predictions:  [8, 4, 0, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 2, 9, 8, 11, 6, 1, 6, 6, 6, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 0, 12, 0, 9, 4, 10, 7, 1, 7, 6, 0, 0, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3404, Accuracy: 0.8846, Precision: 0.8980, Recall: 0.8291, F1: 0.8538
Epoch 16/70
Train Loss: 0.0545, Accuracy: 0.9834, Precision: 0.9833, Recall: 0.9831, F1: 0.9832
Validation Loss: 1.1527, Accuracy: 0.7356, Precision: 0.7411, Recall: 0.7344, F1: 0.7349
Testing Loss: 1.1340, Accuracy: 0.7533, Precision: 0.7627, Recall: 0.7604, F1: 0.7566
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2125, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8690, F1: 0.8975
Epoch 17/70
Train Loss: 0.0245, Accuracy: 0.9926, Precision: 0.9925, Recall: 0.9925, F1: 0.9925
Validation Loss: 1.2764, Accuracy: 0.7118, Precision: 0.7185, Recall: 0.7125, F1: 0.7083
Testing Loss: 1.2249, Accuracy: 0.7371, Precision: 0.7434, Recall: 0.7402, F1: 0.7338
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1271, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8960, F1: 0.9133
Epoch 18/70
Train Loss: 0.0504, Accuracy: 0.9838, Precision: 0.9843, Recall: 0.9839, F1: 0.9841
Validation Loss: 1.2365, Accuracy: 0.7341, Precision: 0.7415, Recall: 0.7373, F1: 0.7340
Testing Loss: 1.2355, Accuracy: 0.7364, Precision: 0.7419, Recall: 0.7423, F1: 0.7376
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 13, 9, 0, 0, 2, 11, 13, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 0, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 14, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 6, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3182, Accuracy: 0.8942, Precision: 0.9007, Recall: 0.8386, F1: 0.8613
Epoch 19/70
Train Loss: 0.0581, Accuracy: 0.9819, Precision: 0.9823, Recall: 0.9823, F1: 0.9823
Validation Loss: 1.4347, Accuracy: 0.6972, Precision: 0.7418, Recall: 0.6882, F1: 0.6950
Testing Loss: 1.3380, Accuracy: 0.7002, Precision: 0.7513, Recall: 0.6975, F1: 0.7024
LM Predictions:  [8, 4, 2, 10, 4, 10, 0, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 3, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 0, 13, 11, 10, 13, 6, 6, 9, 0, 10, 7, 1, 7, 14, 14, 3, 13, 0, 6, 13, 1, 2, 0, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2690, Accuracy: 0.8846, Precision: 0.8919, Recall: 0.8275, F1: 0.8502
Epoch 20/70
Train Loss: 0.0337, Accuracy: 0.9900, Precision: 0.9900, Recall: 0.9897, F1: 0.9898
Validation Loss: 1.1443, Accuracy: 0.7487, Precision: 0.7457, Recall: 0.7491, F1: 0.7454
Testing Loss: 1.1018, Accuracy: 0.7525, Precision: 0.7501, Recall: 0.7592, F1: 0.7518
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 13, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0883, Accuracy: 0.9615, Precision: 0.9250, Recall: 0.8942, F1: 0.9065
Epoch 21/70
Train Loss: 0.0474, Accuracy: 0.9845, Precision: 0.9848, Recall: 0.9847, F1: 0.9847
Validation Loss: 1.2204, Accuracy: 0.7256, Precision: 0.7292, Recall: 0.7272, F1: 0.7238
Testing Loss: 1.1644, Accuracy: 0.7356, Precision: 0.7375, Recall: 0.7344, F1: 0.7289
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1642, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8694, F1: 0.8989
Epoch 22/70
Train Loss: 0.0519, Accuracy: 0.9832, Precision: 0.9835, Recall: 0.9837, F1: 0.9836
Validation Loss: 1.3523, Accuracy: 0.7064, Precision: 0.7234, Recall: 0.7054, F1: 0.7015
Testing Loss: 1.2672, Accuracy: 0.7210, Precision: 0.7422, Recall: 0.7218, F1: 0.7209
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 7, 4, 3, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 4, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 6, 3, 13, 0, 13, 6, 1, 6, 4, 1, 11, 1, 1, 3, 6, 9, 14, 10, 3, 11, 4, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 13, 12, 2, 11, 8, 10, 1, 5, 0, 1, 4, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3493, Accuracy: 0.8654, Precision: 0.8779, Recall: 0.8044, F1: 0.8256
Epoch 23/70
Train Loss: 0.0407, Accuracy: 0.9869, Precision: 0.9873, Recall: 0.9871, F1: 0.9872
Validation Loss: 1.3205, Accuracy: 0.7233, Precision: 0.7343, Recall: 0.7301, F1: 0.7198
Testing Loss: 1.2151, Accuracy: 0.7341, Precision: 0.7413, Recall: 0.7391, F1: 0.7316
LM Predictions:  [8, 6, 6, 10, 4, 10, 7, 8, 5, 11, 9, 0, 7, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 6, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 11, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 6, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 9, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3025, Accuracy: 0.8846, Precision: 0.9081, Recall: 0.8209, F1: 0.8585
Epoch 24/70
Train Loss: 0.0359, Accuracy: 0.9870, Precision: 0.9874, Recall: 0.9871, F1: 0.9873
Validation Loss: 1.2571, Accuracy: 0.7279, Precision: 0.7328, Recall: 0.7319, F1: 0.7264
Testing Loss: 1.2284, Accuracy: 0.7279, Precision: 0.7356, Recall: 0.7419, F1: 0.7278
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 0, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 1, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 0, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 13, 14, 7, 6, 2, 0, 12, 0, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 0, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1700, Accuracy: 0.9038, Precision: 0.8925, Recall: 0.8466, F1: 0.8607
Epoch 25/70
Train Loss: 0.0320, Accuracy: 0.9895, Precision: 0.9904, Recall: 0.9900, F1: 0.9902
Validation Loss: 1.3852, Accuracy: 0.7118, Precision: 0.7302, Recall: 0.7137, F1: 0.7134
Testing Loss: 1.3229, Accuracy: 0.7133, Precision: 0.7307, Recall: 0.7231, F1: 0.7194
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 13, 9, 0, 0, 2, 3, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 0, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 10, 3, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1667, Accuracy: 0.9231, Precision: 0.8933, Recall: 0.8735, F1: 0.8807
Epoch 26/70
Train Loss: 0.0371, Accuracy: 0.9880, Precision: 0.9881, Recall: 0.9879, F1: 0.9880
Validation Loss: 1.2327, Accuracy: 0.7333, Precision: 0.7489, Recall: 0.7282, F1: 0.7328
Testing Loss: 1.2575, Accuracy: 0.7379, Precision: 0.7516, Recall: 0.7309, F1: 0.7340
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 4, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1776, Accuracy: 0.9231, Precision: 0.9238, Recall: 0.8644, F1: 0.8901
Epoch 27/70
Train Loss: 0.0444, Accuracy: 0.9853, Precision: 0.9859, Recall: 0.9858, F1: 0.9859
Validation Loss: 1.3230, Accuracy: 0.7225, Precision: 0.7418, Recall: 0.7212, F1: 0.7244
Testing Loss: 1.2933, Accuracy: 0.7264, Precision: 0.7411, Recall: 0.7245, F1: 0.7264
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 0, 0, 13, 6, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 5, 6, 9, 2, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2335, Accuracy: 0.9135, Precision: 0.8994, Recall: 0.8472, F1: 0.8650
Epoch 28/70
Train Loss: 0.0298, Accuracy: 0.9908, Precision: 0.9911, Recall: 0.9912, F1: 0.9912
Validation Loss: 1.2245, Accuracy: 0.7310, Precision: 0.7448, Recall: 0.7255, F1: 0.7300
Testing Loss: 1.2540, Accuracy: 0.7341, Precision: 0.7509, Recall: 0.7301, F1: 0.7326
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 6, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2244, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8521, F1: 0.8878
Epoch 29/70
Train Loss: 0.0389, Accuracy: 0.9870, Precision: 0.9870, Recall: 0.9870, F1: 0.9870
Validation Loss: 1.2485, Accuracy: 0.7410, Precision: 0.7437, Recall: 0.7471, F1: 0.7411
Testing Loss: 1.1571, Accuracy: 0.7510, Precision: 0.7499, Recall: 0.7611, F1: 0.7507
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1188, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8700, F1: 0.8980
Epoch 30/70
Train Loss: 0.0150, Accuracy: 0.9948, Precision: 0.9947, Recall: 0.9948, F1: 0.9947
Validation Loss: 1.2243, Accuracy: 0.7525, Precision: 0.7548, Recall: 0.7499, F1: 0.7497
Testing Loss: 1.1400, Accuracy: 0.7533, Precision: 0.7539, Recall: 0.7518, F1: 0.7478
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0844, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8980, F1: 0.9131
Epoch 31/70
Train Loss: 0.0500, Accuracy: 0.9829, Precision: 0.9824, Recall: 0.9826, F1: 0.9825
Validation Loss: 1.3020, Accuracy: 0.7056, Precision: 0.7175, Recall: 0.6995, F1: 0.7042
Testing Loss: 1.2578, Accuracy: 0.7018, Precision: 0.7167, Recall: 0.6992, F1: 0.7032
LM Predictions:  [8, 4, 2, 10, 4, 10, 14, 8, 5, 11, 9, 0, 0, 2, 11, 6, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 2, 1, 2, 5, 5, 6, 4, 6, 7, 10, 1, 13, 11, 10, 13, 6, 0, 13, 4, 10, 7, 1, 6, 9, 14, 6, 13, 0, 13, 13, 1, 6, 13, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 6, 6, 2, 3, 12, 0, 11, 3, 1, 12, 2, 11, 6, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.5023, Accuracy: 0.8462, Precision: 0.8917, Recall: 0.7835, F1: 0.8198
Epoch 32/70
Train Loss: 0.0373, Accuracy: 0.9877, Precision: 0.9878, Recall: 0.9873, F1: 0.9875
Validation Loss: 1.1805, Accuracy: 0.7471, Precision: 0.7566, Recall: 0.7468, F1: 0.7485
Testing Loss: 1.1536, Accuracy: 0.7617, Precision: 0.7646, Recall: 0.7644, F1: 0.7613
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1757, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8985, F1: 0.9147
Epoch 33/70
Train Loss: 0.0228, Accuracy: 0.9915, Precision: 0.9916, Recall: 0.9916, F1: 0.9916
Validation Loss: 1.3385, Accuracy: 0.7279, Precision: 0.7352, Recall: 0.7324, F1: 0.7251
Testing Loss: 1.3343, Accuracy: 0.7333, Precision: 0.7417, Recall: 0.7422, F1: 0.7317
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 6, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1220, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8755, F1: 0.9018
Epoch 34/70
Train Loss: 0.0397, Accuracy: 0.9868, Precision: 0.9873, Recall: 0.9874, F1: 0.9874
Validation Loss: 1.3645, Accuracy: 0.7302, Precision: 0.7567, Recall: 0.7261, F1: 0.7319
Testing Loss: 1.2612, Accuracy: 0.7302, Precision: 0.7535, Recall: 0.7305, F1: 0.7334
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 0, 1, 0, 14, 9, 14, 10, 3, 11, 12, 0, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 2, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1914, Accuracy: 0.9231, Precision: 0.9056, Recall: 0.8758, F1: 0.8882
Epoch 35/70
Train Loss: 0.0375, Accuracy: 0.9875, Precision: 0.9879, Recall: 0.9877, F1: 0.9878
Validation Loss: 1.3417, Accuracy: 0.7333, Precision: 0.7456, Recall: 0.7285, F1: 0.7290
Testing Loss: 1.2212, Accuracy: 0.7341, Precision: 0.7497, Recall: 0.7413, F1: 0.7373
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 13, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 14, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 6, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2164, Accuracy: 0.9135, Precision: 0.9167, Recall: 0.8429, F1: 0.8745
Epoch 36/70
Train Loss: 0.0299, Accuracy: 0.9898, Precision: 0.9903, Recall: 0.9902, F1: 0.9902
Validation Loss: 1.3409, Accuracy: 0.7210, Precision: 0.7337, Recall: 0.7156, F1: 0.7198
Testing Loss: 1.3172, Accuracy: 0.7310, Precision: 0.7429, Recall: 0.7264, F1: 0.7303
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 6, 6, 0, 9, 4, 10, 7, 1, 7, 9, 6, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 6, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 6, 8, 10, 1, 5, 0, 1, 14, 14, 9, 6, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2142, Accuracy: 0.8942, Precision: 0.9333, Recall: 0.8298, F1: 0.8757
Epoch 37/70
Train Loss: 0.0357, Accuracy: 0.9870, Precision: 0.9878, Recall: 0.9876, F1: 0.9877
Validation Loss: 1.3484, Accuracy: 0.7317, Precision: 0.7380, Recall: 0.7296, F1: 0.7274
Testing Loss: 1.2926, Accuracy: 0.7387, Precision: 0.7441, Recall: 0.7434, F1: 0.7363
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 2, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 3, 6, 9, 14, 6, 3, 11, 1, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1721, Accuracy: 0.8942, Precision: 0.9107, Recall: 0.8333, F1: 0.8635
Epoch 38/70
Train Loss: 0.0359, Accuracy: 0.9873, Precision: 0.9879, Recall: 0.9877, F1: 0.9878
Validation Loss: 1.2948, Accuracy: 0.7187, Precision: 0.7214, Recall: 0.7255, F1: 0.7165
Testing Loss: 1.2866, Accuracy: 0.7410, Precision: 0.7470, Recall: 0.7509, F1: 0.7400
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 0, 1, 2, 4, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1150, Accuracy: 0.9519, Precision: 0.9167, Recall: 0.8869, F1: 0.8985
Epoch 39/70
Train Loss: 0.0136, Accuracy: 0.9947, Precision: 0.9944, Recall: 0.9947, F1: 0.9945
Validation Loss: 1.1884, Accuracy: 0.7640, Precision: 0.7724, Recall: 0.7618, F1: 0.7641
Testing Loss: 1.1121, Accuracy: 0.7771, Precision: 0.7851, Recall: 0.7828, F1: 0.7824
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1366, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8706, F1: 0.8996
Epoch 40/70
Train Loss: 0.0073, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9969, F1: 0.9968
Validation Loss: 1.2016, Accuracy: 0.7679, Precision: 0.7736, Recall: 0.7667, F1: 0.7665
Testing Loss: 1.1824, Accuracy: 0.7733, Precision: 0.7842, Recall: 0.7775, F1: 0.7750
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1632, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8754, F1: 0.9014
Epoch 41/70
Train Loss: 0.0076, Accuracy: 0.9964, Precision: 0.9967, Recall: 0.9966, F1: 0.9966
Validation Loss: 1.1614, Accuracy: 0.7733, Precision: 0.7721, Recall: 0.7756, F1: 0.7729
Testing Loss: 1.0983, Accuracy: 0.7863, Precision: 0.7874, Recall: 0.7932, F1: 0.7884
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0999, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8886, F1: 0.9093
Epoch 42/70
Train Loss: 0.0071, Accuracy: 0.9965, Precision: 0.9967, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.1661, Accuracy: 0.7725, Precision: 0.7811, Recall: 0.7712, F1: 0.7716
Testing Loss: 1.1107, Accuracy: 0.7855, Precision: 0.7919, Recall: 0.7904, F1: 0.7883
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1488, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8521, F1: 0.8884
Epoch 43/70
Train Loss: 0.0075, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.2100, Accuracy: 0.7663, Precision: 0.7782, Recall: 0.7646, F1: 0.7679
Testing Loss: 1.1296, Accuracy: 0.7825, Precision: 0.7889, Recall: 0.7849, F1: 0.7845
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1344, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8811, F1: 0.9052
Epoch 44/70
Train Loss: 0.0075, Accuracy: 0.9968, Precision: 0.9971, Recall: 0.9970, F1: 0.9970
Validation Loss: 1.1701, Accuracy: 0.7733, Precision: 0.7850, Recall: 0.7702, F1: 0.7728
Testing Loss: 1.2071, Accuracy: 0.7763, Precision: 0.7836, Recall: 0.7815, F1: 0.7780
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1047, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8790, F1: 0.9040
Epoch 45/70
Train Loss: 0.0073, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.1811, Accuracy: 0.7756, Precision: 0.7782, Recall: 0.7734, F1: 0.7740
Testing Loss: 1.1184, Accuracy: 0.7863, Precision: 0.7894, Recall: 0.7897, F1: 0.7875
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1570, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8687, F1: 0.8979
Epoch 46/70
Train Loss: 0.1211, Accuracy: 0.9626, Precision: 0.9619, Recall: 0.9619, F1: 0.9619
Validation Loss: 1.2180, Accuracy: 0.7364, Precision: 0.7360, Recall: 0.7339, F1: 0.7328
Testing Loss: 1.2199, Accuracy: 0.7341, Precision: 0.7491, Recall: 0.7377, F1: 0.7383
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 6, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 0, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1866, Accuracy: 0.9327, Precision: 0.9238, Recall: 0.8731, F1: 0.8967
Epoch 47/70
Train Loss: 0.0270, Accuracy: 0.9914, Precision: 0.9914, Recall: 0.9913, F1: 0.9914
Validation Loss: 1.2966, Accuracy: 0.7271, Precision: 0.7469, Recall: 0.7175, F1: 0.7244
Testing Loss: 1.2362, Accuracy: 0.7510, Precision: 0.7674, Recall: 0.7489, F1: 0.7508
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 11, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1414, Accuracy: 0.9327, Precision: 0.9259, Recall: 0.8694, F1: 0.8941
Epoch 48/70
Train Loss: 0.0087, Accuracy: 0.9964, Precision: 0.9966, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.1826, Accuracy: 0.7487, Precision: 0.7504, Recall: 0.7439, F1: 0.7457
Testing Loss: 1.1059, Accuracy: 0.7771, Precision: 0.7817, Recall: 0.7798, F1: 0.7784
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0702, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9044, F1: 0.9177
Epoch 49/70
Train Loss: 0.0052, Accuracy: 0.9968, Precision: 0.9971, Recall: 0.9969, F1: 0.9970
Validation Loss: 1.1695, Accuracy: 0.7563, Precision: 0.7603, Recall: 0.7548, F1: 0.7558
Testing Loss: 1.1252, Accuracy: 0.7756, Precision: 0.7814, Recall: 0.7823, F1: 0.7785
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0560, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9111, F1: 0.9200
Epoch 50/70
Train Loss: 0.0054, Accuracy: 0.9965, Precision: 0.9966, Recall: 0.9967, F1: 0.9967
Validation Loss: 1.1863, Accuracy: 0.7533, Precision: 0.7547, Recall: 0.7497, F1: 0.7509
Testing Loss: 1.1177, Accuracy: 0.7756, Precision: 0.7806, Recall: 0.7792, F1: 0.7774
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0859, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8906, F1: 0.9092
Epoch 51/70
Train Loss: 0.0058, Accuracy: 0.9963, Precision: 0.9964, Recall: 0.9965, F1: 0.9964
Validation Loss: 1.1826, Accuracy: 0.7656, Precision: 0.7730, Recall: 0.7633, F1: 0.7663
Testing Loss: 1.1298, Accuracy: 0.7825, Precision: 0.7899, Recall: 0.7863, F1: 0.7863
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1620, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8521, F1: 0.8878
Epoch 52/70
Train Loss: 0.0058, Accuracy: 0.9972, Precision: 0.9975, Recall: 0.9973, F1: 0.9974
Validation Loss: 1.1808, Accuracy: 0.7663, Precision: 0.7678, Recall: 0.7611, F1: 0.7627
Testing Loss: 1.1355, Accuracy: 0.7832, Precision: 0.7857, Recall: 0.7866, F1: 0.7833
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0615, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9071, F1: 0.9193
Epoch 53/70
Train Loss: 0.0063, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 1.2062, Accuracy: 0.7679, Precision: 0.7735, Recall: 0.7683, F1: 0.7676
Testing Loss: 1.1550, Accuracy: 0.7840, Precision: 0.7887, Recall: 0.7889, F1: 0.7856
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0937, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8843, F1: 0.9056
Epoch 54/70
Train Loss: 0.0063, Accuracy: 0.9964, Precision: 0.9966, Recall: 0.9966, F1: 0.9966
Validation Loss: 1.2115, Accuracy: 0.7648, Precision: 0.7610, Recall: 0.7655, F1: 0.7615
Testing Loss: 1.2105, Accuracy: 0.7763, Precision: 0.7758, Recall: 0.7857, F1: 0.7763
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0904, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8958, F1: 0.9131
Epoch 55/70
Train Loss: 0.0063, Accuracy: 0.9968, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 1.3142, Accuracy: 0.7725, Precision: 0.7817, Recall: 0.7710, F1: 0.7728
Testing Loss: 1.2629, Accuracy: 0.7740, Precision: 0.7773, Recall: 0.7821, F1: 0.7762
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0873, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8898, F1: 0.9094
Epoch 56/70
Train Loss: 0.0680, Accuracy: 0.9788, Precision: 0.9787, Recall: 0.9787, F1: 0.9787
Validation Loss: 1.5174, Accuracy: 0.6549, Precision: 0.6815, Recall: 0.6522, F1: 0.6523
Testing Loss: 1.4523, Accuracy: 0.6664, Precision: 0.7034, Recall: 0.6663, F1: 0.6609
LM Predictions:  [8, 4, 2, 6, 4, 14, 7, 14, 0, 0, 9, 0, 0, 2, 11, 3, 8, 3, 9, 8, 11, 1, 0, 7, 6, 13, 3, 1, 2, 5, 3, 9, 4, 0, 7, 10, 1, 6, 4, 6, 13, 6, 0, 13, 4, 10, 7, 1, 0, 6, 6, 6, 13, 0, 13, 13, 1, 2, 0, 1, 6, 1, 9, 0, 6, 9, 14, 6, 3, 11, 14, 6, 14, 6, 7, 2, 3, 6, 10, 1, 6, 1, 2, 2, 6, 0, 10, 1, 5, 0, 9, 14, 14, 14, 14, 6, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.1797, Accuracy: 0.6346, Precision: 0.7772, Recall: 0.5870, F1: 0.6305
Epoch 57/70
Train Loss: 0.0892, Accuracy: 0.9688, Precision: 0.9694, Recall: 0.9692, F1: 0.9693
Validation Loss: 1.3673, Accuracy: 0.7279, Precision: 0.7456, Recall: 0.7301, F1: 0.7312
Testing Loss: 1.3114, Accuracy: 0.7387, Precision: 0.7476, Recall: 0.7384, F1: 0.7365
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 13, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 11, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1243, Accuracy: 0.9135, Precision: 0.9176, Recall: 0.8606, F1: 0.8854
Epoch 58/70
Train Loss: 0.0182, Accuracy: 0.9928, Precision: 0.9934, Recall: 0.9933, F1: 0.9934
Validation Loss: 1.4270, Accuracy: 0.7179, Precision: 0.7323, Recall: 0.7137, F1: 0.7179
Testing Loss: 1.3029, Accuracy: 0.7379, Precision: 0.7471, Recall: 0.7372, F1: 0.7379
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1142, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8664, F1: 0.8960
Epoch 59/70
Train Loss: 0.0229, Accuracy: 0.9908, Precision: 0.9913, Recall: 0.9912, F1: 0.9913
Validation Loss: 1.4853, Accuracy: 0.7171, Precision: 0.7393, Recall: 0.7118, F1: 0.7170
Testing Loss: 1.3763, Accuracy: 0.7410, Precision: 0.7591, Recall: 0.7401, F1: 0.7418
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 7, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 14, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1172, Accuracy: 0.9327, Precision: 0.9167, Recall: 0.8717, F1: 0.8906
Epoch 60/70
Train Loss: 0.0279, Accuracy: 0.9895, Precision: 0.9895, Recall: 0.9895, F1: 0.9895
Validation Loss: 1.4083, Accuracy: 0.7171, Precision: 0.7429, Recall: 0.7178, F1: 0.7148
Testing Loss: 1.4679, Accuracy: 0.7164, Precision: 0.7352, Recall: 0.7180, F1: 0.7157
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 8, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 13, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1111, Accuracy: 0.9327, Precision: 0.9139, Recall: 0.8676, F1: 0.8862
Epoch 61/70
Train Loss: 0.0364, Accuracy: 0.9865, Precision: 0.9873, Recall: 0.9868, F1: 0.9871
Validation Loss: 1.4157, Accuracy: 0.7079, Precision: 0.7172, Recall: 0.7070, F1: 0.7069
Testing Loss: 1.3624, Accuracy: 0.7271, Precision: 0.7341, Recall: 0.7317, F1: 0.7289
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 5, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 0, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1237, Accuracy: 0.9135, Precision: 0.9105, Recall: 0.8512, F1: 0.8754
Epoch 62/70
Train Loss: 0.0306, Accuracy: 0.9893, Precision: 0.9894, Recall: 0.9895, F1: 0.9895
Validation Loss: 1.3445, Accuracy: 0.7248, Precision: 0.7337, Recall: 0.7237, F1: 0.7232
Testing Loss: 1.2820, Accuracy: 0.7348, Precision: 0.7353, Recall: 0.7367, F1: 0.7315
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0767, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9028, F1: 0.9156
Epoch 63/70
Train Loss: 0.0285, Accuracy: 0.9898, Precision: 0.9899, Recall: 0.9897, F1: 0.9898
Validation Loss: 1.3284, Accuracy: 0.7310, Precision: 0.7378, Recall: 0.7313, F1: 0.7314
Testing Loss: 1.2587, Accuracy: 0.7533, Precision: 0.7587, Recall: 0.7597, F1: 0.7549
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0954, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8811, F1: 0.9040
Epoch 64/70
Train Loss: 0.0153, Accuracy: 0.9935, Precision: 0.9932, Recall: 0.9935, F1: 0.9933
Validation Loss: 1.4541, Accuracy: 0.7118, Precision: 0.7108, Recall: 0.7200, F1: 0.7105
Testing Loss: 1.3554, Accuracy: 0.7348, Precision: 0.7372, Recall: 0.7435, F1: 0.7322
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 0, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0939, Accuracy: 0.9423, Precision: 0.9238, Recall: 0.8866, F1: 0.9020
Epoch 65/70
Train Loss: 0.0339, Accuracy: 0.9887, Precision: 0.9882, Recall: 0.9884, F1: 0.9883
Validation Loss: 1.3483, Accuracy: 0.7248, Precision: 0.7408, Recall: 0.7225, F1: 0.7272
Testing Loss: 1.2789, Accuracy: 0.7425, Precision: 0.7496, Recall: 0.7414, F1: 0.7429
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 14, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1011, Accuracy: 0.9231, Precision: 0.9238, Recall: 0.8632, F1: 0.8912
Epoch 66/70
Train Loss: 0.0224, Accuracy: 0.9916, Precision: 0.9918, Recall: 0.9918, F1: 0.9918
Validation Loss: 1.3822, Accuracy: 0.7294, Precision: 0.7450, Recall: 0.7353, F1: 0.7325
Testing Loss: 1.3881, Accuracy: 0.7371, Precision: 0.7493, Recall: 0.7452, F1: 0.7388
LM Predictions:  [8, 4, 2, 10, 4, 14, 7, 8, 5, 11, 9, 0, 0, 2, 11, 14, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 14, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1726, Accuracy: 0.9327, Precision: 0.9133, Recall: 0.8734, F1: 0.8908
Epoch 67/70
Train Loss: 0.0421, Accuracy: 0.9848, Precision: 0.9852, Recall: 0.9853, F1: 0.9852
Validation Loss: 1.3656, Accuracy: 0.7118, Precision: 0.7311, Recall: 0.7075, F1: 0.7138
Testing Loss: 1.3308, Accuracy: 0.7364, Precision: 0.7598, Recall: 0.7352, F1: 0.7386
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 14, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 0, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1574, Accuracy: 0.9231, Precision: 0.9155, Recall: 0.8547, F1: 0.8825
Epoch 68/70
Train Loss: 0.0163, Accuracy: 0.9924, Precision: 0.9928, Recall: 0.9926, F1: 0.9927
Validation Loss: 1.3471, Accuracy: 0.7425, Precision: 0.7472, Recall: 0.7407, F1: 0.7414
Testing Loss: 1.3569, Accuracy: 0.7448, Precision: 0.7475, Recall: 0.7484, F1: 0.7441
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0863, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8858, F1: 0.9077
Epoch 69/70
Train Loss: 0.0081, Accuracy: 0.9964, Precision: 0.9966, Recall: 0.9966, F1: 0.9966
Validation Loss: 1.3287, Accuracy: 0.7448, Precision: 0.7579, Recall: 0.7445, F1: 0.7494
Testing Loss: 1.2727, Accuracy: 0.7679, Precision: 0.7741, Recall: 0.7740, F1: 0.7717
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0616, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9032, F1: 0.9170
Epoch 70/70
Train Loss: 0.0397, Accuracy: 0.9865, Precision: 0.9869, Recall: 0.9871, F1: 0.9870
Validation Loss: 1.5231, Accuracy: 0.7148, Precision: 0.7381, Recall: 0.7076, F1: 0.7128
Testing Loss: 1.4002, Accuracy: 0.7171, Precision: 0.7363, Recall: 0.7153, F1: 0.7195
LM Predictions:  [8, 4, 2, 10, 4, 4, 7, 14, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 0, 1, 2, 5, 5, 9, 4, 9, 7, 6, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 4, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1870, Accuracy: 0.9231, Precision: 0.9016, Recall: 0.8549, F1: 0.8722
For middle layers:  [4, 5, 6, 7]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 1.3623, Accuracy: 0.5753, Precision: 0.5808, Recall: 0.5608, F1: 0.5646
Validation Loss: 0.8024, Accuracy: 0.7594, Precision: 0.7689, Recall: 0.7538, F1: 0.7567
Testing Loss: 0.8274, Accuracy: 0.7456, Precision: 0.7587, Recall: 0.7433, F1: 0.7459
LM Predictions:  [14, 14, 6, 6, 0, 6, 3, 14, 6, 6, 6, 6, 0, 6, 6, 6, 6, 8, 10, 12, 6, 6, 6, 6, 13, 6, 6, 0, 6, 14, 6, 0, 14, 6, 14, 6, 6, 6, 14, 6, 6, 12, 6, 13, 6, 6, 13, 3, 6, 14, 6, 6, 6, 6, 6, 6, 14, 6, 6, 6, 0, 0, 8, 14, 0, 11, 0, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 13, 6, 0, 6, 6, 3, 14, 0, 6, 6, 0, 13, 0, 6, 6, 6, 0, 6, 6, 6, 6, 6]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 4.2922, Accuracy: 0.0288, Precision: 0.0417, Recall: 0.0302, F1: 0.0283
Epoch 2/70
Train Loss: 0.6183, Accuracy: 0.8197, Precision: 0.8201, Recall: 0.8163, F1: 0.8181
Validation Loss: 0.7564, Accuracy: 0.7517, Precision: 0.7716, Recall: 0.7481, F1: 0.7445
Testing Loss: 0.7268, Accuracy: 0.7802, Precision: 0.8023, Recall: 0.7820, F1: 0.7764
LM Predictions:  [14, 0, 2, 0, 8, 6, 3, 14, 6, 0, 6, 6, 0, 0, 6, 6, 4, 4, 10, 12, 11, 11, 6, 6, 11, 6, 0, 11, 0, 0, 14, 0, 6, 6, 3, 11, 0, 0, 14, 3, 0, 12, 0, 0, 0, 7, 11, 0, 6, 0, 0, 0, 6, 0, 6, 6, 0, 0, 4, 0, 0, 0, 8, 0, 12, 11, 11, 6, 3, 0, 11, 0, 6, 0, 0, 0, 0, 6, 11, 0, 0, 11, 0, 6, 0, 6, 6, 3, 0, 0, 0, 6, 0, 9, 11, 6, 0, 12, 6, 6, 6, 0, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 3.2542, Accuracy: 0.1538, Precision: 0.3282, Recall: 0.1526, F1: 0.1486
Epoch 3/70
Train Loss: 0.2849, Accuracy: 0.9236, Precision: 0.9258, Recall: 0.9231, F1: 0.9244
Validation Loss: 0.6729, Accuracy: 0.7925, Precision: 0.7991, Recall: 0.7939, F1: 0.7913
Testing Loss: 0.6473, Accuracy: 0.8017, Precision: 0.8187, Recall: 0.8062, F1: 0.8064
LM Predictions:  [6, 4, 2, 6, 4, 6, 7, 6, 5, 6, 6, 6, 0, 6, 6, 6, 4, 4, 9, 8, 11, 1, 6, 6, 13, 13, 9, 1, 2, 6, 5, 9, 6, 9, 6, 11, 6, 13, 6, 6, 6, 6, 6, 9, 4, 7, 11, 9, 7, 6, 14, 6, 6, 0, 11, 13, 6, 6, 4, 13, 11, 1, 1, 0, 6, 11, 11, 6, 3, 0, 0, 6, 14, 0, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0, 0, 6, 6, 0, 9, 6, 6, 1, 12, 6, 6, 6, 9, 13, 6]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.9516, Accuracy: 0.3654, Precision: 0.7015, Recall: 0.3460, F1: 0.4245
Epoch 4/70
Train Loss: 0.1247, Accuracy: 0.9715, Precision: 0.9722, Recall: 0.9709, F1: 0.9715
Validation Loss: 0.7537, Accuracy: 0.7802, Precision: 0.8078, Recall: 0.7774, F1: 0.7827
Testing Loss: 0.6889, Accuracy: 0.7894, Precision: 0.8152, Recall: 0.7894, F1: 0.7924
LM Predictions:  [6, 6, 2, 6, 6, 10, 7, 8, 13, 13, 6, 0, 0, 6, 6, 6, 4, 6, 9, 8, 11, 6, 6, 6, 6, 13, 3, 1, 2, 6, 5, 9, 4, 9, 3, 11, 6, 13, 6, 10, 6, 6, 6, 9, 6, 10, 6, 1, 6, 6, 6, 6, 6, 0, 6, 13, 6, 6, 4, 1, 11, 1, 1, 0, 14, 6, 14, 6, 3, 13, 12, 6, 14, 6, 6, 2, 6, 6, 6, 6, 3, 1, 12, 6, 6, 6, 6, 1, 5, 0, 6, 14, 14, 9, 14, 6, 8, 12, 12, 6, 6, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.6141, Accuracy: 0.5096, Precision: 0.8692, Recall: 0.4798, F1: 0.5994
Epoch 5/70
Train Loss: 0.0978, Accuracy: 0.9738, Precision: 0.9746, Recall: 0.9740, F1: 0.9743
Validation Loss: 0.8498, Accuracy: 0.7733, Precision: 0.7729, Recall: 0.7733, F1: 0.7652
Testing Loss: 0.8094, Accuracy: 0.7894, Precision: 0.7926, Recall: 0.7934, F1: 0.7852
LM Predictions:  [8, 6, 2, 6, 4, 10, 7, 8, 13, 11, 9, 0, 0, 2, 11, 3, 4, 4, 10, 8, 11, 1, 1, 6, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 8, 1, 7, 6, 14, 6, 6, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 13, 12, 1, 14, 7, 6, 12, 3, 0, 13, 11, 3, 1, 12, 2, 6, 8, 0, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 6, 6, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.5341, Accuracy: 0.8077, Precision: 0.8607, Recall: 0.7468, F1: 0.7893
Epoch 6/70
Train Loss: 0.0590, Accuracy: 0.9853, Precision: 0.9859, Recall: 0.9852, F1: 0.9855
Validation Loss: 0.7463, Accuracy: 0.7871, Precision: 0.7920, Recall: 0.7821, F1: 0.7825
Testing Loss: 0.7237, Accuracy: 0.8017, Precision: 0.8108, Recall: 0.7953, F1: 0.7976
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 6, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 6, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 6, 3, 11, 12, 1, 14, 9, 6, 2, 6, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 6, 6, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.4428, Accuracy: 0.8462, Precision: 0.9250, Recall: 0.7876, F1: 0.8463
Epoch 7/70
Train Loss: 0.0834, Accuracy: 0.9759, Precision: 0.9760, Recall: 0.9753, F1: 0.9756
Validation Loss: 0.8588, Accuracy: 0.7771, Precision: 0.7908, Recall: 0.7788, F1: 0.7728
Testing Loss: 0.8700, Accuracy: 0.7840, Precision: 0.7918, Recall: 0.7847, F1: 0.7789
LM Predictions:  [8, 4, 2, 10, 4, 10, 3, 8, 5, 11, 6, 0, 0, 6, 11, 3, 4, 4, 9, 12, 11, 1, 1, 6, 6, 13, 3, 1, 2, 5, 5, 9, 6, 9, 7, 10, 1, 13, 14, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 3, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 14, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3032, Accuracy: 0.8846, Precision: 0.8941, Recall: 0.8256, F1: 0.8531
Epoch 8/70
Train Loss: 0.0613, Accuracy: 0.9826, Precision: 0.9824, Recall: 0.9829, F1: 0.9826
Validation Loss: 0.8032, Accuracy: 0.7894, Precision: 0.7992, Recall: 0.7869, F1: 0.7852
Testing Loss: 0.8100, Accuracy: 0.7971, Precision: 0.8090, Recall: 0.7989, F1: 0.7968
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 13, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 0, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2413, Accuracy: 0.9231, Precision: 0.9155, Recall: 0.8632, F1: 0.8868
Epoch 9/70
Train Loss: 0.0511, Accuracy: 0.9858, Precision: 0.9858, Recall: 0.9852, F1: 0.9855
Validation Loss: 0.8810, Accuracy: 0.7840, Precision: 0.7882, Recall: 0.7875, F1: 0.7821
Testing Loss: 0.8728, Accuracy: 0.7902, Precision: 0.7954, Recall: 0.7957, F1: 0.7887
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 10, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 10, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 10, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2813, Accuracy: 0.9038, Precision: 0.9152, Recall: 0.8496, F1: 0.8758
Epoch 10/70
Train Loss: 0.0487, Accuracy: 0.9858, Precision: 0.9858, Recall: 0.9855, F1: 0.9856
Validation Loss: 0.7880, Accuracy: 0.7925, Precision: 0.7970, Recall: 0.7912, F1: 0.7908
Testing Loss: 0.8329, Accuracy: 0.7971, Precision: 0.8069, Recall: 0.7980, F1: 0.7980
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 6, 0, 0, 2, 11, 3, 4, 4, 6, 8, 11, 4, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 6, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2398, Accuracy: 0.9135, Precision: 0.9250, Recall: 0.8574, F1: 0.8869
Epoch 11/70
Train Loss: 0.0390, Accuracy: 0.9893, Precision: 0.9892, Recall: 0.9891, F1: 0.9891
Validation Loss: 0.8645, Accuracy: 0.7871, Precision: 0.7984, Recall: 0.7843, F1: 0.7848
Testing Loss: 0.8492, Accuracy: 0.7940, Precision: 0.7987, Recall: 0.7957, F1: 0.7930
LM Predictions:  [6, 4, 2, 10, 4, 10, 7, 8, 5, 11, 6, 0, 0, 2, 11, 3, 4, 4, 9, 8, 14, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 6, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 14, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3679, Accuracy: 0.8750, Precision: 0.9185, Recall: 0.8171, F1: 0.8606
Epoch 12/70
Train Loss: 0.0690, Accuracy: 0.9787, Precision: 0.9784, Recall: 0.9777, F1: 0.9781
Validation Loss: 0.8957, Accuracy: 0.7840, Precision: 0.7816, Recall: 0.7903, F1: 0.7794
Testing Loss: 0.8584, Accuracy: 0.8032, Precision: 0.8017, Recall: 0.8132, F1: 0.8000
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 0, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 6, 3, 11, 12, 1, 4, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 6, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2395, Accuracy: 0.9038, Precision: 0.9155, Recall: 0.8456, F1: 0.8756
Epoch 13/70
Train Loss: 0.0400, Accuracy: 0.9884, Precision: 0.9887, Recall: 0.9886, F1: 0.9886
Validation Loss: 0.9651, Accuracy: 0.7779, Precision: 0.8066, Recall: 0.7747, F1: 0.7803
Testing Loss: 0.9633, Accuracy: 0.7786, Precision: 0.8057, Recall: 0.7782, F1: 0.7812
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 11, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2946, Accuracy: 0.9135, Precision: 0.9259, Recall: 0.8521, F1: 0.8838
Epoch 14/70
Train Loss: 0.0358, Accuracy: 0.9885, Precision: 0.9887, Recall: 0.9886, F1: 0.9887
Validation Loss: 1.0803, Accuracy: 0.7533, Precision: 0.7747, Recall: 0.7587, F1: 0.7487
Testing Loss: 1.1067, Accuracy: 0.7571, Precision: 0.7767, Recall: 0.7615, F1: 0.7516
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 4, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1958, Accuracy: 0.9327, Precision: 0.9250, Recall: 0.8690, F1: 0.8924
Epoch 15/70
Train Loss: 0.0492, Accuracy: 0.9858, Precision: 0.9853, Recall: 0.9858, F1: 0.9856
Validation Loss: 0.9014, Accuracy: 0.7909, Precision: 0.7983, Recall: 0.7897, F1: 0.7879
Testing Loss: 0.9048, Accuracy: 0.7794, Precision: 0.8031, Recall: 0.7871, F1: 0.7844
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 6, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2499, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8521, F1: 0.8884
Epoch 16/70
Train Loss: 0.0471, Accuracy: 0.9840, Precision: 0.9842, Recall: 0.9836, F1: 0.9839
Validation Loss: 0.9009, Accuracy: 0.7733, Precision: 0.7889, Recall: 0.7722, F1: 0.7752
Testing Loss: 0.8114, Accuracy: 0.8025, Precision: 0.8139, Recall: 0.7997, F1: 0.8036
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 6, 0, 0, 2, 11, 6, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 13, 1, 2, 5, 5, 9, 4, 9, 7, 10, 0, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 0, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 0, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 0, 14, 6, 8, 12, 6, 9, 1, 14, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3913, Accuracy: 0.8558, Precision: 0.8912, Recall: 0.8179, F1: 0.8379
Epoch 17/70
Train Loss: 0.0223, Accuracy: 0.9933, Precision: 0.9934, Recall: 0.9933, F1: 0.9933
Validation Loss: 0.9047, Accuracy: 0.7925, Precision: 0.7996, Recall: 0.7958, F1: 0.7929
Testing Loss: 0.9535, Accuracy: 0.7840, Precision: 0.7927, Recall: 0.7869, F1: 0.7843
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1366, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8921, F1: 0.9097
Epoch 18/70
Train Loss: 0.0468, Accuracy: 0.9851, Precision: 0.9850, Recall: 0.9846, F1: 0.9848
Validation Loss: 0.9602, Accuracy: 0.7871, Precision: 0.7939, Recall: 0.7864, F1: 0.7843
Testing Loss: 0.8980, Accuracy: 0.7948, Precision: 0.8012, Recall: 0.7954, F1: 0.7931
LM Predictions:  [8, 4, 2, 0, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 11, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1902, Accuracy: 0.9327, Precision: 0.9176, Recall: 0.8664, F1: 0.8876
Epoch 19/70
Train Loss: 0.0365, Accuracy: 0.9874, Precision: 0.9879, Recall: 0.9878, F1: 0.9878
Validation Loss: 0.9407, Accuracy: 0.7825, Precision: 0.7876, Recall: 0.7818, F1: 0.7769
Testing Loss: 0.8987, Accuracy: 0.7955, Precision: 0.8016, Recall: 0.8000, F1: 0.7954
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0906, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8921, F1: 0.9110
Epoch 20/70
Train Loss: 0.0201, Accuracy: 0.9933, Precision: 0.9937, Recall: 0.9936, F1: 0.9936
Validation Loss: 1.0277, Accuracy: 0.7717, Precision: 0.7800, Recall: 0.7721, F1: 0.7703
Testing Loss: 0.9813, Accuracy: 0.7848, Precision: 0.7928, Recall: 0.7884, F1: 0.7845
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 6, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 1, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1971, Accuracy: 0.9231, Precision: 0.9289, Recall: 0.8597, F1: 0.8914
Epoch 21/70
Train Loss: 0.0535, Accuracy: 0.9808, Precision: 0.9814, Recall: 0.9814, F1: 0.9814
Validation Loss: 0.9217, Accuracy: 0.7871, Precision: 0.7938, Recall: 0.7837, F1: 0.7862
Testing Loss: 0.8602, Accuracy: 0.7978, Precision: 0.8006, Recall: 0.7984, F1: 0.7975
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 6, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 6, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2664, Accuracy: 0.9038, Precision: 0.9333, Recall: 0.8454, F1: 0.8843
Epoch 22/70
Train Loss: 0.0175, Accuracy: 0.9943, Precision: 0.9945, Recall: 0.9944, F1: 0.9944
Validation Loss: 0.9821, Accuracy: 0.7802, Precision: 0.8025, Recall: 0.7798, F1: 0.7858
Testing Loss: 0.9211, Accuracy: 0.7971, Precision: 0.8091, Recall: 0.8003, F1: 0.8026
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 6, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 0, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1669, Accuracy: 0.9423, Precision: 0.9250, Recall: 0.8815, F1: 0.9011
Epoch 23/70
Train Loss: 0.0209, Accuracy: 0.9932, Precision: 0.9933, Recall: 0.9934, F1: 0.9933
Validation Loss: 1.2934, Accuracy: 0.7071, Precision: 0.7504, Recall: 0.7116, F1: 0.7071
Testing Loss: 1.1922, Accuracy: 0.7356, Precision: 0.7744, Recall: 0.7435, F1: 0.7349
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 1, 13, 3, 1, 2, 5, 5, 0, 4, 9, 7, 10, 1, 13, 5, 10, 13, 6, 6, 9, 4, 10, 7, 5, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 5, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 0, 0, 3, 8, 5, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2627, Accuracy: 0.8750, Precision: 0.8730, Recall: 0.8206, F1: 0.8328
Epoch 24/70
Train Loss: 0.0566, Accuracy: 0.9820, Precision: 0.9821, Recall: 0.9815, F1: 0.9818
Validation Loss: 0.9689, Accuracy: 0.7894, Precision: 0.8027, Recall: 0.7852, F1: 0.7878
Testing Loss: 0.9127, Accuracy: 0.7917, Precision: 0.8002, Recall: 0.7934, F1: 0.7929
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 10, 12, 12, 9, 1, 3, 6, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1873, Accuracy: 0.9135, Precision: 0.9259, Recall: 0.8499, F1: 0.8843
Epoch 25/70
Train Loss: 0.0325, Accuracy: 0.9883, Precision: 0.9881, Recall: 0.9883, F1: 0.9882
Validation Loss: 1.0014, Accuracy: 0.7817, Precision: 0.7923, Recall: 0.7810, F1: 0.7816
Testing Loss: 0.8949, Accuracy: 0.8002, Precision: 0.8077, Recall: 0.8008, F1: 0.8011
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0716, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9053, F1: 0.9182
Epoch 26/70
Train Loss: 0.0256, Accuracy: 0.9919, Precision: 0.9923, Recall: 0.9922, F1: 0.9922
Validation Loss: 1.0778, Accuracy: 0.7625, Precision: 0.7716, Recall: 0.7622, F1: 0.7563
Testing Loss: 1.0226, Accuracy: 0.7817, Precision: 0.7868, Recall: 0.7858, F1: 0.7775
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1596, Accuracy: 0.9231, Precision: 0.9333, Recall: 0.8632, F1: 0.8957
Epoch 27/70
Train Loss: 0.0360, Accuracy: 0.9880, Precision: 0.9876, Recall: 0.9879, F1: 0.9878
Validation Loss: 1.0166, Accuracy: 0.7840, Precision: 0.7887, Recall: 0.7789, F1: 0.7800
Testing Loss: 0.9491, Accuracy: 0.7902, Precision: 0.7976, Recall: 0.7900, F1: 0.7894
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1664, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8874, F1: 0.9087
Epoch 28/70
Train Loss: 0.0399, Accuracy: 0.9864, Precision: 0.9868, Recall: 0.9862, F1: 0.9865
Validation Loss: 1.0424, Accuracy: 0.7694, Precision: 0.7875, Recall: 0.7630, F1: 0.7662
Testing Loss: 0.9151, Accuracy: 0.7909, Precision: 0.8130, Recall: 0.7896, F1: 0.7932
LM Predictions:  [8, 4, 2, 6, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 6, 7, 1, 7, 6, 14, 3, 13, 0, 13, 14, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 6, 3, 11, 12, 1, 14, 6, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 6, 14, 14, 9, 14, 3, 8, 12, 6, 6, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3036, Accuracy: 0.8558, Precision: 0.9238, Recall: 0.8054, F1: 0.8555
Epoch 29/70
Train Loss: 0.0259, Accuracy: 0.9901, Precision: 0.9902, Recall: 0.9900, F1: 0.9901
Validation Loss: 1.1694, Accuracy: 0.7686, Precision: 0.7594, Recall: 0.7687, F1: 0.7598
Testing Loss: 0.9538, Accuracy: 0.7955, Precision: 0.7911, Recall: 0.8058, F1: 0.7923
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0870, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8901, F1: 0.9101
Epoch 30/70
Train Loss: 0.0230, Accuracy: 0.9914, Precision: 0.9913, Recall: 0.9913, F1: 0.9913
Validation Loss: 0.9988, Accuracy: 0.7817, Precision: 0.7833, Recall: 0.7797, F1: 0.7781
Testing Loss: 0.9693, Accuracy: 0.7909, Precision: 0.7954, Recall: 0.7925, F1: 0.7898
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1503, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8671, F1: 0.8970
Epoch 31/70
Train Loss: 0.0304, Accuracy: 0.9883, Precision: 0.9884, Recall: 0.9881, F1: 0.9883
Validation Loss: 1.2016, Accuracy: 0.7494, Precision: 0.7562, Recall: 0.7452, F1: 0.7415
Testing Loss: 1.0570, Accuracy: 0.7748, Precision: 0.7829, Recall: 0.7798, F1: 0.7715
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1086, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8970, F1: 0.9138
Epoch 32/70
Train Loss: 0.0216, Accuracy: 0.9924, Precision: 0.9926, Recall: 0.9925, F1: 0.9925
Validation Loss: 1.0769, Accuracy: 0.7709, Precision: 0.7803, Recall: 0.7691, F1: 0.7695
Testing Loss: 0.9141, Accuracy: 0.8109, Precision: 0.8164, Recall: 0.8103, F1: 0.8097
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0693, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8933, F1: 0.9116
Epoch 33/70
Train Loss: 0.0381, Accuracy: 0.9862, Precision: 0.9865, Recall: 0.9865, F1: 0.9865
Validation Loss: 1.1068, Accuracy: 0.7786, Precision: 0.7823, Recall: 0.7806, F1: 0.7764
Testing Loss: 0.9674, Accuracy: 0.7932, Precision: 0.8014, Recall: 0.7965, F1: 0.7916
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1362, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8858, F1: 0.9077
Epoch 34/70
Train Loss: 0.0340, Accuracy: 0.9884, Precision: 0.9886, Recall: 0.9884, F1: 0.9885
Validation Loss: 1.1435, Accuracy: 0.7594, Precision: 0.7634, Recall: 0.7640, F1: 0.7556
Testing Loss: 1.0660, Accuracy: 0.7686, Precision: 0.7739, Recall: 0.7755, F1: 0.7655
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 13, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 13, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1589, Accuracy: 0.9038, Precision: 0.9185, Recall: 0.8475, F1: 0.8779
Epoch 35/70
Train Loss: 0.0161, Accuracy: 0.9937, Precision: 0.9937, Recall: 0.9938, F1: 0.9938
Validation Loss: 1.1074, Accuracy: 0.7694, Precision: 0.7657, Recall: 0.7728, F1: 0.7642
Testing Loss: 1.0349, Accuracy: 0.7863, Precision: 0.7817, Recall: 0.7942, F1: 0.7808
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0926, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8934, F1: 0.9114
Epoch 36/70
Train Loss: 0.0222, Accuracy: 0.9926, Precision: 0.9929, Recall: 0.9928, F1: 0.9928
Validation Loss: 1.2016, Accuracy: 0.7471, Precision: 0.7762, Recall: 0.7443, F1: 0.7465
Testing Loss: 1.0785, Accuracy: 0.7694, Precision: 0.7912, Recall: 0.7705, F1: 0.7682
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 6, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 5, 3, 11, 12, 1, 4, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1801, Accuracy: 0.9038, Precision: 0.9105, Recall: 0.8481, F1: 0.8753
Epoch 37/70
Train Loss: 0.0404, Accuracy: 0.9855, Precision: 0.9855, Recall: 0.9854, F1: 0.9854
Validation Loss: 1.1111, Accuracy: 0.7740, Precision: 0.7843, Recall: 0.7699, F1: 0.7722
Testing Loss: 1.0444, Accuracy: 0.7825, Precision: 0.7896, Recall: 0.7823, F1: 0.7802
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 6, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1439, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8652, F1: 0.8957
Epoch 38/70
Train Loss: 0.0232, Accuracy: 0.9919, Precision: 0.9914, Recall: 0.9918, F1: 0.9916
Validation Loss: 1.0914, Accuracy: 0.7779, Precision: 0.7829, Recall: 0.7741, F1: 0.7750
Testing Loss: 1.0797, Accuracy: 0.7733, Precision: 0.7776, Recall: 0.7714, F1: 0.7697
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 3, 9, 4, 9, 7, 10, 1, 13, 4, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1919, Accuracy: 0.9327, Precision: 0.9167, Recall: 0.8647, F1: 0.8863
Epoch 39/70
Train Loss: 0.0217, Accuracy: 0.9918, Precision: 0.9919, Recall: 0.9918, F1: 0.9919
Validation Loss: 1.0091, Accuracy: 0.7879, Precision: 0.7911, Recall: 0.7862, F1: 0.7867
Testing Loss: 0.9572, Accuracy: 0.8032, Precision: 0.8038, Recall: 0.8060, F1: 0.8033
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0749, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9044, F1: 0.9177
Epoch 40/70
Train Loss: 0.0224, Accuracy: 0.9918, Precision: 0.9920, Recall: 0.9918, F1: 0.9919
Validation Loss: 1.0422, Accuracy: 0.7848, Precision: 0.7854, Recall: 0.7836, F1: 0.7799
Testing Loss: 1.0020, Accuracy: 0.8025, Precision: 0.7984, Recall: 0.8079, F1: 0.7993
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0949, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8922, F1: 0.9113
Epoch 41/70
Train Loss: 0.0280, Accuracy: 0.9908, Precision: 0.9910, Recall: 0.9908, F1: 0.9909
Validation Loss: 1.1971, Accuracy: 0.7563, Precision: 0.7620, Recall: 0.7597, F1: 0.7541
Testing Loss: 1.0642, Accuracy: 0.7779, Precision: 0.7762, Recall: 0.7818, F1: 0.7745
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 13, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1800, Accuracy: 0.9135, Precision: 0.9250, Recall: 0.8585, F1: 0.8886
Epoch 42/70
Train Loss: 0.0454, Accuracy: 0.9847, Precision: 0.9839, Recall: 0.9839, F1: 0.9839
Validation Loss: 1.0116, Accuracy: 0.7855, Precision: 0.7902, Recall: 0.7869, F1: 0.7840
Testing Loss: 0.9499, Accuracy: 0.7909, Precision: 0.7887, Recall: 0.7934, F1: 0.7867
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0763, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8970, F1: 0.9138
Epoch 43/70
Train Loss: 0.0071, Accuracy: 0.9963, Precision: 0.9965, Recall: 0.9965, F1: 0.9965
Validation Loss: 1.0584, Accuracy: 0.7886, Precision: 0.7902, Recall: 0.7866, F1: 0.7845
Testing Loss: 1.0040, Accuracy: 0.7909, Precision: 0.8004, Recall: 0.7936, F1: 0.7921
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0953, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8839, F1: 0.9069
Epoch 44/70
Train Loss: 0.0363, Accuracy: 0.9872, Precision: 0.9868, Recall: 0.9872, F1: 0.9870
Validation Loss: 1.0792, Accuracy: 0.7663, Precision: 0.7729, Recall: 0.7629, F1: 0.7655
Testing Loss: 1.0892, Accuracy: 0.7817, Precision: 0.7871, Recall: 0.7801, F1: 0.7811
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 8, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 0, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1209, Accuracy: 0.9327, Precision: 0.9139, Recall: 0.8685, F1: 0.8862
Epoch 45/70
Train Loss: 0.0402, Accuracy: 0.9864, Precision: 0.9861, Recall: 0.9858, F1: 0.9859
Validation Loss: 1.1465, Accuracy: 0.7725, Precision: 0.7933, Recall: 0.7666, F1: 0.7698
Testing Loss: 1.0103, Accuracy: 0.7932, Precision: 0.8020, Recall: 0.7942, F1: 0.7922
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0967, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8754, F1: 0.9009
Epoch 46/70
Train Loss: 0.0162, Accuracy: 0.9929, Precision: 0.9924, Recall: 0.9925, F1: 0.9925
Validation Loss: 1.2869, Accuracy: 0.7371, Precision: 0.7669, Recall: 0.7268, F1: 0.7282
Testing Loss: 1.1388, Accuracy: 0.7617, Precision: 0.7825, Recall: 0.7518, F1: 0.7536
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1048, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8960, F1: 0.9133
Epoch 47/70
Train Loss: 0.0218, Accuracy: 0.9921, Precision: 0.9916, Recall: 0.9917, F1: 0.9916
Validation Loss: 1.0924, Accuracy: 0.7786, Precision: 0.7842, Recall: 0.7790, F1: 0.7767
Testing Loss: 0.9918, Accuracy: 0.8063, Precision: 0.8086, Recall: 0.8093, F1: 0.8029
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 4, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1102, Accuracy: 0.9423, Precision: 0.9250, Recall: 0.8811, F1: 0.8996
Epoch 48/70
Train Loss: 0.0262, Accuracy: 0.9904, Precision: 0.9905, Recall: 0.9905, F1: 0.9905
Validation Loss: 1.0688, Accuracy: 0.7848, Precision: 0.7875, Recall: 0.7805, F1: 0.7776
Testing Loss: 0.9668, Accuracy: 0.8094, Precision: 0.8090, Recall: 0.8125, F1: 0.8063
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 6, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1070, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8811, F1: 0.9052
Epoch 49/70
Train Loss: 0.0211, Accuracy: 0.9919, Precision: 0.9923, Recall: 0.9923, F1: 0.9923
Validation Loss: 1.1396, Accuracy: 0.7679, Precision: 0.7831, Recall: 0.7627, F1: 0.7616
Testing Loss: 0.9823, Accuracy: 0.7925, Precision: 0.7979, Recall: 0.7948, F1: 0.7929
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0721, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9164, F1: 0.9243
Epoch 50/70
Train Loss: 0.0225, Accuracy: 0.9928, Precision: 0.9930, Recall: 0.9933, F1: 0.9932
Validation Loss: 1.1746, Accuracy: 0.7610, Precision: 0.7670, Recall: 0.7623, F1: 0.7576
Testing Loss: 1.0306, Accuracy: 0.7971, Precision: 0.7977, Recall: 0.7998, F1: 0.7939
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0884, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8827, F1: 0.9062
Epoch 51/70
Train Loss: 0.0157, Accuracy: 0.9941, Precision: 0.9944, Recall: 0.9944, F1: 0.9944
Validation Loss: 1.1355, Accuracy: 0.7717, Precision: 0.7905, Recall: 0.7662, F1: 0.7722
Testing Loss: 1.1118, Accuracy: 0.7740, Precision: 0.7894, Recall: 0.7691, F1: 0.7741
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 6, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0999, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8861, F1: 0.9072
Epoch 52/70
Train Loss: 0.0401, Accuracy: 0.9857, Precision: 0.9857, Recall: 0.9851, F1: 0.9854
Validation Loss: 1.1011, Accuracy: 0.7717, Precision: 0.7743, Recall: 0.7724, F1: 0.7666
Testing Loss: 1.0121, Accuracy: 0.7917, Precision: 0.7975, Recall: 0.7944, F1: 0.7905
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1133, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8775, F1: 0.9033
Epoch 53/70
Train Loss: 0.0180, Accuracy: 0.9922, Precision: 0.9924, Recall: 0.9924, F1: 0.9924
Validation Loss: 1.3697, Accuracy: 0.7433, Precision: 0.7624, Recall: 0.7436, F1: 0.7383
Testing Loss: 1.2313, Accuracy: 0.7694, Precision: 0.7872, Recall: 0.7741, F1: 0.7671
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 1, 13, 3, 1, 2, 5, 14, 14, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 3, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1581, Accuracy: 0.9327, Precision: 0.9057, Recall: 0.8636, F1: 0.8819
Epoch 54/70
Train Loss: 0.0175, Accuracy: 0.9928, Precision: 0.9927, Recall: 0.9927, F1: 0.9927
Validation Loss: 1.1059, Accuracy: 0.7848, Precision: 0.7831, Recall: 0.7817, F1: 0.7794
Testing Loss: 0.9794, Accuracy: 0.8109, Precision: 0.8112, Recall: 0.8150, F1: 0.8104
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1094, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8692, F1: 0.8982
Epoch 55/70
Train Loss: 0.0127, Accuracy: 0.9950, Precision: 0.9953, Recall: 0.9953, F1: 0.9953
Validation Loss: 1.1676, Accuracy: 0.7733, Precision: 0.7836, Recall: 0.7695, F1: 0.7704
Testing Loss: 1.0550, Accuracy: 0.7948, Precision: 0.8117, Recall: 0.7933, F1: 0.7961
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0681, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9081, F1: 0.9198
Epoch 56/70
Train Loss: 0.0415, Accuracy: 0.9859, Precision: 0.9856, Recall: 0.9853, F1: 0.9854
Validation Loss: 1.1219, Accuracy: 0.7725, Precision: 0.7793, Recall: 0.7662, F1: 0.7677
Testing Loss: 1.0294, Accuracy: 0.7902, Precision: 0.7990, Recall: 0.7843, F1: 0.7877
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 6, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0943, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8922, F1: 0.9113
Epoch 57/70
Train Loss: 0.0209, Accuracy: 0.9930, Precision: 0.9928, Recall: 0.9931, F1: 0.9930
Validation Loss: 1.2224, Accuracy: 0.7610, Precision: 0.7803, Recall: 0.7615, F1: 0.7616
Testing Loss: 1.1379, Accuracy: 0.7779, Precision: 0.7946, Recall: 0.7763, F1: 0.7755
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 10, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1555, Accuracy: 0.9135, Precision: 0.9259, Recall: 0.8471, F1: 0.8815
Epoch 58/70
Train Loss: 0.0244, Accuracy: 0.9912, Precision: 0.9915, Recall: 0.9914, F1: 0.9914
Validation Loss: 1.1210, Accuracy: 0.7594, Precision: 0.7739, Recall: 0.7528, F1: 0.7556
Testing Loss: 1.0363, Accuracy: 0.7779, Precision: 0.7883, Recall: 0.7749, F1: 0.7760
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1274, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8829, F1: 0.9057
Epoch 59/70
Train Loss: 0.0276, Accuracy: 0.9890, Precision: 0.9892, Recall: 0.9892, F1: 0.9892
Validation Loss: 1.1316, Accuracy: 0.7648, Precision: 0.7718, Recall: 0.7645, F1: 0.7613
Testing Loss: 1.0696, Accuracy: 0.7725, Precision: 0.7727, Recall: 0.7756, F1: 0.7692
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 0, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 5, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 8, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1928, Accuracy: 0.8846, Precision: 0.8994, Recall: 0.8283, F1: 0.8560
Epoch 60/70
Train Loss: 0.0219, Accuracy: 0.9913, Precision: 0.9913, Recall: 0.9910, F1: 0.9912
Validation Loss: 1.0666, Accuracy: 0.7733, Precision: 0.7726, Recall: 0.7776, F1: 0.7705
Testing Loss: 1.0265, Accuracy: 0.7809, Precision: 0.7827, Recall: 0.7883, F1: 0.7803
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 3, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0920, Accuracy: 0.9712, Precision: 0.9250, Recall: 0.9091, F1: 0.9165
Epoch 61/70
Train Loss: 0.0105, Accuracy: 0.9950, Precision: 0.9951, Recall: 0.9953, F1: 0.9952
Validation Loss: 1.0636, Accuracy: 0.7709, Precision: 0.7741, Recall: 0.7665, F1: 0.7661
Testing Loss: 1.0468, Accuracy: 0.7940, Precision: 0.7963, Recall: 0.7960, F1: 0.7914
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0624, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9139, F1: 0.9228
Epoch 62/70
Train Loss: 0.0213, Accuracy: 0.9924, Precision: 0.9922, Recall: 0.9922, F1: 0.9922
Validation Loss: 1.0856, Accuracy: 0.7740, Precision: 0.7804, Recall: 0.7806, F1: 0.7705
Testing Loss: 1.0349, Accuracy: 0.7902, Precision: 0.7924, Recall: 0.7973, F1: 0.7892
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 4, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 0, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1316, Accuracy: 0.9231, Precision: 0.9167, Recall: 0.8587, F1: 0.8802
Epoch 63/70
Train Loss: 0.0153, Accuracy: 0.9940, Precision: 0.9938, Recall: 0.9939, F1: 0.9938
Validation Loss: 1.1977, Accuracy: 0.7733, Precision: 0.7762, Recall: 0.7769, F1: 0.7714
Testing Loss: 1.1513, Accuracy: 0.7763, Precision: 0.7752, Recall: 0.7844, F1: 0.7738
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1607, Accuracy: 0.9231, Precision: 0.9333, Recall: 0.8595, F1: 0.8923
Epoch 64/70
Train Loss: 0.0362, Accuracy: 0.9873, Precision: 0.9876, Recall: 0.9874, F1: 0.9875
Validation Loss: 1.0687, Accuracy: 0.7671, Precision: 0.7718, Recall: 0.7677, F1: 0.7613
Testing Loss: 1.0703, Accuracy: 0.7825, Precision: 0.7899, Recall: 0.7830, F1: 0.7764
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 3, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2017, Accuracy: 0.9231, Precision: 0.9259, Recall: 0.8668, F1: 0.8923
Epoch 65/70
Train Loss: 0.0225, Accuracy: 0.9925, Precision: 0.9926, Recall: 0.9927, F1: 0.9927
Validation Loss: 1.1383, Accuracy: 0.7671, Precision: 0.7835, Recall: 0.7678, F1: 0.7690
Testing Loss: 1.0335, Accuracy: 0.7917, Precision: 0.8000, Recall: 0.7925, F1: 0.7916
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 11, 6, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1229, Accuracy: 0.9231, Precision: 0.9259, Recall: 0.8571, F1: 0.8858
Epoch 66/70
Train Loss: 0.0088, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9964, F1: 0.9965
Validation Loss: 1.0040, Accuracy: 0.7917, Precision: 0.7916, Recall: 0.7894, F1: 0.7877
Testing Loss: 0.9848, Accuracy: 0.8032, Precision: 0.8015, Recall: 0.8091, F1: 0.8032
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1795, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8817, F1: 0.9057
Epoch 67/70
Train Loss: 0.0062, Accuracy: 0.9972, Precision: 0.9973, Recall: 0.9974, F1: 0.9974
Validation Loss: 0.9953, Accuracy: 0.7940, Precision: 0.7952, Recall: 0.7906, F1: 0.7907
Testing Loss: 0.9682, Accuracy: 0.8148, Precision: 0.8156, Recall: 0.8195, F1: 0.8153
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1076, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8938, F1: 0.9122
Epoch 68/70
Train Loss: 0.0055, Accuracy: 0.9965, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.9999, Accuracy: 0.7963, Precision: 0.7963, Recall: 0.7930, F1: 0.7921
Testing Loss: 0.9590, Accuracy: 0.8132, Precision: 0.8117, Recall: 0.8183, F1: 0.8119
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0533, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9091, F1: 0.9204
Epoch 69/70
Train Loss: 0.0057, Accuracy: 0.9968, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.9841, Accuracy: 0.8055, Precision: 0.8048, Recall: 0.8029, F1: 0.8018
Testing Loss: 0.9521, Accuracy: 0.8201, Precision: 0.8166, Recall: 0.8246, F1: 0.8187
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0829, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8960, F1: 0.9133
Epoch 70/70
Train Loss: 0.0056, Accuracy: 0.9969, Precision: 0.9971, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.9977, Accuracy: 0.8017, Precision: 0.7973, Recall: 0.8010, F1: 0.7967
Testing Loss: 0.9885, Accuracy: 0.8155, Precision: 0.8126, Recall: 0.8218, F1: 0.8127
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0673, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8996, F1: 0.9152
For later layers:  [8, 9, 10, 11]
Layer: backbone.vit.embeddings.cls_token, Size: torch.Size([1, 1, 384]), req grad: True
Layer: backbone.vit.embeddings.position_embeddings, Size: torch.Size([1, 197, 384]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.weight, Size: torch.Size([384, 3, 16, 16]), req grad: True
Layer: backbone.vit.embeddings.patch_embeddings.projection.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.0.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.0.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.0.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.1.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.1.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.1.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.2.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.2.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.2.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.3.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.3.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.3.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.4.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.4.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.4.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.5.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.5.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.5.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.6.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.6.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.6.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.7.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.7.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_before.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.7.layernorm_after.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.8.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.8.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.9.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.9.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.10.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.10.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.query.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.key.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.attention.value.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.weight, Size: torch.Size([384, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.attention.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.weight, Size: torch.Size([1536, 384]), req grad: True
Layer: backbone.vit.encoder.layer.11.intermediate.dense.bias, Size: torch.Size([1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.weight, Size: torch.Size([384, 1536]), req grad: True
Layer: backbone.vit.encoder.layer.11.output.dense.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.weight, Size: torch.Size([384]), req grad: True
Layer: backbone.vit.layernorm.bias, Size: torch.Size([384]), req grad: True
Layer: backbone.classifier.weight, Size: torch.Size([15, 384]), req grad: True
Layer: backbone.classifier.bias, Size: torch.Size([15]), req grad: True
Epoch 1/70
Train Loss: 0.9611, Accuracy: 0.7128, Precision: 0.7230, Recall: 0.7054, F1: 0.7118
Validation Loss: 0.5096, Accuracy: 0.8401, Precision: 0.8437, Recall: 0.8458, F1: 0.8396
Testing Loss: 0.4831, Accuracy: 0.8686, Precision: 0.8697, Recall: 0.8730, F1: 0.8672
LM Predictions:  [14, 13, 6, 6, 6, 6, 3, 14, 6, 13, 6, 6, 0, 6, 6, 6, 6, 3, 14, 8, 6, 13, 6, 6, 13, 6, 14, 0, 12, 6, 14, 0, 6, 6, 6, 6, 6, 14, 14, 6, 6, 12, 0, 6, 6, 6, 13, 4, 6, 6, 13, 6, 6, 0, 6, 13, 6, 6, 13, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 12, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 14, 14, 6, 6, 6, 0, 14, 14, 6, 13, 6, 6, 6, 6, 14, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 3.9126, Accuracy: 0.0865, Precision: 0.1374, Recall: 0.0899, F1: 0.0927
Epoch 2/70
Train Loss: 0.2906, Accuracy: 0.9231, Precision: 0.9266, Recall: 0.9238, F1: 0.9251
Validation Loss: 0.4522, Accuracy: 0.8686, Precision: 0.8739, Recall: 0.8724, F1: 0.8685
Testing Loss: 0.4271, Accuracy: 0.8686, Precision: 0.8704, Recall: 0.8709, F1: 0.8681
LM Predictions:  [14, 6, 2, 6, 14, 6, 3, 14, 5, 6, 6, 6, 0, 0, 13, 6, 4, 8, 9, 8, 11, 1, 6, 6, 14, 6, 3, 0, 2, 6, 5, 14, 4, 13, 6, 6, 6, 13, 5, 6, 6, 6, 6, 6, 4, 6, 13, 4, 6, 6, 14, 6, 6, 0, 13, 13, 6, 6, 4, 13, 5, 13, 1, 0, 14, 6, 14, 6, 6, 14, 4, 6, 14, 0, 6, 2, 6, 6, 6, 5, 3, 6, 13, 6, 6, 6, 6, 1, 14, 6, 6, 6, 14, 9, 14, 6, 8, 12, 6, 6, 6, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 2.3770, Accuracy: 0.3462, Precision: 0.5995, Recall: 0.3395, F1: 0.3773
Epoch 3/70
Train Loss: 0.1005, Accuracy: 0.9792, Precision: 0.9805, Recall: 0.9792, F1: 0.9798
Validation Loss: 0.4621, Accuracy: 0.8655, Precision: 0.8710, Recall: 0.8698, F1: 0.8680
Testing Loss: 0.4597, Accuracy: 0.8601, Precision: 0.8683, Recall: 0.8627, F1: 0.8617
LM Predictions:  [8, 6, 2, 0, 4, 6, 13, 8, 5, 11, 9, 0, 0, 2, 11, 6, 4, 2, 9, 8, 11, 6, 6, 11, 6, 13, 3, 14, 2, 6, 5, 9, 4, 9, 7, 6, 6, 13, 11, 10, 6, 12, 0, 9, 4, 10, 11, 1, 14, 9, 14, 6, 6, 0, 13, 13, 0, 6, 4, 1, 11, 1, 1, 0, 14, 0, 14, 6, 3, 11, 11, 6, 14, 7, 6, 2, 0, 12, 6, 11, 3, 0, 6, 2, 6, 2, 0, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 6, 6, 6, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.2680, Accuracy: 0.6442, Precision: 0.8376, Recall: 0.6203, F1: 0.6715
Epoch 4/70
Train Loss: 0.0432, Accuracy: 0.9920, Precision: 0.9927, Recall: 0.9920, F1: 0.9923
Validation Loss: 0.4744, Accuracy: 0.8701, Precision: 0.8832, Recall: 0.8713, F1: 0.8742
Testing Loss: 0.4709, Accuracy: 0.8678, Precision: 0.8787, Recall: 0.8712, F1: 0.8712
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 11, 13, 3, 1, 2, 9, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 11, 1, 0, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 6, 12, 10, 11, 3, 1, 13, 2, 11, 8, 6, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 0, 5, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.4433, Accuracy: 0.8654, Precision: 0.8728, Recall: 0.7946, F1: 0.8191
Epoch 5/70
Train Loss: 0.0323, Accuracy: 0.9943, Precision: 0.9947, Recall: 0.9946, F1: 0.9947
Validation Loss: 0.4825, Accuracy: 0.8640, Precision: 0.8693, Recall: 0.8649, F1: 0.8646
Testing Loss: 0.4685, Accuracy: 0.8716, Precision: 0.8746, Recall: 0.8739, F1: 0.8712
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 0, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1764, Accuracy: 0.9423, Precision: 0.9250, Recall: 0.8750, F1: 0.8955
Epoch 6/70
Train Loss: 0.0565, Accuracy: 0.9849, Precision: 0.9859, Recall: 0.9859, F1: 0.9859
Validation Loss: 0.6314, Accuracy: 0.8278, Precision: 0.8312, Recall: 0.8312, F1: 0.8262
Testing Loss: 0.5812, Accuracy: 0.8370, Precision: 0.8394, Recall: 0.8392, F1: 0.8359
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 6, 6, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 6, 1, 13, 11, 3, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 6, 6, 13, 0, 6, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 9, 11, 12, 13, 6, 7, 6, 2, 0, 12, 6, 11, 3, 1, 12, 2, 11, 8, 10, 3, 5, 0, 1, 6, 9, 9, 14, 6, 8, 12, 6, 9, 6, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.8390, Accuracy: 0.7596, Precision: 0.8811, Recall: 0.7298, F1: 0.7786
Epoch 7/70
Train Loss: 0.0597, Accuracy: 0.9825, Precision: 0.9828, Recall: 0.9825, F1: 0.9826
Validation Loss: 0.5802, Accuracy: 0.8540, Precision: 0.8648, Recall: 0.8504, F1: 0.8524
Testing Loss: 0.5593, Accuracy: 0.8493, Precision: 0.8535, Recall: 0.8499, F1: 0.8495
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 6, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3003, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8440, F1: 0.8828
Epoch 8/70
Train Loss: 0.0276, Accuracy: 0.9922, Precision: 0.9928, Recall: 0.9926, F1: 0.9927
Validation Loss: 0.5369, Accuracy: 0.8578, Precision: 0.8640, Recall: 0.8581, F1: 0.8586
Testing Loss: 0.5097, Accuracy: 0.8663, Precision: 0.8697, Recall: 0.8681, F1: 0.8669
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 0, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1834, Accuracy: 0.9423, Precision: 0.9238, Recall: 0.8763, F1: 0.8982
Epoch 9/70
Train Loss: 0.0493, Accuracy: 0.9847, Precision: 0.9850, Recall: 0.9846, F1: 0.9848
Validation Loss: 0.5399, Accuracy: 0.8732, Precision: 0.8703, Recall: 0.8807, F1: 0.8727
Testing Loss: 0.5587, Accuracy: 0.8586, Precision: 0.8555, Recall: 0.8619, F1: 0.8567
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1992, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8839, F1: 0.9062
Epoch 10/70
Train Loss: 0.0264, Accuracy: 0.9924, Precision: 0.9922, Recall: 0.9921, F1: 0.9921
Validation Loss: 0.5673, Accuracy: 0.8655, Precision: 0.8701, Recall: 0.8662, F1: 0.8660
Testing Loss: 0.5206, Accuracy: 0.8616, Precision: 0.8610, Recall: 0.8606, F1: 0.8591
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1578, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8708, F1: 0.8991
Epoch 11/70
Train Loss: 0.0135, Accuracy: 0.9957, Precision: 0.9959, Recall: 0.9958, F1: 0.9959
Validation Loss: 0.5645, Accuracy: 0.8616, Precision: 0.8717, Recall: 0.8647, F1: 0.8637
Testing Loss: 0.5748, Accuracy: 0.8601, Precision: 0.8725, Recall: 0.8657, F1: 0.8651
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0676, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9083, F1: 0.9194
Epoch 12/70
Train Loss: 0.0096, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.5334, Accuracy: 0.8755, Precision: 0.8821, Recall: 0.8775, F1: 0.8767
Testing Loss: 0.4904, Accuracy: 0.8778, Precision: 0.8795, Recall: 0.8808, F1: 0.8789
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 0, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2023, Accuracy: 0.9231, Precision: 0.9238, Recall: 0.8668, F1: 0.8931
Epoch 13/70
Train Loss: 0.0087, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.6217, Accuracy: 0.8601, Precision: 0.8666, Recall: 0.8663, F1: 0.8598
Testing Loss: 0.5656, Accuracy: 0.8670, Precision: 0.8673, Recall: 0.8721, F1: 0.8659
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1097, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8877, F1: 0.9082
Epoch 14/70
Train Loss: 0.0088, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9970, F1: 0.9970
Validation Loss: 0.6048, Accuracy: 0.8701, Precision: 0.8845, Recall: 0.8697, F1: 0.8728
Testing Loss: 0.5599, Accuracy: 0.8647, Precision: 0.8716, Recall: 0.8631, F1: 0.8645
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2274, Accuracy: 0.9231, Precision: 0.9333, Recall: 0.8583, F1: 0.8916
Epoch 15/70
Train Loss: 0.1080, Accuracy: 0.9645, Precision: 0.9653, Recall: 0.9646, F1: 0.9650
Validation Loss: 0.7097, Accuracy: 0.8263, Precision: 0.8372, Recall: 0.8357, F1: 0.8268
Testing Loss: 0.6435, Accuracy: 0.8394, Precision: 0.8450, Recall: 0.8491, F1: 0.8409
LM Predictions:  [8, 4, 2, 10, 4, 6, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 5, 3, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 0, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 0, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2662, Accuracy: 0.9231, Precision: 0.8978, Recall: 0.8672, F1: 0.8770
Epoch 16/70
Train Loss: 0.0473, Accuracy: 0.9841, Precision: 0.9842, Recall: 0.9841, F1: 0.9842
Validation Loss: 0.6917, Accuracy: 0.8501, Precision: 0.8530, Recall: 0.8578, F1: 0.8478
Testing Loss: 0.6685, Accuracy: 0.8470, Precision: 0.8447, Recall: 0.8526, F1: 0.8438
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0877, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8954, F1: 0.9116
Epoch 17/70
Train Loss: 0.0130, Accuracy: 0.9954, Precision: 0.9957, Recall: 0.9956, F1: 0.9957
Validation Loss: 0.5582, Accuracy: 0.8586, Precision: 0.8690, Recall: 0.8571, F1: 0.8619
Testing Loss: 0.5649, Accuracy: 0.8624, Precision: 0.8744, Recall: 0.8648, F1: 0.8673
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 6, 5, 9, 4, 9, 7, 10, 6, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 6, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3381, Accuracy: 0.9038, Precision: 0.9333, Recall: 0.8470, F1: 0.8860
Epoch 18/70
Train Loss: 0.0092, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9972, F1: 0.9971
Validation Loss: 0.5578, Accuracy: 0.8693, Precision: 0.8690, Recall: 0.8723, F1: 0.8698
Testing Loss: 0.5595, Accuracy: 0.8670, Precision: 0.8690, Recall: 0.8724, F1: 0.8693
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2147, Accuracy: 0.8942, Precision: 0.9333, Recall: 0.8343, F1: 0.8782
Epoch 19/70
Train Loss: 0.0084, Accuracy: 0.9969, Precision: 0.9972, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.6358, Accuracy: 0.8586, Precision: 0.8642, Recall: 0.8610, F1: 0.8603
Testing Loss: 0.5833, Accuracy: 0.8663, Precision: 0.8721, Recall: 0.8691, F1: 0.8681
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1272, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8839, F1: 0.9062
Epoch 20/70
Train Loss: 0.0073, Accuracy: 0.9970, Precision: 0.9972, Recall: 0.9971, F1: 0.9972
Validation Loss: 0.6410, Accuracy: 0.8678, Precision: 0.8712, Recall: 0.8747, F1: 0.8696
Testing Loss: 0.6109, Accuracy: 0.8678, Precision: 0.8652, Recall: 0.8748, F1: 0.8670
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0854, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9107, F1: 0.9213
Epoch 21/70
Train Loss: 0.0654, Accuracy: 0.9797, Precision: 0.9802, Recall: 0.9797, F1: 0.9799
Validation Loss: 0.8111, Accuracy: 0.8048, Precision: 0.8065, Recall: 0.8072, F1: 0.7991
Testing Loss: 0.8094, Accuracy: 0.8163, Precision: 0.8193, Recall: 0.8251, F1: 0.8164
LM Predictions:  [8, 4, 2, 10, 4, 10, 3, 8, 5, 11, 9, 6, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 6, 7, 6, 6, 3, 6, 2, 9, 5, 9, 4, 9, 7, 10, 1, 13, 5, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 6, 0, 13, 13, 1, 6, 5, 1, 11, 1, 1, 0, 12, 9, 14, 10, 3, 0, 12, 1, 14, 14, 6, 2, 3, 12, 5, 6, 3, 1, 12, 2, 6, 0, 10, 1, 5, 0, 1, 14, 14, 9, 14, 6, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.5401, Accuracy: 0.7788, Precision: 0.8474, Recall: 0.7289, F1: 0.7716
Epoch 22/70
Train Loss: 0.0594, Accuracy: 0.9825, Precision: 0.9826, Recall: 0.9821, F1: 0.9823
Validation Loss: 0.6576, Accuracy: 0.8509, Precision: 0.8598, Recall: 0.8555, F1: 0.8511
Testing Loss: 0.6415, Accuracy: 0.8493, Precision: 0.8540, Recall: 0.8535, F1: 0.8514
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 0, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 0, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1304, Accuracy: 0.9231, Precision: 0.9167, Recall: 0.8648, F1: 0.8884
Epoch 23/70
Train Loss: 0.0228, Accuracy: 0.9929, Precision: 0.9925, Recall: 0.9927, F1: 0.9926
Validation Loss: 0.7339, Accuracy: 0.8363, Precision: 0.8528, Recall: 0.8296, F1: 0.8343
Testing Loss: 0.6774, Accuracy: 0.8455, Precision: 0.8604, Recall: 0.8448, F1: 0.8451
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1726, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8712, F1: 0.8980
Epoch 24/70
Train Loss: 0.0196, Accuracy: 0.9930, Precision: 0.9932, Recall: 0.9930, F1: 0.9931
Validation Loss: 0.7885, Accuracy: 0.8209, Precision: 0.8294, Recall: 0.8249, F1: 0.8178
Testing Loss: 0.7041, Accuracy: 0.8394, Precision: 0.8430, Recall: 0.8486, F1: 0.8404
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 12, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1483, Accuracy: 0.9615, Precision: 0.9238, Recall: 0.8970, F1: 0.9087
Epoch 25/70
Train Loss: 0.0286, Accuracy: 0.9896, Precision: 0.9900, Recall: 0.9900, F1: 0.9900
Validation Loss: 0.6991, Accuracy: 0.8324, Precision: 0.8370, Recall: 0.8347, F1: 0.8310
Testing Loss: 0.6370, Accuracy: 0.8501, Precision: 0.8497, Recall: 0.8541, F1: 0.8498
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 4, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 0, 12, 13, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1550, Accuracy: 0.9038, Precision: 0.9071, Recall: 0.8337, F1: 0.8647
Epoch 26/70
Train Loss: 0.0120, Accuracy: 0.9954, Precision: 0.9954, Recall: 0.9954, F1: 0.9954
Validation Loss: 0.7404, Accuracy: 0.8347, Precision: 0.8619, Recall: 0.8238, F1: 0.8359
Testing Loss: 0.6483, Accuracy: 0.8563, Precision: 0.8772, Recall: 0.8504, F1: 0.8570
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 6, 11, 9, 6, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 6, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 6, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2133, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8422, F1: 0.8796
Epoch 27/70
Train Loss: 0.0202, Accuracy: 0.9923, Precision: 0.9925, Recall: 0.9925, F1: 0.9925
Validation Loss: 0.8161, Accuracy: 0.8294, Precision: 0.8456, Recall: 0.8310, F1: 0.8329
Testing Loss: 0.7153, Accuracy: 0.8447, Precision: 0.8515, Recall: 0.8456, F1: 0.8446
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 3, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 3, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 4, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1248, Accuracy: 0.9327, Precision: 0.9102, Recall: 0.8683, F1: 0.8859
Epoch 28/70
Train Loss: 0.0374, Accuracy: 0.9858, Precision: 0.9863, Recall: 0.9864, F1: 0.9863
Validation Loss: 0.7285, Accuracy: 0.8478, Precision: 0.8580, Recall: 0.8511, F1: 0.8493
Testing Loss: 0.6972, Accuracy: 0.8463, Precision: 0.8546, Recall: 0.8493, F1: 0.8488
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 0, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1105, Accuracy: 0.9519, Precision: 0.9250, Recall: 0.8873, F1: 0.9020
Epoch 29/70
Train Loss: 0.0291, Accuracy: 0.9896, Precision: 0.9895, Recall: 0.9896, F1: 0.9896
Validation Loss: 0.7005, Accuracy: 0.8478, Precision: 0.8520, Recall: 0.8544, F1: 0.8495
Testing Loss: 0.7271, Accuracy: 0.8409, Precision: 0.8415, Recall: 0.8486, F1: 0.8425
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1125, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8922, F1: 0.9113
Epoch 30/70
Train Loss: 0.0221, Accuracy: 0.9924, Precision: 0.9925, Recall: 0.9926, F1: 0.9926
Validation Loss: 0.6761, Accuracy: 0.8501, Precision: 0.8538, Recall: 0.8514, F1: 0.8498
Testing Loss: 0.6834, Accuracy: 0.8586, Precision: 0.8660, Recall: 0.8622, F1: 0.8618
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 13, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1042, Accuracy: 0.9615, Precision: 0.9250, Recall: 0.8960, F1: 0.9088
Epoch 31/70
Train Loss: 0.0195, Accuracy: 0.9918, Precision: 0.9919, Recall: 0.9919, F1: 0.9919
Validation Loss: 0.9723, Accuracy: 0.7986, Precision: 0.8217, Recall: 0.8007, F1: 0.8002
Testing Loss: 0.8471, Accuracy: 0.8186, Precision: 0.8372, Recall: 0.8226, F1: 0.8227
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 0, 1, 2, 5, 5, 9, 4, 9, 14, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 10, 6, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2285, Accuracy: 0.9038, Precision: 0.9081, Recall: 0.8413, F1: 0.8687
Epoch 32/70
Train Loss: 0.0268, Accuracy: 0.9904, Precision: 0.9904, Recall: 0.9905, F1: 0.9905
Validation Loss: 0.7384, Accuracy: 0.8386, Precision: 0.8438, Recall: 0.8431, F1: 0.8404
Testing Loss: 0.6392, Accuracy: 0.8670, Precision: 0.8690, Recall: 0.8704, F1: 0.8685
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0804, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8877, F1: 0.9082
Epoch 33/70
Train Loss: 0.0190, Accuracy: 0.9927, Precision: 0.9925, Recall: 0.9926, F1: 0.9926
Validation Loss: 0.8749, Accuracy: 0.8286, Precision: 0.8537, Recall: 0.8204, F1: 0.8267
Testing Loss: 0.7311, Accuracy: 0.8401, Precision: 0.8631, Recall: 0.8349, F1: 0.8410
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0967, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8831, F1: 0.9049
Epoch 34/70
Train Loss: 0.0243, Accuracy: 0.9918, Precision: 0.9917, Recall: 0.9917, F1: 0.9917
Validation Loss: 0.8168, Accuracy: 0.8355, Precision: 0.8446, Recall: 0.8396, F1: 0.8328
Testing Loss: 0.7611, Accuracy: 0.8493, Precision: 0.8505, Recall: 0.8543, F1: 0.8484
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1096, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8755, F1: 0.9018
Epoch 35/70
Train Loss: 0.0149, Accuracy: 0.9941, Precision: 0.9942, Recall: 0.9939, F1: 0.9940
Validation Loss: 0.7786, Accuracy: 0.8409, Precision: 0.8527, Recall: 0.8412, F1: 0.8426
Testing Loss: 0.7832, Accuracy: 0.8386, Precision: 0.8513, Recall: 0.8399, F1: 0.8399
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 3, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 2, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1052, Accuracy: 0.9519, Precision: 0.9164, Recall: 0.8962, F1: 0.9039
Epoch 36/70
Train Loss: 0.0305, Accuracy: 0.9890, Precision: 0.9891, Recall: 0.9888, F1: 0.9890
Validation Loss: 0.7402, Accuracy: 0.8440, Precision: 0.8532, Recall: 0.8488, F1: 0.8459
Testing Loss: 0.7671, Accuracy: 0.8432, Precision: 0.8445, Recall: 0.8520, F1: 0.8450
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0772, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8938, F1: 0.9122
Epoch 37/70
Train Loss: 0.0159, Accuracy: 0.9939, Precision: 0.9938, Recall: 0.9938, F1: 0.9938
Validation Loss: 0.7960, Accuracy: 0.8355, Precision: 0.8461, Recall: 0.8363, F1: 0.8326
Testing Loss: 0.8188, Accuracy: 0.8317, Precision: 0.8324, Recall: 0.8341, F1: 0.8268
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 6, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0679, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8960, F1: 0.9126
Epoch 38/70
Train Loss: 0.0304, Accuracy: 0.9882, Precision: 0.9880, Recall: 0.9881, F1: 0.9880
Validation Loss: 0.8308, Accuracy: 0.8294, Precision: 0.8470, Recall: 0.8259, F1: 0.8301
Testing Loss: 0.7737, Accuracy: 0.8378, Precision: 0.8532, Recall: 0.8373, F1: 0.8405
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 12, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 13, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 13, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2026, Accuracy: 0.9231, Precision: 0.9090, Recall: 0.8648, F1: 0.8817
Epoch 39/70
Train Loss: 0.0286, Accuracy: 0.9903, Precision: 0.9904, Recall: 0.9901, F1: 0.9902
Validation Loss: 0.7183, Accuracy: 0.8470, Precision: 0.8431, Recall: 0.8525, F1: 0.8459
Testing Loss: 0.7636, Accuracy: 0.8378, Precision: 0.8365, Recall: 0.8453, F1: 0.8380
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0583, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9176, F1: 0.9250
Epoch 40/70
Train Loss: 0.0069, Accuracy: 0.9965, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.6783, Accuracy: 0.8647, Precision: 0.8665, Recall: 0.8661, F1: 0.8641
Testing Loss: 0.6810, Accuracy: 0.8678, Precision: 0.8669, Recall: 0.8729, F1: 0.8685
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0622, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9111, F1: 0.9200
Epoch 41/70
Train Loss: 0.0056, Accuracy: 0.9964, Precision: 0.9966, Recall: 0.9966, F1: 0.9966
Validation Loss: 0.6493, Accuracy: 0.8655, Precision: 0.8646, Recall: 0.8670, F1: 0.8639
Testing Loss: 0.6553, Accuracy: 0.8670, Precision: 0.8662, Recall: 0.8711, F1: 0.8677
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0528, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9164, F1: 0.9243
Epoch 42/70
Train Loss: 0.0058, Accuracy: 0.9969, Precision: 0.9970, Recall: 0.9971, F1: 0.9971
Validation Loss: 0.6518, Accuracy: 0.8632, Precision: 0.8650, Recall: 0.8653, F1: 0.8627
Testing Loss: 0.6576, Accuracy: 0.8709, Precision: 0.8702, Recall: 0.8745, F1: 0.8711
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0790, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8952, F1: 0.9115
Epoch 43/70
Train Loss: 0.0058, Accuracy: 0.9965, Precision: 0.9967, Recall: 0.9967, F1: 0.9967
Validation Loss: 0.6563, Accuracy: 0.8578, Precision: 0.8624, Recall: 0.8588, F1: 0.8567
Testing Loss: 0.6536, Accuracy: 0.8555, Precision: 0.8597, Recall: 0.8591, F1: 0.8574
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1450, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8679, F1: 0.8968
Epoch 44/70
Train Loss: 0.0055, Accuracy: 0.9973, Precision: 0.9974, Recall: 0.9974, F1: 0.9974
Validation Loss: 0.6603, Accuracy: 0.8640, Precision: 0.8683, Recall: 0.8660, F1: 0.8644
Testing Loss: 0.6548, Accuracy: 0.8678, Precision: 0.8667, Recall: 0.8714, F1: 0.8678
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0714, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8960, F1: 0.9126
Epoch 45/70
Train Loss: 0.0063, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9968, F1: 0.9969
Validation Loss: 0.6385, Accuracy: 0.8670, Precision: 0.8686, Recall: 0.8711, F1: 0.8681
Testing Loss: 0.6628, Accuracy: 0.8663, Precision: 0.8630, Recall: 0.8715, F1: 0.8659
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0548, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000
Epoch 46/70
Train Loss: 0.0060, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9973, F1: 0.9972
Validation Loss: 0.6548, Accuracy: 0.8670, Precision: 0.8718, Recall: 0.8698, F1: 0.8682
Testing Loss: 0.6345, Accuracy: 0.8701, Precision: 0.8681, Recall: 0.8729, F1: 0.8696
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1749, Accuracy: 0.9135, Precision: 0.9333, Recall: 0.8533, F1: 0.8885
Epoch 47/70
Train Loss: 0.0672, Accuracy: 0.9786, Precision: 0.9787, Recall: 0.9781, F1: 0.9784
Validation Loss: 0.7793, Accuracy: 0.8271, Precision: 0.8275, Recall: 0.8329, F1: 0.8253
Testing Loss: 0.7162, Accuracy: 0.8278, Precision: 0.8245, Recall: 0.8334, F1: 0.8256
LM Predictions:  [8, 4, 2, 0, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 6, 14, 13, 3, 1, 2, 5, 5, 9, 4, 6, 7, 10, 1, 13, 4, 10, 13, 6, 6, 9, 4, 0, 7, 4, 7, 6, 14, 6, 6, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 1, 10, 3, 13, 12, 1, 14, 7, 7, 2, 0, 12, 10, 11, 3, 1, 12, 2, 11, 8, 6, 1, 5, 11, 1, 14, 14, 14, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.4634, Accuracy: 0.8173, Precision: 0.8598, Recall: 0.7774, F1: 0.8097
Epoch 48/70
Train Loss: 0.0475, Accuracy: 0.9843, Precision: 0.9846, Recall: 0.9841, F1: 0.9843
Validation Loss: 0.7450, Accuracy: 0.8363, Precision: 0.8439, Recall: 0.8392, F1: 0.8366
Testing Loss: 0.7223, Accuracy: 0.8424, Precision: 0.8435, Recall: 0.8441, F1: 0.8405
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 13, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 13, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1465, Accuracy: 0.9231, Precision: 0.9185, Recall: 0.8675, F1: 0.8880
Epoch 49/70
Train Loss: 0.0161, Accuracy: 0.9930, Precision: 0.9932, Recall: 0.9931, F1: 0.9931
Validation Loss: 0.8011, Accuracy: 0.8263, Precision: 0.8385, Recall: 0.8274, F1: 0.8290
Testing Loss: 0.7473, Accuracy: 0.8301, Precision: 0.8420, Recall: 0.8299, F1: 0.8330
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0957, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8929, F1: 0.9111
Epoch 50/70
Train Loss: 0.0169, Accuracy: 0.9938, Precision: 0.9937, Recall: 0.9936, F1: 0.9936
Validation Loss: 0.7439, Accuracy: 0.8401, Precision: 0.8566, Recall: 0.8398, F1: 0.8432
Testing Loss: 0.7414, Accuracy: 0.8370, Precision: 0.8542, Recall: 0.8360, F1: 0.8381
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 6, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0775, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9093, F1: 0.9205
Epoch 51/70
Train Loss: 0.0194, Accuracy: 0.9930, Precision: 0.9929, Recall: 0.9929, F1: 0.9929
Validation Loss: 0.7556, Accuracy: 0.8493, Precision: 0.8491, Recall: 0.8516, F1: 0.8493
Testing Loss: 0.6674, Accuracy: 0.8578, Precision: 0.8591, Recall: 0.8628, F1: 0.8601
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0577, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9190, F1: 0.9257
Epoch 52/70
Train Loss: 0.0172, Accuracy: 0.9939, Precision: 0.9939, Recall: 0.9942, F1: 0.9940
Validation Loss: 0.8585, Accuracy: 0.8132, Precision: 0.8247, Recall: 0.8123, F1: 0.8136
Testing Loss: 0.8154, Accuracy: 0.8248, Precision: 0.8348, Recall: 0.8257, F1: 0.8278
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 6, 10, 6, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 6, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 6, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.2694, Accuracy: 0.9038, Precision: 0.9333, Recall: 0.8442, F1: 0.8834
Epoch 53/70
Train Loss: 0.0159, Accuracy: 0.9936, Precision: 0.9937, Recall: 0.9935, F1: 0.9936
Validation Loss: 1.0057, Accuracy: 0.8071, Precision: 0.8367, Recall: 0.7984, F1: 0.8056
Testing Loss: 0.8505, Accuracy: 0.8263, Precision: 0.8528, Recall: 0.8162, F1: 0.8224
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 4, 0, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 6, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1827, Accuracy: 0.9038, Precision: 0.9155, Recall: 0.8462, F1: 0.8725
Epoch 54/70
Train Loss: 0.0353, Accuracy: 0.9875, Precision: 0.9878, Recall: 0.9876, F1: 0.9877
Validation Loss: 0.8208, Accuracy: 0.8294, Precision: 0.8307, Recall: 0.8364, F1: 0.8292
Testing Loss: 0.8009, Accuracy: 0.8493, Precision: 0.8538, Recall: 0.8565, F1: 0.8510
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 4, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1424, Accuracy: 0.9231, Precision: 0.9250, Recall: 0.8688, F1: 0.8932
Epoch 55/70
Train Loss: 0.0146, Accuracy: 0.9936, Precision: 0.9936, Recall: 0.9937, F1: 0.9937
Validation Loss: 0.6825, Accuracy: 0.8601, Precision: 0.8632, Recall: 0.8593, F1: 0.8598
Testing Loss: 0.6796, Accuracy: 0.8663, Precision: 0.8702, Recall: 0.8699, F1: 0.8689
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 6, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0948, Accuracy: 0.9327, Precision: 0.9333, Recall: 0.8742, F1: 0.9002
Epoch 56/70
Train Loss: 0.0084, Accuracy: 0.9958, Precision: 0.9961, Recall: 0.9959, F1: 0.9960
Validation Loss: 0.7823, Accuracy: 0.8370, Precision: 0.8420, Recall: 0.8386, F1: 0.8369
Testing Loss: 0.7991, Accuracy: 0.8432, Precision: 0.8462, Recall: 0.8475, F1: 0.8437
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1107, Accuracy: 0.9423, Precision: 0.9333, Recall: 0.8762, F1: 0.9012
Epoch 57/70
Train Loss: 0.0280, Accuracy: 0.9895, Precision: 0.9897, Recall: 0.9898, F1: 0.9898
Validation Loss: 0.7751, Accuracy: 0.8401, Precision: 0.8421, Recall: 0.8445, F1: 0.8392
Testing Loss: 0.7720, Accuracy: 0.8417, Precision: 0.8424, Recall: 0.8502, F1: 0.8425
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0749, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.9008, F1: 0.9153
Epoch 58/70
Train Loss: 0.0200, Accuracy: 0.9924, Precision: 0.9929, Recall: 0.9926, F1: 0.9927
Validation Loss: 0.9240, Accuracy: 0.8040, Precision: 0.8299, Recall: 0.8078, F1: 0.8050
Testing Loss: 0.9609, Accuracy: 0.8048, Precision: 0.8173, Recall: 0.8107, F1: 0.8046
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 5, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 13, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 13, 7, 7, 2, 3, 6, 10, 11, 3, 1, 12, 2, 11, 5, 10, 1, 5, 0, 1, 6, 14, 9, 6, 3, 8, 12, 12, 5, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.3035, Accuracy: 0.8942, Precision: 0.8899, Recall: 0.8330, F1: 0.8390
Epoch 59/70
Train Loss: 0.0207, Accuracy: 0.9916, Precision: 0.9919, Recall: 0.9916, F1: 0.9918
Validation Loss: 0.7348, Accuracy: 0.8424, Precision: 0.8467, Recall: 0.8453, F1: 0.8436
Testing Loss: 0.7152, Accuracy: 0.8501, Precision: 0.8520, Recall: 0.8554, F1: 0.8528
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1589, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.9021, F1: 0.9167
Epoch 60/70
Train Loss: 0.0071, Accuracy: 0.9972, Precision: 0.9972, Recall: 0.9975, F1: 0.9974
Validation Loss: 0.7336, Accuracy: 0.8493, Precision: 0.8585, Recall: 0.8521, F1: 0.8518
Testing Loss: 0.7148, Accuracy: 0.8563, Precision: 0.8627, Recall: 0.8598, F1: 0.8591
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 0, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1080, Accuracy: 0.9231, Precision: 0.9250, Recall: 0.8607, F1: 0.8879
Epoch 61/70
Train Loss: 0.0060, Accuracy: 0.9969, Precision: 0.9971, Recall: 0.9969, F1: 0.9970
Validation Loss: 0.6849, Accuracy: 0.8547, Precision: 0.8559, Recall: 0.8582, F1: 0.8554
Testing Loss: 0.7045, Accuracy: 0.8593, Precision: 0.8592, Recall: 0.8667, F1: 0.8610
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0797, Accuracy: 0.9519, Precision: 0.9333, Recall: 0.8950, F1: 0.9123
Epoch 62/70
Train Loss: 0.0051, Accuracy: 0.9966, Precision: 0.9968, Recall: 0.9968, F1: 0.9968
Validation Loss: 0.6890, Accuracy: 0.8586, Precision: 0.8616, Recall: 0.8624, F1: 0.8598
Testing Loss: 0.6840, Accuracy: 0.8609, Precision: 0.8602, Recall: 0.8680, F1: 0.8623
LM Predictions:  [8, 6, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1129, Accuracy: 0.9231, Precision: 0.9333, Recall: 0.8648, F1: 0.8960
Epoch 63/70
Train Loss: 0.0050, Accuracy: 0.9967, Precision: 0.9970, Recall: 0.9969, F1: 0.9969
Validation Loss: 0.6883, Accuracy: 0.8563, Precision: 0.8532, Recall: 0.8612, F1: 0.8549
Testing Loss: 0.7193, Accuracy: 0.8586, Precision: 0.8588, Recall: 0.8670, F1: 0.8607
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 6, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0530, Accuracy: 0.9808, Precision: 0.9333, Recall: 0.9164, F1: 0.9243
Epoch 64/70
Train Loss: 0.0062, Accuracy: 0.9971, Precision: 0.9972, Recall: 0.9973, F1: 0.9972
Validation Loss: 0.7048, Accuracy: 0.8563, Precision: 0.8590, Recall: 0.8580, F1: 0.8556
Testing Loss: 0.7048, Accuracy: 0.8632, Precision: 0.8645, Recall: 0.8705, F1: 0.8657
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 6, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 6, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 6, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1705, Accuracy: 0.9038, Precision: 0.9333, Recall: 0.8438, F1: 0.8833
Epoch 65/70
Train Loss: 0.0057, Accuracy: 0.9963, Precision: 0.9966, Recall: 0.9965, F1: 0.9966
Validation Loss: 0.7212, Accuracy: 0.8501, Precision: 0.8556, Recall: 0.8536, F1: 0.8508
Testing Loss: 0.6994, Accuracy: 0.8640, Precision: 0.8648, Recall: 0.8719, F1: 0.8655
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0722, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8921, F1: 0.9097
Epoch 66/70
Train Loss: 0.0253, Accuracy: 0.9925, Precision: 0.9927, Recall: 0.9927, F1: 0.9927
Validation Loss: 1.3783, Accuracy: 0.7302, Precision: 0.7695, Recall: 0.7085, F1: 0.7017
Testing Loss: 1.2756, Accuracy: 0.7325, Precision: 0.7682, Recall: 0.7154, F1: 0.7100
LM Predictions:  [2, 4, 2, 10, 4, 10, 0, 9, 13, 11, 9, 0, 0, 2, 6, 3, 4, 4, 9, 8, 11, 6, 6, 7, 14, 0, 13, 1, 2, 3, 13, 9, 4, 9, 7, 12, 0, 13, 4, 10, 0, 12, 0, 9, 4, 0, 7, 1, 13, 9, 14, 6, 13, 0, 13, 13, 1, 2, 4, 1, 0, 1, 1, 0, 12, 3, 13, 6, 6, 0, 12, 6, 14, 13, 6, 12, 3, 12, 10, 6, 3, 13, 12, 6, 0, 6, 6, 4, 9, 0, 1, 6, 14, 9, 14, 2, 0, 12, 12, 9, 1, 3, 6, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 1.4257, Accuracy: 0.6058, Precision: 0.6919, Recall: 0.5468, F1: 0.5537
Epoch 67/70
Train Loss: 0.0772, Accuracy: 0.9740, Precision: 0.9746, Recall: 0.9742, F1: 0.9744
Validation Loss: 0.8009, Accuracy: 0.8324, Precision: 0.8458, Recall: 0.8332, F1: 0.8359
Testing Loss: 0.6952, Accuracy: 0.8470, Precision: 0.8543, Recall: 0.8500, F1: 0.8488
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 6, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0733, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8968, F1: 0.9124
Epoch 68/70
Train Loss: 0.0074, Accuracy: 0.9962, Precision: 0.9963, Recall: 0.9962, F1: 0.9962
Validation Loss: 0.7174, Accuracy: 0.8493, Precision: 0.8579, Recall: 0.8509, F1: 0.8521
Testing Loss: 0.6641, Accuracy: 0.8578, Precision: 0.8635, Recall: 0.8619, F1: 0.8603
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 6, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1028, Accuracy: 0.9615, Precision: 0.9333, Recall: 0.8952, F1: 0.9115
Epoch 69/70
Train Loss: 0.0092, Accuracy: 0.9957, Precision: 0.9959, Recall: 0.9959, F1: 0.9959
Validation Loss: 0.8144, Accuracy: 0.8271, Precision: 0.8360, Recall: 0.8339, F1: 0.8310
Testing Loss: 0.7850, Accuracy: 0.8186, Precision: 0.8272, Recall: 0.8205, F1: 0.8201
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 6, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 6, 0, 9, 4, 10, 7, 1, 7, 6, 14, 3, 13, 0, 13, 13, 3, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 7, 12, 1, 14, 7, 6, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 3, 5, 0, 1, 14, 14, 9, 14, 3, 8, 6, 6, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.1830, Accuracy: 0.9038, Precision: 0.9105, Recall: 0.8493, F1: 0.8718
Epoch 70/70
Train Loss: 0.0289, Accuracy: 0.9901, Precision: 0.9902, Recall: 0.9901, F1: 0.9902
Validation Loss: 0.7517, Accuracy: 0.8378, Precision: 0.8454, Recall: 0.8454, F1: 0.8424
Testing Loss: 0.7115, Accuracy: 0.8478, Precision: 0.8500, Recall: 0.8527, F1: 0.8498
LM Predictions:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 6, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 6, 13, 0, 13, 13, 1, 6, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Labels:  [8, 4, 2, 10, 4, 10, 7, 8, 5, 11, 9, 0, 0, 2, 11, 3, 4, 4, 9, 8, 11, 1, 1, 7, 14, 13, 3, 1, 2, 5, 5, 9, 4, 9, 7, 10, 1, 13, 11, 10, 13, 12, 0, 9, 4, 10, 7, 1, 7, 9, 14, 3, 13, 0, 13, 13, 1, 2, 4, 1, 11, 1, 1, 0, 14, 9, 14, 10, 3, 11, 12, 1, 14, 7, 7, 2, 3, 12, 10, 11, 3, 1, 12, 2, 11, 8, 10, 1, 5, 0, 1, 14, 14, 9, 14, 3, 8, 12, 12, 9, 1, 3, 13, 0]
LM Loss: 0.0654, Accuracy: 0.9712, Precision: 0.9333, Recall: 0.9091, F1: 0.9204
